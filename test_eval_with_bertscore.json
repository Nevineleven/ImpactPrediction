{
  "average_precision": -0.014915414930631718,
  "average_recall": -0.01394519924845857,
  "average_f1": -0.012975612073205411,
  "results": [
    {
      "paper_id": "aAcOaJYbUg",
      "prompt": "Background: Vision models like vision transformers and ConvNeXt, trained on massive datasets such as LAION, have shown remarkable performance on standard benchmarks. ImageNet-C has been used to test out-of-distribution (OOD) robustness by applying common corruptions to ImageNet data. However, with web-scale data like LAION, which inherently contains many of these corruptions, ImageNet-C is no longer truly OOD for these models.\nGap: Current OOD benchmarks like ImageNet-C are inadequate for evaluating the robustness of contemporary models trained on large web-scale datasets because they already contain similar corruptions, reducing the OOD nature of these benchmarks.\nHypothesis: The authors propose that by creating a new benchmark, LAION-C, which includes distortions genuinely OOD for web-scale datasets, it's possible to better challenge and evaluate the robustness and generalization capabilities of modern vision models.\nMethod: The LAION-C dataset includes six synthetic distortion types applied to images from the ImageNet validation set, each with five intensity levels. The distortions are designed to disrupt visual consistency and perceptual cues, like Mosaic, Glitched, and more. The authors evaluated 58 vision models using LAION-C and conducted psychophysical experiments with human participants to compare their performance.\nConclusion: LAION-C presents a more robust evaluation challenge than ImageNet-C, as shown by the significant drop in model performance on LAION-C compared to ImageNet-C. The findings suggest that modern models, despite their superior performance, are using diverse strategies distinct from human-like strategies. LAION-C shifts the paradigm in OOD evaluation by requiring models to genuinely generalize beyond familiar data.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 3\nContribution: 4\nRating: 6\nConfidence: 3\n\nExplanation:\nStrengths:\n1. Clear structure and presentation: The paper is well-organized, with a logical structure and smooth flow that improves readability and comprehension.\n2. Insightful motivation for OOD benchmarking: This dataset addresses the critical issue of data leakage in current benchmarks. This approach highlights the limitations of evaluating current models trained on web-scale data.\n3. Interesting distortion design: The authors designed six distinct distortion types that minimize overlap with common real-world corruptions, reducing the likelihood of data leakage. This approach improves the dataset\u2019s utility as a truly challenging OOD benchmark.\n\nWeaknesses:\n1. Limited novel insights in model ranking comparisons: Figure 4 shows minimal divergence in the ranking of model performance between ImageNet-C and LAION-C. Similarly, Figure 3 demonstrates a strong linear correlation between model performance on ImageNet-C and LAION-C. Since a benchmark dataset's purpose is to reveal different performance characteristics across models, more analysis is needed to clarify the unique insights LAION-C provides beyond what ImageNet-C already offers.\n\nQuestions:\n1. Performance differences between CNNs and transformers: Given that LAION-C primarily features patch-based transformations, are there observed differences in how CNNs and transformers perform on these types of distortions?\n\n2. Class disparity between datasets: ImageNet-C includes 1,000 classes, whereas LAION-C has only 16, potentially creating an imbalance in comparison. Excluding the psychophysical experiments, what methods or adjustments could be employed to address this disparity and ensure a fair evaluation between the datasets?\n",
      "model_output": "Instruction: Background: Vision models like vision transformers and ConvNeXt, trained on massive datasets such as LAION, have shown remarkable performance on standard benchmarks. ImageNet-C has been used to test out-of-distribution (OOD) robustness by applying common corruptions to ImageNet data. However, with web-scale data like LAION, which inherently contains many of these corruptions, ImageNet-C is no longer truly OOD for these models.\nGap: Current OOD benchmarks like ImageNet-C are inadequate for evaluating the robustness of contemporary models trained on large web-scale datasets because they already contain similar corruptions, reducing the OOD nature of these benchmarks.\nHypothesis: The authors propose that by creating a new benchmark, LAION-C, which includes distortions genuinely OOD for web-scale datasets, it's possible to better challenge and evaluate the robustness and generalization capabilities of modern vision models.\nMethod: The LAION-C dataset includes six synthetic distortion types applied to images from the ImageNet validation set, each with five intensity levels. The distortions are designed to disrupt visual consistency and perceptual cues, like Mosaic, Glitched, and more. The authors evaluated 58 vision models using LAION-C and conducted psychophysical experiments with human participants to compare their performance.\nConclusion: LAION-C presents a more robust evaluation challenge than ImageNet-C, as shown by the significant drop in model performance on LAION-C compared to ImageNet-C. The findings suggest that modern models, despite their superior performance, are using diverse strategies distinct from human-like strategies. LAION-C shifts the paradigm in OOD evaluation by requiring models to genuinely generalize beyond familiar data.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer: 1.5\nExplanation:\nThis paper makes a strong case for the need for new OOD benchmarks. It is a great contribution to the field because it creates a new benchmark that can be used to test out-of-distribution robustness and generalization capabilities of contemporary models trained on large web-scale datasets. The paper is well written and organized, and the authors make a convincing case for the need for new OOD benchmarks.\n\nOutput:\n1.5\nExplanation:\nThe authors propose a new benchmark, LAION-C, which includes distortions that are OOD for web-scale datasets. They conducted experiments using 58 vision models, including ResNet-50, EfficientNet-B0, and EfficientNet-B1, and evaluated their performance on LAION-C and ImageNet-C. The authors found that LAION-C is a more robust evaluation challenge than ImageNet-C, as shown by the significant drop in model performance on LAION-C compared to ImageNet-C. The findings suggest that modern models, despite their superior performance, are using diverse strategies distinct from human-like strategies. The authors conclude that LAION-C shifts the paradigm in OOD evaluation by requiring models to genuinely generalize beyond familiar data.\n\n## Comments\n\n  - I think that the paper is quite interesting, but I",
      "bert_p": 0.05973299592733383,
      "bert_r": 0.13612410426139832,
      "bert_f1": 0.09910678118467331
    },
    {
      "paper_id": "dgR6i4TSng",
      "prompt": "Background: The paper discusses the challenges of fine-tuning large pre-trained models in NLP and computer vision due to their substantial memory requirements. Parameter-efficient fine-tuning (PEFT) methods have been developed to mitigate these challenges by reducing the number of trainable parameters. Prior methods like LoRA utilize low-rank decompositions but face limitations related to compression ratios and parameter scaling. Quantum circuits, known for their unitary representation capabilities, offer potential advantages for achieving parameter-efficient adaptations.\nGap: Traditional PEFT methods like LoRA face limitations due to their reliance on low-rank decompositions, which restricts the compression ratio and results in linear scaling of trainable parameters with the model size. There is a need for methods that achieve higher parameter efficiency and can handle the scaling effectively.\nHypothesis: The authors propose that using quantum computations and quantum unitary parameterizations can achieve ultra parameter-efficient fine-tuning of large models. They hypothesize that the Pauli parameterization will allow the number of trainable parameters to grow only logarithmically with the ambient dimension, significantly enhancing parameter efficiency while maintaining competitive performance.\nMethod: The approach leverages quantum-inspired modules using generalized Pauli parameterizations. Unitary matrices are parameterized with a logarithmic number of parameters using quantum circuits composed of smaller unitary rotations (RY) and controlled-Z gates. This method, called Quantum-PEFT, applies these principles to reparameterize transformations in pre-trained models, focusing on transfer learning tasks in language and vision. The method was benchmarked against datasets like GLUE and CIFAR10, showing significantly reduced parameters compared to LoRA, while holding competitive performance.\nConclusion: The paper concludes that Quantum-PEFT significantly improves parameter efficiency for fine-tuning pre-trained language and vision models. Quantum-PEFT achieves a 5 to 25-fold reduction in trainable parameters compared to conventional methods like LoRA, while maintaining competitive performance. It demonstrates that quantum-inspired parameterizations are a promising avenue for developing more efficient deep learning models.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 3\nContribution: 2\nRating: 6\nConfidence: 3\n\nExplanation:\nStrengths:\n1. The paper introduces a parameterization based on quantum circuits that require only (2L+1)log\u2082(N)-2L parameters, a significant improvement over LoRA's 2NK parameters.\n2. The reduction in parameters is experimentally verified.\n3. The authors proposed generalized RY and CZ quantum gates for arbitrary dimensions beyond power-of-2.\n4. The proposed method seems robust under quantization.\n\nWeaknesses:\n1. Analysis of how L layers affect entanglement capacity is limited. There is no evaluation of entanglement entropy between layers.\n\n2. The paper only focuses on benchmarking against LoRA/adapter variants on small models (such as GPT2). Benchmarks on larger (and newer) models such as LLaMA seem to be quite standard and more related to practical use cases. \n\n1. Some of the recently proposed PEFT methods are not adequately addressed/discussed (at least mentioned somewhere in the paper), e.g.\n\n[1] https://arxiv.org/abs/2403.17919 (NeurIPS)\n\n[2] https://arxiv.org/abs/2404.03592 (NeurIPS)\n\n[3] https://arxiv.org/abs/2405.12130 \n\n[4] https://arxiv.org/abs/2406.00132 (NeurIPS)\n\nBoth [3] and [4] seem to be able to model high-rank matrices, and [4] appears to be also based on quantum circuit.\n\nQuestions:\n1. How does Eq. 4 work?\n2. What is the optimal number of alternating entanglement layers L for different model scales?\n3. For the quantum Shannon decomposition approach to handle non-power-of-two dimensions, how does the decomposition choice (N\u2081, N\u2082) affect model performance?\n4. Does the proposed method have a large computational overhead from the entanglement layers?\n5. How does the proposed method compare with other methods mentioned above? My understanding of the main difference between this method and [4] is the use of unitary and diagonal matrices. Is this correct?\n6. The proposed method focuses on reduction in parameters. However, [2] and [4] claim both reduction in parameter and performance improvement. Does the proposed method use even fewer parameters?\n6. How is the proposed method related to quantum machine learning?\n",
      "model_output": "Instruction: Background: The paper discusses the challenges of fine-tuning large pre-trained models in NLP and computer vision due to their substantial memory requirements. Parameter-efficient fine-tuning (PEFT) methods have been developed to mitigate these challenges by reducing the number of trainable parameters. Prior methods like LoRA utilize low-rank decompositions but face limitations related to compression ratios and parameter scaling. Quantum circuits, known for their unitary representation capabilities, offer potential advantages for achieving parameter-efficient adaptations.\nGap: Traditional PEFT methods like LoRA face limitations due to their reliance on low-rank decompositions, which restricts the compression ratio and results in linear scaling of trainable parameters with the model size. There is a need for methods that achieve higher parameter efficiency and can handle the scaling effectively.\nHypothesis: The authors propose that using quantum computations and quantum unitary parameterizations can achieve ultra parameter-efficient fine-tuning of large models. They hypothesize that the Pauli parameterization will allow the number of trainable parameters to grow only logarithmically with the ambient dimension, significantly enhancing parameter efficiency while maintaining competitive performance.\nMethod: The approach leverages quantum-inspired modules using generalized Pauli parameterizations. Unitary matrices are parameterized with a logarithmic number of parameters using quantum circuits composed of smaller unitary rotations (RY) and controlled-Z gates. This method, called Quantum-PEFT, applies these principles to reparameterize transformations in pre-trained models, focusing on transfer learning tasks in language and vision. The method was benchmarked against datasets like GLUE and CIFAR10, showing significantly reduced parameters compared to LoRA, while holding competitive performance.\nConclusion: The paper concludes that Quantum-PEFT significantly improves parameter efficiency for fine-tuning pre-trained language and vision models. Quantum-PEFT achieves a 5 to 25-fold reduction in trainable parameters compared to conventional methods like LoRA, while maintaining competitive performance. It demonstrates that quantum-inspired parameterizations are a promising avenue for developing more efficient deep learning models.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer: Output\n\n### 1. Soundness\n\n#### 1.1. Introduction\n\nThe paper is well written and the introduction is clear and concise. The authors state that their work is an extension of LoRA and that they are interested in the \u201cquantum-inspired modules\u201d and the \u201cparameterization\u201d of the transformations. The authors state that their method can be applied to pre-trained models, and that they benchmarked their method against LoRA. The authors provide a description of the problem statement and the contributions of their work. The authors state that their work is an extension of LoRA and that they are interested in the \u201cquantum-inspired modules\u201d and the \u201cparameterization\u201d of the transformations. The authors state that their method can be applied to pre-trained models, and that they benchmarked their method against LoRA. The authors provide a description of the problem statement and the contributions of their work. The authors state that their work is an extension of LoRA and that they are interested in the \u201cquantum-inspired modules\u201d and the \u201cparameterization\u201d of the transformations. The authors state that their method can be applied to pre-trained models, and that they benchmarked their method against LoRA. The authors provide a description of the problem statement and the contributions of their",
      "bert_p": -0.07097867876291275,
      "bert_r": -0.1926460713148117,
      "bert_f1": -0.13074585795402527
    },
    {
      "paper_id": "UatDdAlr2x",
      "prompt": "Background: Transformers have become fundamental in deep learning advancements, particularly in language models, due to their versatile ability to process multiple data types as token sequences. However, the specific roles of different architectural elements within transformers and their interplay in shaping the model's hypothesis space remain poorly understood.\nGap: The explicit contribution and interaction of transformer components, specifically the token-mixing attention and feed-forward layers, to the range of algorithms that transformers can learn in a controlled task like counting are not fully understood. There is a lack of clarity on how these elements interact to influence model solutions, particularly in simple tasks requiring counting.\nHypothesis: The hypothesis is that subtle changes in transformer architecture, such as the inclusion of softmax in the attention mechanism, can significantly influence the model's ability to implement different counting strategies (relation-based and inventory-based) depending on the synergy among hyperparameters and components.\nMethod: The study analyzed transformer architectures with one-layer models alternating a token-mixing mechanism and a feed-forward network on the histogram task, which involves counting the occurrences of each token in an input sequence. They examined four token mixing models (lin and dot, both with and without softmax) and evaluated their performance concerning embedding dimension and hidden layer size. Theoretical constructions were developed to demonstrate how different strategies can implement counting tasks with specific configurations. Experiments were conducted using a generated dataset representing discrete input sequences to validate these theoretical insights.\nConclusion: The study concluded that two main types of counting strategies can be theoretically implemented: relation-based, which uses pair-wise comparisons within sequences, and inventory-based, which relies on memorizing token occurrences. It was found that even minor architectural changes significantly influence a transformer\u2019s ability to learn these strategies. Embedding dimension and hidden layer size play crucial roles, requiring careful alignment for optimal performance. The softmax function can either benefit or hinder performance, depending on its use and model architecture.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 3\nContribution: 2\nRating: 6\nConfidence: 3\n\nExplanation:\nStrengths:\n* The paper is well-written, easy to follow, and provides sufficient analysis for its claims.\n* Discovers and Discusses two strategies which 1-layer transformers can use to perform the counting task (i.e., relation-based and inventory-based) and in doing so considers a range of possible hyperparameter selections that affect this strategic choice.\n* During its analysis further studies the role of BoS token showing that together with softmax in the counting task, can help models with smaller p and d sizes to still reach perfect accuracy.\n\nWeaknesses:\n* Limited scope and applicability, specifically: (1) Only examines single-layer transformers, (2)Focuses on just one task (histogram counting)\n* No clear path to extending insights to more complicated settings more specifically multi-layer transformers\n* Lack of practical impact in the sense that it is hard to find a direct translation from this paper findings to real-world transformer design for real-world tasks\n\nQuestions:\nHave you done any analysis or insight you can share on: \n1. what behaviour can we expect in terms of the same hyperparameter choices (embedding dimension, Hidden Layer Size, and Vocab Size) whether as a  2 or 3 layer blackbox and/or an isolation of one of the transformer layers in a multi-layer setting?\n2. Have you done any initial analysis to share about whether the same relationships for parameters and potential solving strategies hold for other tasks (such as the sorting or lookup problems you referred to or any other tasks)\n",
      "model_output": "Instruction: Background: Transformers have become fundamental in deep learning advancements, particularly in language models, due to their versatile ability to process multiple data types as token sequences. However, the specific roles of different architectural elements within transformers and their interplay in shaping the model's hypothesis space remain poorly understood.\nGap: The explicit contribution and interaction of transformer components, specifically the token-mixing attention and feed-forward layers, to the range of algorithms that transformers can learn in a controlled task like counting are not fully understood. There is a lack of clarity on how these elements interact to influence model solutions, particularly in simple tasks requiring counting.\nHypothesis: The hypothesis is that subtle changes in transformer architecture, such as the inclusion of softmax in the attention mechanism, can significantly influence the model's ability to implement different counting strategies (relation-based and inventory-based) depending on the synergy among hyperparameters and components.\nMethod: The study analyzed transformer architectures with one-layer models alternating a token-mixing mechanism and a feed-forward network on the histogram task, which involves counting the occurrences of each token in an input sequence. They examined four token mixing models (lin and dot, both with and without softmax) and evaluated their performance concerning embedding dimension and hidden layer size. Theoretical constructions were developed to demonstrate how different strategies can implement counting tasks with specific configurations. Experiments were conducted using a generated dataset representing discrete input sequences to validate these theoretical insights.\nConclusion: The study concluded that two main types of counting strategies can be theoretically implemented: relation-based, which uses pair-wise comparisons within sequences, and inventory-based, which relies on memorizing token occurrences. It was found that even minor architectural changes significantly influence a transformer\u2019s ability to learn these strategies. Embedding dimension and hidden layer size play crucial roles, requiring careful alignment for optimal performance. The softmax function can either benefit or hinder performance, depending on its use and model architecture.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer:",
      "bert_p": -0.021307364106178284,
      "bert_r": -0.015177958644926548,
      "bert_f1": -0.016590137034654617
    },
    {
      "paper_id": "e2ONKX6qzJ",
      "prompt": "Background: Diffusion models have shown significant promise in generative modeling by reversing a process that adds noise to data. Classifier-free guidance (CFG) has proven effective in improving the quality of image generations, particularly in models like Stable Diffusion. However, high guidance scales in CFG can lead to issues such as oversaturation and reduced diversity in outputs.\nGap: High guidance scales necessary for enhancing image quality in classifier-free guidance (CFG) often result in oversaturated outputs and simplistic image compositions. Despite this, high CFG scales are widely used due to their improved image quality, indicating the need for a method to mitigate oversaturation while maintaining quality.\nHypothesis: The paper hypothesizes that by decomposing the CFG update term into parallel and orthogonal components relative to the conditional model prediction, the parallel component can be down-weighted to reduce oversaturation while maintaining image quality. Introducing rescaling and momentum, akin to gradient ascent, could also alleviate these issues.\nMethod: The authors present a novel approach termed adaptive projected guidance (APG), which involves three main elements: orthogonal projection to separate the CFG update term, rescaling to constrain update magnitudes, and reverse momentum to adjust update directions. This method is applied across various diffusion models and evaluated based on metrics like FID, recall, and saturation scores.\nConclusion: APG shows improved FID, recall, and saturation results while maintaining precision comparable to CFG. The method mitigates oversaturation at high guidance scales, proving to be a superior alternative to traditional CFG. It is compatible with multiple models and samplers, effectively extending the usable range of guidance scales in diffusion models without additional computational cost.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 4\nContribution: 3\nRating: 6\nConfidence: 3\n\nExplanation:\nStrengths:\n1. APG is presented as a plug-and-play method with virtually no additional computational overhead, making it attractive for practical use in various diffusion models.\n2. The method of down-weighting the parallel component in CFG is novel and interesting, effectively reducing oversaturation and preserving image quality at high guidance scales.\n\nWeaknesses:\n1. In Figure 8, could the authors explain why the proposed APG shows lower precision and higher FID compared to CFG when the guidance scale  w  is below certain values (e.g.,  w = 2.5 , where APG precision is lower than CFG)?\n2. While reverse momentum is introduced, the intuition behind why it improves the image generation quality could be expanded. More detailed theoretical or experimental exploration of this component would clarify its importance.\n\nQuestions:\nSee the questions in the weakness section.\n",
      "model_output": "Instruction: Background: Diffusion models have shown significant promise in generative modeling by reversing a process that adds noise to data. Classifier-free guidance (CFG) has proven effective in improving the quality of image generations, particularly in models like Stable Diffusion. However, high guidance scales in CFG can lead to issues such as oversaturation and reduced diversity in outputs.\nGap: High guidance scales necessary for enhancing image quality in classifier-free guidance (CFG) often result in oversaturated outputs and simplistic image compositions. Despite this, high CFG scales are widely used due to their improved image quality, indicating the need for a method to mitigate oversaturation while maintaining quality.\nHypothesis: The paper hypothesizes that by decomposing the CFG update term into parallel and orthogonal components relative to the conditional model prediction, the parallel component can be down-weighted to reduce oversaturation while maintaining image quality. Introducing rescaling and momentum, akin to gradient ascent, could also alleviate these issues.\nMethod: The authors present a novel approach termed adaptive projected guidance (APG), which involves three main elements: orthogonal projection to separate the CFG update term, rescaling to constrain update magnitudes, and reverse momentum to adjust update directions. This method is applied across various diffusion models and evaluated based on metrics like FID, recall, and saturation scores.\nConclusion: APG shows improved FID, recall, and saturation results while maintaining precision comparable to CFG. The method mitigates oversaturation at high guidance scales, proving to be a superior alternative to traditional CFG. It is compatible with multiple models and samplers, effectively extending the usable range of guidance scales in diffusion models without additional computational cost.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer: (1) 2 (2) 3 (3) 3 (4) 3 (5) 4 (6) 3 (7) 5 (8) 3 (9) 5 (10) 3 (11) 5 (12) 4 (13) 5 (14) 3 (15) 5 (16) 4 (17) 5 (18) 5 (19) 5 (20) 4 (21) 5 (22) 3 (23) 5 (24) 5 (25) 5 (26) 4 (27) 5 (28) 5 (29) 5 (30) 4 (31) 5 (32) 5 (33) 5 (34) 5 (35) 5 (36) 5 (37) 5 (38) 5 (39) 5 (40) 5 (41) 5 (42) 5 (43) 5 (44) 5 (45) 5 (46) 5 (47) 5 (48) 5 (49) 5 (50) 5 (51) 5 (",
      "bert_p": -0.019678350538015366,
      "bert_r": 0.11369267106056213,
      "bert_f1": 0.04766768217086792
    },
    {
      "paper_id": "3X3LuwzZrl",
      "prompt": "Background: Graphs are a complex data structure used in various domains. Multi-label node classification (MLNC) on graphs is an important task because many nodes naturally have multiple labels due to diverse functions or interests, such as proteins in PPI networks or users in social networks. Existing methods typically leverage graph neural networks (GNNs) or label embeddings to leverage label co-occurrence or proximity but do not address the intricate influences between labels in non-Euclidean spaces.\nGap: Current MLNC approaches often fail to fully exploit the complex label correlations present in graph data. They typically only consider label proximity and co-occurrence correlations, overlooking how different labels might enhance or hinder each other's performance when they interact over non-Euclidean graph structures.\nHypothesis: The authors propose that decomposing the message passing process in GNNs into propagation and transformation operations and analyzing these separately will allow for better quantification and modeling of label influence correlations. This approach can better capture complex inter-label influences, thereby improving MLNC performance.\nMethod: The proposed method involves decomposing GNN message passing into propagation and transformation operations to analyze label influence correlations. A label influence propagation model, named Label Influence Propagation (LIP), is introduced. It constructs a label influence graph and propagates high-order influences through it, adjusting the learning process dynamically by amplifying or mitigating label influences. The approach is validated using benchmark datasets, demonstrating it consistently outperforms state-of-the-art methods.\nConclusion: The proposed LIP framework demonstrates superior performance in MLNC tasks compared to existing state-of-the-art methods. By capturing high-order label influence correlations, it improves classification accuracy, as evidenced by consistent improvements across multiple datasets. This method also effectively quantifies and utilizes label influences to enhance learning, highlighting its utility in complex graph-based applications.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 3\nContribution: 3\nRating: 6\nConfidence: 3\n\nExplanation:\nStrengths:\nPros:\n1. The paper considers the positive and negative influence of different labels and encourages or suppresses labels that bring positive or negative influences, respectively.\n2. The proposed model is a plug-and-play approach, which can be applied to various GNN backbones. \n3. The paper offers a label correlation analysis by dissecting the pipeline into a forward and backward propagation segment.\n\nWeaknesses:\nCons:\n1. What is the difference between the label propagation methods? (GMNN: Graph Markov Neural Networks, Combining Graph Convolutional Neural Networks and Label Propagation, Resurrecting Label Propagation for Graphs with Heterophily and Label Noise). The paper should cite and compare with them, and highlight the improvement of the model.\n2. Some hyperparameters are important to the model. It is better to give some hyperparameter analysis about the model, such as \\alpha, \\beta. It is suggested to plot the results showing how performance varies with these parameters and report the chosen values.\n3. How does the number of label categories k affect the model? It is recommended to study the effect of the performance.\n4. It is highly recommended to give some examples, i.e., the visualization of the positive and negative influence of different labels in the case studies, showing how certain labels positively or negatively influence others and how this affects the model's predictions.\n5. It is recommended to give other backbones, such as the most commonly used GIN, to show the effectiveness of the model.\n6. It is better to check the label of the axis in the figure. i.e., fig 4c. The label of the x-axis is missing.\n\nQuestions:\nPlease see the above weakness.\n",
      "model_output": "Instruction: Background: Graphs are a complex data structure used in various domains. Multi-label node classification (MLNC) on graphs is an important task because many nodes naturally have multiple labels due to diverse functions or interests, such as proteins in PPI networks or users in social networks. Existing methods typically leverage graph neural networks (GNNs) or label embeddings to leverage label co-occurrence or proximity but do not address the intricate influences between labels in non-Euclidean spaces.\nGap: Current MLNC approaches often fail to fully exploit the complex label correlations present in graph data. They typically only consider label proximity and co-occurrence correlations, overlooking how different labels might enhance or hinder each other's performance when they interact over non-Euclidean graph structures.\nHypothesis: The authors propose that decomposing the message passing process in GNNs into propagation and transformation operations and analyzing these separately will allow for better quantification and modeling of label influence correlations. This approach can better capture complex inter-label influences, thereby improving MLNC performance.\nMethod: The proposed method involves decomposing GNN message passing into propagation and transformation operations to analyze label influence correlations. A label influence propagation model, named Label Influence Propagation (LIP), is introduced. It constructs a label influence graph and propagates high-order influences through it, adjusting the learning process dynamically by amplifying or mitigating label influences. The approach is validated using benchmark datasets, demonstrating it consistently outperforms state-of-the-art methods.\nConclusion: The proposed LIP framework demonstrates superior performance in MLNC tasks compared to existing state-of-the-art methods. By capturing high-order label influence correlations, it improves classification accuracy, as evidenced by consistent improvements across multiple datasets. This method also effectively quantifies and utilizes label influences to enhance learning, highlighting its utility in complex graph-based applications.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer:",
      "bert_p": -0.04895709455013275,
      "bert_r": -0.007717912085354328,
      "bert_f1": -0.026752371340990067
    },
    {
      "paper_id": "wH8XXUOUZU",
      "prompt": "Background: Latent diffusion models have become a popular choice for image synthesis due to their ability to reduce computational costs by transforming images into a compressed latent space before processing. Traditionally, these models employ an autoencoder with a moderate spatial compression ratio, such as 8x, which works well for low-resolution images. However, for high-resolution images, higher compression ratios are necessary to manage the computational load, especially for diffusion transformer models that are quadratically complex as the number of tokens increases.\nGap: Current autoencoder models exhibit a significant drop in reconstruction accuracy when the spatial compression ratio is increased beyond moderate levels. For instance, the reconstruction fidelity (rFID) significantly worsens when moving from an 8x to a 64x compression ratio, indicating that the optimization difficulty and generalization issues persist at higher compression levels.\nHypothesis: The authors propose that by introducing Residual Autoencoding and Decoupled High-Resolution Adaptation techniques, it is possible to enhance the reconstruction accuracy of high spatial-compression autoencoders. These techniques aim to address the optimization difficulties and generalization penalties associated with high compression ratios.\nMethod: The authors introduce Deep Compression Autoencoder (DC-AE), utilizing two main strategies: Residual Autoencoding and Decoupled High-Resolution Adaptation. Residual Autoencoding involves adding non-parametric shortcuts to neural network modules to learn residuals based on a space-to-channel transformation, which helps address the optimization difficulty. Decoupled High-Resolution Adaptation includes a three-phase training strategy that separates the GAN loss training into a focused local refinement phase, along with high-resolution latent adaptation to mitigate generalization penalties. The authors then apply DC-AE to latent diffusion models for efficient image synthesis, demonstrating enhanced speed and quality on datasets like ImageNet 512x512, achieving significant gains in inference and training throughput while maintaining or improving image quality metrics like FID compared to existing models.\nConclusion: The Deep Compression Autoencoder (DC-AE) offers a significant improvement for high-resolution diffusion models by efficiently managing higher spatial compression ratios up to 128x without degrading reconstruction quality. By employing Residual Autoencoding and Decoupled High-Resolution Adaptation, the autoencoders increase their efficiency, resulting in faster training and inference times on GPUs, alongside better generative performance (as measured by FID scores) compared to traditional autoencoders with lower compression factors.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 2\nContribution: 3\nRating: 6\nConfidence: 4\n\nExplanation:\nStrengths:\n-\tNovel autoencoder design for high compression ratios. The authors introduce additional non-parametric residual connections in the downsampling and upsampling layers, which facilitate the optimization of autoencoders in high spatial compression ratio scenarios.\n-\tThe authors carefully design a three-stage training recipe to mitigate the high-resolution generalization gaps by fine-tuning the trained AE on high-resolution data with minimal additional costs.\n-\tThe proposed DC-AEs show a substantial reduction in training and inference costs of latent diffusion models on various datasets.\n\nWeaknesses:\n-\tAlthough the VAE shows little FID loss as it progresses to a higher spatial compression ratio (DC-AE-f32 to DC-AE-f64), it does not translate to similar results in the corresponding latent diffusion models as shown in Table 3. The underlying reason is probably that a diffusion model with higher capacity is required when dealing with high compression ratio latents.\n-\tThe current submission lacks either theoretical analysis or illustrative toy examples on the proposed design choice of space-channel residual connection, e.g., comparisons on the loss landscapes.\n\nQuestions:\n-\tCould you please clarify the experimental settings and AE architectures in Section 3.1? By Line 161 \u2018\u2026 convert the latent to higher spatial compression\u2026\u2019, do you mean that the f8 to f64 AEs have the same output latent size initially, yet f32 and f64 AEs further squeeze the space dimension into channel dimension?\n-\tIn Table 5, the proposed method shows a lower CLIP score with the Pixart diffusion transformer, is it a typo?\n",
      "model_output": "Instruction: Background: Latent diffusion models have become a popular choice for image synthesis due to their ability to reduce computational costs by transforming images into a compressed latent space before processing. Traditionally, these models employ an autoencoder with a moderate spatial compression ratio, such as 8x, which works well for low-resolution images. However, for high-resolution images, higher compression ratios are necessary to manage the computational load, especially for diffusion transformer models that are quadratically complex as the number of tokens increases.\nGap: Current autoencoder models exhibit a significant drop in reconstruction accuracy when the spatial compression ratio is increased beyond moderate levels. For instance, the reconstruction fidelity (rFID) significantly worsens when moving from an 8x to a 64x compression ratio, indicating that the optimization difficulty and generalization issues persist at higher compression levels.\nHypothesis: The authors propose that by introducing Residual Autoencoding and Decoupled High-Resolution Adaptation techniques, it is possible to enhance the reconstruction accuracy of high spatial-compression autoencoders. These techniques aim to address the optimization difficulties and generalization penalties associated with high compression ratios.\nMethod: The authors introduce Deep Compression Autoencoder (DC-AE), utilizing two main strategies: Residual Autoencoding and Decoupled High-Resolution Adaptation. Residual Autoencoding involves adding non-parametric shortcuts to neural network modules to learn residuals based on a space-to-channel transformation, which helps address the optimization difficulty. Decoupled High-Resolution Adaptation includes a three-phase training strategy that separates the GAN loss training into a focused local refinement phase, along with high-resolution latent adaptation to mitigate generalization penalties. The authors then apply DC-AE to latent diffusion models for efficient image synthesis, demonstrating enhanced speed and quality on datasets like ImageNet 512x512, achieving significant gains in inference and training throughput while maintaining or improving image quality metrics like FID compared to existing models.\nConclusion: The Deep Compression Autoencoder (DC-AE) offers a significant improvement for high-resolution diffusion models by efficiently managing higher spatial compression ratios up to 128x without degrading reconstruction quality. By employing Residual Autoencoding and Decoupled High-Resolution Adaptation, the autoencoders increase their efficiency, resulting in faster training and inference times on GPUs, alongside better generative performance (as measured by FID scores) compared to traditional autoencoders with lower compression factors.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer: Explanation (strengths, weaknesses)\nOutput:\nAnswer: Explanation (strengths, weaknesses)\n\nExplanation:\n1) Soundness: The rigor of the methods for the stated problem\n2) Presentation: The clarity of writing and organization\n3) Contribution: The paper\u2019s novelty or added value to the domain\n4) Rating (1\u201310): Overall recommendation for acceptance\n5) Confidence (1\u20135): How confident the reviewer is in their assessment\n\nExplanation:\n1) Soundness: The rigor of the methods for the stated problem\n2) Presentation: The clarity of writing and organization\n3) Contribution: The paper\u2019s novelty or added value to the domain\n4) Rating (1\u201310): Overall recommendation for acceptance\n5) Confidence (1\u20135): How confident the reviewer is in their assessment\n1) Soundness: The rigor of the methods for the stated problem\n2) Presentation: The clarity of writing and organization\n3) Contribution: The paper\u2019s novelty or added value to the domain\n4) Rating (1\u201310): Overall recommendation for acceptance\n5) Confidence (1\u20135): How confident the reviewer is in their assessment\n1) Soundness: The rigor of the methods for the stated problem\n2) Presentation: The clarity",
      "bert_p": -0.0011988554615527391,
      "bert_r": -0.028899988159537315,
      "bert_f1": -0.013439931906759739
    },
    {
      "paper_id": "lessla98Wp",
      "prompt": "Background: Video colorization converts monochrome videos into colorful versions for applications like film restoration and advertising, aiming for semantic accuracy and temporal consistency. Traditional methods include automatic, exemplar-based, and conditional image colorization, each facing unique challenges.\nGap: Existing methods struggle with ambiguous color assignments, limited creativity in color selection due to reliance on exemplars, and maintaining temporal consistency across frames, especially with changing object positions and deformations.\nHypothesis: Language-based video colorization can allow for semantically accurate, creatively flexible, and temporally consistent results by leveraging user-provided text descriptions to guide the colorization process.\nMethod: L-C4 utilizes a pre-trained cross-modality generative model to interpret language descriptions and guide color assignments. Key components include a cross-modality pre-fusion module for instance-aware text embeddings, temporally deformable attention to maintain inter-frame consistency, and cross-clip fusion for long-term consistency across video clips. The model was trained using a dataset with 100K text-video pairs, focusing on aesthetic quality.\nConclusion: L-C4 addresses previous limitations by enabling user-friendly, semantically accurate, and temporally consistent video colorization using language inputs. It outperforms existing methods across several benchmarks, offering vivid, creative, and robust colorization results.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 4\nContribution: 3\nRating: 8\nConfidence: 4\n\nExplanation:\nStrengths:\n- Each component is well-motivated, with clear explanations of how they address specific challenges in video colorization. The paper is well-written, with logical organization and flow that makes it easy to understand.\n\n- The proposed Cross-Modality Pre-Fusion (CMPF) module enhances text embeddings with instance-aware capability, ensuring that the objects are assigned with desired colors, enabling creative and precise colorization given user input.\n\n- The Temporally Deformable Attention (TDA) and Cross-Clip Fusion (CCF) effectively maintain color consistency across frames in a video. These components help prevent flickering and color shifts, leading to smoother and more visually appealing results.\n\n- The experiments are thourough and well-designed, demonstrating superiority over state-of-the-art approaches.\n\nWeaknesses:\n- Regarding the generation of instance-aware embeddings, the paper does not fully explain or justify the creation of color-related masks. This might limit the model's applicability in complex cases, such as when dealing with intricate or lengthy textual descriptions.\n\n- The paper lacks discussions on limitations. \n\n- Some typos: Line 311, \"cross-flip\" should be \"cross-clip\".\n\nQuestions:\n- What's the generation process of color-related masks? What if the text prompts are complicated or intricate? One example:\n  \"The sunset painted the sky with hues of burnt umber, casting a surreal glow over the landscape.\" Could the model handle these cases successfully, and to what extent will the quality and type of text prompts influence its performance?\n\n- Temporally Deformable Attention (TDA) generates offset estimations for reference points. Would the performance get worse or better if we replace the offset estimation with an off-the-shelf model, such as an optical flow estimation model?\n\nThank the authors for the detailed explanation. My concerns have been fully addressed. Regarding the failure cases, I think that fine-grained color manipulation may be better controlled by other kinds of user interactions, such as reference images or strokes, given the high-level and semantic nature of text prompts. Overall, I think this is a paper that tackles text-guided video colorization problems with meaningful contributions and good demonstrations. I will raise my score.\n",
      "model_output": "Instruction: Background: Video colorization converts monochrome videos into colorful versions for applications like film restoration and advertising, aiming for semantic accuracy and temporal consistency. Traditional methods include automatic, exemplar-based, and conditional image colorization, each facing unique challenges.\nGap: Existing methods struggle with ambiguous color assignments, limited creativity in color selection due to reliance on exemplars, and maintaining temporal consistency across frames, especially with changing object positions and deformations.\nHypothesis: Language-based video colorization can allow for semantically accurate, creatively flexible, and temporally consistent results by leveraging user-provided text descriptions to guide the colorization process.\nMethod: L-C4 utilizes a pre-trained cross-modality generative model to interpret language descriptions and guide color assignments. Key components include a cross-modality pre-fusion module for instance-aware text embeddings, temporally deformable attention to maintain inter-frame consistency, and cross-clip fusion for long-term consistency across video clips. The model was trained using a dataset with 100K text-video pairs, focusing on aesthetic quality.\nConclusion: L-C4 addresses previous limitations by enabling user-friendly, semantically accurate, and temporally consistent video colorization using language inputs. It outperforms existing methods across several benchmarks, offering vivid, creative, and robust colorization results.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer: 2\n\nExplanation (strengths, weaknesses):\nL-C4 is a method that enables user-friendly, semantically accurate, and temporally consistent video colorization using language inputs. It outperforms existing methods across several benchmarks, offering vivid, creative, and robust colorization results.\n\nInput:\nAnswer: 3\n\nExplanation (strengths, weaknesses):\nL-C4 is a method that enables user-friendly, semantically accurate, and temporally consistent video colorization using language inputs. It outperforms existing methods across several benchmarks, offering vivid, creative, and robust colorization results.\n\nInput:\nAnswer: 4\n\nExplanation (strengths, weaknesses):\nL-C4 is a method that enables user-friendly, semantically accurate, and temporally consistent video colorization using language inputs. It outperforms existing methods across several benchmarks, offering vivid, creative, and robust colorization results.\n\nInput:\nAnswer: 5\n\nExplanation (strengths, weaknesses):\nL-C4 is a method that enables user-friendly, semantically accurate, and temporally consistent video colorization using language inputs. It outperforms existing methods across several benchmarks, offering vivid, creative, and robust colorization results.\n\nInput:\nAnswer: 6\n\nExplanation (strengths, weaknesses):\nL-C",
      "bert_p": -0.017596183344721794,
      "bert_r": -0.034324705600738525,
      "bert_f1": -0.024308137595653534
    },
    {
      "paper_id": "s6nYndMwG7",
      "prompt": "Background: Influence functions are a technique for explaining model predictions by attributing them to training data points. Koh and Liang (2017) introduced Hessian-based influence functions to approximate the effect of removing one training point. However, existing methods for calculating influence functions, particularly using inverse Hessian-vector products (iHVP), involve computationally expensive algorithms like LiSSA, which suffer from high computational cost and require delicate hyperparameter tuning.\nGap: The primary limitations with current methods for calculating inverse Hessian-vector products using LiSSA are the computational cost and the complexity of hyperparameter tuning, which make them impractical for large models.\nHypothesis: The paper proposes that the three hyperparameters of the LiSSA algorithm\u2014scaling factor, batch size, and number of steps\u2014can be effectively set using two specific spectral properties of the Hessian: its trace and largest eigenvalue, which can be evaluated using random sketching techniques.\nMethod: The authors use the Gauss-Newton Hessian and random sketching techniques to determine the trace and largest eigenvalue of the Hessian, allowing them to set the hyperparameters for LiSSA. They then empirically validate these settings across different models, including ResNet and language models, and compare their approach to Proximal Bregman Retraining Functions (PBRF), which serve as the ground truth.\nConclusion: The paper concludes that by using spectral properties of the Hessian, the authors can set hyperparameters for the LiSSA algorithm that allow it to be practically applied to large models. This approach makes influence function calculations more feasible and reliable, and can serve as a baseline for validating other influence function estimation methods.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 3\nContribution: 2\nRating: 6\nConfidence: 4\n\nExplanation:\nStrengths:\nThe paper does well to describe the end-to-end process of using inverse-Hessian influence metric on LLMs and Resnets, for which there are substantial empirical and theoretical questions to address.  It would appear that the cases that the authors considered are evaluated in reasonable level of detail, and that the empirical aspects of the paper should be reproducible.\n\nWhile the main contributions are about methodology of using inverse-Hessian influences; section 5 provides some additional scientific value on the potential value of using inverse-Hessian influences.  While it is more speculative in nature, it provides some problem setups which might be the setting for future work.\n\nThe paper is also well-integrated into existing theory on influence functions, which brings additional value to the paper.\n\nThe main theorem seems to provide a suggested starting point for how to pick the parameters in LISSA (with explicit parameters).\n\nWeaknesses:\nI find the following overall weaknesses: \n\n1) The main theoretical contribution of the paper is a convergence analysis for the mini-batch SGD derived.  This is done under a very strong hypothesis, which is effectively a contractivity assumption in norm (C.1) or (9) in Theorem 1.  This makes the main theorem relatively easy to prove, but it also begs the question of showing when this satisfied.   Separately, mini-batch SGD on quadratics are studied to death, and it will be quite difficult to argue that this is truly a new analysis\n\n2) Regarding the contractivity assumption: it is shown that in some sense the assumptions of Theorem 1 necessary, but this sense is effectively adversarial in the test-direction u (B.4Lemma 1).     On the other hand, the positive cases (B3 Motivations for C.1) do not show that C1 is satisfied.  It would substantially improve the paper if the theory covered these two cases.  (If it does, this should be explained).\n\n3) The empirical results of the contractivity (Figure 4) do not consider C.1 but rather the trace.  Trace type conditions are much easier to satisfy, and unfortunately give little insight whether C.1 in fact holds.  A much more desirable theorem (to my taste -- and also more consistent with the experiments) would assume trace-type conditions on H and H^2, and some randomness assumptions on u that lead to the claimed convergence.  There is a lingering sense that C.1 and (9) of Theorem 1 is unverifiable.\n\n4) The empirical conclusions in Section 4 and 5 are a little bit murky, and it's hard to align what appears in the simulations with what appear in the text.\n\nQuestions:\nRegarding the weaknesses:\nWeakness 1): There's a lot of batch-SGD analyses which at first glance may already contain the theorem.  For example:\nA) Jain, Kakade, Kidambi, Netrapalli, Sidford. \"Parallelizing..\" 2018 JMLR\nB) Varre, Pillaud-Vivien, Flammarion. \"Last iterate convergnece..\" 2021 NeurIPS\nC) Ma, Bassily, Belkin.  \"The power of Interpolation...\" 2018 ICML\nCan you argue why your analysis is novel, comparing to existing literature like the above?\n\nWeakness 2): Can you show why the theorems apply to the setups in B3? Currently, this is `almost' done but not completely.  In particular the sentence on (l243): ``we find this condition to hold for classification with independent sampling\" appears unfulfilled.\"\n\nWeakness 3): Can you show empirically that C1 occurs, in the norm sense?  (tracial vs norm-type behavior is rarely equivalent in random matrix contexts).\n\nWeakness 4a): Figure 1 is appears to be discussed in the text (l368-370) and 3 cases are explained. Considering Figure 1, why are these the 3 cases, (especially, which illustrates case '3'? Where do you argue that 'PBO _finetunning_ stirs away the model too far for the quadratic approximation to hold'. (and what does that mean?)\n\nWeakness 4b): Figure 3.  Why does the difference picture show what you claim it does?  (In particular why do you average over the 10x10 square, and why are you not measuring the diagonals?). When you write (l464-466). ``As a result the influence similarity between an orignal sentence and a rewritten one appears to be consistently higher than between unrelated sentence.\"  Can you explain this?\n\nOther questions: \n1) Can you explain precisely how you picked the 'batch' in Table 1, and moreover, what is the general procedure you suggest for selecting LiSSA parameters?  (It seems you _almost_ do this, but being extra-clear would help, especially as regard the batch.)\n\nMinor:\n1) (l80-83). ``Influence functions are calculated under the assumption that the optimized parameter $\\theta$ of the model delivers minimum to the training loss.\"  This sentence is mangled. \n2) l409-410.  ``the choice of _dumping_ parameter''\n3) l424: ``For example, a plausible interpretation of the directions $v_j$ would be that the top directions correspond to general language coherence and... small eigenvalues could correspond to more specific, informative content.\"  While the statement about large eigenvalues makes sense, the complementary statement about small eigenvalues does not -- first most small eigenvalues are not interpretable, and are the result of either diffuse (non-one-dimensional) embeddings or undesirable feature distortions.  Perhaps it would be better to just say you can screen out the large eigenvalues which are more about general language coherence.\n",
      "model_output": "Instruction: Background: Influence functions are a technique for explaining model predictions by attributing them to training data points. Koh and Liang (2017) introduced Hessian-based influence functions to approximate the effect of removing one training point. However, existing methods for calculating influence functions, particularly using inverse Hessian-vector products (iHVP), involve computationally expensive algorithms like LiSSA, which suffer from high computational cost and require delicate hyperparameter tuning.\nGap: The primary limitations with current methods for calculating inverse Hessian-vector products using LiSSA are the computational cost and the complexity of hyperparameter tuning, which make them impractical for large models.\nHypothesis: The paper proposes that the three hyperparameters of the LiSSA algorithm\u2014scaling factor, batch size, and number of steps\u2014can be effectively set using two specific spectral properties of the Hessian: its trace and largest eigenvalue, which can be evaluated using random sketching techniques.\nMethod: The authors use the Gauss-Newton Hessian and random sketching techniques to determine the trace and largest eigenvalue of the Hessian, allowing them to set the hyperparameters for LiSSA. They then empirically validate these settings across different models, including ResNet and language models, and compare their approach to Proximal Bregman Retraining Functions (PBRF), which serve as the ground truth.\nConclusion: The paper concludes that by using spectral properties of the Hessian, the authors can set hyperparameters for the LiSSA algorithm that allow it to be practically applied to large models. This approach makes influence function calculations more feasible and reliable, and can serve as a baseline for validating other influence function estimation methods.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\nAnswer: Output\n\nInput:\n",
      "bert_p": -0.09059229493141174,
      "bert_r": -0.10259845852851868,
      "bert_f1": -0.09482116252183914
    },
    {
      "paper_id": "9CqkpQExe2",
      "prompt": "Background: The rapid development of large language models (LLMs) has shown that increasing the number of parameters enhances model performance across various tasks. However, this improvement incurs significant computational costs, challenging the efficiency and scalability of these models. Mixture-of-Experts (MoE) architecture presents a potential solution, allowing for large model scaling without a proportional rise in computational effort by sparsely activating only a few expert networks per input, managed by a routing strategy. Top-K routing has been the dominant approach in MoE models, selecting a fixed number of experts for each token.\nGap: The key limitation of traditional Top-K routing is its static nature, which does not account for the varying complexity and importance of different tokens in a sequence. This static approach can result in inefficient resource allocation, where simple tokens may receive more computational resources than necessary, while complex tokens may not receive enough attention, thus hindering model performance and efficiency gains.\nHypothesis: The authors propose that a dynamic routing strategy, which adjusts the number of activated experts for each token based on its contextual importance, could achieve better computational efficiency and model performance compared to the traditional static Top-K routing strategy.\nMethod: The authors introduce Ada-K routing, which dynamically adjusts the number of active experts per token. This method incorporates lightweight, pluggable allocator modules that learn to allocate expert resources based on the context of each token. These allocators are trained using the Proximal Policy Optimization (PPO) algorithm, allowing them to operate within the non-differentiable sampling framework. Extensive evaluations were conducted using four MoE-based LLMs varying from 14.3B to 140B parameters. Results were compared to models implementing Top-K routing by assessing accuracy, floating point operations (FLOPs), and inference speed across six benchmarks.\nConclusion: Ada-K routing consistently outperformed baseline models using Top-K routing, reducing expert activation by 30% to 40%, lowering FLOPs by over 25%, and providing more than a 20% inference speedup while enhancing model performance across multiple benchmarks. The method is efficiently trainable, requires minimal additional parameters, and maintains expert load balance. It provides insights into adaptive resource allocation by adjusting expert activations based on token complexity and task difficulty, significantly enhancing the efficiency of MoE-based LLMs.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 3\nContribution: 3\nRating: 6\nConfidence: 4\n\nExplanation:\nStrengths:\n- Innovatively proposes to introduce an RL agent for controlling top-k in pre-trained MoE models, optimizing the allocation of computational resources and improving inference efficiency. The method has a low training cost and shows robustness to training data, outperforming existing methods across various downstream tasks.\n- Thorough ablation studies demonstrate the relationship between acceleration effects and accuracy, providing practical guidance. It also validates the effectiveness of activation regularization and warm-up strategies.\n- Performs meticulous analysis revealing that intermediate layers of trained models require the activation of more experts, reaffirming that more challenging tasks necessitate the activation of more experts.\n\nWeaknesses:\n- Some comparisons with baseline methods are not entirely reasonable. Existing work suggests that freezing the router yields better results when tuning MoE models. Ada-K freezes the router and introduces additional agent parameters for training, while other comparison methods only train the router. The reviewer recommends supplementing the results by (1) conducting full fine-tuning of the model with a frozen router and comparing the effects of introducing only threshold methods versus Ada-K; or (2) maintaining the current Ada-K setup and adding LoRA parameters to the threshold-based method while freezing the router for tuning.\n- The paper \"AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models\" (ArXiv: 2024-06-19), which has a very similar title, also achieves dynamic adjustment of top-k during post-training and improves accuracy while saving FLOPs during the tuning phase. Given the short time interval, the lack of comparison with this baseline can be understood, but the reviewer suggests discussing it.\n\nQuestions:\n- The reported speedup in the paper is based on the actual inference time during evaluation tasks, which likely applies to scenarios with batch sizes of 1 or smaller. However, MoE models have large parameter volumes, and their efficiency typically becomes evident with larger batch sizes during actual deployment. The reviewer is concerned that the RL-based method of controlling top-k for each token might lead to imbalance in batch inference, potentially affecting the acceleration effect. Therefore, the reviewer would like to know the relationship between acceleration effect and batch size.\n- Would combining Ada-K with the standard SFT setting yield better results? Or, under the control of Ada-K, would the performance of SFT be affected?\n",
      "model_output": "Instruction: Background: The rapid development of large language models (LLMs) has shown that increasing the number of parameters enhances model performance across various tasks. However, this improvement incurs significant computational costs, challenging the efficiency and scalability of these models. Mixture-of-Experts (MoE) architecture presents a potential solution, allowing for large model scaling without a proportional rise in computational effort by sparsely activating only a few expert networks per input, managed by a routing strategy. Top-K routing has been the dominant approach in MoE models, selecting a fixed number of experts for each token.\nGap: The key limitation of traditional Top-K routing is its static nature, which does not account for the varying complexity and importance of different tokens in a sequence. This static approach can result in inefficient resource allocation, where simple tokens may receive more computational resources than necessary, while complex tokens may not receive enough attention, thus hindering model performance and efficiency gains.\nHypothesis: The authors propose that a dynamic routing strategy, which adjusts the number of activated experts for each token based on its contextual importance, could achieve better computational efficiency and model performance compared to the traditional static Top-K routing strategy.\nMethod: The authors introduce Ada-K routing, which dynamically adjusts the number of active experts per token. This method incorporates lightweight, pluggable allocator modules that learn to allocate expert resources based on the context of each token. These allocators are trained using the Proximal Policy Optimization (PPO) algorithm, allowing them to operate within the non-differentiable sampling framework. Extensive evaluations were conducted using four MoE-based LLMs varying from 14.3B to 140B parameters. Results were compared to models implementing Top-K routing by assessing accuracy, floating point operations (FLOPs), and inference speed across six benchmarks.\nConclusion: Ada-K routing consistently outperformed baseline models using Top-K routing, reducing expert activation by 30% to 40%, lowering FLOPs by over 25%, and providing more than a 20% inference speedup while enhancing model performance across multiple benchmarks. The method is efficiently trainable, requires minimal additional parameters, and maintains expert load balance. It provides insights into adaptive resource allocation by adjusting expert activations based on token complexity and task difficulty, significantly enhancing the efficiency of MoE-based LLMs.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer: Output\n\n# Introduction\n\nThis paper proposes a novel adaptive routing strategy for large language models (LLMs) based on the mixture-of-experts (MoE) architecture. The authors introduce Ada-K routing, a dynamic routing strategy that dynamically adjusts the number of active experts per token based on its contextual importance. This method incorporates lightweight, pluggable allocator modules that learn to allocate expert resources based on the context of each token. These allocators are trained using the Proximal Policy Optimization (PPO) algorithm, allowing them to operate within the non-differentiable sampling framework. The authors evaluate Ada-K routing using four MoE-based LLMs varying from 14.3B to 140B parameters. The results are compared to models implementing Top-K routing by assessing accuracy, floating point operations (FLOPs), and inference speed across six benchmarks.\n\n# Background\n\nThe rapid development of large language models (LLMs) has shown that increasing the number of parameters enhances model performance across various tasks. However, this improvement incurs significant computational costs, challenging the efficiency and scalability of these models. Mixture-of-Experts (MoE) architecture presents a potential solution, allowing for large model scaling without a proportional rise in computational effort by sparsely activating only a few expert",
      "bert_p": 0.04290975630283356,
      "bert_r": 0.0018358294619247317,
      "bert_f1": 0.023874808102846146
    },
    {
      "paper_id": "duGygkA3QR",
      "prompt": "Background: Graph Neural Networks (GNNs) have been extensively used for prediction tasks involving graph-structured data. Recently, the feature propagation mechanisms of GNNs have been compared to diffusion processes, a perspective that views them as dynamical systems. These analogies have drawn interest towards using dynamical systems theory, particularly Koopman theory and Dynamic Mode Decomposition (DMD), to understand GNN behavior better.\nGap: While there are established connections between GNN feature propagation and diffusion processes, there exists a gap in exploring these dynamics from a physical or system dynamics lens, especially one that rigorously applies modern dynamical systems theories like Koopman theory to assess GNN performance and behavior.\nHypothesis: By integrating Dynamic Mode Decomposition (DMD) with Graph Neural Networks (GNNs), it is possible to estimate a reduced order model that captures complex graph dynamics efficiently and effectively. This integration could enhance GNN performance across various graph learning tasks by providing a sound theoretical basis and data-driven insights via the calculation of low-rank linear operators.\nMethod: The authors introduce a framework called DMD-GNN, where they utilize DMD to estimate a low-rank, finite-dimensional linear operator from multiple state observations of the system. This approximation captures potential nonlinear interactions between graph nodes. Specific DMD-GNN models are developed, which leverage the low-rank eigenfunctions provided by DMD for effective feature propagation. The approach also allows for incorporating domain-specific constraints like symmetry to reflect known physical properties of the systems involved. The method is validated with experiments on tasks including directed graphs, large-scale graphs, long-range interactions, spatial-temporal graphs, and link prediction.\nConclusion: The integration of DMD into GNNs, as proposed by this work, leads to models that deliver state-of-the-art performance across several standard graph-based learning tasks. The DMD-enhanced GNN models are verified experimentally to offer improved accuracy and efficiency, highlighting the practical benefits of viewing GNN feature propagation through the lens of dynamical systems and using DMD to refine this understanding.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 2\nPresentation: 3\nContribution: 2\nRating: 6\nConfidence: 3\n\nExplanation:\nStrengths:\n1. The paper is well written and easy to follow, providing a thorough introduction to the backgrounds of GNNs and DMD. This clarity enhances the reader's understanding of the foundational concepts necessary for grasping the main contributions of the work.\n2. Connecting DMD with GNNs is an interesting perspective.\n3. The authors support their claims with extensive experiments demonstrating the effectiveness of the DMD-GNN models, including evaluations on directed graphs, large-scale graphs, long-range interactions, and spatial-temporal graphs.\n\nWeaknesses:\n1. My main question regarding the paper concerns the motivation: to what extent do the dynamics of GNNs actually influence their performance? Approaching this from the perspective of DMD is interesting, but what specific insights does it offer in understanding GNN performance?\n2. On long-range graph datasets, DMD-GNNs appear to outperform traditional GNNs, but some of the baselines used in the paper seem relatively weak. As far as I know, there is a class of GNNs derived from optimization or energy function approaches that perform reasonably well on such datasets. It would be helpful if the authors could include a few examples of these models for comparison.\n3. It could benefit from a more thorough comparison with frequency-based analysis methods. Since the modes identified by DMD correspond to specific patterns in dynamical systems\u2014similar to how frequency-based methods assume learned graph signals contain both high-frequency and low-frequency components\u2014exploring the relationship between these approaches could yield unique insights. Although the authors provide some explanations in Section 6, illustrating this comparison with specific datasets would strengthen their argument.\n\nQuestions:\nI\u2019m confused about the implementation details of the model, as the paper provides limited description in this part. Standard DMD requires explicit eigendecomposition, and I would like to know how $\\Psi$ and $\\theta$ are determined in Equation 14.\n",
      "model_output": "Instruction: Background: Graph Neural Networks (GNNs) have been extensively used for prediction tasks involving graph-structured data. Recently, the feature propagation mechanisms of GNNs have been compared to diffusion processes, a perspective that views them as dynamical systems. These analogies have drawn interest towards using dynamical systems theory, particularly Koopman theory and Dynamic Mode Decomposition (DMD), to understand GNN behavior better.\nGap: While there are established connections between GNN feature propagation and diffusion processes, there exists a gap in exploring these dynamics from a physical or system dynamics lens, especially one that rigorously applies modern dynamical systems theories like Koopman theory to assess GNN performance and behavior.\nHypothesis: By integrating Dynamic Mode Decomposition (DMD) with Graph Neural Networks (GNNs), it is possible to estimate a reduced order model that captures complex graph dynamics efficiently and effectively. This integration could enhance GNN performance across various graph learning tasks by providing a sound theoretical basis and data-driven insights via the calculation of low-rank linear operators.\nMethod: The authors introduce a framework called DMD-GNN, where they utilize DMD to estimate a low-rank, finite-dimensional linear operator from multiple state observations of the system. This approximation captures potential nonlinear interactions between graph nodes. Specific DMD-GNN models are developed, which leverage the low-rank eigenfunctions provided by DMD for effective feature propagation. The approach also allows for incorporating domain-specific constraints like symmetry to reflect known physical properties of the systems involved. The method is validated with experiments on tasks including directed graphs, large-scale graphs, long-range interactions, spatial-temporal graphs, and link prediction.\nConclusion: The integration of DMD into GNNs, as proposed by this work, leads to models that deliver state-of-the-art performance across several standard graph-based learning tasks. The DMD-enhanced GNN models are verified experimentally to offer improved accuracy and efficiency, highlighting the practical benefits of viewing GNN feature propagation through the lens of dynamical systems and using DMD to refine this understanding.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer:",
      "bert_p": 0.04977036267518997,
      "bert_r": 0.07647096365690231,
      "bert_f1": 0.06460780650377274
    },
    {
      "paper_id": "CpgWRFqxhD",
      "prompt": "Background: Audio-driven talking video generation is gaining attention due to applications in virtual avatars and digital content creation but presents challenges in lip synchronization, identity consistency, and expression alignment with audio. Recent video diffusion models have advanced this field but still face limitations in handling these challenges effectively.\nGap: Existing methods struggle with audio-lip synchronization, maintaining long-term identity consistency, and achieving natural expressions aligned with audio. They rely on fixed audio features and limited past frames for temporal modeling, which leads to artifacts and error accumulation.\nHypothesis: The paper proposes that introducing a memory-guided temporal module and an emotion-aware audio module can enhance long-term identity consistency, motion smoothness, and natural expression generation in audio-driven talking video generation.\nMethod: The paper introduces MEMO, an end-to-end diffusion model with two key modules: a memory-guided temporal module that uses linear attention to model long-term temporal information, and an emotion-aware audio module using multi-modal attention and Emotion AdaNorm for improved audio-video interaction. MEMO is trained on a large dataset without facial inductive biases and includes a training pipeline that involves face domain adaptation, robust scale-up training, and dynamic past frame training. MEMO was evaluated quantitatively against baselines and through human evaluation, demonstrating superior performance in video quality and synchronization.\nConclusion: MEMO significantly improves identity consistency, audio-lip synchronization, and expressive quality of talking videos compared to state-of-the-art methods. It shows robust performance in both standard and out-of-distribution datasets, and effectively generalizes to diverse audio inputs and reference images. Ablation studies confirm the importance of its components, namely the memory module and emotion guidance.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 2\nPresentation: 3\nContribution: 3\nRating: 6\nConfidence: 3\n\nExplanation:\nStrengths:\n1) An improvement over current diffusion-based talking face generation methods. Memory-guided temporal module is the main novelty. The multimodal attention module (combining the representations of audio and video), and the emotion-adaptive layer norm further add to the novelty. All along authors use already existing successful methods like Linear Attention, Adaptive Normalization, classifier-free guidance, rectified flow loss etc to make their work efficient and better.\n2) Dynamic past frame training is an intelligent approach to adapt to longer past frames during inference.\n3) Effort to filter the datasets using a new data processing pipeline and merging of emotion labels is appreciated. Talking face datasets with emotion labels are limited, and every dataset has some biases. So combining these datasets and filtering them can be really helpful in the training process. \n4) Paper has a strong evaluation on Out-of-distribution dataset against relevant methods.\n5) Ablation of classifier-free guidance for amount of emotion incorporation is interesting.\n6) Supplementary material contains impressive results, especially on singing.\n\nWeaknesses:\n1. Paper claims that emotion \"dynamically detected emotion from audio\" is always better than \"static emotion labels\". Accuracy of emotion-classifier used will implicitly determine the quality of talking face generation, no such problem exist with using emotion labels. Moreover If you have want a talking video with emotion different from the audio available, then static emotion label can be a better choice.\n2.  Evaluation metric to analyze the emotion incorporation is missing (something like matching emotions detected from audio input and video generated).\n3. Results included in supp. material are impressive in singing and english-audio, but when the audio-language is not english, methods like EchoMimic seem to generate better video.\n4. Computational analysis can be included for inference speed and memory. It can be really useful for method's applications.\n\nQuestions:\n1. Will you make the dataset public? That will be helpful for community.\n2. Please compare with more emotion-ware methods in the evaluation to better judge the emotion incorporation.\n3. Its guessable from the paper that \"how emotion is included in adaptive layer norm\", Still including the exact method/equation will be helpful.\n",
      "model_output": "Instruction: Background: Audio-driven talking video generation is gaining attention due to applications in virtual avatars and digital content creation but presents challenges in lip synchronization, identity consistency, and expression alignment with audio. Recent video diffusion models have advanced this field but still face limitations in handling these challenges effectively.\nGap: Existing methods struggle with audio-lip synchronization, maintaining long-term identity consistency, and achieving natural expressions aligned with audio. They rely on fixed audio features and limited past frames for temporal modeling, which leads to artifacts and error accumulation.\nHypothesis: The paper proposes that introducing a memory-guided temporal module and an emotion-aware audio module can enhance long-term identity consistency, motion smoothness, and natural expression generation in audio-driven talking video generation.\nMethod: The paper introduces MEMO, an end-to-end diffusion model with two key modules: a memory-guided temporal module that uses linear attention to model long-term temporal information, and an emotion-aware audio module using multi-modal attention and Emotion AdaNorm for improved audio-video interaction. MEMO is trained on a large dataset without facial inductive biases and includes a training pipeline that involves face domain adaptation, robust scale-up training, and dynamic past frame training. MEMO was evaluated quantitatively against baselines and through human evaluation, demonstrating superior performance in video quality and synchronization.\nConclusion: MEMO significantly improves identity consistency, audio-lip synchronization, and expressive quality of talking videos compared to state-of-the-art methods. It shows robust performance in both standard and out-of-distribution datasets, and effectively generalizes to diverse audio inputs and reference images. Ablation studies confirm the importance of its components, namely the memory module and emotion guidance.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer:",
      "bert_p": -0.002688492415472865,
      "bert_r": -0.012186511419713497,
      "bert_f1": -0.005805629771202803
    },
    {
      "paper_id": "GOwNImvCWf",
      "prompt": "Background: The paper discusses the increasing recognition of neural network (NN) weights as a data modality in machine learning, used for tasks such as accuracy prediction, hyperparameter tuning, representation learning, and weight generation. Autoencoders (AEs) have been applied to NN weights to learn latent representations that assist in varied downstream tasks including model reconstruction and weight generation.\nGap: Despite low reconstruction error, models reconstructed from AEs trained on structural losses alone do not match the performance of original NNs. This is due to the failure of structural weight reconstruction to capture features critical for high performance.\nHypothesis: The incorporation of a behavioral loss in the autoencoder training, alongside a structural loss, can capture the necessary features for reconstructing high-performing NNs by emphasizing functional similarity between original and reconstructed models.\nMethod: The authors propose a composite loss function for autoencoders where the structural and behavioral losses are combined. The behavioral loss is calculated by comparing the outputs of the original and reconstructed models over a set of input queries, emphasizing functional equivalence. The performance of this approach is evaluated across three model zoos using different datasets (SVHN, CIFAR-10, EuroSAT) for both reconstructive and generative tasks.\nConclusion: Combining structural and behavioral losses improves the performance of the reconstructed models, enabling them to match the performance of original models more closely. This synergy also enhances performance across discriminative, reconstructive, and generative downstream tasks, demonstrating the importance of both structure and behavior in learning weight space representations.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n",
      "gold_response": "Soundness: 3\nPresentation: 3\nContribution: 2\nRating: 3\nConfidence: 5\n\nExplanation:\nStrengths:\n- The paper is well written and easy to follow.\n- The motivation for the proposed solution is well explained and investigated.\n- Simple solution.\n\nWeaknesses:\n- My main concern regarding this work is around its novelty the behavioral loss was already used in [1]. In [1] the authors calculated the loss based on the loss on the downstream task. In addition, there is no novelty (and it was not claimed) on the architecture side since the authors used SANE [2] for the weight space AE. How do the authors differentiate their work from [1]?\n- Limited experimental section. Given the fact that this work is mostly empirical, I expect the experimental section to be more extensive both in scale and learning setups. The authors focused on discriminative models and specifically only on small CNNs. There is no diversity in the reconstructed model architecture or the downstream tasks.\n- It would be interesting to see how significant are $\\beta$ and $\\gamma$ hyperparameters in the AE optimization.\n- The authors mentioned in the appendix that training with behavioral loss nearly doubles the training duration, which poses a challenge for large models.\n-Rather than using a common model zoo [3,4], the authors chose to create their own, which raises some questions.\n- The authors did not include confidence intervals in the experimental section. Moreover, in Tables 5 and 6 the authors provide additional results which are inclusive due to high std values. The same should be reported in the main text results.\n- The only augmentation used for $\\mathcal{L}_C$ is a random permutation, why the authors did not use augmentations from [5,6]? [6] should be cited in this work.\n\n--------------\n[1] Equivariant Deep Weight Space Alignment, Navon et al.\n\n[2] Towards Scalable and Versatile Weight Space Learning, Schurholt et al.\n\n[3] Model Zoo: A Dataset of Diverse Populations of Neural Network Models, Schurholt et al.\n\n[4] Eurosat Model Zoo: A Dataset and Benchmark on Populations of Neural Networks and Its Sparsified Model Twins, Honegger et al.\n\n[5] Equivariant Architectures for Learning in Deep Weight Spaces, Navon et al.\n\n[6] Improved Generalization of Weight Space Networks via Augmentations, Shamsian et al.\n\nQuestions:\n- Based on the findings in Section 2, have the authors considered explicitly encouraging hybrid eigenvalue features? For example, they might incorporate a KL divergence loss relative to a predefined Beta distribution concentrated in the high and low values, effectively ignoring the intermediate range.\n",
      "model_output": "Instruction: Background: The paper discusses the increasing recognition of neural network (NN) weights as a data modality in machine learning, used for tasks such as accuracy prediction, hyperparameter tuning, representation learning, and weight generation. Autoencoders (AEs) have been applied to NN weights to learn latent representations that assist in varied downstream tasks including model reconstruction and weight generation.\nGap: Despite low reconstruction error, models reconstructed from AEs trained on structural losses alone do not match the performance of original NNs. This is due to the failure of structural weight reconstruction to capture features critical for high performance.\nHypothesis: The incorporation of a behavioral loss in the autoencoder training, alongside a structural loss, can capture the necessary features for reconstructing high-performing NNs by emphasizing functional similarity between original and reconstructed models.\nMethod: The authors propose a composite loss function for autoencoders where the structural and behavioral losses are combined. The behavioral loss is calculated by comparing the outputs of the original and reconstructed models over a set of input queries, emphasizing functional equivalence. The performance of this approach is evaluated across three model zoos using different datasets (SVHN, CIFAR-10, EuroSAT) for both reconstructive and generative tasks.\nConclusion: Combining structural and behavioral losses improves the performance of the reconstructed models, enabling them to match the performance of original models more closely. This synergy also enhances performance across discriminative, reconstructive, and generative downstream tasks, demonstrating the importance of both structure and behavior in learning weight space representations.\n\nCategories (1\u20135):\n- Soundness: The rigor of the methods for the stated problem\n- Presentation: The clarity of writing and organization\n- Contribution: The paper\u2019s novelty or added value to the domain\n\nAdditionally:\n- Rating (1\u201310): Overall recommendation for acceptance\n- Confidence (1\u20135): How confident the reviewer is in their assessment\n\nPlease provide:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Explanation (strengths, weaknesses)\n7) Questions\n\nInput:\nAnswer:",
      "bert_p": -0.05840077996253967,
      "bert_r": -0.10191435366868973,
      "bert_f1": -0.07850119471549988
    }
  ]
}