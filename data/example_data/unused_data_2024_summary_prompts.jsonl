{"paper_id": "4N7v4w2r3b", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: The robustness of neural network proxies is critical as these models are increasingly used in various domains to optimize or monitor quantities of interest. Proxies often serve as stand-ins for true objectives that are costly or difficult to evaluate directly. Despite their practicality, proxies are susceptible to 'gaming,' where optimization pressure leads them to fail in representing the true objective accurately. This issue has been acknowledged in several domains, including education and public policy, and poses significant risks when neural networks are tasked with capturing human values and preferences.\nGap: The robustness of neural network proxies under optimization pressure remains largely unexplored and unsolved. Existing research indicates that proxies may collapse under optimization pressure, but there is limited work on systematically evaluating proxy robustness and developing robust methods.\nHypothesis: Proxy robustness is a solvable problem that can be incrementally improved, and devising comprehensive benchmarks can uncover new properties of the proxy gaming problem, aiding in the development of methods to enhance proxy robustness.\nMethod: The paper introduces \"ProxyBench,\" a benchmark to assess the robustness of neural network proxies against optimization pressure in the text domain, particularly in Reinforcement Learning from Human Feedback (RLHF) settings. The benchmark includes: (1) gold reward models, representing true objectives; (2) a dataset of example prompts paired with preferred responses to train proxy models; and (3) various optimization methods, including best-of-n (BoN), reinforcement learning (RL), and white-box adversarial optimization. Multiple experiments are conducted using baselines and variations of proxy models, evaluating them under different optimization pressures to measure the divergence between proxy and gold rewards and identify gaming.\nConclusion: The study finds that proxy models are prone to gaming under optimization pressure, and this vulnerability increases with the complexity and scale of both the policy and the optimization process. Larger proxy models exhibit more robustness, but common methods like adversarial training are insufficient, as they do not significantly improve robustness across all settings. This underscores the need for new techniques to enhance the robustness of proxy models, and the open-sourcing of the benchmark and experiment code aims to facilitate further research in this area.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 4, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"The strengths of the work is listed below:\\n1. The introduction of ProxyBench is a substantial contribution, as it provides a practical and comprehensive benchmark for assessing the robustness of neural network proxies against optimization pressure, especially in the text domain.\\n2. The paper conducted extensive experimental studies, and the insights from the statistics are very meaningful.\\n3. This work uncovers the relationship between proxy model size and its robustness, contributing to the understanding of how different factors like model parameters, training data, and training steps affect proxy stability.\\n4. The introduction of metrics for evaluating proxy reward model robustness and detailed analysis on the performance of baseline methods are practical.\\n5. The exploration of different optimization strategies, including best-of-n, reinforcement learning, and white-box optimization, indicates a deep understanding of the landscape and provides a nuanced perspective on potential vulnerabilities.\", \"Weaknesses\": \"1. Assumption of Gold Model Accuracy (Section 4.1): The paper assumes that the ensemble of functions trained on human preferences accurately reflects the true objective. However, there's an inherent assumption that the datasets used encompass all aspects of \\\"helpful and harmless\\\" which might not be comprehensive. There is also a risk that the ensemble could inherit systemic biases or errors present in the training datasets.\\n2. Training the proxy model on a fixed dataset without further interaction with the gold model may not reflect the iterative nature of learning and adapting to new data.\\n3. There is a missing relevant work \\\"TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization, ICLR2023\\\".\\n4. The paper notes a significant correlation of gamed examples across different proxy models. This suggests potential inherent weaknesses or biases in the training process or data. However, the paper does not provide a detailed analysis of the underlying causes of this correlation or strategies to mitigate it.\\n5. The appearance of phase shifts in reward curves during RLHF optimization highlights that current methods may not capture the complexity of policy learning dynamics. The paper's methods might be missing other, subtler forms of proxy gaming.\", \"Questions\": \"I do not have other questions. Please refer to the weakness colum above.\"}"}]}
{"paper_id": "GtnNhtuVrc", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Supervised learning is essential in modern computer vision but requires extensive labeled data, which is costly. Semi-supervised learning (SSL) combines labeled and unlabeled data to address this challenge, particularly useful in tasks like semantic segmentation where manual labeling is expensive. Pseudo-labeling is a popular SSL approach where labels are dynamically assigned based on model predictions but suffers from confirmation bias and erroneous predictions.\nGap: Current pseudo-labeling methods suffer from confirmation bias and rely heavily on filtering low-confidence predictions, which can lead to overfitting and inefficient learning when labeled data is sparse.\nHypothesis: Incorporating spatial contextual information in confidence refinement can improve pseudo-labeling in semi-supervised semantic segmentation. By considering neighboring pixels collectively, it is possible to increase the availability of pseudo-labels without a loss in accuracy.\nMethod: The authors propose S4MC, a novel confidence refinement scheme. It employs a teacher-student paradigm with event-union probability for grouping neighboring pixels and evaluating their pseudo-labels collectively. The method includes pseudo-label refinement, dynamic partition adjustment for thresholding, and considers spatial context to refine pseudo-label creation. It uses a teacher-student setup where the teacher model is updated via an exponential moving average of student weights. The approach was experimentally validated on datasets like PASCAL VOC 12, Cityscapes, and MS COCO, where it showed improvements in mIoU over existing methods.\nConclusion: S4MC leverages marginal contextual information to enhance pseudo-labels in semi-supervised semantic segmentation, outperforming existing methods in benchmarks and increasing data usage while maintaining label quality. The method shows potential for reducing annotation costs but may not generalize to non-spatially coherent tasks without modification.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 3, \"Strengths\": \"Originality: The approach offers some degree of novelty - filtering low-confidence predictions by using the context around the pixel, rather than the pixel in isolation (current sota approaches). The contribution is relevant to an actual problem, it increases the use of unlabeled data.\\nQuality: The method is sound and thoroughly explained. Experiments prove the effectiveness of the approach when applied on top of state-of-the-art methods with a negligible added computational cost. \\nClarity: The paper is an interesting read, well-structured, well-detailed, and very easy to understand (fairly enjoyed reading it). \\nSignificance: The results offer marginal improvements only in some scenarios, compared to state-of-the-art methods.\", \"Weaknesses\": \"* I would suggest changing the main figure of the paper (the elements within the figure are way too small and hard to follow).\\n* The contribution is not groundbreaking. The +1.29 mIoU gain on PASCAL VOC 2012 and +1.01 mIoU improvement on Cityscapes declared at the beginning of the paper are not backed up by the numbers in the table (Table 1 and Table 3). The numbers in the tables show that the method is not robust enough to offer a consistent improvement in all tested scenarios.  \\n* The biggest weakness of the paper is Section 4.3 (the ablation studies) and Tables 4 & 5. The text states that the experiments were conducted using the CutMix-Seg framework, but I could not find the numbers in the previous tables. Also in Table 5, the caption states that the numbers are for FixMatch. The text, the numbers, and the tables do not correspond, this part needs further clarification (or another check) because it confuses me the most. \\n* Low range of datasets, more experiments that include more varied and challenging scenarios to better understand the method's limitations.\", \"Questions\": \"* There are no insights as to why the best window for the used contextual information is in a 3x3 range - this actually suggests that the context is not used properly, or what is actually causing this degradation in performance when more neighboring pixels are used?\"}"}]}
{"paper_id": "28L2FCtMWq", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Recent advancements in video editing have achieved success in single-attribute editing and style transfer using text-to-video (T2V) models. These models either require training on text-video datasets or use training-free methods. However, complex multi-attribute editing remains challenging, often resulting in issues like omitted edits, incorrect modifications, and poor consistency.\nGap: Current video editing techniques struggle with multi-attribute editing, often failing to make all intended changes, applying edits to the wrong elements, or altering regions that should remain unchanged. This indicates a lack of precision and consistency in handling multiple attributes simultaneously.\nHypothesis: The authors propose that integrating grounding information through a novel framework can achieve temporally consistent multi-attribute video editing in a training-free manner, thus overcoming the shortcomings of existing methods.\nMethod: The proposed method, Ground-A-Video, employs cross-frame gated attention combined with modulated cross-attention and optical flow guided inverted latents smoothing. This approach incorporates grounding information\u2014bounding box coordinates and textual descriptions\u2014into the latent representations to ensure precise and temporally consistent edits across video frames without additional training. The framework utilizes Stable Diffusion and ControlNet for structure preservation and employs DDIM inversion for video frames. Groundings are used to guide spatially-continuous and discrete editing, with experiments demonstrating superior performance in edit-accuracy and frame consistency compared to baseline methods.\nConclusion: Ground-A-Video effectively addresses the limitations of current video editing techniques, achieving superior accuracy and temporal consistency in multi-attribute video editing scenarios through a zero-shot approach. The method demonstrates improved performance over existing solutions by incorporating grounding information to guide edits in a structured and consistent manner.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 4, \"Strengths\": \"S1. This paper presents the \ufb01rst training-free grounding-driven video editing framework, which is relatively innovative.\\n\\nS2. The proposed method and experimental results are consistent with their motivation and e\ufb00ectively solve the problem of multi-attribute video editing in complex scenes.\\n\\nS3. The method is clearly stated, and the details are comprehensive.\", \"Weaknesses\": \"W1. Since the introduced depth map and optical \ufb02ow map both re\ufb02ect pixel-level structural information, will this cause the structure before and after editing to be too consistent, so that if the foreground is replaced by an object with inconsistent structure, the editing result will be poor and lack of \ufb02exibility? e.g. replace the \u201crabbit\u201d in the phrase \\\"A rabbit is eating a watermelon on the table\\\" with an animal without long ears.\\n\\nW2. For similar reasons, this may also limit the editing method to the task of adding or deleting objects.\", \"Questions\": \"See weaknesses above.\"}"}]}
{"paper_id": "BpAxeHmQ94", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Recent advances have shown that deep learning models are highly vulnerable to adversarial examples, leading to the development of defensive mechanisms divided into empirical defenses that lack robustness guarantees and certifiable methods that offer robustness certificates. Certifiable methods focus on model robustness within certain perturbation norms. There is also an increasing interest in cost-sensitive learning, where different adversarial misclassifications incur different costs, which is vital when certain misclassifications have more significant real-world consequences.\nGap: Existing methods for adversarially robust classification either do not provide robustness certification or face scalability issues. While many methods focus on improving overall model robustness, they often disregard the varying costs of different adversarial misclassifications. There is a need for scalable, certifiable methods that also account for these cost sensitivities.\nHypothesis: Randomized smoothing, a scalable robustness certification framework, can be adapted to certify cost-sensitive robustness. By introducing a cost-sensitive certified radius, it is possible to provide tight robustness guarantees customized for any given cost matrix.\nMethod: The paper introduces a cost-sensitive certified radius, an adaptation of the traditional randomized smoothing certification, to account for class-specific misclassification costs. This involves extending the standard randomized smoothing framework to include cost-sensitive considerations, optimizing smoothed classifiers through fine-grained radius optimization schemes, and training with a focus on different data subgroups. The method involves using Monte Carlo sampling to estimate robustness bounds and aims to balance the trade-off between cost-sensitive robustness and overall accuracy. Experiments on image benchmarks and a real-world medical dataset demonstrate the approach.\nConclusion: The proposed method significantly improves certified cost-sensitive robustness without compromising overall accuracy, as demonstrated through experiments. It outperforms baseline methods, offering a better trade-off between robustness and accuracy while providing tight robustness guarantees for various cost matrices. The study opens new opportunities for developing certifiably robust models that align better with cost-sensitive real-world applications.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"The paper studies provable robustness in a setting that has largely remained unexplored. The paper is well-written and easy to follow.\", \"Weaknesses\": \"1. Binary Cost Matrix: A 0/1 cost matrix may not be sufficient to capture real-world cost-sensitive ML tasks. The cost of misclassification would rarely be zero. Take the example mentioned in the second paragraph of the introduction. While misclassifying a benign tumor as malignant is less detrimental than the reverse, the cost of such a misclassification will not be zero. If so, one could simply label all tumors as malignant and achieve an overall classification cost of zero. However, such a classifier would not provide us with any valuable information.\\n\\n   It would be more impactful to design robustness certificates for a general cost matrix where the entries need not be 0/1. It might be possible to certify the expected misclassification cost by using the distribution of the cost under the smoothing noise. The following work on certifying the expected confidence of a neural network could be adapted for a general cost matrix:\\n\\n   Certifying Confidence via Randomized Smoothing, Kumar et al., NeurIPS 2020.\\n\\n2. Novelty: The robustness certificate designed in this work is a straightforward adaptation of Cohen et al.'s certificate [1]. The certificate in [1] takes the difference between two terms where the second term depends on p_b, the probability of the second most likely class. This paper redefines p_b as the probability of the most likely class in the set of class labels with cost 1.\\n\\n   [1] Certified Adversarial Robustness via Randomized Smoothing, Cohen et al., ICML 2019.\\n\\n3. Sample Complexity: The number of samples required for computing the proposed certificate is higher than that of the baseline certificate from [1]. It depends on the number of classes with cost 1. While this might be manageable for the small number of classes considered in the experiments (<= 10), scaling to a large number of classes, such as in ImageNet (1000 classes), would be difficult.\", \"Questions\": \"1. What would be a practical application where a binary cost matrix would be sufficient? In most scenarios, the misclassification cost would take a range of different values.\\n\\n2. During inference, when the ground truth is unknown, how do we find the classes with cost 1? This set depends on the correct class label, which is not known during inference.\"}"}]}
{"paper_id": "DO2WFXU1Be", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Physics-Informed Neural Networks (PINNs) have gained traction in numerically solving partial differential equations (PDEs) due to their ability to embed physical laws within the neural network framework. Traditional numerical methods, like the finite element or pseudo-spectral methods, are computationally costly, especially in high dimensions. PINNs, using multilayer perceptrons (MLP), have achieved success in various applications but struggle with high-frequency or multiscale features and typically neglect temporal dependencies.\nGap: Conventional PINNs rely on MLPs which often fail to model temporal dependencies in physical systems properly. This shortcoming results in inaccurate global solutions, as PINNs cannot effectively propagate initial condition constraints and accurately capture dynamic PDE solutions. Current approaches to improve PINNs, such as data interpolation and training scheme variations, often involve high computational costs and still fail to handle specific PINN failure modes.\nHypothesis: The authors propose that a Transformer-based approach, called PINNsFormer, which utilizes multi-head attention mechanisms, can better capture temporal dependencies in PDE solutions. By transforming point-wise inputs into pseudo sequences and employing a sequential loss, this framework aims to improve the generalization and accuracy of solutions obtained by PINNs.\nMethod: The methodology involves designing a new framework, PINNsFormer, which applies a Transformer architecture to PINNs. Key components include a Pseudo Sequence Generator for transforming inputs into time series, a Spatio-Temporal Mixer for data embedding, and an Encoder-Decoder architecture to model temporal dependencies using self-attention. Additionally, a novel activation function, Wavelet, is introduced to anticipate Fourier decomposition, enhancing the approximating power of the network. The model is trained using a modified loss function, tailored for sequential data, which allows PINNsFormer to handle boundary and initial conditions appropriately.\nConclusion: Empirical evaluations demonstrate that PINNsFormer outperforms traditional PINNs and their variants in generalizing solutions to complex PDEs, mitigating known failure modes, and handling high-dimensional problems. The framework's flexibility also allows it to integrate with other learning schemes, further boosting performance. The findings suggest that focusing on capturing temporal dependencies significantly improves the accuracy and robustness of PDE solutions obtained using PINNs.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 4, \"Contribution\": 4, \"Rating\": 8, \"Confidence\": 5, \"Strengths\": \"Impressive results.  Clear representation.\", \"Weaknesses\": \"The system is using a time discretised set of function values to predict the next time step. This reminds me of the finite difference method, In this case the stencil is 100 elements long, so the optimum stencil would have a very high order in accuracy. \\n\\nThe reason why very large stencils are not used is that these bear a computational cost, and the same happens in using attention, although most of the computing is parallel.\\n\\nNow the manuscript does not provide a baseline using a normal, discrete PDE solver, of course,  on the par with the  computational load that the attention mechanism is requiring . Of course, having an analytical, although complicated, solution for a problem has its advantages compared to a set of discrete nodal values.\\n\\nI would like that the authors would address this in their submission for better rating.\", \"Questions\": \"See the weakness part.\"}"}]}
{"paper_id": "hH5HK4hsLY", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Fingerprint recognition is a widely used biometric identification method owing to its uniqueness and permanence. It is essential in law enforcement, personal identification, and secure authentication. Traditional fingerprint recognition methods often use minutiae matching, which can be sensitive to noise and partial prints. More recently, convolutional neural networks (CNNs) have been employed to handle these challenges better, enhancing the accuracy and scalability of fingerprint recognition systems. Self-supervised learning has also emerged as a powerful approach for learning representations without requiring labeled data.\nGap: The main problem addressed in this paper is the challenge of deriving robust fingerprint representations that can improve verification performance, especially from degraded images, without relying heavily on enhanced sample data. Existing methods, particularly those based on minutiae matching, face limitations due to noise sensitivity and difficulties handling partial or distorted fingerprints.\nHypothesis: The authors propose that leveraging a U-Net-based fingerprint enhancement approach for pre-training can help obtain robust fingerprint representations in a self-supervised setting, which can significantly improve fingerprint verification accuracy, especially when dealing with degraded images.\nMethod: The proposed method involves a two-stage framework leveraging U-Net architecture. The first stage is self-supervised pre-training of a U-Net encoder on a fingerprint enhancement task, aiming to learn meaningful features from degraded fingerprints. The second stage involves adding a multi-layer perceptron (MLP) for fingerprint verification, using the encodings from the pre-trained encoder. This involves freezing the encoder's weights and training the MLP for fingerprint verification using labeled data. The approach is compared against other self-supervised methods using datasets like SFinGe, FVC, and NIST SD-302, with augmentation techniques like rotation and color jitter used during training.\nConclusion: The proposed enhancement-driven pre-training method outperformed existing self-supervised techniques in learning stable and effective fingerprint representations for verification tasks. The results suggest that it is possible to derive meaningful fingerprint representations from degraded images without relying on enhanced samples. However, the method showed better performance on synthetic datasets than on real-world data, indicating potential biases and the challenges of real-world application.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"The main strength of the paper is its set of experimental results. They indicate that the proposed approach provides better accuracies than other comparable approaches, such as SimCLR, SimSiam, MoCo and BYOL.\\n\\nAnother strength of the paper is that it is easy to understand and the quality of the language is good.\", \"Weaknesses\": \"This manuscript has following high-level weaknesses that need to be addressed in any revision.\\n\\n1. Fingerprint verification accuracy on FVC test dataset is worse than on SFinGe test dataset. While I agree with the authors' explanation that it \\\"might be due to underrepresentation of FVC data in the training sets, leading to potential bias, and also due to inherent complexities in real-life fingerprint data, which are harder to handle\\\", these challenges are faced by all learning-based fingerprint recognition approaches and solutions that don't perform well on real data will be less attractive.\\n\\n2. Perhaps this is a weakness for deep learning based fingerprint recognition systems, but given that there are many real-world fingerprint verification systems based on minutiae matching, there needs to be a stronger case made for how the proposed deep learning approach is expected to have an impact in the real world.\\n\\n3. It is not sufficiently explained what \\\"self supervision\\\" means in this paper. My understanding is that both degraded and enhanced fingerprints are used for training. Aren't the enhanced fingerprints akin to having ground truth and if so isn't that training supervised? Not enough details are provided to understand this correctly.\\n\\n4. The paper needs to provide more mathematical details of the proposed approach. For example, more details should be provided about the fingerprint enhancement procedure and results.\\n\\n5. It is not clear what attributes of fingerprints are being taken advantage of, in the proposed approach. Are fingerprint geometric structures or minutiae being used somehow in the training? Overall, this paper is lacking in technical details.\", \"Questions\": \"1. Please be more clear about what self-supervision refers to.\\n\\n2. Provide more details about the fingerprint enhancement process. How is the enhancement quality evaluated?\\n\\n3. In Fig. 3, I assume that degraded images are on top and enhanced ones on the bottom  --- if this is correct, please state that in that figure caption.  It appears that the fingerprint degradation is artificial and not based on real-world challenges. If that is correct, could it be the reason for the poorer performance on FVC datasets?\\n\\n4. I am a little confused about how the accuracy numbers on the entire dataset are computed. In Table 2, it is stated that the accuracy of the proposed method on the entire data is 0.973. But if the impostor accuracy is 0.982 and the genuine accuracy is 0.886 and the data split is 1 genuine pair for every 3 impostor pairs, shouldn't the overall accuracy be (3*0.982 + 1*0.886)/4 = 0.958, not 0.973?\"}"}]}
{"paper_id": "jFox1iMWUa", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Causal inference is essential in many fields such as medical decision-making, advertising evaluation, and voucher distribution, where it aims to estimate the causal effect of treatments on outcomes using observational data. Traditional approaches struggle with bias due to confounding factors and often only rank samples by uplift rather than precisely estimating treatment effects, especially when treatments are continuous.\nGap: Existing methods for causal inference often fail to adequately model the response performance while handling continuous treatments and mitigating confounding bias. Most previous work has focused on categorical or binary treatments and has not sufficiently addressed continuous treatments or provided unbiased uplift estimation in the presence of confounders.\nHypothesis: An end-to-end multi-task deep neural network can effectively capture the relationship between treatment propensity and treatment effect in scenarios with continuous treatments, thereby providing better uplift modeling by balancing estimation of response performance and individual treatment effect.\nMethod: The authors propose a three-headed neural network structure comprising logistic, monotonicity, and Diffloss networks to estimate continuous treatment effects while addressing confounder bias. The approach involves embedding treatments and features into networks to predict outcomes based on mutually independent factors. This architecture is tested using semi-synthetic and real-world datasets, and its effectiveness is further evaluated by implementing it in an online voucher distribution system on a major ride-hailing platform.\nConclusion: The proposed method manages to balance response estimation and uplift ranking, outperforming benchmarks in terms of estimation accuracy for individual treatment effects (ITE) and uplift. Online testing in a real-world application showed improved market scale and better return on investment (ROI) compared to existing models.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 1, \"Presentation\": 1, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"Continuous treatment effect estimation is a significant problem in causal inference.\", \"Weaknesses\": \"- **The statement \\\"The following mild assumptions are made (Holland (1986); Kennedy et al. (2017))\\\" does not correspond to reality. The Monotonicity Assumption is not mentioned in (Holland (1986); Kennedy et al. (2017)), and the Consistency Assumption also differs from the one proposed by Kennedy et al. (2017). Furthermore, there are many other statements in this paper that do not match reality.**\\n\\n- The writing needs significant improvement. The survey on relevant literature is not comprehensive. \\n\\n- The statement \\\"Traditional methods focus on the ordering of the problem. Little attention has been paid to the response performance, neither on the evaluation metric, nor the modeling\\\" is confusing. In both binary and continuous settings, researchers have recently proposed numerous estimators to predict CATE or ITE, such as Johansson et al. (2016), Shalit et al. (2017), Bica et al. (2019; 2020), Schwab et al. (2020) and Nie et al. (2021). Recent deep methods typically use PEHE or MSE on CATE to evaluate the response performance, and none of them focus on the ordering of the problem. This statement contradicts my understanding.\\n\\n- The statement \\\"Not to mention that most of the works limit to categorical treatment\\\" is incorrect. Recently, many machine learning IV algorithms have been proposed to identify CATE and are not limited to categorical treatment, such as NPIV, DeepIV, KernelIV, DualIV, FastIV, DFIV, CBIV, AGMM, and DeepGMM.  **The survey on relevant literature is not comprehensive.** \\n\\n- The statement \\\"Most works in causal inference area focus on the binary or discrete treatment case. The continuous treatment case is less studied\\\" is incorrect. Many studies have been conducted on estimating continuous treatment effects, particularly in predicting average dose-response function (ADRF) or average dose-response curve (ADRC) to identify causal effects. Some notable works in this area include (Robins et al., 2000), (Hirano & Imbens, 2004), (Imai et al., 2004), (Flores et al., 2007), (Flores et al., 2012), (Kennedy et al., 2017), (Wilson et al., 2018), (Kallus et al., 2019), (Colangelo et al., 2020), (Sharma et al., 2020), (Klosin, 2021), (Linton & Zhang, 2021), (Zhang et al., 2022), and many others. **The survey on relevant literature is not comprehensive.** \\n\\n- That statement \\\"Conditional average treatment effect (CATE) is known as causal inference\\\" is incorrect. Conditional average treatment effect (CATE) is not synonymous with causal inference. CATE refers to the average effect of a treatment (intervention) on an outcome under a specific condition. Causal inference, on the other hand, involves analyzing causal relationships to determine the effect of a treatment (intervention) on an outcome of interest. CATE is one method used in causal inference, but they are not identical concepts.\\n\\n- **Algorithm**: The feature X is a common cause of treatment T and outcome Y, which could potentially confound the causal effect of T on Y. Although this paper uses lossdiff to make embedding b independent of treatment T, the embedding factor w may remain confounders of the causal effect of T on Y. How to address the confounding bias from w?\\n\\n- **Experiments**: Due to the incomplete literature review, the paper lacks a comprehensive evaluation and comparison with existing methods, such as GPS (Imbens, 2000; Fong, 2018), DRNet (Schwab et al., 2020), SCIGAN (Bica et al., 2020), VCNet (Nie et al., 2021), making it difficult to assess the practical contribution of the proposed approach.\", \"Questions\": \"See Above.\"}"}]}
{"paper_id": "9lvyCHhQix", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Continual Learning (CL) involves the ability of models to learn continuously from non-stationary data distributions, often addressing the issue of catastrophic forgetting, where new tasks negatively impact previously learned ones. Previous CL approaches focus primarily on avoiding forgetting but often do not balance parameter efficiency and capacity saturation. Parameter efficiency ensures the effective use of parameters without overfitting, while capacity saturation can occur when a model's ability to generalize is compromised as task diversity increases.\nGap: Existing approaches to continual learning struggle with the trade-off between parameter efficiency and capacity saturation, which is particularly problematic in long-term task-incremental settings with storage constraints. The challenge is maintaining parameter efficiency while handling capacity saturation for evolving tasks, which current methods fail to adequately address.\nHypothesis: The paper hypothesizes that a dynamic approach to expanding a model's weight space can effectively balance parameter efficiency and capacity saturation in continual learning. By introducing a knowledge hypergraph structure that captures latent knowledge across tasks, it is possible to measure task diversity and estimate necessary capacity increases for new tasks, ensuring efficient parameter usage and avoiding capacity saturation.\nMethod: The authors propose a novel CL approach called Continual Knowledge HyperGraph Learning (HyperGKL). This method introduces a dynamic knowledge hypergraph structure, which identifies and leverages latent knowledge across tasks to measure task diversity and manage capacity increases for new tasks. The hypergraph connects shared skills across tasks and estimates the required capacity increment. The method uses a hypernetwork for dynamic skill-specific subnetwork generation to ensure constant parameter numbers over time. It involves decomposing tasks into skills, constructing a dynamic hypergraph, and using constraints and parameter generators to manage adaptation and efficiency. The approach is empirically validated on several benchmark CL datasets, comparing it with existing methods for performance and resource utilization.\nConclusion: The proposed HyperGKL method effectively addresses the balance between parameter efficiency and capacity saturation in continual learning, achieving state-of-the-art results on several benchmark datasets. It maintains low parameter counts through a novel hypergraph structure and a hypernetwork that dynamically manages model complexity, demonstrating its robustness in long-term, memory-constrained CL scenarios.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"- The trade-off between capacity saturation and parameter efficiency is an interesting point that is not discussed frequently\\n- The idea of modeling a task diversity using hyper graphs seem novel\", \"Weaknesses\": \"- The setting in which capacity saturation and parameter efficiency really matters is, as mentioned in the manuscript, when CL methods are deployed on edge devices with little memory. This is the main reason why replay-based CL methods are seldom compared to in the submission but I disagree. If using a replay buffer is too costly, what's to say that expanding the model size (however efficiently that might be) is not too costly? Replay based CL methods can be understood as having the best parameter efficiency (as the model size does not grow) and tackling the capacity saturation issue with past task samples in the replay buffer. I think more comparisons both in terms of concepts and experiments should be done against replay based CL methods to really justify the proposed trade-off in the paper.\", \"Questions\": \"Please see the weaknesses.\"}"}]}
{"paper_id": "YxvmODVWny", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Natural language and images are typically used for goal specification in goal-conditioned imitation learning, but each has limitations. Language can be ambiguous, and images can be over-specified. The paper explores hand-drawn sketches as a new modality, which is easy to create like language but more spatially aware like images.\nGap: The gap identified is the lack of a goal representation that balances the intuitive, easy-to-provide nature of language with the spatial precision of images, all while avoiding the overspecification issue inherent in images and the ambiguity in natural language for goal-conditioned imitation learning.\nHypothesis: Hand-drawn sketches can serve as an effective goal representation in visual imitation learning by providing a balance between abstraction and spatial specificity, leading to better task performance, especially in the presence of ambiguities or visual distractors.\nMethod: The approach involves developing RT-Sketch, a policy that uses hand-drawn sketches for manipulation tasks. The model is trained on a dataset of 80K trajectories paired with synthetically generated sketches. An image-to-sketch translation network is used to generate goal sketches from images which are then used to train the policy using imitation learning. Experimentation is conducted across six manipulation tasks with varying scene complexities on real robots.\nConclusion: RT-Sketch is shown to perform on par with language and image-conditioned policies in straightforward settings while demonstrating greater robustness to language ambiguity and visual distractions. The model also adapts well to sketches with varying details, from simple lines to colored drawings, indicating its flexibility and potential practical advantages in real-world applications.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"- The direction the authors are going with this work, thinking about different ways of specifying a goal, will be useful for improving accessibility and has intellectual merits. \\n- The authors take steps to perform surveys to study human preference in specifying goals rather than just quantitative analysis through robot performance.\\n- Creation of the RT-Sketch dataset and the Image-To-Sketch model have technical merits.\\n- The limitations and failure modes are honest from a methodology perspective and are appreciated.\\n- Overall this paper is well written, Figure 2 does a good job of demonstrating the architecture of RT-Sketch and Figure 3 does a great job of conveying the survey results.\", \"Weaknesses\": \"The main concerns with this manuscript come from two sources. The first is with respect to the motivation of using sketches to specify a goal and the second is concerning the quantitative robotics results.\\n## Motivation\\nOverall the reviewer is not convinced that the examples and arguments given motivate the superiority of using a sketch as a goal over using natural language.\\n- Regarding the granularity argument that the authors use in the introduction including the examples of \\\"put utensils, ..., on the table\\\" and \\\"put the fork 2cm to the right...\\\". Doesn't this demonstrate the flexibility that language has as a goal? Even if a human had to communicate the placement of utensils on a table, this would still seem easier than drawing a corresponding representation for an entire table.\\n- While language can be ambiguous, so can sketches. As an example, if a sketch was given with an empty table, am I telling the agent that I want it to throw out the garbage on the table or am I telling it to ignore the garbage? It would seem like the desirable solution would be to create more intelligent agents to create reasonable solutions or ask for clarifications when given an ambiguous problem.\\n\\n## Robotics Results\\n- The metrics, \\\"Spatial Precision\\\" and \\\"Failure Occurrence\\\" are not carefully defined or motivated. Failure occurrence is not defined at all. The spatial precision metric is at best defined as \\\"the distance (in pixels) between object centroids in achieved and ground truth goal states, using manual keypoint annotation\\\". However, how these centroids are obtained and why manual keypoint annotation is necessary over using an off-the-shelf image classifier should have been mentioned. \\n- It is not obvious how big of a difference the errors are when looking at the RMSE in pixels. Could the errors when finding the centroid and the manual keypoint annotations be an issue in measuring this? Can a visualization be created to show this?\\n- Typically bolded numbers in a column/row represent the method with best performance. However, in the column for failure occurrences, RT-Goal-Image is bolded despite having the highest failure occurrence.\\n- The meaning of the shading of the cells of Table 1 adds a lot of confusion and should have been defined in the caption to improve readability. This confusion comes because, in one portion of the table, darker gray colors represent lower centroid distance and in another portion it represents the frequency of failures. This frequency of failure metric is also not well defined, how is this different than failure occurrence?\", \"Questions\": \"Beyond the concerns and questions given in the weakness section.\\n\\n- How many people took the survey? How was this survey conducted?\"}"}]}
{"paper_id": "R3CDj2DLln", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: The study focuses on multimodal physical scene understanding where an embodied agent needs to discern the properties, direction, and distance of an impact sound source to locate fallen objects. Previous work, such as Neural Acoustic Fields (NAFs), could capture sound propagation in a single scene but lacked generalizability across multiple scenes due to overfitting. Acoustic rendering and sound-based scene understanding are critical for applications in navigation, particularly under multimodal scenarios that integrate both auditory and visual inputs.\nGap: Previous methods, specifically feed-forward neural networks used for sound source inference, failed to generalize well across different environments and struggled with poor domain adaptation. NAFs, while capturing acoustics effectively within single scenes, were not effective for analyzing sound across multiple environments.\nHypothesis: By learning an inverse model of acoustic formation, termed as the Disentangled Acoustic Field (DAF), the embodied agent could construct a spatial uncertainty map to improve the localization and understanding of fallen objects through sound.\nMethod: The method involves creating a disentangled acoustic field model that captures the generation and propagation of sounds. The DAF approach includes an encoder to process short-time Fourier transform (STFT) into latent factors and a generator to produce the power spectral density (PSD) representing the emitted sound characteristics. The analysis-by-synthesis framework enables sound properties inference by decomposing latent space. The system uses the Testament Dataset with experiments conducted in the TDW simulation platform for audio-visual scene understanding tasks. During tests, agents use sound to form hypotheses about object characteristics and location, refining them with visual data.\nConclusion: The DAF framework significantly advances the success rate for localizing fallen objects in multimodal environments, outperforming previous models by providing both improved generalization across different scenes and enhanced interpretability of sound data. The framework facilitates effective navigation plans and can generalize to novel scene types, indicating its robustness in complex audio-visual environments.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"1. The proposed architecture is interesting. If we can obtain lots of pairs of audio signals and object properties, the proposed architecture might be one of the best choices for simultaneously analyzing and synthesizing audio scenes.\\n\\n2. Based on the experimental evaluations, the proposed method reasonably work well for several tasks.\", \"Weaknesses\": \"1. The task of this paper is closely related to sound source localization. If the authors justify the effectiveness of the proposed method in terms of position errors of sound sources, experimental comparisons with several previous methods for this task would be mandatory. As presented in [Grumiaux+ JASA 2021 https://arxiv.org/abs/2109.03465], lots of previous methods have already been proposed for this purpose. I understand that many of those previous methods typically require multi-channel audio inputs and the proposed method employs a single-channel or binaural audio clip. However, you will find several techniques that work well only with single-channel audio, since single-channel sound source localization has been one of the typical tasks in audio signal processing before the deep learning era.\\n\\n2. If we want to simply predict acoustic scenes from audio signals, we do not have to introduce decoders that generate audio signals from object properties. In this sense, the ablation study that compares the full proposed method and the one without decoders should be presented.\\n\\n3. If the main objective of this paper is a proposal of a novel construction of neural acoustic fields, the proposed method should be compared with the original NAFs in the task of audio synthesis.\", \"Questions\": \"Please check the above Weakness section.\"}"}]}
{"paper_id": "zUHgYRRAWl", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Variational autoencoders (VAE) have become popular in drug discovery for generating molecules, leveraging large-scale datasets like ChEMBL and ZINC. However, they struggle with poor manifold recovery in complex data settings\u2014a challenge known in high-dimensional data spaces.\nGap: Current VAE approaches for molecule generation suffer from poor manifold recovery, particularly when data is embedded on a low-dimensional manifold within a high-dimensional space. This issue leads to inferior property matching with the target dataset.\nHypothesis: A multi-stage VAE approach can improve manifold recovery over traditional single-stage VAEs by creating better latent variable representations, enhancing the quality of generated molecules without using property predictors in the training process.\nMethod: The authors propose a multi-stage VAE method where subsequent VAEs are trained on the latent representations of the prior stage. The approach was tested on a synthetic dataset and the ChEMBL dataset for molecule generation, along with fine-tuning on smaller datasets targeting specific protein activities. The study compares the multi-stage VAE against one-stage models and other methods that integrate property predictors.\nConclusion: The multi-stage VAE demonstrates improved manifold recovery, generating molecules with properties more similar to target datasets without relying on property predictors. It performs effectively against models using learned property metrics, offering an objective-agnostic improvement method.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 1, \"Presentation\": 2, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"1. Correct posing of a problem, with correct references to related work.\\n2. The authors undertake the issue of finding better low-dimension space immersion in high-dimensional space. On the other hand, it is not proved that their solution is the right one.\", \"Weaknesses\": \"1. The authors note that typically, high-dimensional data can be projected onto a low-dimensional space immersed in a high-dimensional space. To demonstrate this, they conduct a very simple experiment on synthetic data. This experiment does not show much, only the authors claim that for one of the later layers a space with the correct dimensionality for the data is obtained. This experiment is clearly spurious and can be removed.\\n2. The authors propose to build a VAE model with many hidden layers iteratively. In each step, developing the projection of the most recently obtained hidden layer into a new VAE model. The obtained model would get the variances on the diagonal reach the values {0, 1}, which would show the selection/reduction of individual dimensions projection. \\nIt seems that the analogy with synthetic experiment is insufficient for a direct application of this approach.\\n3. Several models with randomly selected numbers of hidden layers are used in the experiments.\\n4. In the comparisons, each model has a different dimensionality of hidden layers for the same data.\\n5. There is no bibliography in the work. I suspect that this is a simple editorial error (references in the work are marked as links), but such an error in a work for a major conference is unacceptable. Similarly, there is no appendix to which there is a reference in the main text.\", \"Questions\": \"1. Is the synthetic experiment really needed? I would remove it if I were you. In place of it, I would give some better mathematical discussion.\\n2. Is the analogy between the scheme presented in the synthetic data experiment to the problem of molecule generation really valid? Could you, please, better justify the analogy?\\n3. Why just that number of layers are used in the models? Why are there 3 layers for HGNN and MoLeR? The \\\"MoLeR + prop\\\" model is completely unclear? Why does the RNN model only have two layers? The LatentGAN model seems to have only one hidden layer, right? Or maybe some of the nodels are for comparison? This is not clear from the text of the work.\\n4. If one of the goals was to show that multi-layer models, along with variance optimization, allow for better matching of the implicit dimensions, does using different dimensions allow this to be shown for different models? There is no description of the individual statistics used in the work.\\n5. Was variance optimization used for all models? This is not clear from the text.\\n6. The standard in the editorial composition of scientific works is to place descriptions of tables above them, not below.\"}"}]}
{"paper_id": "o1TKGCrSL7", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: The paper discusses the concept of domain shift in machine learning, particularly focusing on sub-population shifts where the data distribution changes within specific sub-groups or populations during training vs. testing. Domain shifts, including sub-population shifts, are identified as significant sources of algorithmic bias. The vision-language model CLIP is highlighted for its inherent robustness to distributional changes, although this robustness can be compromised through fine-tuning.\nGap: Despite the robustness of models like CLIP to sub-population shifts, fine-tuning such models often compromises this robustness. Furthermore, existing universal distributionally robust optimization (DRO) methods combined with CLIP may result in performance instability. There is a need to effectively handle sub-population shifts without compromising robustness or requiring domain-aware validation datasets.\nHypothesis: The authors propose that leveraging natural language inputs to debias image feature representations in multi-modality models like CLIP can improve performance under sub-population shifts, particularly improving worst-case performance without requiring instance-wise label information.\nMethod: The proposed method, L-DRO, utilizes natural language to mitigate sub-population shifts in CLIP by debiasing the image feature representations. It employs a feature adapter that optimizes between the entropy of sub-population predictions and consistency with original features. This approach uses a two-phase training where DRO-like risk is addressed by oversampling or re-weighting significant data points. Experiments are conducted on datasets like CelebA and Waterbirds to compare its performance against baseline methods, using various configurations of text prompts for classification and debiasing.\nConclusion: The proposed L-DRO method significantly improves worst-case performance and stability across sub-population shifts compared to baseline methods. L-DRO can achieve such improvements without requiring domain-aware validation datasets during training and occasionally enhances average performance. However, the paper notes limitations in the necessary careful selection of text prompts and potentially challenging sub-populations to describe.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I\u2019m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations\u2014where domain predictability is removed and task predictability is emphasized\u2014is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive \u2014 It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}"}]}
{"paper_id": "cNi2EJ8OCh", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Local differential privacy (LDP) is important in data privacy, especially when dealing with sensitive data in untrusted environments. While differential privacy (DP) is well-studied, LDP remains less explored, particularly in the context of functional data classification. This is significant because functional data, observed over time or space, can reveal personal information. The challenge lies in managing the infinite dimensionality and preserving privacy while maintaining data utility.\nGap: The paper identifies a significant gap in the application of local differential privacy to the field of functional data classification, which is largely unexplored. Most existing research focuses on differential privacy or on multivariate data, not on functional data characterized by infinite dimensions.\nHypothesis: The authors propose that by leveraging the property of functional data\u2014being approximable by a finite set of basis functions\u2014they can reduce its dimensionality, thereby facilitating the construction of classifiers under the constraints of local differential privacy (LDP). They posit that this approach can effectively balance privacy and utility in functional data classification.\nMethod: The authors develop algorithms to construct functional classifiers under LDP in both single-server and multi-server settings. In single-server scenarios, they propose a strategy of using fewer samples to train multiple weak classifiers, reserving most samples for evaluation, and using techniques like model reversal and model averaging to improve classifier performance. In multi-server settings, they use federated learning to allow servers to benefit from shared knowledge. The method involves encoding, perturbation using a Laplace mechanism, aggregation, estimation, and leveraging model reversal and averaging strategies to enhance classifier accuracy under LDP.\nConclusion: The paper concludes that the proposed algorithms significantly improve the performance of functional data classifiers under LDP. Techniques like model reversal and model averaging, along with federated learning in multi-server environments, enhance the accuracy of classifiers while adhering to privacy constraints. These findings demonstrate the feasibility and effectiveness of the proposed methods in privacy-preserving functional data classification.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"1.The paper introduces a novel approach to functional data classification under Local Differential Privacy (LDP), a topic that has not been extensively explored in the existing literature.  \\n2.The introduction of model reversal is particularly innovative, as it provides a unique solution to enhance the performance of weak classifiers by inverting their parameters when their accuracy is below a certain threshold.\", \"Weaknesses\": \"1.Differential Privacy (DP) has already proven to be sufficiently effective in protecting individual privacy, for instance, in defending against membership inference attacks. Moreover, there are numerous existing methods within DP for adding noise to functional input data, where the idea of projecting onto a set of finite bases is also quite common. From this perspective, the innovation of projection might not be high enough, and the necessity of employing Local Differential Privacy (LDP) remains to be further examined.At the same time, the performance degradation caused by residuals has not been analyzed theoretically. The expressive power of a finite basis is quite limited, and for some functions, their residuals could be fatal.\\n\\n2.Regarding the ideas of model average and model reversal proposed by the authors, compared to traditional ensemble techniques, model average utilizes more clients in the evaluation process, aiming to select better weak classifiers. For each poor classifier, a model reversal approach is employed for improvement. However, since only a small number of clients are used to train the parameters, the classifiers might generally perform poorly; model reversal can enhance the performance of the learners, but it may not necessarily improve them to a satisfactory level. Theorem three provides an expected conclusion, but it does not directly lead to a high-probability bound; the theoretical analysis of model reversal is still lacking.\", \"Questions\": \"1..Are there specific scenarios or use cases where LDP provides a clear advantage over DP in functional data classification?\\n\\n2.The idea of projecting data onto a finite basis is quite common in the realm of DP. Could you clarify how your approach innovates or differs significantly from existing methods?\\n\\n3.The theoretical analysis of model reversal seems to be lacking. Could you provide more details or elaborate on the theoretical foundations of this technique?\"}"}]}
{"paper_id": "6hzNVNSz8O", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Line search methods have been shown to improve the performance of stochastic gradient descent (SGD) by making the learning rate superfluous. Recent research has suggested that line search approaches can effectively overcome the need for hyperparameter tuning in learning rates by evaluating the loss function at multiple gradient points, thereby finding an adaptive learning rate.\nGap: Current line search methods such as the Stochastic Line Search (SLS) have problems with mini-batch noise and are inefficient for larger scale datasets and more complex data domains. There are also stability issues with standard implementations of line search, such as those seen with large step size variations over different runs.\nHypothesis: The paper proposes that an enhancement to Armijo line search, called SaLSa, which incorporates exponential smoothing (momentum) and reduces the line search frequency, can provide a more stable and effective line search method that is better suited for stochastic mini-batching and larger datasets.\nMethod: The SaLSa method enhances Armijo's line search by incorporating an exponential smoothing factor to account for mini-batch noise and reduce the impact of an erratic step size change. The method also limits the frequency of line search computation to improve efficiency. These modifications are implemented as a PyTorch optimizer and tested against SGD and Adam optimizers across a variety of datasets and architectures, including Transformers, CNNs, and MLPs. Major datasets used include ImageNet and the Glue dataset collection for NLP tasks.\nConclusion: SaLSa achieves better performance in terms of lower loss values and higher average accuracy compared to prior methods and tuned optimizers. The results demonstrate SaLSa's robustness and efficiency without requiring extensive hyperparameter tuning. Its implementation as a PyTorch optimizer makes it accessible and practical for a broad range of machine learning applications.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"The paper is clearly written. The motivation and theoretical analysis are clear. The thoroughness of the experimental setup is excellent. The contribution is very significant and I think likely to be very useful to machine learning practitioners in general.\", \"Weaknesses\": \"While the presented results are very compelling, it would be even stronger to show experiments on Transformer models in a pretaining setting as well. Additionally, it would be beneficial to compare different sizes of Transformer (and CNN) to show the persistence of the benefit of the method across the scaling of the model. These experiments may plausibly be left as future work (the presented ablations are more important and very thorough) but they represent practical questions that ML practitioners will have, so would strengthen the current work if included.\", \"Questions\": \"Nits:\\nFigs 4 and 5: it is a little difficult to read these plots, as you have to go back and forth visually between the plot and the legend to see which curve is which. Consider making Salsa lines dashed / SLS lines dotted / baselines solid (or something of that nature) to help improve readability.\\nFig 5: loss label missing at top of (a), accuracy label missing at top of (d)\\nFig 1: fix occluded label text for y axis\"}"}]}
{"paper_id": "eJhgguibXu", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: In model-based reinforcement learning, agents use learned models of environment dynamics to improve policies. Models help generate experiences for learning policies or planning outcomes, enhancing sample efficiency and adaptability to new tasks by reducing the need to relearn environment fundamentals. Despite this, model accuracy limits these benefits, as inaccuracies can cause failures when agents trust them in erroneous states. Humans, however, effectively use imperfect intuitive physics models to navigate and reason about the world.\nGap: Existing model-based reinforcement learning approaches face challenges with model inaccuracies and compounding errors over long rollouts, which can lead to failures in policy learning and hinder exploration efficiency, especially in environments with continuous action spaces and sparse rewards. Current literature focuses on mitigating these inaccuracies rather than leveraging them for exploration.\nHypothesis: The authors hypothesize that learned approximate models can be used to guide exploration towards useful regions of the state and action space, thereby improving sample efficiency and policy learning in complex environments with large action spaces and sparse rewards.\nMethod: The authors propose learning dynamics models for intuitive physics tasks using graph neural networks (GNNs) that incorporate object, relational, and event structures. By training these models in a task-agnostic way with data collected from object collision interactions, they develop methods to identify rewarding action clusters. These clusters guide exploration in policy learning through an epsilon-greedy strategy, combined with Deep Deterministic Policy Gradients (DDPG), to improve learning efficiency. The models were applied to the CREATE environment for physics-based puzzles, targeting tasks requiring precise tool placements to achieve goals.\nConclusion: The study demonstrates that approximate models learned using GNNs can effectively generalize to unseen tasks and improve policy sample efficiency by guiding exploration towards rewarding action spaces. This approach accelerates convergence in reinforcement learning tasks, suggesting that approximate models can be advantageous for exploration in environments with challenging features such as large action spaces and sparse rewards.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 1, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"The paper is mostly fairly easy to understand and aims to tackle an important issue of efficient exploration.\", \"Weaknesses\": \"The description of the experiments needs improvement. Moreover, the results are not very convincing. Further details are described below.\", \"Questions\": \"1.\\tFigures 2,3 and 4 need more descriptive captions as well as better descriptions in the text.  For example, what do the symbols correspond to in Fig 3? Similarly, in Fig 4, a legend (along with better descriptions) would have made it much easier to interpret the results. \\n\\n2.\\tWhy is it that the relative Goal hits in Fig 5a are much higher compared to other tasks?\\n\\n3.\\tIt is not immediately clear why the approach applies only to intuitive physics based tasks. I think this point needs to be emphasized better in the introduction.\\n\\n4.\\tOver how many trials were the experiments conducted in Fig 6? In general, from the learning curves, the learning does not look stable.\\n\\n5.\\tDoesn\u2019t exploration epsilon=0 imply no model guidance? If so, for say, task 4, they both reach the same asymptotic performance. Why is this the case, while in some of the other tasks, the asymptotic  performances are very different?\\n\\n6.\\tAblations showing the effect of $\\\\epsilon_{threshold}$ are missing. \\n\\n7.\\tAs claimed in the last line on Page 7, why would the policy learning diverge? I believe that the learning would still occur (as DDPG learns off-policy) but due to a lack of exploitation, the learning curves would not reflect the learnt policy.\\n\\n8.\\tPerhaps the authors could have considered Phyre environments (https://ai.meta.com/tools/phyre/) to validate their approach.\\n\\n9.\\tIn Fig 6, I assumed the orange color always corresponds to exploration epsilon of 0, but for task 6, the colors are swapped.\\n\\n10.\\t\u201cBy using\u2026however uncertain\u201d \u2013 This sentence towards the end of the introduction is too long and can be phrased better.\"}"}]}
{"paper_id": "eEslYpY6Yq", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Graph Neural Networks (GNNs) have become a state-of-the-art approach for various graph-related tasks due to their efficiency in aggregating features from neighboring nodes. Mixup, on the other hand, is a data augmentation technique that averages features and labels from multiple samples to generate new examples. Both techniques utilize information aggregation from multiple samples to enhance learning models.\nGap: The paper addresses the gap in understanding the potential connection between graph convolution operations used in GNNs and Mixup techniques. There is a lack of exploration on whether these seemingly unrelated techniques are fundamentally connected or could be unified under a common framework.\nHypothesis: The main claim of the paper is that graph convolution can be mathematically expressed as a special form of Mixup under two mild conditions: the Homophily Relabel condition where the target node's label is assigned to its neighbors, and the Test-Time Mixup condition where feature mixing is performed during the testing phase.\nMethod: The paper uses a mathematical framework to establish the equivalence between graph convolution and Mixup. It demonstrates that both Graph Convolutional Networks (GCN) and Simplified Graph Convolution (SGC) can be reformulated to adhere to the Mixup technique under specified conditions. The equivalence is validated by training a Multi-Layer Perceptron (MLP) with homophily relabeling and test-time Mixup and comparing its performance to that of GCNs. Various experiments with different data splits and well-known datasets (Cora, CiteSeer, and PubMed) are conducted to provide empirical support for the claims.\nConclusion: The findings indicate that graph convolution is indeed a form of Mixup when homophily relabeling is applied during the training phase and Mixup is performed during testing. This revelation offers a new perspective on understanding graph neural networks, suggesting that efficient network designs can be achieved by integrating Mixup techniques. Additionally, the novel insights into GNNs could lead to development of simpler yet effective versions of these networks, promising comparable performance with reduced complexity.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"- **Novel and original.** The paper proposes a very interesting interpretation of graph convolution, which to the best of my knowledge, has not been studied yet.\\n- **Great presentation.** Paper is well-written with clear mathematical derivations that are easy to follow.\", \"Weaknesses\": \"- **Overall significance is unclear and claimed practical/theoretical implications lack support.**\\n  - [W1] While Section 6 mentions how TMLP and HMLP can be training-efficient with large-scale graphs since they are MLP-based, there are no experiments to compare computational costs and demonstrate this claim. I also suspect the gain in efficiency would be fairly small since graph convolution can be highly optimized via sparse-dense matrix multiplications.\\n  - [W2] The theoretical implications also seem a bit far-fetched: there is a rich line of work on the theoretical expressivity of GNNs [A, B, C, D, E], yet the paper does not convey any clear connection between Mixup and such work to support its theoretical significance. This could most likely constitute another research paper on its own, but any further discussion on what makes \\\"the Mixup perspective\\\" particularly interesting with respect to GNN expressivity would be helpful.\\n- **Discussion on empirical results do not provide much insight and are often unconvincing due to lack of evidence.**\\n  - [W3] Section 3.2 and Figure 3 show that HMLP and GCN share the same test curves, but not the training curves, which the paper conjectures to be \\\"because the labels of nodes are changed\\\". I think the discussion could go a bit deeper (maybe via proper ablation),  considering that the training dynamics of HMLP differs from that of GCN in ways other than the node-labels: not only are all the node-labels mixed, but also 1) nodes in the test-set are used for training HMLP (not the case for GCN) and 2) the model parametrization is different. \\n  - [W4] Section 4.2 mentions how \\\"overdoing Mixup may reduce accuracy\\\", but this observation is not evident from the results in Figure 7, nor is the discussion consistent with the claim that \\\"Test-Time Mixup enhances model robustness\\\". Are there any experimental results that can support this observation? Is this discussion in any way related to the oversmoothing problem of graph convolution [F]?\\n  - [W5] Figure 8 shows a fairly large discrepancy between GNNs and Mixup on the PubMed dataset. Considering that the main claim is that GNNs and Mixup are equivalent, why are we seeing this discrepancy on performance despite PubMed being a homophilic network just like Cora and CiteSeer?\\n\\n[A] Morris et al., Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks. (AAAI 2019)\\\\\\n[B] Xu et al., How Powerful are Graph Neural Networks? (ICLR 2019)\\\\\\n[C] Maron et al., Provably Powerful Graph Networks. (NeurIPS 2019)\\\\\\n[D] Zopf, 1-WL Expressiveness Is (Almost) All You Need. (IJCNN 2022)\\\\\\n[E] Feng et al., How Powerful are K-hop Message Passing Graph Neural Networks. (NeurIPS 2022)\\\\\\n[F] Li et al., Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. (AAAI 2018)\", \"Questions\": \"- [Q1] I am not sure whether Section 2.4 is really necessary on its own as it does not seem to provide significant information. The section could instead be merged to the Related Work paragraph in Section 1.\\n- [Q2] Question on HMLP: given the example graph in Figure 2, HMLP uses $(x_i, (0.5, 0.5))$ for training, yet the ground-truth sample during test time will be just one of $(x_i, (1, 0))$ or $(x_i, (0, 1))$. In this case, wouldn't the difference in the labels be detrimental for test-time performance since the model will be trained to output $(0.5, 0.5)$ given $x_i$?\\n- [Q3] How are the \\\"MLP\\\"s and \\\"Mixup\\\"s different for each row of plots in Figure 8? Was slightly confused why the same method appears in different graphs with different accuracies.\\n- [Q4] The end of Practical Potentials paragraph in section 6 mentions that HMLP \\\"eliminates the need for connection information during both training and testing\\\". Is this true? Although the model being trained may not require connectivity information, the Homophily Relabeling taken place prior to training does seem to require the connectivity.\\n\\nThere are also several typos:\\n- End of Section 1: \\\"be considered as a generlized ...\\\" -> \\\"be considered as a generalized ...\\\"\\n- Notations paragraph in Section 2: \\\"one-hot labels $Y \\\\in \\\\\\\\{0,1\\\\\\\\}^{N \\\\times (C-1)}$...\\\" -> Shouldn't it be $Y \\\\in \\\\\\\\{0,1\\\\\\\\}^{N \\\\times C}$ with $C$ classes?\\n- Top of page 5: \\\"We rewrite the $\\\\tilde{a}i \\\\cdot X$...\\\" -> should be subscript \\\"$\\\\tilde{a}_i \\\\cdot X$\\\"\\n- Section 2.4: \\\"... understanding of this phoneme ...\\\" -> \\\"... understanding of this phenomenon ...\\\"\\n- End of Section 3.1: \\\"Thus in the next, we propose ...\\\" -> \\\"Thus in the next paragraph, we propose ...\\\"?\\n- Bottom of page 7: \\\"In the Figure 4, the performance ...\\\" -> Wrong reference. \\\"In Figure 6, the performance ...\\\"\\n- End of Section 4.1: \\\"The node representation clearly show that what TMLP ...\\\" -> \\\"... clearly show what TMLP ...\\\"\"}"}]}
{"paper_id": "vnKf1jG5eK", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Recent advancements in AI have led to the development of sophisticated multimodal generative models, leveraging both language models and vision models. The progress in the field can be attributed to large language models (LLMs) for text generation and diffusion models for image generation. Collaborative models like Visual ChatGPT and MM-REACT have emerged, which integrate visual information into text descriptions via pre-trained tools. These models heavily rely on pre-trained components and often struggle with requiring extensive training data or dependencies on encoders like CLIP and ImageBind for modality alignment.\nGap: Current multimodal models face limitations such as dependency on extensive training data to bridge the gap between modalities and a scarce ability to generate comprehensive multimodal responses. They frequently employ CLIP or ImageBind encoders that, while effective at learning joint representations for text and images, require massive datasets to map these encodings to language model spaces effectively. Additionally, these models are generally constrained to understand multimodal content rather than generate it.\nHypothesis: The authors propose that a model based on a bidirectional conditional diffusion model, dubbed BiDiffuser, can more efficiently handle the interaction between modalities by minimizing the necessity for vast datasets and complex pre-training, thus improving the generation capabilities in multimodal tasks such as image-to-text and text-to-image generation.\nMethod: EasyGen consists of a bidirectional conditional diffusion model named BiDiffuser and a large language model (LLM). It is designed to manage image-to-text generation tasks by synchronizing the embedding space of BiDiffuser with that of an LLM using a simple projection layer. BiDiffuser converts images into text format for semantic alignment with the LLM. For text-to-image generation, it utilizes the LLM to generate detailed textual descriptions which BiDiffuser interprets to produce visual content. The training involves fine-tuning the BiDiffuser specifically for image-to-text and text-to-image tasks, with the integration layer conditioned via semantically aligned inputs from multimodal datasets, allowing the model to work efficiently in a lab setting with relatively low computational resources.\nConclusion: EasyGen demonstrates the effectiveness of leveraging a bidirectional conditional diffusion model and LLMs for multimodal generation, performing on par with existing state-of-the-art models while utilizing significantly less training data. The approach showcases robust multimodal generation capabilities with efficient training requirements and improved adaptability through simplified architectural adjustments, marking a significant contribution to the field of AI-generated content.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 5, \"Confidence\": 5, \"Strengths\": \"- The idea of tuning UniDiffuser as LLM encoders via image-text bidirectional generation is simple and novel, and the results are interesting to me.\\n- The targeted problem of multimodal dialogue is relevant and trending, especially in the modern LLM era.\\n- The method seems very data-efficient, which is good.\", \"Weaknesses\": \"My primary concern is the limited applications and evaluations. For multimodal dialogue, when considering long context conditional image generation or image conditional (multi-images or single-image) image generation like image edition/translation (it is, however, what UniDiffuser initially can do), only generating text inputs as diffusion modal conditions is limited. \\n\\nFor the evaluations, the current results only include traditional short QA or image captioning tasks. However, one of the advantages of LLMs is that they are mighty at world knowledge and long-context reasoning. It would be better if results on modern benchmarks like MM-Vet and MMBench were provided. Also, the most commonly used VQAv2 results are not provided.\\n\\nOn the other hand, since the method converts images to texts to obtain multimodal understandings, lots of information may be diluted or missing. It will harm the understanding that requires detailed knowledge, such as OCR-related tasks (results on TextVQA are also encouraged).  Besides, results on commonly used text-to-image generation benchmarks are required, such as COCO FID results. \\n\\nIt is somewhat overclaimed to criticize the large data requirement of CLIP/ImageBind models since UniDiffuser is also trained on large-scale corpora using large amounts of resources that cannot be affordable by most labs.\\n\\nMissing citations and discussions. The method of first converting images to texts and then feeding them to LLMs is the same as Img2LLM [A], but it is not cited or discussed. Besides, several closely related concurrent works should be discussed [B-F].\\n\\n[A] From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models.\\n[B] DreamLLM: Synergistic Multimodal Comprehension and Creation.\\n[C] NExT-GPT: Any-to-Any Multimodal LLM.\\n[D] MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens.\\n[E] Generating Images with Multimodal Language Models.\\n[F] Kosmos-G: Generating Images in Context with Multimodal Large Language Models.\", \"Questions\": \"- What about COCO captioning results on `test` split?\\n- Is is possible if some language capability can be provided? Such as MMLU and HellaSwag benchmarks.\"}"}]}
{"paper_id": "2PKZtPMyvI", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Transformers have become a dominant framework in sequential modeling, particularly in NLP, outweighing models like CNNs due to their ability to handle large datasets effectively. They are used in models such as BERT and GPT-3, and various innovations like Reformer and Linformer have been developed to enhance performance by reducing computational complexity.\nGap: Despite the widespread use of transformers and numerous architectural advancements, their underlying operational mechanics remain not well-understood, particularly how embedding dimensions and layer depth affect performance.\nHypothesis: The intrinsic dimension (ID), representing the minimum parameter count for effective modeling, can provide insight into the geometrical characteristics of data representations learned by Transformers, revealing trends in embedding dimensions, layer depth, and task performance.\nMethod: The study uses intrinsic dimension (ID) analysis to explore the geometric characteristics of data representations in Transformers. It conducts several text classification experiments using the TwoNN method to estimate IDs across different layers of Transformer models and examines relationships between ID, embedding dimensions, and classification performance across three datasets: IMDB, AG, and SST2.\nConclusion: The study finds that higher terminal feature IDs in Transformers correlate with lower classification error rates, opposite to CNNs. ID tends to decrease with layer depth, especially in complex architectures. Nonlinear dimension reduction is achieved in Transformers, with varying sequence lengths impacting ID and performance, supporting the efficacy of data reduction in training.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 1, \"Rating\": 1, \"Confidence\": 4, \"Strengths\": \"None\", \"Weaknesses\": \"This paper seems to be a study. And an incomplete one. It goes from related work where they describe the TwoNN method proposed by another paper, to experiment results. There is no technical section? It is also written kind of strangely.\", \"Questions\": \"See weaknesses\"}"}]}
{"paper_id": "JzvIWvC9MG", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Game theory provides a mathematical framework for modeling interactions among self-interested agents, typically leading to Nash equilibria. However, the parameters of the payoff functions driving these interactions are often unobserved in real situations, necessitating methods for inverse game theory, which infers these parameters from observed equilibria.\nGap: Existing methods for inverse game theory, particularly in multiagent environments, struggle with computational complexity and accuracy, especially when dealing with stochastic elements and real-world data with unclear payoff structures.\nHypothesis: The authors hypothesize that formulating inverse game theoretical problems as generative-adversarial min-max optimization problems can allow for efficient (polynomial-time) computation of inverse Nash equilibria and related predictions.\nMethod: The authors develop polynomial-time algorithms relying on min-max optimization frameworks that utilize exact or stochastic first-order oracles to infer game parameters from observed equilibriums. Specifically, they extend these methods to inverse multiagent simulacral learning, aiming to replicate given observations using computed parameters and equilibria.\nConclusion: The proposed methods demonstrate effective prediction on synthetic economic games and outperform traditional ARIMA models in forecasting electricity prices using Spanish market data, indicating both enhanced computational efficiency and prediction accuracy in complex multiagent settings.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 3, \"Contribution\": 4, \"Rating\": 10, \"Confidence\": 3, \"Strengths\": \"The simple formulation of the set of inverse Nash equilibria (NE) as a min-max\\ngame is elegant and appears to be original. If it is indeed original, for this\\nalone, the paper merits publication and should be highlighted.\\n\\nThe paper overall is well written and showcases immediate applications of the\\nproposed solution to an important and practical domain as a proof-of-concept. I\\nbelieve these results are significant and will be impactful.\", \"Weaknesses\": \"As an easily rectified issue, Figure 1 could have been better represented by\\nplotting residuals over time or, by subsampling the data, plotting mean\\nresiduals with error bars.\\n\\nAs a minor complaint, I do not prefer the language of \\\"generative-adversarial\\\"\\n(especially not in terms of a \\\"discriminator\\\"), even if this is the closest\\nanalogy familiar to machine learning practitioners: This is a standard min-max\\noptimization problem that need not be wed to the ML setting.\", \"Questions\": \"Remark 1 is indeed interesting, but it is not obvious. Did I miss an associated\\nproof or example?\\n\\nWhy was the proof of Theorem 3.2 omitted? Was it rephrased to appear as Theorem\\n6.1 in the supplementary material?  Establishing the convergence rates of\\nvarious algorithms is not my expertise, but the results seem reasonable,\\nespecially given assumptions of convexity and Lipshitz smoothness.\"}"}]}
{"paper_id": "5rrYpa2vts", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: The proliferation of fake news on social media has become a significant issue, with substantial efforts made over the past decade in developing methods for detecting fake news. Initial efforts included using manually crafted textual features, and later, deep learning methods like LSTM and RNN, which evolved to incorporate external knowledge alongside textual features. Recent models like KAN and Dual-CAN have attempted to integrate external evidence and social information, respectively, to improve the accuracy of fake news detection.\nGap: Current fake news detection models have limitations in maintaining longer text dependencies and capturing complex semantic relationships. They also face challenges in integrating external knowledge efficiently. Models like KAN and FinerFact have shown reliance on single-entity contexts or socially sourced claims, which can be less reliable or manipulated.\nHypothesis: The authors propose that by incorporating Abstract Meaning Representation (AMR) and external knowledge from Wikidata, specifically through a novel graph representation and evidence linking algorithm, a more robust and accurate model for fake news detection can be developed.\nMethod: The proposed model, EA2N, combines a language encoder and a graph encoder to integrate transformer-encoded textual features with affective lexical features. The graph encoder constructs an AMR graph, enriching it with external knowledge from Wikidata to form a WikiAMR graph. A path-aware graph learning module is used to capture semantic relationships among entities. The model predicts the veracity of news by integrating features from both the language and graph encoders, using a transformer for classification. The model was evaluated using datasets from PolitiFact and GossipCop, comparing its performance to state-of-the-art models.\nConclusion: EA2N, leveraging AMR and external knowledge, outperformed state-of-the-art models in fake news detection on benchmark datasets. The integration of evidence through the WikiAMR graph was shown to be effective, suggesting this method's potential for improving semantic understanding in NLP applications.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"- The authors provide an effective amalgamation of the graph- and text-based pipeline for learning representation (although not entirely novel).\\n- The figures and tables give a clear picture of the underlying model and experimentation.\\n- The authors perform the much required ablation studies.\", \"Weaknesses\": \"The proposed architecture seems to be an attempt to combine several pre-existing architectures -- i.e. Language Encoder (BERT [6] + FakeFlow [7]), Path-aware Graph Learning Module (Graph Transformer [8]) and Graph Generation and Integration ($\\\\mathcal{A}^*$ search with a TagMe API [9] -based heuristic). While these architectures have been amalgamated to propose a new model, these aren't *novel* contributions. The paper isn't well written (in some places) in the sense that several key notations are missing, and the narrative of the work could have been improved. All the baselines have been directly adopted from the FinerFact [5] paper. Such practices should be avoided. I have highlighted several weaknesses and concerns under the \\\"Questions\\\" section.\\n\\n\\n[1] Zixuan Zhang and Heng Ji. 2021. Abstract Meaning Representation Guided Graph Encoding and Decoding for Joint Information Extraction. (NAACL-HLT 2021)\\n\\n[2] Shu, Kai, et al. \\\"Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media.\\\" Big data 8.3 (2020): 171-188.\\n\\n[3] Martinez-Rodriguez, Jose L., Ivan L\u00f3pez-Ar\u00e9valo, and Ana B. Rios-Alvarado. \\\"Openie-based approach for knowledge graph construction from text.\\\" Expert Systems with Applications 113 (2018): 339-355.\\n\\n[4] Yi-Ju Lu and Cheng-Te Li. GCAN: Graph-aware co-attention networks for explainable fake news detection on social media. In ACL, pp. 505\u2013514, Online, July 2020. ACL.\\n\\n[5] Yiqiao Jin, Xiting Wang, Ruichao Yang, Yizhou Sun, Wei Wang, Hao Liao, and Xing Xie. Towards fine-grained reasoning for fake news detection. AAAI, 36:5746\u20135754, 06 2022.\\n\\n[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In NAACL Volume 1 (Long and Short Papers), pp. 4171\u20134186, Minneapolis, Minnesota, June 2019. ACL.\\n\\n[7] Bilal Ghanem, Simone Paolo Ponzetto, Paolo Rosso, and Francisco Rangel. Fakeflow: Fake news detection by modeling the flow of affective information. In 16th EACL, 2021.\\n\\n[8] Deng Cai and Wai Lam. Graph transformer for graph-to-sequence learning. In AAAI, pp. 7464\u2013 7471. AAAI Press, 2020.\\n\\n[9] Paolo Ferragina and Ugo Scaiella. Tagme: On-the-fly annotation of short text fragments (by wikipedia entities). In ICIKM, CIKM \u201910, pp. 1625\u20131628, New York, NY, USA, 2010. ACM. ISBN 9781450300995.\", \"Questions\": \"**Evidence Integration with AMR**: There seem to be several incomplete parts, which need to be explained.\\n\\n---  In Entity-level Filtering $(\\\\mathcal{R}^{(S,D)}_{ELF} = Relatedness(v_s^{wiki}, v_d^{wiki}))$, the authors have not mentioned what the $Relatedness(.)$ function is? Without an ***explicit*** definition of the function, it is diffiucult to assess the working of the ELF and CLF algorithms since the $Relatedness(.)$ function seems to be the \\\"main\\\" heuristic being used here.\\n\\n- From a look at the Appendix, it seems (***implicitly***) that the authors use the TagMe API to compute the relatedness, but what \\\"explicitly\\\" is the function definition used? \\n\\n--- The Figure 2 (and following text) mentions that the authors use $\\\\mathcal{A}^*$ search on the Wiki-graph to find the (optimal) path between source $v_s^{amr}$ and destination $v_d^{amr}$. However the Algorithm 2 described as \\\"Context-level Filtering\\\" doesn't seem to represent $\\\\mathcal{A}^*$ search. \\n\\n- For $\\\\mathcal{A}^*$ search, $f$ (total cost) = $g$ (current cost) + $h$ (heuristic approximation of the future cost). Here, $f$ (total cost) must be the criterion for choosing the next node in path. If we assume that, $h = \\\\mathcal{R}^{(i,D)}_{CLF} = Relatedness(v_i^{wiki}, v_d^{wiki}) > \\\\delta$ is the heuristic cost to reach the destination $d$ from $i$, what is $g$? The authors don't provide information for that. Incase $g$ is being ignored (or taken 0), it becomes a *greedy-heuristic* search, and not $\\\\mathcal{A}^*$. \\n- A possible $\\\\mathcal{A}^*$ variant could have been:\\n\\n$g + h = \\\\mathcal{R}^{(S,i)}\\\\_{CLF} + \\\\mathcal{R}^{(i,D)}\\\\_{CLF} = Relatedness(v_s^{wiki}, v_i^{wiki}) + Relatedness(v_i^{wiki}, v_d^{wiki}) > \\\\delta*$\\n\\n\\n**Relation Encoder in Path-aware Graph Learning Module**: For every pair of entities $(v_s^{amr}, v_d^{amr})$ in $\\\\mathcal{G}^{amr}$, two distinct sources of relational data exist in $\\\\mathcal{G}^{WikiAMR}$: AMR-based relations and evidence-based relations from Wikidata:\\n\\n- Using the notation from paper: $\\\\mathcal{G}^{WikiAMR} = \\\\mathcal{G}^{amr} \\\\cup \\\\sum_{s, d} \\\\mathcal{P}^{wiki}(v_s^{amr}, v_d^{amr})$.\\n- Consider the shortest path denoted as $sp_{s \\\\rightarrow d} = \\\\set { e(v_s^{amr}, n_1), e(n_1, n_2), \\\\dots, e(n_k, v_d^{amr})\\\\}$ within $\\\\mathcal{G}^{WikiAMR}$. Here, $e^{amr}$ represents an edge within $\\\\mathcal{G}^{amr}$, and $e^{wiki}$ represents an edge within $\\\\sum_{s, d} \\\\mathcal{P}^{wiki}(v_s^{amr}, v_d^{amr})$. Therefore, the collective edge set $e^{WikiAMR} = e^{wiki} \\\\cup e^{amr}$.\\n- Let $sp^{amr}\\\\_{s \\\\rightarrow d} = \\\\set {e^{amr}(v_s^{amr}, n_1), e^{amr}(n_1, n_2), \\\\dots, e^{amr}(n_k, v_d^{amr})\\\\}$ be the shortest path that relies solely on AMR-based relations (i.e., exclusively within $\\\\mathcal{G}^{amr}$). Simultaneously, $sp^{wiki}\\\\_{s \\\\rightarrow d} = \\\\set {e^{wiki}(v_s^{amr}, n_1), \\\\dots, e^{wiki}(n_k, v_d^{amr})}$ represents the shortest path utilizing only evidence-based connections.\\n- As indicated by Table 2 and Figure 5, a significant portion of entities are linked through evidence-based connections with just one hop, meaning they are connected directly. In other words, for most entity pairs, the shortest path is the \\\"direct\\\" evidence path with a single edge originating from the Wiki graph. This can be represented as $sp_{s \\\\rightarrow d} = sp^{wiki}\\\\_{s \\\\rightarrow d} = \\\\{ e^{wiki}(v_s^{amr}, v_d^{amr})\\\\}$ (Because, as per Table 2, in most cases, the number of edges in $sp^{wiki}\\\\_{s \\\\rightarrow d}$ (being 1 in majority cases), is less than or equal to that in $sp^{amr}_{s \\\\rightarrow d}$.\\n\\nIn essence, this implies that in most cases, when encoding a relationship $r_{s \\\\rightarrow d}$, the relation encoder would **overlook the AMR-based relation information**. While Wikidata relations are valuable, disregarding AMR-level relations may not be technically justified. Therefore, the authors should contemplate how to adapt the relation encoder in the graph transformer to effectively integrate both information sources.\\n\\n**Abstract Meaning Representation**: I have a few major concerns about using an AMR representation here:\\n\\n- The average length of news articles in the Gossipcop dataset is **~600 words** [2] (Some articles are as large as 1000 words). In the case of such large input length, the AMR graphs are going to be \\\"very\\\" noisy. How do the authors handle this case?\\n- The authors don't elaborate on the intuition behind using the Abstract Meaning Representation (\\\"Why specificaly AMR?\\\")? There can be other (more sophisticated) variants of AMR like **AMR-IE** [1] (which uses an AMR guided graph decoder to extract knowledge elements based on the order decided by the hierarchical structures in AMR) which seem more relevant owing to the \\\"integration of external knowledge\\\" used in this work. What about knowledge graphs other than AMR (eg. OpenIE-based approaches [3])?\\n- It seems that the authors have used an off-the-shelf pretrained AMR parser, however they have not provided any details about the same. Was the AMR parser finetuned? (I am guessing not!)\\n\\n**Insufficient Experimentation**: \\n\\n- The presented results are exclusively based on two datasets, Politifact and Gossipcop, both of which are part of the FakeNewsNet database. To ensure the generalizability of the proposed architecture, it is essential for the authors to include results from additional datasets spanning various domains or social media platforms. Moreover, it's worth noting that Politifact, one of the datasets, contains only 815 news articles.\\n- Several of the selected baseline models do not provide a fair basis for comparison. For instance, GCAN [4] incorporates the propagation path of the tweet and user profiles in addition to the source tweet content, features not utilized by the proposed model.\\n- A logistical concern arises from the fact that all the baseline models and their results, including SVM, DTC, RFC, GRU-2, FF, B- TransE, KCNN, GCAN, and KAN, appear to **have been directly borrowed from the FinerFact** [5] paper. Such practices should be avoided, and the authors should explicitly mention the sources of these baseline models in their paper.\\n- In the ablation study examining different variants of the proposed model, such as LM, AMR, LE|AMR, and LE|WikiAMR, the authors should provide significance hypothesis test results (e.g., T-test) alongside the standard deviation of the metrics across multiple runs. Including these statistical measures would enhance the interpretability of the results.\"}"}]}
{"paper_id": "TyFrPOKYXw", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Large language models (LLMs) have revolutionized tasks like understanding instructions and complex reasoning. With their increased societal impact, ensuring their outputs are not harmful is critical. Safety alignment in LLMs is crucial, particularly in minimizing harmful responses through fine-tuning. Recent advances involve Reinforcement Learning with Human Feedback (RLHF), which aligns LLMs with human preferences but struggles with balancing helpfulness and harmlessness.\nGap: Current methods like RLHF face significant challenges in balancing the objectives of being helpful while being harmless, as the two can often conflict. For example, a model refusing to answer a harmful query might be considered safe but is unhelpful. Hence, achieving a model that is simultaneously helpful, safe, and responsive remains a challenge.\nHypothesis: The authors propose Safe Reinforcement Learning from Human Feedback (Safe RLHF) as a solution to the tension between helpfulness and harmlessness in LLM training. Safe RLHF hypothesizes that decoupling the objectives into distinct reward and cost models, and using constraint optimization, can effectively manage and balance these objectives.\nMethod: Safe RLHF involves a multi-stage process. First, it separates the training data into helpfulness and harmlessness components, avoiding bias in crowdworker feedback. Two separate models are trained: a Reward Model for helpfulness and a Cost Model for harmlessness. Using the Lagrangian method, it dynamically balances the objectives of maximizing helpfulness while satisfying harmlessness constraints. Experiments included three rounds of fine-tuning the Alpaca-7B model, guided by human preferences.\nConclusion: Safe RLHF successfully improves both the helpfulness and harmlessness of LLMs compared to conventional methods. It provides a dynamic mechanism to balance conflicting objectives, significantly reducing the probability of harmful responses while maintaining performance according to human evaluations. Safe RLHF offers a novel integration of Safe RL and RLHF frameworks, contributing to enhanced human value alignment in AI systems.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 4, \"Contribution\": 4, \"Rating\": 8, \"Confidence\": 3, \"Strengths\": \"1. Separation of rewards and costs is an excellent idea that probably resolves the optimization contradiction in RLHF of LLM. \\n2. The paper provides concrete experimental results demonstrating the effectiveness of Safe RLHF in enhancing model performance and reducing harmful responses.\", \"Weaknesses\": \"Minor suggestions in Questions.\", \"Questions\": \"1. Fig2.(a) the symbols of axis indexes are absent.\\n2. Could you add the scatter point of Beaver-v2 and Beaver-v3 in Fig.6(a) and (b)?\"}"}]}
{"paper_id": "NvSwR4IvLO", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: The rapid advancements in Large Language Models (LLMs) enable them to perform various tasks efficiently, posing potential security risks due to misuse in plagiarism, fake news generation, and more. Recent research attempts to identify AI-generated texts using model signatures and watermarking techniques.\nGap: Currently proposed AI-text detectors are not reliable in real-world applications as they are vulnerable to attacks, particularly paraphrasing, which significantly reduces their efficacy. There's a necessity to evaluate the robustness of these detection methods against adversarial strategies.\nHypothesis: Existing AI-text detectors, including watermarking-based schemes, neural network-based classifiers, zero-shot classifiers, and retrieval-based detectors, are susceptible to evasion and spoofing attacks, rendering them ineffective in reliably distinguishing AI-generated from human-generated text.\nMethod: The authors develop a recursive paraphrasing attack using neural network-based paraphrasing models, applied to AI-generated texts to evade detection. They conduct experiments with different detector types and demonstrate this attack on passages of around 300 tokens. They also present a spoofing attack showing how adversaries can mislead detectors. Finally, they provide a theoretical framework connecting the effectiveness of a detector to the total variation distance between human and AI text distributions, using a paraphraser to reduce this distance.\nConclusion: The study reveals that current AI-generated text detectors are unreliable in practical scenarios, as they fall victim to paraphrasing and spoofing attacks. These findings show the inherent difficulty in creating robust detectors capable of differentiating human and AI text without substantial trade-offs. The research suggests that as AI models become more sophisticated, existing detectors will find it increasingly difficult to function effectively.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"* The authors address the important problem of reliable AI-generated text detection. This problem is likely to become increasingly important with the rapid rise in popularity of large language models in society.\\n\\n* The proposed approach is simple yet effective in undermining the reliability of current AI-generated text detectors. The simplicity of the attack may also make it more likely to generalize to different models and domains.\\n\\n* The authors perform a human evaluation using Amazon's Mechanical Turk (MTurk) to evaluate the resulting paraphrased text passages. Their results suggest the original content of the text passage is preserved in addition to the grammar and overall text quality.\\n\\n* The authors also discuss the overall hardness of AI text detection, providing a formal upper bound of detection performance based on the total variation (TV) between AI-generated and human-generated text distributions.\\n\\n* The paper is well-written and easy to follow.\", \"Weaknesses\": \"* The experiments only use text passages from a single dataset, and tend to only evaluate a single model for each detector type. Evaluations on a wider range of datasets and detectors would greatly strengthen any generalizable claims regarding the proposed paraphrasing attack.\\n\\n* Lack of baseline methods. In many of the experiments, the proposed attack is the only method being evaluated, have the authors compared their attack with similar attacks?\\n\\n* I appreciate the human evaluation in the \\\"Watermarked AI Text\\\" section, however, this type of evaluation is missing in the other experimental sections. For example, Figure 5 claims a significant drop in detector accuracy with minimal degradation in text quality; however, it's unclear to me how significantly text quality degrades based on a perplexity score increase from 6.15 to 13.55.\\n\\n* The insight that smaller TV between AI-generated and human-generated text distributions leads to more difficult detection problems seems rather obvious. Although the authors show that more complex models can lead to smaller TV distances, the authors do not provide any empirical evidence that smaller TV distances actually lead to more difficult AI text detection.\\n\\n* There is no empirical runtime evaluation of the proposed attack.\\n\\n* There are several grammatical errors throughout the paper, consider using a service like Grammarly to fix these issues.\\n\\n* Figure 9 is not colorblind friendly.\", \"Questions\": \"* How is TV distance defined, and why is it difficult to compute for larger datasets?\\n\\n* How did the authors determine 5 rounds of paraphrasing to be sufficient?\"}"}]}
{"paper_id": "le1UUMd45T", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Multiobjective combinatorial optimization problems (MOCOPs) are critical in various fields like routing, logistics, and planning, requiring solutions that consider multiple, often conflicting objectives. Traditional methods, such as evolutionary algorithms, have been employed to approximate Pareto optimal solutions, with recent advances in deep reinforcement learning (DRL) showing promise in solving single-objective combinatorial optimization problems (COPs). However, these have limitations in addressing MOCOPs effectively.\nGap: While DRL has been used to tackle MOCOPs, existing models based on the 'Learn to Construct' paradigm struggle with achieving sufficient proximity and diversity of solutions towards the true Pareto front. They heavily depend on model quality and lack comprehensive exploration of potential Pareto solutions in subproblem neighborhoods.\nHypothesis: The authors propose that embedding weight-related policy networks into multiobjective evolutionary algorithm (MOEA) frameworks within a 'Learn to Improve' paradigm can effectively guide the search direction and improve the quality and diversity of solutions for MOCOPs.\nMethod: The method involves a weight-related policy network (WRPN) designed to be integrated into MOEA frameworks like NSGA-II, MOEA/D, and MOGLS. It guides improvement operations based on a proximal policy optimization algorithm with a shared baseline to reduce variance. A quality enhancement mechanism improves the Pareto set via instance augmentation. Experiments were conducted on the multiobjective traveling salesman problem and multiobjective vehicle routing problem, demonstrating significant improvements over existing methods.\nConclusion: The proposed WRPN within the 'Learn to Improve' paradigm outperforms state-of-the-art methods, providing improvements in both proximity and diversity of solutions on classic MOCOPs. The approach, with its quality enhancement mechanism, shows superior results compared to existing DRL approaches and classical solvers like LKH under weighted decomposition schemes.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 4, \"Strengths\": \"L2I introduces a new DRL-based approach for MOCOPs. Unlike the traditional \\\"Learn to Construct\\\" methodology, L2I emphasizes iterative improvements. The L2I module has demonstrated adaptability as it can be integrated into various MOEA frameworks, such as NSGA-II, MOEA/D, and MOGLS. This mechanism, applying instance augmentation techniques, improves both the proximity and diversity of the Pareto set. The L2I methodology outperforms other state-of-the-art techniques on standard MOCOPs, even showing better performance than renowned solutions like the LKH solver for specific problems.\", \"Weaknesses\": \"Since the paper deals with the combinatorial optimization, decomposition methods are not sufficiently elaborated/reviewed.\", \"Questions\": \"How does L2I compare with methods follows a general scheme of \\\"learn-divide-and-conquer\\\" or \\\"divide-learn-and-conquer\\\"? In a sense, there are approaches that learn how to decompose a problem and there are approaches that decompose a problem before learning. I qualitative assessment may be sufficient.\"}"}]}
{"paper_id": "yIv4SLzO3u", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Class Incremental Learning (CIL) is a continuous learning framework aimed at handling tasks sequentially with disjoint class sets, while facing challenges such as catastrophic forgetting, where models forget previously learned information upon learning new tasks. Traditional methods such as knowledge distillation, architecture expansion, and parameter regularization have been employed to address these issues but come with inherent limitations.\nGap: Existing methods for CIL struggle with preserving past knowledge without relying heavily on previous task data or adding significant computational overhead. This hinders their applicability, especially in scenarios where memory storage for previous data is limited or not feasible.\nHypothesis: The authors propose a novel approach leveraging weight ensemble and constrained optimization called Bound-and-Average (BaA), which integrates inter-task and intra-task weight averaging alongside bounded model updates to effectively reduce catastrophic forgetting in CIL without altering network architectures or learning objectives.\nMethod: BaA incorporates two types of weight averaging: inter-task averaging, which maintains knowledge from all previous tasks by averaging model weights, and intra-task averaging, which improves generalization on the current task by averaging weights across multiple checkpoints during training. Additionally, the bounded update technique restricts model updates to remain close to a base model from previous tasks, balancing stability and adaptability. The method is evaluated on standard CIL benchmarks like CIFAR-100 and ImageNet-100/1000, showing improvements over existing methods with minimal extra computational cost.\nConclusion: The BaA approach demonstrates superior performance in retaining past knowledge and adapting to new tasks compared to state-of-the-art methods, while maintaining low overhead. It offers a simple plug-in solution to enhance existing CIL frameworks and is shown to be particularly effective under conditions of limited memory budgets, proving robust against catastrophic forgetting across various tasks.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 5, \"2022\": 364, \"Strengths\": \"The proposed method BaA is simple but effective, and the method can be integrated into existing methods to improve the performance without modifying their algorithm or architecture.\", \"Weaknesses\": \"(1) The contribution of this paper appears to be insufficient to fully support the article. Similar EMA methods are widely used in self-supervised learning and some incremental learning methods [1,2].\\n\\n[1]Yu C, Shi Y, Liu Z, et al. Lifelong person re-identification via knowledge refreshing and consolidation[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2023, 37(3): 3295-3303.\\n\\n[2]Liang M, Zhou J, Wei W, et al. Balancing between forgetting and acquisition in incremental subpopulation learning[C]//European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022: 364-380.\\n\\n(2) Lack of analysis experiments or visualization about how the proposed weight average mitigates the forgetting issue.\\n\\n(3) Tables 1 and 2 show that BaA can improve the performance of certain CIL methods. Experiments on the latest CIL methods in 2023 should be done to show that the BaA can also be integrated into the SOTA methods.\", \"Questions\": \"In Table 3, the results of the experiment are somewhat perplexing as the average new accuracy appears to be lower than the overall accuracy. In my assessment, the new accuracy represents the precision of classes of the current task, and the overall accuracy is expected to be lower than the average new accuracy due to knowledge forgetting.\"}"}]}
