{"paper_id": "u3xwwfHmBC", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nAccurate traffic forecasting is essential to enable advanced utilization of intelligent transportation systems. However, forecasting models often struggle to capture the complex spatio-temporal dependencies of traffic data, as they typically handle spatial and temporal dependencies separately. To overcome this limitation, we introduce the Tri-Tense Former (TTformer), a novel approach that captures spatio-temporal relationships through three tense-specific attention modules. We categorize traffic flow into three tense dimensions: past-to-present (present-perfect), present, and future. Each tense-specific attention module captures the dependencies within its respective traffic flow. Furthermore, to address incomplete traffic data, we improve the robustness of the model by employing contrastive learning with negative filtering technique that operates regardless of predefined adjacency matrices. TTformer significantly outperforms existing models by more effectively capturing spatio-temporal dependencies and improving traffic forecasting accuracy.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"1. Effective Multi-Attention Mechanisms: The network demonstrates that using distinct attention mechanisms—present-perfect and present attention—captures unique perspectives on traffic patterns, thereby enhancing forecasting accuracy.\\n2. Case Study Demonstration: A case study of the Dodger Stadium area highlights the effectiveness of the present-perfect and present attention mechanisms.\\n3. Experimental Results: The model achieves good performance on two datasets.\", \"Weaknesses\": \"1. Key Component Descriptions: Key components, such as present-perfect attention and negative filtering, lack clear explanations. Additionally, several essential components, including the tri-tense attention module and negative filtering, are detailed only in the appendix rather than in the main paper.\\n\\n2. Support for Claims: Some claims lack sufficient support. For example, it is unclear what specific inconsistencies exist in the traffic datasets and how contrastive learning addresses them.\\n\\n3. Computational Cost: The three attention mechanisms likely increase computational cost, yet no runtime comparisons are provided to quantify this impact.\\n\\n4. Related Work Misalignment: The related work section discusses traffic data imputation, even though the paper’s contrastive learning method is primarily intended to enhance representation quality rather than to impute missing data. If data imputation is relevant, clarifying missing data ratios in the experiments would be beneficial.\\n\\n5. Terminology Issues: Certain terms could be clearer. For instance, “future attention” and “present-perfect attention” are somewhat ambiguous.\\n\\n6. Clarity of Figures: Some figures, such as Figure 2, are unclear. For example, the purpose of the \\\"?\\\" symbols is not explained.\", \"Questions\": \"1. How does contrastive learning contribute to more robust representations? Are there experiments to verify this robustness?\\n\\n2. What specific inconsistencies are present in the traffic dataset? Providing examples would be helpful.\\n\\n3. How does present-perfect attention capture the influence of past traffic conditions on the current state? How many past time steps does present-perfect attention consider? Is it limited to 𝑡−1, or does it extend further back?\\n\\n4. Given that predefined adjacency matrices are typically accessible in traffic forecasting, what is the rationale for assuming they might be unavailable? And why is generating similarity matrices via spatial embeddings preferable to using a predefined adjacency matrix? Is there empirical evidence to support this?\\n\\n5. Have any time comparisons been conducted to assess the computational cost of incorporating three attention mechanisms?\"}"}]}
{"paper_id": "YKvBiRWdQC", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe introduce the Overcooked Generalisation Challenge (OGC) – the first bench-mark to study reinforcement learning agents’ zero-shot cooperation abilities when faced with novel partners and levels in the Overcooked-AI environment.\nThis perspective starkly contrasts a large body of previous work that has evaluated cooperating agents only on the same level or with the same partner, thus failing to capture generalisation abilities essential for real-world human-AI cooperation.\nOur challenge interfaces with state-of-the-art dual curriculum design (DCD) methods to generate auto-curricula for training general agents in Overcooked.\nIt is the first cooperative multi-agent environment specially designed for DCD methods and, consequently, the first evaluated with state-of-the-art methods. \nIt is fully GPU-accelerated, built on the DCD benchmark suite minimax, and freely available under an open-source license: http://anonymised.edu. \nWe show that state-of-the-art DCD algorithms fail to produce useful policies on this novel challenge, even if combined with recent network architectures specifically designed for scalability and generalisability. \nAs such, the OGC pushes the boundaries of real-world human-AI cooperation by enabling research on the impact of generalisation on cooperating agents.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"- The paper is well written and easy to understand.\\n- I really like that the authors aim to connect the UED and ad-hoc teamwork literature through this benchmark. The paper highlights clearly what is the gap of existing UED-compatible environments, i.e., environment and partner generalization, and thus is well motivated and novel.\\n- The evaluation seems to be thorough with many baselines and evaluation scenarios\\n- The project will be open-source\", \"Weaknesses\": \"Though I really like the paper at a high-level, there are quite a few significant improvements that can make the paper more mature:\\n\\n- The environment assumes a single recipe in the game and thus missing an important aspect of the game. There are variants of Overcooked that use multiple recipes that make the game more interesting and require more complex coordination [1,2,3]. I believe including more possible recipes improves the depth of the environment significantly, arguably adding another important layer of generalization.\\n- line 288: the observation space is not explained in details, it is especially hard for readers without prior Overcooked knowledge.\\n- It is not clear if the UED agents were just undertrained or the UED algorithms themselves struggle to generate complex layout. I wish the authors include training curves showing the performance on seen and unseen layouts of UED agents.\\n- The result of per layout generalization performance is missing from the main paper. I believe Table 13 shows this result but is not included in the main paper. I compare Table 13 and Table 14 (which is the raw results of Fig 5) and see that the self-play performance is actually lower than *test cross-play* performance, hinting that the agents are being *carried* by the FCP test partners. I believe that this observation is important and should be included and discussed in the main text.\\n- FCP does not explicitly generate diverse agents, which might not be a robust method for generating test partners.\\n\\n\\nMinor comments:\\n- Random and Stay baselines (Fig 5) are never introduced\\n- Fig 4 sentence 2: I find the sentence to not be consistent with the figure. Some of the generated layouts are definitely solvable.\\n- line 54: empty space on the right\\n- last line of page 2: the citation should not have parentheses as it is a part of a sentence\\n\\n\\n[1] Wu, Sarah A., et al. \\\"Too many cooks: Bayesian inference for coordinating multi‐agent collaboration.\\\" Topics in Cognitive Science 13.2 (2021): 414-432.\\n\\n[2] Yu, Chao, et al. \\\"Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased.\\\" The Eleventh International Conference on Learning Representations.\\n\\n[3] Charakorn, Rujikorn, Poramate Manoonpong, and Nat Dilokthanakul. \\\"Generating diverse cooperative agents by learning incompatible policies.\\\" The Eleventh International Conference on Learning Representations. 2023.\", \"Questions\": \"- Is it possible to **only** test partner generalization under the proposed environment (e.g., something similar to Fig. 5 but under seen layouts)? This would allow user to isolate between two types of generalization, diagnose, and develop better UED+ZSC algorithms.\"}"}]}
{"paper_id": "tePFpDgyqg", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nTraining large language models for long context understanding faces the challenge of data shortage.\nPrevious data engineering approaches mechanically concatenate short documents, which may create many pseudo long documents but raise concerns about data quality.\nIn this paper, we study the core attribute of high quality data for long context training, and provide a data pipeline, LongPack, to scale\nsuch data.\nWe found that long distance referrals, which occur in natural long documents, are crucial for long-context training.\nHowever, simply concatenating short documents does not reliably generate these relations.\nWe further show that the density of long-distance referrals, which is higher in longer documents, has a key role in training efficiency, making previous upsampling methods suboptimal.\nTo enrich long documents, we propose LongPack, a data pipeline that constructs long documents by packing shorter ones based on referral relationships.\nSpecifically, for web pages, which are the primary source for language model training, we found hyper-link a native signal for such a relation.\nBy packing web pages through their hyper-link connection, we can create longer, high-quality documents.\nOur experiments demonstrate that LongPackis highly scalable, generating a corpus of long documents equivalent in size to an entire pretraining dataset using just 0.5% root documents.\nFurthermore, the constructed documents have a ‘near-natural’ quality as innate long documents for long context training, reaching a 32.7% higher score than previous state-of-the-art methods.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"+ This goal of constructing long-distance referrals is well-motivated. Using semantically related tokens separated by a significant distance in pre-training will make the LLMs more capable of dealing with long contexts.\\n\\n+ The use of hyperlinks in data packing is simple and intuitive. The authors demonstrate the benefit of utilizing such natural signals of referral relationships between documents, especially on the web.\\n\\n+ The proposed framework is efficient, producing a corpus of long documents equivalent to an entire pretraining dataset using only 0.5% of the original documents.\", \"Weaknesses\": \"- The idea of using links between documents during language model pre-training has been explored in [1], where text segments from two linked documents are concatenated together as input. I feel the packing idea proposed in this paper bears similarity to that in [1]. Therefore, the technical novelty is somehow limited.\\n\\n- Statistical significance tests are not conducted. It is not clear whether the gaps between LongPack and the baselines are statistically significant or not in Tables 2 and 7. In fact, the improvement is subtle in some columns. \\n\\n- The study focuses heavily on web-based documents. It would be valuable to explore how long-distance referrals could be identified and leveraged in other domains, such as academic papers.\\n\\n[1] LinkBERT: Pretraining Language Models with Document Links. ACL 2022.\", \"Questions\": \"- Could you conduct a statistical significance test (e.g., two-tailed t-test) to compare LongPack with the baselines in Tables 2 and 7, and report the p-values?\"}"}]}
{"paper_id": "gx3LMRB15C", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSelf-supervision is often used for pre-training to foster performance on a downstream task by constructing meaningful representations of samples. Self-supervised learning (SSL) generally involves generating different views of the same sample and thus requires data augmentations that are challenging to construct for tabular data. This constitutes one of the main challenges of self-supervision for structured data. In the present work, we propose a novel augmentation-free SSL method for tabular data. Our approach, T-JEPA, relies on a Joint Embedding Predictive Architecture (JEPA) and is akin to mask reconstruction in the latent space. It involves predicting the latent representation of one subset of features from the latent representation of a different subset within the same sample, thereby learning rich representations without augmentations. We use our method as a pre-training technique and train several deep classifiers on the obtained representation. Our experimental results demonstrate a substantial improvement in both classification and regression tasks, outperforming models trained directly on samples in their original data space. Moreover, T-JEPA enables some methods to consistently outperform or match the performance of traditional methods likes Gradient Boosted Decision Trees. To understand why, we extensively characterize the obtained representations and show that T-JEPA effectively identifies relevant features for downstream tasks without access to the labels. Additionally, we introduce regularization tokens, a novel regularization method critical for training of JEPA-based models on structured data.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 4, \"Strengths\": \"1. The proposed SSL method is model-agnostic and could be coupled with various deep tabular models, which has wide range application.  \\n2. The strategy for masking representations is novel in tabular domain.  \\n3. The experiment is extensive.\", \"Weaknesses\": \"Please refer to the questions below.\", \"Questions\": \"1. What is the meaning of sentence 'We also learn h-dimensional index and feature-type embeddings' in Line 194-195? Please make it more clear.  \\n2. For Regularization token ablation in Fig.4, it seems that without including any regularization token (blue) has the best performance. However, the authors indicate that without including any regularization token, the optimization process does not manage to escape the initial collapse, thereby resulting in a poor performance. Please give more explanations.  \\n3. Except for regularization token ablation on training loss, the authors should further give ablation study on performance, since (1) training loss is not identical to the final evaluation performance and (2) the regularization token is critical for training JEPA-based models on structured data.  \\n4. The sentence 'We construct context and target masks so that there is no overlap between context and target masks but allow overlap within context masks and target masks' in Line 215-216 is confusing. 'no overlap between context and target masks' and 'allow overlap within context masks and target masks' are contradictory.  \\n5. The description about right four subfigures of Fig.3 is not enough.\"}"}]}
{"paper_id": "kTH3bEH6hW", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nFew-shot learning is essential in many applications, particularly in tabular domains where the high cost of labeling often limits the availability of annotated data. To address this challenge, we propose range-limited augmentation for contrastive learning in tabular domains. Our augmentation method shuffles or samples values within predefined feature-specific ranges, preserving semantic consistency during contrastive learning to enhance few-shot classification performance. To evaluate the effectiveness of our approach, we introduce FeSTa (Few-Shot Tabular classification benchmark), a benchmark consisting of 42 tabular datasets and 31 algorithms. On this benchmark, contrastive learning with our augmentation method effectively preserves task-relevant information and significantly outperforms existing approaches, including supervised, unsupervised, self-supervised, semi-supervised, and foundation models. In particular, our method achieves an average rank of 2.3 out of 31 algorithms in the 1-shot learning scenario, demonstrating its robustness and effectiveness when labeled data is highly limited. The benchmark code is available in the supplementary material.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 5, \"Strengths\": \"- This paper introduces an underexplored problem by focusing few-shot learning on tabular data. This is due to data unavailability in tabular domains, prohibiting training in a large scale manner. Thus, few-shot learning is a reasonable perspective in tackling such problems.\\n- This work also introduces a novel benchmark with 42 tabular datasets and 31 techniques for comparison. This benchmark has the potential to serve as a resource for future research efforts, providing a standardized comparison and facilitating the evaluation of new methods in tabular data analysis.\", \"Weaknesses\": \"- The problem scope is quite narrow and the proposed approach only works well in tabular domains. Additionally, the proposed augmentation approach demonstrates effectiveness primarily within tabular data domains and might not generalize to other types of data structures or formats.\\n- This paper has serious clarity issues in terms of problem introduction. The problem in this work is not elaborated well in the paper. The problem setup is quite general in which previous few-shot learning papers have discussed it. However, a specific focus problem setup on tabular domains is not described in the paper. Additionally, there is no clear problem description to differentiate among few-shot learning in several domains e.g., image, text, and tabular domains. This causes confusion in understanding the core problem in tabular domains compared to other modalities.\\n- Based on my understanding, the augmentation method is based on the ranged limited shuffling and sampling. However, this method is largely inspired by augmentation methods in the image domain, but here it is applied to a different domain. The strategy closely resembles what SimCLR introduced in its paper, with only a specific range constraint added to the technique. In SimCLR, we can interpret “range-limited sampling” as modifying the colors from a range between 0-255, and shuffling as cropping from a specific region. Therefore, the novelty of this approach sounds quite limited.\\n- The writing is quite poor. There are many irrelevant points in the paper e.g., lists of detailed baselines and augmentation. These sections do not provide meaningful insights or support the main contributions. As a result, the core contributions are obscured by unrelated information that does not directly connect to the main focus of the paper.\", \"Questions\": \"This paper missed explanation on how each method can be used to the problem at hands. For instance, XGBoost, CatBoost, LightBGM are not methods designed for few-shot learning. How are these methods modified to accommodate learning with a few data?\"}"}]}
{"paper_id": "EqcLAU6gyU", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThrough the collaboration of multiple agents possessing diverse expertise and tools, multi-agent systems achieve impressive progress in solving real-world problems. Given the user queries, the meta-agents, serving as the brain within these systems, are required to decompose the queries into multiple sub-tasks that can be allocated to suitable agents capable of solving them, so-called agent-oriented planning. In this study, we identify three critical design principles of agent-oriented planning, including solvability, completeness, and non-redundancy, to ensure that each sub-task is effectively resolved, leading to satisfactory responses to the original queries. These principles further inspire us to propose a novel framework for agent-oriented planning in multi-agent systems, leveraging a fast task decomposition and allocation process followed by an effective and efficient evaluation via a reward model. During the planning process, the meta-agent is also responsible for evaluating the performance of the expert agents, making timely adjustments to the sub-tasks and scheduling as necessary. Besides, we integrate a feedback loop into the proposed framework to further enhance the effectiveness and robustness of such a problem-solving process. Extensive experiments demonstrate the advancement of the proposed framework in solving real-world problems compared to both single-agent systems and existing planning strategies for multi-agent systems.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 2, \"Strengths\": \"The work shows three components which improve the ability of multi-agent LLM systems to improve the results of general LLM queries as compared to current methods.\\n\\nAll three components are shown to meaningfully add to the overall model, and directly tackle the presented critical principles for design.\", \"Weaknesses\": \"The work is difficult to follow at times, I believe it can be made much clearer, especially with regards to Figure 2. It is difficult to understand this diagram without enough direct context. There is no clear direction that it takes. The detector does not seem to lead to a replan as described.\\n\\nThe ordering of the sections, particularly the related work, and how it reads in context at the end, does not make sense, was this just compiled in the wrong place accidentally?\\n\\nThe results only have one dataset to my understanding. Can this be extended to more datasets?\\n\\nI have concerns that the rewards model does not generalize outside of this dataset? Or would that simply require more training on bigger datasets?\\n\\nI believe this work is good and novel, however it could be improved upon with clearer writing.\", \"Questions\": \"The results only have one dataset to my understanding. Can this be extended to more datasets?\\n\\nI have concerns that the rewards model does not generalize outside of this dataset? Or would that simply require more training on bigger datasets?\\n\\nThe ordering of the sections, particularly the related work, and how it reads in context at the end, does not make sense, was this just compiled in the wrong place accidentally?\\n\\nAre there cases where the scorers are human experts? It was a bit ambiguous as to whether this was in fact the case.\"}"}]}
{"paper_id": "qrTrnrEi9d", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nLarge language models (LLMs) combined with instruction tuning have shown significant progress in information extraction (IE) tasks, exhibiting strong generalization capabilities to unseen datasets by following annotation guidelines. However, their applicability to low-resource languages remains limited due to lack of both labeled data for fine-tuning, and unlabeled text for pre-training. In this paper, we propose TransFusion, a framework in which models are fine-tuned to use English translations of low-resource language data, enabling more precise predictions through annotation fusion. Based on TransFusion, we introduce GoLLIE-TF, a cross-lingual instruction-tuned LLM for IE tasks, designed to close the performance gap between high and low-resource languages. Our experiments across twelve multilingual IE datasets spanning 50 languages demonstrate that GoLLIE-TF achieves better cross-lingual transfer over the base model. In addition, we show that TransFusion significantly improves low-resource language named entity recognition when applied to proprietary models such as GPT-4 (+5 F1) with a prompting approach, or fine-tuning different language models including decoder-only (+14 F1) and encoder-only (+13 F1) architectures.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"line\": 419, \"Strengths\": \"The approach is effective and can be applied in a variety of configurations, i.e in decoder only models, on a large pretrained model like GPT-4 to be used zero shot on even on an encoder only model.\\nThe work makes a good effort in covering several low resource languages from available datasets.\\nThe approach improves over GPT-4 and for translate-traine baselines in most of the languages.\", \"Weaknesses\": \"Although the approach is relatively simple and straightforward it is not clearly explained on the paper and requires a thorough reading to understand it (see below).\\nOne of the salient points of this paper could also be considered a drawback. TransFusion has been shown to be flexible enough to be used in three different scenarios, each one of them having some minor differences in implementation. One could argue these three \\\"flavours\\\"of TransFusion are, in fact, different models (see below)\", \"Questions\": \"* Figure 1 could have shown more clearly the fact that the initial portion of the text is translated into English, ran on an english-based model and then with its output and the portion in the original language, the output is predicted. None of these aspects (nor the fact the TransFusion module is trained separately) is shown in this image. \\n\\n* Please fix the reference \\\"Team et all, 2023\\\", which took the \\\"Gemini Team\\\" as the name of the first author, and \\\"Team\\\" as its last name\\n\\n* Although it's not an issue, a better presentation would have completely filled the 10 pages in the submission.\\n \\n* line: 419  \\\"lagnauge\\\"\\n\\n* line 423 fix double parenthesis. Authors might be referring about two varieties of Tagalog, from Philippines and from Uganda\\n\\n* Authors might like to stress the fact that the different configurations of TransFusion are, indeed, different usages of the same approach.\"}"}]}
{"paper_id": "Bp0HBaMNRl", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nDiscovering causal structures with latent variables from observational data is a fundamental challenge in causal discovery. Existing methods often rely on constraint-based, iterative discrete searches, limiting their scalability to large numbers of variables. Moreover, these methods frequently assume linearity or invertibility, restricting their applicability to real-world scenarios. We present new theoretical results on the identifiability of nonlinear latent hierarchical causal models, relaxing previous assumptions in literature about the deterministic nature of latent variables and exogenous noise. Building on these insights, we develop a novel differentiable causal discovery algorithm that efficiently estimates the structure of such models. To the best of our knowledge, this is the first work to propose a differentiable causal discovery method for nonlinear latent hierarchical models. Our approach outperforms existing methods in both accuracy and scalability. We demonstrate its practical utility by learning interpretable hierarchical latent structures from high-dimensional image data and demonstrate its effectiveness on downstream tasks.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 3, \"Strengths\": \"- I thought this was interesting, original work. The class of graphs that they study is obviously limited but seems practical & the rank condition is intuitive.\\n- The paper is very well written - both the theory and methods section do a good job of explaining the intuition for why the method works\\n- The empirical results are strong on the datasets that they tested.\", \"Weaknesses\": \"* The coloured MNIST results appear very strong (though this is not my area), but not contextualized in the domain generalization literature. I would have at least expected you to report the published numbers from recent work from that setting. Autoencoders & Beta-VAE is not the right baselines?\\n* I would have liked a more detailed discussion of the learned MNIST graph. I am not sure what to make of figure 4 or table 3 in the appendix? Do those latents make sense? Is there a natural hierarchical structure that we would expect?\", \"Questions\": \"See weakness above.\"}"}]}
{"paper_id": "JzLcKWtGnl", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nNew era has unlocked exciting possibilities for extending Large Language Models (LLMs) to tackle 3D vision-language tasks. However, most existing 3D Multimodal LLMs (MLLMs) rely on holistic 3D scene information or specifically designated regions for 3D vision-language tasks, failing to capture multi-level location-based information.\nAddressing these concerns, we present Spatial 3D-LLM, a 3D MLLM specifically designed to enhance spatial perception and reasoning for 3D vision-language tasks by enriching the spatial embeddings of 3D scenes.\nSpatial 3D-LLM incorporates an LLM backbone and a meticulously designed progressive spatial awareness scheme that captures spatial information as the perception field expands, generating location-enriched 3D scene embeddings that serve as visual prompt.\nAdditionally, we introduce two novel tasks, namely 3D object distance measurement and 3D layout editing, and construct a 3D instruction dataset MODEL, to inspire more profound 3D spatial perception capabilities.\nExperimental results demonstrate that Spatial 3D-LLM achieves state-of-the-art performance across a wide range of 3D vision-language tasks, revealing the improvements stemmed from our progressive spatial awareness scheme of mining more profound spatial information and the proposed dataset.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 5, \"Strengths\": \"Current 3D LLMs still struggle to capture rich spatial information. The paper proposes an architectural improvement to address this issue. Additionally, the newly introduced tasks of distance measurement and object movement have great potential for valuable applications.\", \"Weaknesses\": \"My main concern is twofold. First, the method lacks an important comparison with LEO (An Embodied Generalist Agent in 3D World, ICML'24). The reported performance on public benchmarks seems to underperform LEO’s results, and this discrepancy is not sufficiently explained. Second, the newly introduced task does not include important baseline comparisons. For the measurement and movement task, incorporating several simple approaches as meaningful baselines would enhance the evaluation. For example, using off-the-shelf 3D segmentation and detection to extract object bounding boxes for direct measurement or constructing scene graphs from 3D scenes and using existing LLMs for both measurement and movement tasks.\", \"Questions\": \"* How does Spatial 3D-LLM compared to LEO?\\n* How to obtain the centers of the object for the refinement loss? Does the number of object center points need to be the same as seed points (256)? \\n* Is it possible to use off-the-shelf 3D segmentation and detection to extract object bounding boxes for direct measurement? Or construct scene graphs and leverage LLMs for both measuring and movement tasks?\\n* Does the movement task also consider whether there is space for the movement? Or is it more like an object localization task where the model only needs to ground the described object’s location and apply the movement?\\n* How do other baseline methods perform on distance measurement/movement tasks if fine-tuned with the proposed new data?\"}"}]}
{"paper_id": "hXJrQWIoR3", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nExplainable artificial intelligence (XAI) is an important area in the AI community, and interpretability is crucial for building robust and trustworthy AI models. While previous work has explored model-level and instance-level explainable graph learning, there has been limited investigation into explainable graph representation learning.\nIn this paper, we focus on representation-level explainable graph learning and ask a fundamental question: What specific information about a graph is captured in graph representations? Our approach is inspired by graph kernels, which evaluate graph similarities by counting substructures within specific graph patterns. Although the pattern counting vector can serve as an explainable representation, it has limitations such as ignoring node features and being high-dimensional.\nTo address these limitations, we introduce a framework for learning and explaining graph representations through graph pattern analysis. We start by sampling graph substructures of various patterns. Then, we learn the representations of these patterns and combine them using a weighted sum, where the weights indicate the importance of each graph pattern's contribution.\nWe also provide theoretical analyses of our methods, including robustness and generalization. In our experiments, we show how to learn and explain graph representations for real-world data using pattern analysis. Additionally, we compare our method against multiple baselines in both supervised and unsupervised learning tasks to demonstrate its effectiveness.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"- The notation is clearly defined, contributing to a well-articulated description of the proposed approach.\\n- The use of visualizations enhances the accessibility of pattern-based explanations.\\n- The paper effectively conveys the need to provide explanations based on graph patterns.\", \"Weaknesses\": \"- The time complexity would be significantly higher than the time complexity analysis. However, it is difficult to say it is incorrect because details about kernel usage, such as the number of graphlets employed, and preprocessing requirements are missing. In particular, efficiently identifying graphlets with more than four nodes is a challenging task.\\n- While the theoretical analysis is included, it lacks the intuition and analysis for understanding the proposed work.\\n - The introduction mentions post-hoc interpretability methods, but the connection to the proposed approach is unclear, as they appear to address entirely different tasks.\\n - As the paper addresses explanations at the representation level, comparisons with methods like UNR-Explainer [1] and MotifExplainer [2] would strengthen the related work or introduction section.\\n - The paper employs graph sampling, yet details and sensitivity analysis are omitted.\\n - GNNs typically struggle with modeling paths, trees, and graphlets due to limited expressive power. It remains unclear if this aspect is effectively visualized and well-learned in the training analysis.\\n\\n\\n\\nReferences:\\n\\n[1] Kang, Hyunju, Geonhee Han, and Hogun Park. \\\"UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models.\\\" The Twelfth International Conference on Learning Representations, 2024.\\n\\n[2] Yu, Zhaoning, and Hongyang Gao. \\\"MotifExplainer: a motif-based graph neural network explainer.\\\" arXiv preprint arXiv:2202.00519, 2022.\", \"Questions\": \"Please refer to the weaknesses above.\"}"}]}
{"paper_id": "67sSPPAZiG", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThis research aims to comprehensively explore building a multimodal foundation model for egocentric video understanding. To achieve this goal, we work on three fronts. First, as there is a lack of QA data for egocentric video understanding, we automatically generate 7M high-quality QA samples for egocentric videos ranging from 30 seconds to one hour long, based on human-annotated data. This is one of the largest egocentric QA datasets. Second, we contribute a challenging egocentric QA benchmark with 629 videos and 7,026 questions to evaluate the models’ ability in recognizing and memorizing visual details across videos of varying lengths. We introduce a new de-biasing evaluation method to help mitigate the unavoidable language bias present in the models being evaluated. Third, we propose a specialized multimodal architecture featuring a novel “Memory Pointer Prompting” mechanism. This design includes a global glimpse step to gain an overarching understanding of the entire video and identify key visual information, followed by a fallback step that utilizes the key visual information to generate responses. This enables the model to more effectively comprehend extended video content. With the data, benchmark, and model, we build MM-Ego, an egocentric multimodal LLM that shows powerful performance on egocentric video understanding.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"1. The authors curate a large-scale dataset with over 7 million QA samples for egocentric videos of varying lengths and introduce a QA benchmark called EgoMemoria, which contains 7,026 questions for 629 videos of different lengths. \\n\\n2. A specialized multimodal architecture is proposed, using a \\\"Memory Pointer Prompting\\\" mechanism. This includes a global glimpse step for overarching video understanding and a fallback step that uses key visual information to generate responses, enabling the model to comprehend extended video content more effectively.\", \"Weaknesses\": \"1. The first claim of contribution, the “narration to egocentric QA” data pipeline, I believe, should not be emphasized as a major contribution. This type of generating QA from dense captions have been used in multiple previous works, from the non-LLM era (like TVQA) to the LLM era (like LLama-VID). I believe it is better to tone down this statement.\\n2. The generated EgoMemoria Benchmark does not stands itself out of many long video understanding benchmarks. Even we narrow down to only egocentric videos, the GroundVQA dataset is also good to be compared and especially be used to test the MMEgo model. I would also recommend the authors to compare a long of long video datasets, providing more proofs that this benchmark is not so incremental.\\n\\nOverall, I think this paper is proposing a good model, while the benchmark side is relatively weak. I would recommend the authors to either tone down the benchmark in the paper to put more emphasize on this model, or improve the benchmark. I recommend the authors to consider using the datasets of EgoExo4D and EgoExoLearn, both of which also contain dense narrations of egocentric videos and should be very suitable for enriching your benchmark in terms of both size and diversity.\", \"Questions\": \"It would be great if the authors could answer my two points in the weakness section.\"}"}]}
{"paper_id": "kjmLabjSE2", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe study the Differential Privacy (DP) guarantee of hidden-state Noisy-SGD algorithms over a bounded domain. Standard privacy analysis for Noisy-SGD assumes all internal states are revealed, which leads to a divergent R\\'enyi DP bound with respect to the number of iterations. Ye & Shokri (2022) and Altschuler & Talwar (2022) proved convergent bounds for smooth (strongly) convex losses, and raise open questions about whether these assumptions can be relaxed. We provide positive answers by proving convergent R\\'enyi DP bound for non-convex non-smooth losses, where we show that requiring losses to have H\\\"older continuous gradient is sufficient. We also provide a strictly better privacy bound compared to state-of-the-art results for smooth strongly convex losses. Our analysis relies on the improvement of shifted divergence analysis in multiple aspects, including forward Wasserstein distance tracking, identifying the optimal shifts allocation, and the  H\\\"older reduction lemma. Our results further elucidate the benefit of hidden-state analysis for DP and its applicability.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 4, \"Strengths\": \"**New Bounds and Relevance:** The paper studies a crucial problem: finding tight privacy bounds for solutions of non-convex optimization problems. Tight privacy accounting is essential for practical implementations of DP-SGD, particularly in sensitive domains like healthcare. When assumptions about a privacy guarantee are not met (e.g. convexity), the guarantee is inapplicable, forcing the use of  overly conservative bounds that can hinder accuracy. \\n\\n**Novel assumption:** The authors introduce an assumption that allows them to reuse previous techniques (shifted divergence) under a milder condition (holder continuous gradient).\\n\\n**Clarity:** The techniques are clearly explained  for the full batch setting. While I did not check the math exactly, the proofs do follow logically. \\n\\n**Improved bounds:** The authors provide examples where their bound improves over prior work, even in the already studies (strongly) convex setting. \\n\\n**Broader impact:** The results are valuable for the broader ICLR community by enabling practical implementation of ML with sensitive data. The paper presents interesting techniques (Lemma 3.7) and assumptions (reduction of smoothness to Holder continuous gradient) in a clear and insightful way.\", \"Weaknesses\": \"Below I state some potential weaknesses of the paper and point to specific questions in the next question that would allow me to understand better. \\n\\n1. The authors present a contrived loss function that meets the Holder assumption to demonstrate it is not a vacuous  relaxation from the convex to the non-convex setting. While this function meets the assumption, it questions the applicability of their results in real world settings. (Q1)\\n\\n2. Theorems 3.1, 3.6, 3.11. Present bounds parameterized by optimal values of $\\\\tau$ and a sequence $\\\\beta$ making it hard to parse and consequently unintuitive. It becomes hard to understand practical implications and compare to prior work, and the claims about the burning period are hard to verify. (Q2)\\n\\n\\n3. The originality of Lemma 3.5 is questionable since a similar result was introduced before by Chien et al (2024b). While the authors acknowledge this prior work, they argue that it applies to a different context, machine unlearning. However, this is a misleading distinction because machine unlearning literature also tracks unlearning with a DP definition. (Q6)\\n\\n4. Minor comments:\\n- For a general reader it is not clear from the paragraph in the introduction why Output perturbation is not a good option. (It becomes more clear in figure 1 but I would suggest having it in the main body).\\n\\n- The first sentence presents noisy SGD and DP-SGD as equivalent, which is not true, in general. Noisy SGD typically refers to SGD where gradients are noisy, but there is no expectation about privacy guarantees. DP-SGD, should provide DP guarantees which might involve more steps than Noisy-SGD, e.g.,  clipping. \\n\\n- Line 96, K having diameter D would suggest the set is bounded but it does not matter for the bounds, D could be infinite and the bound still holds. I would clarify this since it makes the paper stronger :) \\n\\n- I suggest proofreading for typos. A few are:\\n    - Line 106: “differing with one point.” differing by?\\n\\n    - Fig 2 caption, line 125: “It done by constructing a coupling (G_t, G_t’), resulting a coupled process….”\\n\\n    - Theorem 3.11 statement “Then the DP-SGD update (1) under without replacement…”\\n\\n    - Missing parenthesis in Eq. 19.\\n\\n** Update **\\nSee discussion below addressing these weaknesses.\", \"Questions\": \"While I believe that the topic of the paper is significant, (1) the originality of ideas is not clear to me and (2) the applicability of the results it introduces could invalidate the progress I believe the paper makes in the area. The following questions are mostly to clarify this.\\n\\n\\n\\n**Q1** Is there a practical setting where one would use the function exhibiting Holder continuity ? Or is there another function used in a practical setting that meets this assumption?\\n\\n**Q2** How tractable are the problems in theorem statements 3.1, 3.6, 3.11? I assume it is easy since the plots for different settings are provided but I would suggest:\\n- Can the authors clarify how the bounds are calculated for the provided plots?\\n- Provide simplified versions or corollaries of these theorems that give more intuitive bounds? even if they are slightly looser. \\n- Provide concrete examples comparing these bounds to prior work for specific parameter settings?\\n\\n**Q3** From Figure 1 (b) one can assume there is a regime where the presented bounds are better than [AT22]. Is there a closed characterization for this regime? And can we compare with the convergence rate to see if this number of iterations is sufficient? This would prove the presented bounds are more practical than previous ones. \\n\\n**Q4** The $\\\\hat{L}$-Lipschitz constant estimated in Figure 2 is necessary to calibrate the noise value in practical deployment of DP-SGD. After reading the methodology in the appendix it is still unclear to me how it is estimated and if this estimate is an upper bound on the real constant. Can the authors comment on how to guarantee that $\\\\hat{L}$ is an upper bound and that this approach would not break privacy guarantees? \\n\\n**Q5** In Fig 2. a) what happens as $\\\\lambda \\\\to  0$? The paper only shows values for $\\\\lambda>0.5$… \\n\\n**Q6** What are the differences between the introduced Lemma 3.5 and the lemma from Chien et al.? \\n\\n**Q7** I found the following related works that have related topics, can the authors comment on them and how they relate to their work? \\n1. [https://arxiv.org/abs/2407.06496](https://arxiv.org/abs/2407.06496)\\n2. [https://arxiv.org/abs/2407.05237](https://arxiv.org/abs/2407.05237)\"}"}]}
{"paper_id": "I18MA5DjoP", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nTransformer-based large language models (LLMs) play a vital role in various NLP tasks, but the internal neurons are rather functioning in a black box style. In this work, we introduce the *Neuron Predictability Lens* (NPL), an analytical framework that focuses on the way neurons work within feed-forward networks (FFNs). NPL is useful in understanding and analyzing transformer-based LLMs. Based on this proposed framework, we conduct extensive experiments on LLaMA-2 and GPT-J. Firstly, we show that neuron activations are predictable and for the first time we introduce the concept of *Neuron Predictability*. Secondly, we apply NPL to both global and local analysis. For global analysis, we investigate how FFNs contribute to model behaviors explicitly and implicitly with the aid of NPL. For local analysis, we explore the connection between neuron predictability and neuron interpretability. We examine various functional neurons under NPL and uncover the existence of “background neurons.” With the findings mentioned above, we demonstrate the value of NPL as a novel analytical tool and shed light on its future application on model efficiency and/or effectiveness for improved language modeling.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 1, \"Contribution\": 3, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"Simple idea of modeling neuron predictability: The idea is simple, which is learning linear mapping between a state (neurons) to another state at different feed-forward network (FFN) layers.\\n\\nInteresting analysis results: Some results of analyses sound new and interesting. For example, easy-to-predict neurons are more important for performance than other hard-to-predict neurons.\\n\\nPotential to contribute future works of large language model field:\\nAs described in section 6, these analyses could contribute to other works for better computational efficiency if some concerns (in Weaknesses) are addressed well.\", \"Weaknesses\": \"Major: \\n- Experiment results: The PPL of original LLAMA-2 and GPT-J (33.08 and 26.58 in Table 2), on wikitext2 are too high regarding their large number of parameters. For example, GPT-J (6B) is known to be better than GPT-2 (1.5B) (check https://huggingface.co/EleutherAI/gpt-j-6b) , but GPT-2 (1.5B) achieved 18.34 PPL on wikitext2. I guess the trained large language models did not converge well, or maybe the simplified forward propagation (no consideration of layer normalization) is the key reason.\\n- Lack of explanations: I believe that this paper could be improved by explaining more clearly some parts as follows: \\n: In section 3, to select which dimension of state to substitute, this paper used L2 distance and Pearson correlation. However, it is unclear what are the two objects used to compute distance (or correlation). \\n: Equations 7, 8 are introduced without explanations of some notations, such as ‘g’ with square brackets, sigma square (maybe variance?), operation ‘|’ with ‘ㄱ’ shape symbol, and ‘theta_P’.\\n: The difficulty score, ‘s^{l,i}’ in Equation 8, is indexed with only i-th neuron and l-th layer. However, because this means difficulty for predictability, I guess it needs additional index to indicate ‘from which layer’s neuron is used to predict’.\\n: For the baseline of Figure 5’s experiments, this paper utilized the difficulty score of a random subset of tokens. Firstly, it is hard to understand what is the random subset of tokens. Also, the difficulty score requires a property function (P) to filter out neurons. This is not explained in the paragraph within lines 384~391. Also, it is not clear why this could be the global baseline for n-gram sensitive, difficulty (loss) sensitive, position sensitive analyses? \\n: Each property functions, such as n-gram and position sensitivity, need clearer definitions. Also, it was hard to understand what ‘arbitrary’ and ‘successive’ positions with only text.\\n\\nMinor: \\n- Less intuitive naming for two main perspectives: For example, ‘global view’ (relationship between neuron activation and model performance) and ‘local view’ (relationship between neuron activation and linguistic functions) are less intuitive.\\n- Location of the paragraph (line 213~215) looks improper in section 3.2, because it contains the contents of Section 4 (Table 1, ‘Complete’, ‘Partial’ substitutions and ‘Original‘ models). It is hard to follow this paragraph.\\n- Need clearer explanations: For example, about the findings in section 4.2, the authors might want to clearly mention which type of substitution (complete or partial) they are talking about.\", \"Questions\": \"- In Figure 2 (a, b), the MSE losses of diagonal terms indicate the performances of linear mappings learned to predict the neuron activation (hidden state of FFN) of a layer given the same hidden state of that layer. This sounds like a trivial task and can be perfectly solved by identity weight matrix. However, in results, the diagonal MSE performances are not 0.0, and some of other off-diagonal linear mappings achieved better MSE performances. Could you explain what I am missing here? \\n\\n- Why the predictor is a linear model? Can we use multi-layer perceptrons?\"}"}]}
{"paper_id": "qpDqO7qa3R", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThis paper introduces a method for zero-shot video restoration using pre-trained image restoration diffusion models. Traditional video restoration methods often need retraining for different settings and struggle with limited generalization across various degradation types and datasets. Our approach uses a hierarchical latent warping strategy for keyframes and local frames, combined with token merging that uses a hybrid correspondence mechanism that integrates spatial information, optical flow, and feature-based matching. We show that our method not only achieves top performance in zero-shot video restoration but also significantly surpasses trained models in generalization across diverse datasets and extreme degradations (8$\\times$ super-resolution and high-standard deviation video denoising). We present evidence through quantitative metrics and visual comparisons on various challenging datasets. Additionally, our technique works with any 2D restoration diffusion model, offering a versatile and powerful tool for video enhancement tasks without extensive retraining.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 3, \"Strengths\": \"1. The method is training-free which makes it computationally practical.\", \"Weaknesses\": \"1. To my understanding, the method relies on certain architectural heuristics inspired by the video-editing literature rather than on a solid mathematical framework. Since the method involves no training, there is no theoretical guarantee that it won't fail under certain conditions.\\n\\n2. The method combines existing ideas from video editing, which on my opinion is still acceptable; however, this limits its novelty.\\n\\n3. The improvement over the baseline on some datasets, particularly in the case of denoising, is not significant.\", \"Questions\": \"See weaknesses.\"}"}]}
{"paper_id": "dSQtMx6dPE", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nGraph Neural Networks (GNNs) have shown remarkable performance in various applications. Recently, graph prompt learning has emerged as a powerful GNN training paradigm, inspired by advances in language and vision models. Here, a GNN is pre-trained on public data and then adapted to sensitive tasks using lightweight graph prompts. However, using prompts from sensitive data poses privacy risks.\nIn this work, we are the first to investigate these risks in graph prompts by instantiating a membership inference attack that reveals significant privacy leakage. We also find that the standard privacy method, DP-SGD, fails to provide practical privacy-utility trade-offs in graph prompt learning, likely due to the small number of sensitive data points used to learn the prompts.\nAs a solution, we propose two algorithms, DP-GPL and DP-GPL+W, for differentially private graph prompt learning based on the PATE framework, that generate a graph prompt with differential privacy guarantees.\nOur evaluation across various graph prompt learning methods, GNN architectures, and pre-training strategies demonstrates that our algorithms achieve high utility at strong privacy, effectively mitigating privacy concerns while preserving the powerful capabilities of prompted GNNs.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 3, \"Strengths\": \"1. The paper is well-structured, easy to read, and well-written.\\n2. It addresses privacy risks in graph prompt learning and proposes two non-gradient-based methods.\", \"Weaknesses\": \"1. Lack of Experimentation: In Section 3, the author demonstrates through MIA experiments that prompts based on private graphs can lead to node privacy leakage, proving the existence of privacy risks and subsequently proposing a DP-based protection method. However, while DP provides theoretical guarantees, it is unclear whether there is any impact on the effectiveness of attacks after DP is applied. The current experiment section lacks a demonstration of MIA attack results after DP has been implemented.\\n2. Unclear Theoretical Section: Graph DP is generally divided into node-DP and edge-DP. The target of the author’s attack experiments is to determine whether a certain node is in the prompt's training graph dataset, which falls under node-DP. However, node-DP involves protecting node features, edges, and labels. In the proposed method, there does not appear to be any protection for labels.\", \"Questions\": \"1. How effective are DP-GPL and DP-GPL+W in resisting MIA? Could the author conduct and report MIA experiments on the DP-protected models (DP-GPL and DP-GPL+W) and compare the results to the unprotected baselines?\\n2. In DP-GPL+W, the teacher voting is weighted based on node centrality, and the partitioning strategy changes to outperform DP-GPL. Why is this effective? Could the author provide experimental or theoretical evidence, such as ablation studies?\\n3. Is the proposed method only applicable to homogeneous graphs, or is it suitable for heterogeneous graphs as well?\\n4. The current experiments focus only on the k-shot scenario where k=5. Could performance comparisons for smaller k-values be added?\\n5. According to weakness 2, please clarify how your method addresses label privacy.\"}"}]}
{"paper_id": "GbgCRJedQ7", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nVarious parameter-efficient fine-tuning (PEFT) methods, including LoRA and its variants, have gained popularity for reducing computational costs. However, there is often an accuracy gap between PEFT approaches and full fine-tuning (FT), and this discrepancy has not yet been systematically explored. In this work, we introduce a method for selecting sparse sub-matrices that aim to minimize the performance gap between PEFT vs. full fine-tuning (FT) while also reducing both fine-tuning computational cost and memory cost. Our Sparse Matrix Tuning (SMT) method begins by identifying the most significant sub-matrices in the gradient update, updating only these blocks during the fine-tuning process. In our experiments, we demonstrate that SMT consistently surpasses other PEFT baseline (e.g. LoRA and DoRA) in fine-tuning popular large language models such as LLaMA across a broad spectrum of tasks, while reducing the GPU memory footprint by 67\\% compared to FT. We also examine how the performance of LoRA and DoRA tends to plateau and decline as the number of trainable parameters increases, in contrast, our SMT method does not suffer from such issue.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 4, \"Strengths\": \"- Good empirical evaluation across multiple model sizes and datasets\\n- Insightful ablations in Sec. 5 and the appendix\", \"Weaknesses\": \"- Some practical questions (e.g. block size and mask generalization) are not addressed\\n- No comparison with other delta tuning / diff pruning approaches and random masking (https://arxiv.org/abs/2405.02596, https://aclanthology.org/2023.emnlp-main.931.pdf)\", \"Questions\": \"- What is the intention behind using 256x256 sub-matrices? What happens in terms of quality and efficiency when you use smaller (down to 1x1) or larger sub-blocks?\\n- iiuc the warm-up phase still needs the same memory as full fine-tuning. Can you avoid this phase by reusing sub-block selection from a different [multi-task] experiment for a new task?\\n- The PET Speed-Ups in Table 1 seem fairly large to me.. I would expect 2-4x speed ups by LoRA, not ~14x. Could you cite work that reports LoRA speed-ups over full fine-tuning in a similar ballpark?\\n- L223: is the gradient step computation cost really z% cheaper? I understand the argument for a single parameter matrix, but don't you need full gradients in layers closer to the output layer to correctly propagate the gradients to this point? Same for the activation costs in the forward pass (L223)\\n- Why are some of the full fine-tuning results in Table 2 missing?\"}"}]}
{"paper_id": "ZZVOrId3yN", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThe fusion of multimodal data in medical image segmentation has emerged as a critical frontier in biomedical research, promising unprecedented diagnostic precision and insights. However, the intricate challenge of effectively integrating diverse data streams while preserving their unique characteristics has persistently eluded comprehensive solutions. This study introduces CrossModalNet, a groundbreaking architecture that revolutionizes multimodal medical image segmentation through advanced mathematical frameworks and innovative domain adaptation techniques. We present a rigorous mathematical analysis of CrossModalNet, proving its universal approximation capabilities and deriving tight generalization bounds. Furthermore, we introduce the Cross-Modal Information Flow (CMIF) metric, providing theoretical justification for the progressive integration of multimodal information through the network layers. Our Joint Adversarial Domain Adaptation (JADA) framework addresses the critical issue of domain shift, simultaneously aligning marginal and conditional distributions while preserving topological structures. Extensive experiments on the MM-WHS dataset demonstrate CrossModalNet's superior performance. This work not only advances the field of medical image segmentation but also provides a robust theoretical foundation for future research in multimodal learning and domain adaptation across various biomedical applications.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 1, \"Presentation\": 1, \"Contribution\": 1, \"Rating\": 1, \"Confidence\": 3, \"Strengths\": \"The authors present detailed definitions and theoretical proofs, and show them works on one dataset.\", \"Weaknesses\": \"I recommend the authors withdraw their submission as it does not meet the necessary standards and may waste reviewers' time.\\n\\n1. Insufficient Loss Function Analysis: The authors need to conduct a thorough analysis of the loss function within the nnUNet framework across multiple cross-modal datasets. Referencing studies like \\\"nnu-net revisited: A call for rigorous validation in 3D medical image segmentation\\\" and \\\"Loss Odyssey in Medical Image Segmentation\\\" would help validate that their approach results in genuine improvements.\\n2. Unoriginal Theoretical Proofs: The theoretical proofs (e.g. Eq.6 to Eq. 8,) lack novelty and logical, appear to replicate content from established sources such as \\\"Pattern Recognition and Machine Learning\\\" (PRML) or may have been generated using AI tools like GPT-4. This raises concerns about the originality and contribution of the theoretical aspects presented. The Complexity of CrossAttention is wierd to be a lemma.\\n3. Non-Innovative Loss Balancing for Multimodal Data: The approach to balancing the loss function for two modalities does not introduce a new concept and has been previously addressed in existing literature. The authors should clarify how their method offers a distinct advantage or improvement over existing techniques.\\n4. It wierd that the classifier present in the Fig. 1, since the task is segmentation. The term jaccard loss, graph mapping loss are not mentioned any where in the paper.\\n5. The Sec 2.1.4 is wierd, the deformable is usually used for medical registration task, maybe the authors just use the GPT in a wrong way by coping (CrossModalNet: exploiting quality preoperative images for multimodal image registration).\\n\\n\\nMinor Issues:\\n1. Missing Citations: The manuscript lacks numerous essential citations, which undermines the depth of the literature review and fails to acknowledge relevant prior work in the field.\\n2. Incorrect Citation Formatting: There is inconsistent use of citation commands, such as mixing \\\\citep and \\\\citet, leading to formatting errors and potential confusion for readers.\\n3. Misleading Network Structure Definitions: Providing definitions and proofs related to the network structure is misleading. Definitions and proofs should specifically address the unique aspects of the proposed network without conflating them with general architecture principles.\\n4. Inaccurate or Incorrect Citations: References cited on lines 216, 220, and 233 appear to be invalid or nonexistent, suggesting that some citations may have been improperly generated, possibly using GPT. These need to be verified for accuracy and legitimacy.\", \"Questions\": \"Please refer to weakness.\"}"}]}
{"paper_id": "gLHuAYGs6a", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nMulti-view clustering, which aims to partition data samples into disjoint clusters by leveraging information from multiple views, has been shown to be highly effective when incorporating structure information, as widely acknowledged in recent works. This paper presents a novel structural multi-view clustering network via heterogeneous random walks, guided by a unified sample-level structure to enhance clustering performance. We first construct a multi-view heterogeneous graph consisting of sample nodes and view nodes, capturing correlations between views while preserving their specific structures. Then, a multi-step random walk strategy on the heterogeneous graph is introduced to explore high-order sample structures across various views, ensuring that each view structure is taken into account. Based on this, a lightweight network is designed to facilitate structure learning both within-view and cross-view, guided by the unified structure derived from heterogeneous random walks, ultimately achieving representations that are conducive to clustering. Extensive experiments on five real-world datasets demonstrate the superiority of the proposed method.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"- The investigated problem holds significant value in the domain of multi-view clustering and is also of great interest to the research community.\\n- This paper is well written and easy to read and understand.\\n- Experiments are done on clustering tasks using different methods, ensuring a comprehensive evaluation.\", \"Weaknesses\": \"- The time and space complexities for Algorithm 1 and the other methods should be given.\\n\\n- Is there any theoretical support for the proposed algorithm expected performance improvement?\\n\\n- How about the convergence of the algorithm? Is there any convergence proof or theoretical guarantee?\\n\\n- I would appreciate a broader discussion on why the proposed method performs better than the others, for well understanding the connection and difference among existing methods.\", \"Questions\": \"Please see Weaknesses.\"}"}]}
{"paper_id": "x5l5PRtvul", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nStein variational gradient descent (SVGD) is a particle based approximate inference algorithm. Many variants of SVGD have been proposed in recent years, including the hybrid kernel variant (h-SVGD), which has demonstrated promising results on image classification with deep neural network ensembles. In this paper, we demonstrate the ability of h-SVGD to alleviate variance collapse, a problem that SVGD is known to suffer from. Unlike other SVGD variants that alleviate variance collapse, h-SVGD does not incur additional computational cost, nor does it require the target density to factorise. We also develop the theory of h-SVGD by demonstrating the existence of a solution to the hybrid Stein partial differential equation. We highlight a special case in which h-SVGD is a kernelised Wasserstein gradient flow on a functional other than the Kullback-Leibler divergence, which is the functional describing the SVGD gradient flow. By characterising the fixed point in this special case, we show that h-SVGD does not converge to the target distribution in the the mean field limit. Other theoretical results include a descent lemma and a large particle limit result. Despite the bias in the mean field limiting distribution, experiments demonstrate that h-SVGD remains competitive on high dimensional inference tasks whilst alleviating variance collapse.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 2, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"The paper provides interesting theoretical results on h-SVGD. It extend the known results on SVGD to h-SVGD. The experimental results effectively support the interest of h-SVGD.\", \"Weaknesses\": \"Major weaknesses:\\n- Assumption (A1) does not seem to be well written. To suppose that $\\\\lim_{|x|\\\\to +\\\\infty} V(x) = +\\\\infty$ must be a more realistic assumption to ensure that $\\\\pi$ could be a probability measure. Is it a writting error ?\\n- There is a few intuitions and comments in the paper, making the paper hard to read. In particular, I suggest to discuss the assumptions in details. A reminder on Wasserstein gradient flow will be appreciable. Finally, Proposition 3.6 is not comment.\\n\\nMinor weaknesses:\\n- Equation 6 : there is a typo, it might be $(x, \\\\cdot)$ instead of $(\\\\cdot, x)$.\\n- line 198 : in the paper notations, it might be $\\\\mathcal{H}$ instead of $\\\\mathcal{H}_1$.\\n- The remark in line 246 seems inconsistent because Assumption (A1) induce that $V$ is bounded.\\n- In line 250, the constant $L$ is said to be dependent of $k_1, k_2$ and $p$. However it is not clear what is the variable $p$.\\n- In line 329, the normal density do not verify Assumption (A1). In fact in this case $V$ is quadratic.\\n- line 226, I suggest to be more precise about the sense of \\\"symetric function\\\" in this context.\", \"Questions\": \"- In Assumption (A2), the first part can be deduce from Assumption (A1). In fact, Assumption (A1) induce that $V$ is bounded. Why do you precise this assumption ?\\n- Can you give an interpretation of the second part of Assumption (A2) ?\\n- Can you give an interpretation of Assumption (A3) ?\\n- Do you have examples of potentials $V$ that verifies Assumptions (A1)-(A2)-(A3)-(A4) ?\\n- According to your analysis of h-SSVD you have a proposition of a sampling strategy that does not suffer from dimensional collaps and sample the right distribution ?\"}"}]}
{"paper_id": "pOUAVXnOQP", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nImplicit Neural Representation (INR) has emerged as a promising method for characterizing continuous signals. This paper addresses the spectral bias exhibited by conventional ReLU networks, which hampers their ability to reconstruct fine details in target signals. We introduce Sinusoidal Trainable Activation Functions (STAF), designed to model and reconstruct diverse complex signals with high precision. STAF mitigates spectral bias, enabling faster learning of high-frequency details compared to ReLU networks. We demonstrate STAF's superiority over state-of-the-art networks such as KAN, WIRE, SIREN, and Fourier features, achieving higher accuracy and faster convergence with superior Peak Signal-to-Noise Ratio (PSNR). Our extensive experimental evaluation establishes STAF's effectiveness in improving the reconstruction quality and training efficiency of continuous signals, making them valuable for various applications in computer graphics and related fields.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 3, \"Strengths\": \"1. The choice of activation functions for each layer's neurons significantly impacts the performance of INRs. SIREN demonstrated that periodic activation functions are effective in INRs by utilizing fixed sine functions. In contrast, STAF employs periodic activation functions that are dynamically trained with the MLP's weights and biases during the training process, enhancing the network's ability to better capture and reconstruct high-frequency signals. This design is similar to Fourier series, aiming to achieve maximum efficiency with minimal coefficients. As STAF uses layer-wise sharing, each layer shares a unique activation function, allowing the activation behavior to adjust according to the features processed by each layer. This approach aligns well with the hierarchical structure of MLPs. As a result, STAF has shown superior performance across various representations, including images, audio, and shapes.\\n\\n\\n2. SIREN's initialization simply uses sine functions to ensure that the output distribution follows a consistent pattern. STAF goes a step further by adjusting the post-activation values to follow a standard normal distribution, thereby enhancing the stability of the training process. This improvement is well-explained with equations and proofs.\", \"Weaknesses\": \"Models utilizing STAF are more efficient than SIREN, as they can achieve higher performance with fewer parameters. This is because the activation function leverages frequency-related parameters to combine multiple sine functions, resulting in greater expressive power. However, as the frequency-related parameter (nf in the code) increases, the computational cost rises rapidly. This can slow down training and require more computational resources and memory. Therefore, when using STAF, it is important to appropriately adjust the nf value to manage the computational burden effectively.\", \"Questions\": \"Minor revision comments:\\n\\n1. Some commas or periods are missing after equations.\\n2. On page 7, in the Results and Analysis section, \\\"Figure 8b\\\" is incorrectly referenced and should be \\\"Figure 2.\\\"\\n3. On page 7, in the Results and Analysis section, the description for \\\"Figure 4\\\" is entirely incorrect. The numerical details related to the methods are misplaced.\\n4. I'm not sure if including NTK (Neural Tangent Kernel) in the key contributions is appropriate, given that it is only discussed in the appendix and not in the main text.\"}"}]}
{"paper_id": "iN64nSYt0z", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nDespite the remarkable success of Large Language Models (LLMs), they still exhibit a limited capability to align their outputs to the user instructions. In this work, we introduce a simple and effective method, which we name as GUIDE, that mechanistically increases attention scores in instruction tokens. To support this operation, we present Influence, a novel metric that highlights how the user's instructions propagate with transformer layers and impact the LLM output. Our results show that GUIDE improves the accuracy of following certain instructions 29.4% to 60.4 %, outperforming natural prompting alternatives.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"- The paper is tackling an important problem in LLM. For instance, as the user prompt gets longer, we observe the LLM not following every part of the user instruction. A method that can enhance instruction following is a great contribution to the field.\\n- The paper is clear and generally well written.\\n- Influence score seems to give a good insight into evaluating the impact of tokens on the entire sequence.\", \"Weaknesses\": \"- It is missing a very relevant work from ICLR 2024, \\\"Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs\\\" by Zhang et al.\\n- While it is good to know that the llm is now producing French more often, but this may be at the cost of degraded output accuracy. I suspect that if the attention weights are manually changed, the quality of the outputs may be affected. I think it is very important to measure this as well.\\n- I think Influence metric shouldn't be called \\\"metric\\\", because a low influence score doesn't necessarily mean the model is not following the instruction well. I think \\\"probe\\\" is a more appropriate term, which helps us to perform intrinsic analysis.\", \"Questions\": \"- Could you please describe your work with respect to Zhang et al. (ICLR 2024) as mentioned in the weakness?\\n- Could you measure the change in output quality as you apply your method?\"}"}]}
{"paper_id": "gRuZkEy49k", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nGenerative Flow Networks, or GFlowNets, formulate generative modelling in discrete spaces as a sequential decision-making problem. Sampling plays a key role in GFlowNet training, as most algorithms use the learned policy to sample trajectories from the environment. Monte-Carlo Tree Search (MCTS) is a planning algorithm that has successfully been applied to train sequential decision-making models with reinforcement learning (RL). In this work, we leverage known connections between GFlowNets and maximum-entropy RL to adapt MCTS for GFlowNet training. We prove that standard MCTS tree construction processes can be modified to calculate the optimal flows for a GFlowNet, given sufficient samples from the environment. Our results extend to multiple cases of GFN modelling, including terminating-energy and intermediate-energy environments. We investigate practical strategies for employing MCTS as a sampling tool and apply it to different GFN parameterizations and training objectives. Through extensive experiments in a variety of discrete domains, including a language-based reasoning task, we show that our proposed method offers an improvement over standard on-policy sampling.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"**Originality:** Whiles MCTS and GFlowNets are not novel ideas, the novelty arises in the adaptation of MCTS sampling to a domain in which it has not been used, namely, in sampling trajectories for training GFlowNets.\\n\\n**Significance:** MCTS is a popular, easily-implementable algorithm known to improve sampling efficiency in planning domains and provide statistical guarantees on performance. Having an MCTS-based sampling method for training GFlowNets can be a quick-and-easy approach for improving on the performance of these models that can be adopted by anyone working with GFlowNets.\\n\\n**Clarity:** Not being familiar with prior work in GFlowNets, it did not take too much effort to get the gist of how they work from this paper. That being said there are some concerns with the clarity (described in the Weaknesses.)\\n\\n**Quality:** For the most part the approach for adapting MCTS to GFlowNets (which the authors call MCDS) is intuitively sound. The authors also chose a sufficient number of domains (one demonstrative and two complex) for conceptualizing GFlowNets (with and without MCDS) and measuring its performance.\", \"Weaknesses\": \"While the paper presents an interesting and simple idea, there are a number of concerns with the work. The more concerning issues deal with the experimental evaluation.\\n\\n1. The results for Hypergrid (Fig 3) do not appear meaningful:\\n\\n    - The plot states that it shows mean and standard deviation however there no markers, fills or any visual indication of the standard deviation.\\n\\n    - The standard deviation is not a statistical significance test --- it is a measure of dispersion. Confidence intervals would be an appropriate choice for visualizing statistical significance.\\n\\n    - Without any statistical testing it is difficult to verify whether the difference in performances are significant. Hence, I believe the results do the support the authors' claims that MCDS improves the performance of GFlowNets over on-policy sampling in Hypergrid.\\n\\n    - Secondly, inspecting the plots do not show that their is indeed any performance gain over conventional MCTS sampling.\\n\\n    - Lastly, even if CI plots were produced it is hard to imagine that averaging over a mere 3 seeds would produce results of significance. With 3 seeds the authors may just plot the results over each seed.\\n\\n2. Some of the issues from (1) similarly exist for the results in Table 1. The standard deviations are reported however this provides no indication of statistical significance.\\n\\n3. The explanation of the Hypergrid domain in Sec 5.1 did not make any sense and there was no explanation of the performance metric. I had to read the original GFlowNet paper to understand it.\\n\\n4. The explanation for MCTS in Sec 2.2 describes it such that all states in a MCTS-tree, and consequently MCDS-tree, are unique which is not necessarily true. In fact, if I understand the diagrams in Fig 2, the equivalent trees all will have duplicate states.\\n\\n5. Additionally, in Fig 2, I cannot understand why the forward policy for MCTS is the way it is. If the reward function for MCTS is using the one shown in Eq 2, then if sampled enough, MCTS should terminate at the bottom left corner and observe a reward. Am I missing something?\", \"Questions\": \"Line 57: \\\"benchmark\\\" has a typo\\n\\nLine 157: What is $Q$? It hasn't been defined.\"}"}]}
{"paper_id": "d23EVDRJ6g", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nGenerative masked transformer have demonstrated remarkable success across various content generation tasks, primarily due to their ability to effectively model large-scale dataset distributions with high consistency. However, in the animation domain, large datasets are not always available. Applying generative masked modeling to generate diverse instances from a single MoCap reference may lead to overfitting, a challenge that remains unexplored. In this work, we present MotionDreamer, a localized masked modeling paradigm designed to learn motion internal patterns from a given motion with arbitrary topology and duration. By embedding the given motion into quantized tokens with a novel distribution regularization method, MotionDreamer constructs a robust and informative codebook for local motion patterns. Moreover, a sliding window local attention is introduced in our masked transformer, enabling the generation of natural yet diverse animations that closely resemble the reference motion patterns. As demonstrated through comprehensive experiments, MotionDreamer outperforms the state-of-the-art methods that are typically GAN or Diffusion-based in both faithfulness and diversity. Thanks to the consistency and robustness of quantization-based approach, MotionDreamer can also effectively perform downstream tasks such as temporal motion editing, crowd motion synthesis, and beat-aligned dance generation, all using a single reference motion. Our implementation, learned models and results are to be made publicly available upon paper acceptance.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"- The paper is well-written and is easy to follow. \\n\\n- Qualitatively results look impressive. Ablation studies prove the effectiveness of the designs.\\n\\n- The authors introduce various applications of motion synthesis and achieve great performance.\", \"Weaknesses\": \"- Generative masked modeling for motion synthesis has been investigated in many recent works, such as MMM, Momask, MotionGPT, as described in paper. On the other hand, single motion synthesis is also not new, such as SinMDM. It seems that MotionDreamer integrates the techniques of generative masked modeling into the task of single motion synthesis, including motion tokenization and codebook distribution regularization.\\n\\n- Capturing local dependencies of motion features is quite important for single motion synthesis. SinMDM introduces QnA layers that allow local attention with a temporally narrow receptive field. And MotionDreamer incorporates sliding window local attention to achieve this. Besides, another key design of codebook distribution regularization has been explored in single image synthesis domain. Therefore, I think the technical contribution of the paper is somewhat limited.\\n\\n-  In Ablation Studies (Sec. 4.4), it's better to use QnA layers in SinMDM to replace sliding window local attention and show the comparison of the performance. Due to the same task, the paper should demonstrate its unique effectiveness.\", \"Questions\": \"See Weakness.\"}"}]}
{"paper_id": "kQ5s9Yh0WI", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nCurrent long context large language models (LLMs) can process inputs up to 100,000 tokens, yet struggle to generate outputs exceeding even a modest length of 2,000 words. Through controlled experiments, we find that the model's effective generation length is inherently bounded by the sample it has seen during supervised fine-tuning (SFT). In other words, their output limitation is due to the scarcity of long-output examples in existing SFT datasets. To address this, we introduce AgentWrite, an agent-based pipeline that decomposes ultra-long generation tasks into subtasks, enabling off-the-shelf LLMs to generate coherent outputs exceeding 20,000 words. Leveraging AgentWrite, we construct LongWriter-6k, a dataset containing 6,000 SFT data with output lengths ranging from 2k to 32k words. By incorporating this dataset into model training, we successfully scale the output length of existing models to over 10,000 words while maintaining output quality. We also develop LongBench-Write, a comprehensive benchmark for evaluating ultra-long generation capabilities. Our 9B parameter model, further improved through DPO, achieves state-of-the-art performance on this benchmark, surpassing even much larger proprietary models. In general, our work demonstrates that existing long context LLM already possesses the potential for a larger output window--all you need is data with extended output during model alignment to unlock this capability.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"1. The paper is written clearly, making it easy to understand.\\n2. This paper focuses on the very practical issue of model output length limitations and provides a systematic research approach.\", \"Weaknesses\": \"I believe there's room for improvement in the experimental aspect.\\n1. Is it possible to directly leverage AgentWrite to generate long responses with the target model, e.g., Llama-3.1-8B? Can it meet our requirements for output length and quality? Can the output be used to train the model? I think only having results from GPT4-o is not sufficient to demonstrate the effectiveness of AgentWrite.\\n2. As shown in Table 3, the performance of LongWriter-9B (w/ and w/o DPO) and LongWriter-8B is worse than the original model in the [0, 500) subset, and the performance of LongWriter-9B is also worse in the [500, 2k) subset. Given that only \\\"over 1%\\\" of user prompts require such lengthy outputs, is it worth sacrificing performance on shorter texts? Furthermore, to me, LONGWRITER seems to be essentially about adjusting the model's generation behaviors with longer data plus using GPT4-o for knowledge distillation. The improvement in long-text generation quality through knowledge distillation seems trivial, and changing the model's generation behaviors in this way does not seem to be a good way to enhance the model's fundamental capabilities, as demonstrated by the declined performance on shorter outputs.\\n\\nMissing reference: Line 189, \\\"Sec\\\"\", \"Questions\": \"1. If we directly set min_new_tokens = max_new_tokens = target length during generation, how would the quality of output from various models be affected?\\n2. I have doubts about LongWrite-Ruler: the current prompts provided are too vague. If we provide more detailed prompts, will the model generate longer outputs (also with higher quality)? For now, it feels like an assessment of the model's capability to follow instructions in generating outputs of a certain length. Also, as shown in Table 2, even after training the model with longer texts, the model's output still largely fails to meet the required length, which seems to confirm that the model lacks this instruction-following ability, rather than being incapable of generating the required output.\"}"}]}
{"paper_id": "9CqkpQExe2", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nIn the era of Large Language Models (LLMs), Mixture-of-Experts (MoE) architectures offer a promising approach to managing computational costs while scaling up model parameters. Conventional MoE-based LLMs typically employ static Top-K routing, which activates a fixed and equal number of experts for each token regardless of their significance within the context. In this paper, we propose a novel Ada-K routing strategy that dynamically adjusts the number of activated experts for each token, thereby improving the balance between computational efficiency and model performance. Specifically, our strategy incorporates learnable and lightweight allocator modules that decide customized expert resource allocation tailored to the contextual needs for each token. These allocators are designed to be fully pluggable, making it broadly applicable across all mainstream MoE-based LLMs. We leverage the Proximal Policy Optimization (PPO) algorithm to facilitate an end-to-end learning process for this non-differentiable decision-making framework. Extensive evaluations on four popular baseline models demonstrate that our Ada-K routing method significantly outperforms conventional Top-K routing. Compared to Top-K, our method achieves over 25% reduction in FLOPs and more than 20% inference speedup while still improving performance across various benchmarks. Moreover, the training of Ada-K is highly efficient. Even for Mixtral-8x22B, a MoE-based LLM with more than 140B parameters, the training time is limited to 8 hours. Detailed analysis shows that harder tasks, middle layers, and content words tend to activate more experts, providing valuable insights for future adaptive MoE system designs. Both the training code and model checkpoints will be publicly available.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"ArXiv\": 2024, \"Strengths\": \"- Innovatively proposes to introduce an RL agent for controlling top-k in pre-trained MoE models, optimizing the allocation of computational resources and improving inference efficiency. The method has a low training cost and shows robustness to training data, outperforming existing methods across various downstream tasks.\\n- Thorough ablation studies demonstrate the relationship between acceleration effects and accuracy, providing practical guidance. It also validates the effectiveness of activation regularization and warm-up strategies.\\n- Performs meticulous analysis revealing that intermediate layers of trained models require the activation of more experts, reaffirming that more challenging tasks necessitate the activation of more experts.\", \"Weaknesses\": \"- Some comparisons with baseline methods are not entirely reasonable. Existing work suggests that freezing the router yields better results when tuning MoE models. Ada-K freezes the router and introduces additional agent parameters for training, while other comparison methods only train the router. The reviewer recommends supplementing the results by (1) conducting full fine-tuning of the model with a frozen router and comparing the effects of introducing only threshold methods versus Ada-K; or (2) maintaining the current Ada-K setup and adding LoRA parameters to the threshold-based method while freezing the router for tuning.\\n- The paper \\\"AdaMOE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models\\\" (ArXiv: 2024-06-19), which has a very similar title, also achieves dynamic adjustment of top-k during post-training and improves accuracy while saving FLOPs during the tuning phase. Given the short time interval, the lack of comparison with this baseline can be understood, but the reviewer suggests discussing it.\", \"Questions\": \"- The reported speedup in the paper is based on the actual inference time during evaluation tasks, which likely applies to scenarios with batch sizes of 1 or smaller. However, MoE models have large parameter volumes, and their efficiency typically becomes evident with larger batch sizes during actual deployment. The reviewer is concerned that the RL-based method of controlling top-k for each token might lead to imbalance in batch inference, potentially affecting the acceleration effect. Therefore, the reviewer would like to know the relationship between acceleration effect and batch size.\\n- Would combining Ada-K with the standard SFT setting yield better results? Or, under the control of Ada-K, would the performance of SFT be affected?\"}"}]}
{"paper_id": "PpYy0dR3Qw", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nIn $D$istributed optimization and $L$earning, and even more in the modern framework of federated learning, communication, which is slow and costly, is critical. We introduce LoCoDL, a communication-efficient algorithm that leverages the two popular and effective techniques of $Lo$cal training, which reduces the communication frequency, and $Co$mpression, in which short bitstreams are sent instead of full-dimensional vectors of floats. LoCoDL works with a large class of unbiased compressors that includes widely-used sparsification and quantization methods. LoCoDL provably benefits from local training and compression and enjoys a doubly-accelerated communication complexity, with respect to the condition number of the functions and the model dimension, in the general heterogeneous regime with strongly convex functions. This is confirmed in practice, with LoCoDL outperforming existing algorithms.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"Proves the proposed algorithm the accelerate communication complexity due to both components used.\", \"Weaknesses\": \"Only demonstrate strongly convex case. Assuming g is smooth (exclude non-smooth penalty such as lasso, for example)\", \"Questions\": \"1. What is the intuition that make the proposed algorithm work compared to existing works that combines LT and CC?\\n2. Is the rate obtained optimal?\"}"}]}
{"paper_id": "UatDdAlr2x", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nHow do different architectural design choices influence the space of solutions that a transformer can implement and learn? How do different components interact with each other to shape the model's hypothesis space? We investigate these questions by characterizing the solutions simple transformer blocks can implement when challenged to solve the histogram task -- counting the occurrences of each item in an input sequence from a fixed vocabulary. Despite its apparent simplicity, this task exhibits a rich phenomenology: our analysis reveals a strong inter-dependence between the model's predictive performance and the vocabulary and embedding sizes, the token-mixing mechanism and the capacity of the feed-forward block. In this work, we characterize two different counting strategies that small transformers can implement theoretically: relation-based and inventory-based counting, the latter being less efficient in computation and memory. The emergence of either strategy is heavily influenced by subtle synergies among hyperparameters and components, and depends on seemingly minor architectural tweaks like the inclusion of softmax in the attention mechanism. By introspecting models \\textit{trained} on the histogram task, we verify the formation of both mechanisms in practice. Our findings highlight that even in simple settings, slight variations in model design can cause significant changes to the solutions a transformer learns.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"* The paper is well-written, easy to follow, and provides sufficient analysis for its claims.\\n* Discovers and Discusses two strategies which 1-layer transformers can use to perform the counting task (i.e., relation-based and inventory-based) and in doing so considers a range of possible hyperparameter selections that affect this strategic choice.\\n* During its analysis further studies the role of BoS token showing that together with softmax in the counting task, can help models with smaller p and d sizes to still reach perfect accuracy.\", \"Weaknesses\": \"* Limited scope and applicability, specifically: (1) Only examines single-layer transformers, (2)Focuses on just one task (histogram counting)\\n* No clear path to extending insights to more complicated settings more specifically multi-layer transformers\\n* Lack of practical impact in the sense that it is hard to find a direct translation from this paper findings to real-world transformer design for real-world tasks\", \"Questions\": \"Have you done any analysis or insight you can share on: \\n1. what behaviour can we expect in terms of the same hyperparameter choices (embedding dimension, Hidden Layer Size, and Vocab Size) whether as a  2 or 3 layer blackbox and/or an isolation of one of the transformer layers in a multi-layer setting?\\n2. Have you done any initial analysis to share about whether the same relationships for parameters and potential solving strategies hold for other tasks (such as the sorting or lookup problems you referred to or any other tasks)\"}"}]}
{"paper_id": "IwgmgidYPS", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThis paper introduces MedTrinity-25M, a comprehensive, large-scale multimodal dataset for medicine, covering over 25 million images across 10 modalities, with multigranular annotations for more than 65 diseases. These multigranular annotations encompass both global information, such as modality and organ detection, and local information like ROI analysis, lesion texture, and region-wise correlations. Unlike the existing multimodal datasets, which are limited by the availability of image-text pairs, we have developed the first automated pipeline that scales up multimodal data by generating multigranular visual and textual annotations in the form of image-ROI-description triplets without the need for any paired text descriptions. Specifically, data from over 30 different sources have been collected, preprocessed, and grounded using domain-specific expert models to identify ROIs related to abnormal regions. We then build a comprehensive knowledge base and prompt multimodal large language models to perform retrieval-augmented generation with the identified ROIs as guidance, resulting in multigranular textual descriptions. Compared to existing datasets, MedTrinity-25M provides the most enriched annotations, supporting a comprehensive range of multimodal tasks such as captioning and report generation, as well as vision-centric tasks like classification and segmentation. We propose LLaVA-Tri by pretraining LLaVA on MedTrinity-25M, achieving state-of-the-art performance on VQA-RAD, SLAKE and PathVQA, surpassing representative SOTA multimodal large language models. Furthermore, MedTrinity-25M can also be utilized to support large-scale pre-training of multimodal medical AI models, contributing to the development of future foundation models in the medical domain. We will make our dataset available.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"1. The dataset uses an automated process with medical knowledge retrieval and domain-specific models, greatly reducing manual labeling needs.\\n2. With over 25 million image-ROI-description triplets, the dataset supports classification, segmentation, report generation, and spans multiple medical domains.\\n3. The LLaVA-Tri model, pre-trained on MedTrinity-25M, performs exceptionally well across multiple benchmarks, showcasing the dataset’s potential to enhance medical AI applications.\", \"Weaknesses\": \"1. Although the labeling process is automated, its reliance on domain-specific models may limit scalability when handling new modalities or emerging diseases.\\n2. The accuracy of automated labeling may fall short of expert-labeled datasets, potentially impacting performance in critical medical applications. How can a high standard of automated labeling be ensured?\\n3. With data from over 30 sources, potential biases in image quality, demographics, or disease distribution call for a deeper integration analysis.\\n4. Performance depends on external medical knowledge bases, risking inconsistency if not updated, and the LLaVA-Tri comparison may be biased due to overlap with MedTrinity-25M's data sources.\", \"Questions\": \"1. Given the reliance on automated processes and external knowledge sources, how is labeling consistency ensured in the data generation process? Additionally, has it been validated by human experts?\\n2. Has a comparison with expert-labeled datasets been considered to further quantify the quality of automated labeling?\\n3. How does the dataset address potential biases in source data? For example, is there a mechanism to prevent overrepresentation of certain demographics?\\n4. What is the expandability of the labeling process for new, unrepresented modalities or diseases? Does it offer strong scalability?\\n5. Although LLaVA-Tri achieved good performance on RAD, PathVQA, and SLAKE, how do the authors ensure that MedTrinity-25M does not contain data from these datasets? If these datasets were included, the model may have seen the questions and answers during training, leading to artificially high accuracy.\"}"}]}
{"paper_id": "WG7GzGx3G9", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nLarge language models have demonstrated promising capabilities upon scaling up parameters. However, serving large language models incurs substantial computation and memory movement costs due to their large scale. Quantization methods have been employed to reduce service costs and latency. Nevertheless, outliers in activations hinder the development of INT4 weight-activation quantization. Existing approaches separate outliers and normal values into two matrices or migrate outliers from activations to weights, suffering from high latency or accuracy degradation. Based on observing activations from large language models, outliers can be classified into channel-wise and spike outliers.\nIn this work, we propose Rotated Runtime Smooth (**RRS**), a plug-and-play activation smoother for quantization, consisting of Runtime Smooth and the Rotation operation. Runtime Smooth (**RS**) is introduced to eliminate **channel-wise outliers** by smoothing activations with channel-wise maximums during runtime. The Rotation operation can narrow the gap between **spike outliers** and normal values, alleviating the effect of victims caused by channel-wise smoothing.\nThe proposed method outperforms the state-of-the-art method in the LLaMA and Qwen families and improves WikiText-2 perplexity from 57.33 to 6.66 for INT4 inference.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 2, \"Strengths\": \"The paper is generally well-written, with a comprehensive ablation study (RRS vs RS and RRS vs SmoothQuant) demonstrating the effectiveness, which is well motivated by the preliminary section.\", \"Weaknesses\": \"The paper lacks an evaluation on the clock-time (instead of the operation count) overhead introduced by the method. This is a concern given that the method determines activation smoothing scale during runtime.\", \"Questions\": \"See Weaknesses\"}"}]}
{"paper_id": "BhECSDSkAE", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThis paper introduces a novel task and approach for one-shot medical video object segmentation using static image datasets. We address the critical challenge of limited annotated video data in medical imaging by proposing a framework that leverages readily available labeled static images to segment objects in medical videos with minimal annotation---specifically, a ground truth mask for only the first frame. Our method comprises training a one-shot segmentation model exclusively on images, followed by adapting it to medical videos through a test-time training strategy. This strategy incorporates a memory mechanism to utilize spatiotemporal context and employs self-distillation to maintain generalization capabilities. To facilitate research in this domain, we present OS-I2V-Seg, a comprehensive dataset comprising 28 categories in images and 4 categories in videos, totaling 68,416 image/frame-mask pairs. Extensive experiments demonstrate the efficacy of our approach in this extremely low-data regime for video object segmentation, establishing baseline performance on OS-I2V-Seg. The code and data will be made publicly available.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 5, \"Strengths\": \"1. The paper tackles an important problem of generalizing dense segmentation task over videos using sparsely annotated frame (in their case the first annotated frame).\\n2. The experiments on several medical videos show that their method outperform different one-shot, cross-domain one-shot and test-time training methods.\\n3. One major strength about this method is incorporation of 2D image segmentation model for 3D video frames during testing using temporal awareness though additional memory mechanism.\", \"Weaknesses\": \"Major Weakness:\\n1. In general, though the main idea of the paper is conveyed clearly, the specific detail about their method is missing. For instance, details about one-shot segmentation model pretrained on the static images is missing in Section 3.2 and Figure 1. Specifically, only backbone network is shown in the figure, while no discussion on the prior mask generation module, multi-scale feature enhancement module and segmentation head is included. It’s unclear how the authors use (Peng et al. 2023)’ s correlation mechanism for prior mask generation module. If I am correct, Peng et al. 2023, use correlation between single support image’s features and the query image’s features to generate the binary mask. Do the authors use the same methodology?\\n \\n2. In the introduction section, the authors mention one of the major limitations of Few Shot methods is dealing with discrepancy between the domains of base and novel classes [line 083-084]. Could the authors clarify what base class means in this context? Does it mean that the support images are from different domain compared to the query image, or it means training and testing datasets are from different domain. In either case, it is unclear how the current methodology tackles the domain shift problem. In the first scenario, there is no domain shift as the support frame is from the same video, while in the second scenario, I am not sure how the current method can overcome domain shifts between the pre-training and testing domains.\\n \\nMinor Weakness:\\n1. In eq. 3, what are the dimension of W, v^R, v^M. It may be unclear to the readers how the read-out value is obtained exactly and further utilized and how it represents weighted average of similar features in the past frames.\\n \\n2. The title of the paper should highlight medical video segmentation as the current approach is not tested for non-medical videos.\\n \\n3. Size of FIFO queue. Since the performance the method is correlated to the FIFO queue, a discussion on how to set the size of queue is lacking.\", \"Questions\": \"1. Different self-distillation regularization? The authors employ KL divergence between the features obtained from pre-trained segmentation backbone and the current adapted model. This model of self-distillation assumes that the features are “logits” for the loss computation, which might give incorrect regularization as the softmax(logits) = softmax(logits + contant). Why is this model motivated? Does this help with the domain shift problem discussed by the authors earlier?\\n \\n2. Is the current method autoregressive? In other words, for predicting the segmentation mask of current query, does the method only look at the past frames? Can this be extended to bidirectional approach, where we look at all the frames for the prediction of the current query for eq 3?\\n \\n3. Can the current method be extended to foundational segmentation models like SAM (Segment Anything Model)? How does current method compare to SAM? It would be good to know if the current method is a useful alternative to these foundation models based on computation, segmentation accuracy, etc.\"}"}]}
{"paper_id": "mnB4hDTIDr", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nLLM-generated datasets have been recently leveraged as training data to mitigate data scarcity in specific domains. However, these LLM-generated datasets exhibit limitations on training models due to a lack of diversity, which underscores the need for effective diversity evaluation. Despite the growing demand, the diversity evaluation of LLM-generated datasets remains under-explored. To this end, we propose a diversity evaluation method for LLM-generated datasets from a classification perspective, namely, DCScore. Specifically, DCScore treats the diversity evaluation as a sample classification task, considering mutual relationships among samples. We further provide theoretical verification of the diversity-related axioms satisfied by DCScore, demonstrating it as a principled diversity evaluation method. Additionally, we show that existing methods can be incorporated into our proposed method in a unified manner. Meanwhile, DCScore enjoys much lower computational costs compared to existing methods. Finally, we conduct experiments on LLM-generated datasets to validate the effectiveness of DCScore. The experimental results indicate that DCScore correlates better with various diversity pseudo-truths of evaluated datasets, thereby verifying its effectiveness.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 2, \"Strengths\": \"1. The authors proposed an LLM-generated dataset diversity evaluation method from a classification perspective called DCScore, which treats the evaluation of each sample in the LLM-generated dataset as a distinct classification task.\\n\\n2. The authors provided theoretical verification that DCScore satisfies four axioms, including effective number, identical samples, symmetry, and monotonicity.\", \"Weaknesses\": \"The paper has several weaknesses:\\n\\n1. **Lack of Purpose and Application**: The significance of studying LLM-generated data diversity is unclear. The authors should clarify whether this research can aid smaller LLM training or accelerate LLMs' overall training, as well as the practical applications of diversity evaluation.\\n\\n2. **Unclear Novelty of DCScore**: It is unclear whether DCScore is a new method or a simplified version of existing approaches. The paper should better highlight its novelty and contribution to the field.\\n\\n3. **Unexplained Correlation Investigation**: The objective of investigating the correlation between DCScore and diversity pseudo-truth is not well explained. The authors should clarify how this experiment supports the overall thesis of the paper.\\n\\n4. **Weak Performance and Experimental Design**: DCScore performs poorly in the zero-shot setting (Table 2), but no explanation is provided. Additionally, the rationale behind using Text Classification and Story Completion tasks needs to be better justified.\", \"Questions\": \"Here are a few questions I would like to ask the authors:\\n\\n1. Large Language Model (LLM)-generated datasets have found widespread applications, but what is the purpose or significance of studying the diversity of LLM-generated data? For instance, can research on the diversity of LLM-generated data contribute to training smaller LLMs or accelerate LLM training? Additionally, what are the potential application scenarios for investigating the diversity of LLM-generated data? I would appreciate it if the authors could provide further clarification on this point.\\n\\n2. In Method 4.3, is DCScore a fusion or a simplified version of existing methods? What is the significance of the discussion in this section?\\n\\n3. In the experiments, the objective of “investigating the correlation between the diversity evaluation of DCScore and the diversity pseudo-truth” is unclear. Could the authors elaborate on this goal and relate it to the central premise of the paper?\\n\\n4. In Table 2 of the experiments, under the zero-shot setting, the performance of DCScore is not very strong. Could the authors provide an explanation for this? What is the rationale behind conducting experiments under the Text Classification and Story Completion settings?\"}"}]}
{"paper_id": "Y0qmwm6tgy", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nIn the existing model pruning literature, the weight gradient has been extensively utilized to measure the importance of weight, where the gradient is well-known to be sensitive to perturbations. On the other hand, the widely used large language models (LLMs) have several billion model parameters, which could increase the fragility of few-shot gradient pruning. In this work, we experimentally show that one-shot gradient pruning algorithms could lead to unstable results under perturbations to model weights. Even the minor error of switching between data formats bfloat16 and float16 could result in obviously different outcomes. To address such instabilities, we leverage optimization analysis and propose an LLM structural pruning method, called MoreauPruner, with provable robustness against weight perturbations. In MoreauPruner, the model weight importance is estimated based on the neural network's Moreau envelope, which can be flexibly combined with $\\ell_1$-norm regularization techniques to induce the sparsity required in the pruning task. We extensively evaluate the MoreauPruner algorithm on several well-known LLMs, including LLaMA-7B, LLaMA-13B, LLaMA3-8B, and Vicuna-7B. Our numerical results suggest the robustness of MoreauPruner against weight perturbation and how robust importance estimation in MoreauPruner contributes to successful accuracy-based scores compared to several existing pruning methods.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"- The key research question of this paper, i.e., finding a pruning mask that is robust to the weight perturbation in the weight, is quite interesting and thought-provoking.\\n\\n- The idea of Moreau envelope is mathematically well-grounded and is linked directly to the problem considered; I have learned a lot from this submission.\\n\\n- The paper is generally quite clear, and well-written.\", \"Weaknesses\": \"- The central weakness of this paper is the unclear motivation. In particular, I am even not sure why the inconsistency of the pruning outcomes up to small perturbation is problematic. There can be many different but equally good pruning masks for a neural network. Indeed, the classic structured pruning work by Srinivas and Babu (2015) proposes to remove either neuron A or neuron B (but not both) whenever two neurons are highly similar to each other, as they are considered redundant. Here, we should be indifferent to the choice whether we remove neuron A or neuron B; both gives us a reasonable good choice. If the authors believe that there should be a unique choice of pruning masks, I recommend giving more supporting evidences, e.g., empirical backups.\\n\\n- Also, it is not clear to me why the results in Table 1 is meaningful. If I understood correctly, it seems like the authors are trying to prove that MoreauPruner a more robust performance on both BF16 and FP16. Here, I am not sure why the \\\"Diff\\\" matters. Perhaps the fact that MoreauPruner achieves smaller perplexity on both cases is what is meaningful, and having a small \\\"diff\\\" may not really have much implications, as working bad on both numeric types can result in small diff as well. Also, I am curious why MoreauPruner seems to consistently work poorer than LLM-Pruner for 5% pruning ratio.\\n\\n- The performance gain over LLM-Pruner is not very dramatic, which I believe is perhaps linked to the unclear motivation.\\n\\n- The set of target models is somewhat restricted, as they are constrained to LLaMA family, except for Vicuna-7B. I recommend adding (at least two) experiments on other options, such as Mistral, Qwen, OPT, or BLOOM.\\n\\n- I am not sure if I missed, but it would be great if authors could make any remarks on the computational costs of obtaining the pruning masks, such as required memory and computations.\\n\\n- The quality of writing can be improved. For instance, the paper uses the terminology \\\"structural pruning,\\\" which I believe should be replaced with much more popular term \\\"structured pruning\\\" (I am aware that the term \\\"structural pruning\\\" has been used in some recent works, but I think they are mostly mistakes). Also, \\\"anti-intuitive\\\" can be replaced by \\\"counterintuitive.\\\" The phrase \\\"robustness pruning result\\\" in L77 is weird. In L165, \\\"easy obtained\\\" should be \\\"easily obtained.\\\" In L181, \\\"effiently\\\" should be \\\"efficiently.\\\" In L230, \\\"envelop\\\" should be \\\"envelope,\\\" as in all other usages. In figure 4 caption, \\\"hyper-paramter\\\" is wrong. There should be much more errors; please locate them and fix them all.\", \"Questions\": \"- A mild suggestion is to draw motivation for perturbation robustness from other sources of weight perturbation. For example, here are some half-baked thoughts: (1) Pruning itself perturbs the weights; that is, pruning some weights may affect gradient evaluations for other weights. (2) Further re-training with LoRA may also be the source of expected weight perturbation; the proposed method can be viewed as being ready for such updates.\"}"}]}
{"paper_id": "aAcOaJYbUg", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nOut-of-distribution (OOD) robustness is a desired property of computer vision models. Improving model robustness requires high-quality signals from robustness benchmarks to quantify progress. While various benchmark datasets such as ImageNet-C were proposed in the ImageNet era, most ImageNet-C corruption types are no longer OOD relative to today's large datasets scraped from the web, which already contain common corruptions such as blur or JPEG compression artifacts. Consequently, these standard benchmarks are no longer well-suited for evaluating OOD robustness in the era of web-scale datasets. Indeed, recent models show saturating scores on ImageNet-era OOD benchmarks, indicating that it is unclear whether models trained on web-scale datasets truly become better at OOD generalization or whether they have simply been exposed to the test distortions during training. To address this, we here introduce LAION-C as a benchmark alternative for ImageNet-C. LAION-C consists of six novel distortion types across five severity levels designed to be OOD, even for web-scale datasets such as LAION. In a comprehensive evaluation of state-of-the-art models, we find that the LAION-C dataset poses significant challenges to contemporary models. We additionally conducted a psychophysical experiment to evaluate the difficulty of our proposed corruptions for human observers, enabling a comparison of models to lab-quality human robustness data. We observe a paradigm shift in OOD generalization: from humans outperforming models to the best models now matching or outperforming the best human observers.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 4, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. Clear structure and presentation: The paper is well-organized, with a logical structure and smooth flow that improves readability and comprehension.\\n2. Insightful motivation for OOD benchmarking: This dataset addresses the critical issue of data leakage in current benchmarks. This approach highlights the limitations of evaluating current models trained on web-scale data.\\n3. Interesting distortion design: The authors designed six distinct distortion types that minimize overlap with common real-world corruptions, reducing the likelihood of data leakage. This approach improves the dataset’s utility as a truly challenging OOD benchmark.\", \"Weaknesses\": \"1. Limited novel insights in model ranking comparisons: Figure 4 shows minimal divergence in the ranking of model performance between ImageNet-C and LAION-C. Similarly, Figure 3 demonstrates a strong linear correlation between model performance on ImageNet-C and LAION-C. Since a benchmark dataset's purpose is to reveal different performance characteristics across models, more analysis is needed to clarify the unique insights LAION-C provides beyond what ImageNet-C already offers.\", \"Questions\": \"1. Performance differences between CNNs and transformers: Given that LAION-C primarily features patch-based transformations, are there observed differences in how CNNs and transformers perform on these types of distortions?\\n\\n2. Class disparity between datasets: ImageNet-C includes 1,000 classes, whereas LAION-C has only 16, potentially creating an imbalance in comparison. Excluding the psychophysical experiments, what methods or adjustments could be employed to address this disparity and ensure a fair evaluation between the datasets?\"}"}]}
{"paper_id": "duGygkA3QR", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nGraph Neural Networks (GNNs) have emerged as fundamental tools for a wide range of prediction tasks on graph-structured data. Recent studies have drawn analogies between GNN feature propagation and diffusion processes, which can be interpreted as dynamical systems. In this paper, we delve deeper into this perspective by connecting the dynamics in GNNs to modern Koopman theory and its numerical method, Dynamic Mode Decomposition (DMD). We illustrate how DMD can estimate a low-rank, finite-dimensional linear operator based on multiple states of the system, effectively approximating potential nonlinear interactions between nodes in the graph. This approach allows us to capture complex dynamics within the graph accurately and efficiently. We theoretically establish a connection between the DMD-estimated operator and the original dynamic operator between system states. Building upon this foundation, we introduce a family of DMD-GNN models that effectively leverage the low-rank eigenfunctions provided by the DMD algorithm. We further discuss the potential of enhancing our approach by incorporating domain-specific constraints such as symmetry into the DMD computation, allowing the corresponding GNN models to respect known physical properties of the underlying system. Our work paves the path for applying advanced dynamical system analysis tools via GNNs. We validate our approach through extensive experiments on various learning tasks, including directed graphs, large-scale graphs, long-range interactions, and spatial-temporal graphs. We also empirically verify that our proposed models can serve as powerful encoders for link prediction tasks. The results demonstrate that our DMD-enhanced GNNs achieve state-of-the-art performance, highlighting the effectiveness of integrating DMD into GNN frameworks.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper is well written and easy to follow, providing a thorough introduction to the backgrounds of GNNs and DMD. This clarity enhances the reader's understanding of the foundational concepts necessary for grasping the main contributions of the work.\\n2. Connecting DMD with GNNs is an interesting perspective.\\n3. The authors support their claims with extensive experiments demonstrating the effectiveness of the DMD-GNN models, including evaluations on directed graphs, large-scale graphs, long-range interactions, and spatial-temporal graphs.\", \"Weaknesses\": \"1. My main question regarding the paper concerns the motivation: to what extent do the dynamics of GNNs actually influence their performance? Approaching this from the perspective of DMD is interesting, but what specific insights does it offer in understanding GNN performance?\\n2. On long-range graph datasets, DMD-GNNs appear to outperform traditional GNNs, but some of the baselines used in the paper seem relatively weak. As far as I know, there is a class of GNNs derived from optimization or energy function approaches that perform reasonably well on such datasets. It would be helpful if the authors could include a few examples of these models for comparison.\\n3. It could benefit from a more thorough comparison with frequency-based analysis methods. Since the modes identified by DMD correspond to specific patterns in dynamical systems—similar to how frequency-based methods assume learned graph signals contain both high-frequency and low-frequency components—exploring the relationship between these approaches could yield unique insights. Although the authors provide some explanations in Section 6, illustrating this comparison with specific datasets would strengthen their argument.\", \"Questions\": \"I’m confused about the implementation details of the model, as the paper provides limited description in this part. Standard DMD requires explicit eigendecomposition, and I would like to know how $\\\\Psi$ and $\\\\theta$ are determined in Equation 14.\"}"}]}
{"paper_id": "s6nYndMwG7", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nInfluence functions are a popular tool for attributing models' outputs to training data. The traditional approach relies on the calculation of inverse Hessian-vector products (iHVP), but the classical solver ``Linear time Stochastic Second-order Algorithm'' (LiSSA, Agarwal et al. (2017)) is often deemed impractical for large models due to expensive computation and hyperparameter tuning. We show that the three hyperparameters --- the scaling factor, the batch size, and the number of steps --- can be chosen depending on two specific spectral properties of the Hessian: its trace and largest eigenvalue. By evaluating them with random sketching (Swartworth and Woodruff, 2023), we find that the batch size has to be sufficiently large for the LiSSA to converge; however, for all of the models we consider, the requirement is mild. We confirm our findings empirically by comparing to the Proximal Bregman Retraining Functions (PBRF, Bae et al. (2022)).\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"The paper does well to describe the end-to-end process of using inverse-Hessian influence metric on LLMs and Resnets, for which there are substantial empirical and theoretical questions to address.  It would appear that the cases that the authors considered are evaluated in reasonable level of detail, and that the empirical aspects of the paper should be reproducible.\\n\\nWhile the main contributions are about methodology of using inverse-Hessian influences; section 5 provides some additional scientific value on the potential value of using inverse-Hessian influences.  While it is more speculative in nature, it provides some problem setups which might be the setting for future work.\\n\\nThe paper is also well-integrated into existing theory on influence functions, which brings additional value to the paper.\\n\\nThe main theorem seems to provide a suggested starting point for how to pick the parameters in LISSA (with explicit parameters).\", \"Weaknesses\": \"I find the following overall weaknesses: \\n\\n1) The main theoretical contribution of the paper is a convergence analysis for the mini-batch SGD derived.  This is done under a very strong hypothesis, which is effectively a contractivity assumption in norm (C.1) or (9) in Theorem 1.  This makes the main theorem relatively easy to prove, but it also begs the question of showing when this satisfied.   Separately, mini-batch SGD on quadratics are studied to death, and it will be quite difficult to argue that this is truly a new analysis\\n\\n2) Regarding the contractivity assumption: it is shown that in some sense the assumptions of Theorem 1 necessary, but this sense is effectively adversarial in the test-direction u (B.4Lemma 1).     On the other hand, the positive cases (B3 Motivations for C.1) do not show that C1 is satisfied.  It would substantially improve the paper if the theory covered these two cases.  (If it does, this should be explained).\\n\\n3) The empirical results of the contractivity (Figure 4) do not consider C.1 but rather the trace.  Trace type conditions are much easier to satisfy, and unfortunately give little insight whether C.1 in fact holds.  A much more desirable theorem (to my taste -- and also more consistent with the experiments) would assume trace-type conditions on H and H^2, and some randomness assumptions on u that lead to the claimed convergence.  There is a lingering sense that C.1 and (9) of Theorem 1 is unverifiable.\\n\\n4) The empirical conclusions in Section 4 and 5 are a little bit murky, and it's hard to align what appears in the simulations with what appear in the text.\", \"Questions\": \"Regarding the weaknesses:\\nWeakness 1): There's a lot of batch-SGD analyses which at first glance may already contain the theorem.  For example:\\nA) Jain, Kakade, Kidambi, Netrapalli, Sidford. \\\"Parallelizing..\\\" 2018 JMLR\\nB) Varre, Pillaud-Vivien, Flammarion. \\\"Last iterate convergnece..\\\" 2021 NeurIPS\\nC) Ma, Bassily, Belkin.  \\\"The power of Interpolation...\\\" 2018 ICML\\nCan you argue why your analysis is novel, comparing to existing literature like the above?\\n\\nWeakness 2): Can you show why the theorems apply to the setups in B3? Currently, this is `almost' done but not completely.  In particular the sentence on (l243): ``we find this condition to hold for classification with independent sampling\\\" appears unfulfilled.\\\"\\n\\nWeakness 3): Can you show empirically that C1 occurs, in the norm sense?  (tracial vs norm-type behavior is rarely equivalent in random matrix contexts).\\n\\nWeakness 4a): Figure 1 is appears to be discussed in the text (l368-370) and 3 cases are explained. Considering Figure 1, why are these the 3 cases, (especially, which illustrates case '3'? Where do you argue that 'PBO _finetunning_ stirs away the model too far for the quadratic approximation to hold'. (and what does that mean?)\\n\\nWeakness 4b): Figure 3.  Why does the difference picture show what you claim it does?  (In particular why do you average over the 10x10 square, and why are you not measuring the diagonals?). When you write (l464-466). ``As a result the influence similarity between an orignal sentence and a rewritten one appears to be consistently higher than between unrelated sentence.\\\"  Can you explain this?\\n\\nOther questions: \\n1) Can you explain precisely how you picked the 'batch' in Table 1, and moreover, what is the general procedure you suggest for selecting LiSSA parameters?  (It seems you _almost_ do this, but being extra-clear would help, especially as regard the batch.)\\n\\nMinor:\\n1) (l80-83). ``Influence functions are calculated under the assumption that the optimized parameter $\\\\theta$ of the model delivers minimum to the training loss.\\\"  This sentence is mangled. \\n2) l409-410.  ``the choice of _dumping_ parameter''\\n3) l424: ``For example, a plausible interpretation of the directions $v_j$ would be that the top directions correspond to general language coherence and... small eigenvalues could correspond to more specific, informative content.\\\"  While the statement about large eigenvalues makes sense, the complementary statement about small eigenvalues does not -- first most small eigenvalues are not interpretable, and are the result of either diffuse (non-one-dimensional) embeddings or undesirable feature distortions.  Perhaps it would be better to just say you can screen out the large eigenvalues which are more about general language coherence.\"}"}]}
{"paper_id": "9BVMD3keG8", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe study the role of _contextual information_ in the online learning problem of brokerage between traders.\nAt each round, two traders arrive with secret valuations about an asset they wish to trade.\nThe broker suggests a trading price based on contextual data about the asset.\nThen, the traders decide to buy or sell depending on whether their valuations are higher or lower than the brokerage price.\nWe assume the market value of traded assets is an unknown linear function of a $d$-dimensional vector representing the contextual information available to the broker. Additionally, at each time step, we model traders' valuations as independent bounded zero-mean perturbations of the asset's current market value, allowing for potentially different unknown distributions across traders and time steps.\nConsistently with the existing online learning literature, we evaluate the performance of a learning algorithm with the regret with respect to the _gain from trade_.\nIf the noise distributions admit densities bounded by some constant $L$, then, for any time horizon $T$:\n\n- If the agents' valuations are revealed after each interaction, we provide an algorithm achieving $O ( L d \\ln T )$ regret, and show a corresponding matching lower bound of $\\Omega( Ld \\ln T )$.\n\n- If only their willingness to sell or buy at the proposed price is revealed after each interaction, we provide an algorithm achieving $O( \\sqrt{LdT \\ln T })$ regret, and show that this rate is optimal (up to logarithmic factors), via a lower bound of $\\Omega(\\sqrt{LdT})$.\n\nTo complete the picture, we show that if the bounded density assumption is lifted, then the problem becomes unlearnable, even with full feedback.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"- The paper is fairly well-written and key ideas and assumptions exposited quite nicely\\n- The technical results look sound. The full feedback algorithm based on online ridge regression is reasonable and I am especially intrigued by the algorithm for the 2-bit feedback case, where it essentially attempts to reconstruct the CDF. I would actually appreciate a bit more discussion on the intuition behind the algorithm. Although some of the techniques borrow from previous works in terms of novelty, I don't see this as a shortcoming. \\n- The technical bounds provided here are nearly tight. Both the full-feedback and 2-bit feedback models have matching lower bounds, and the authors show the necessity of the bounded distributional assumption.\", \"Weaknesses\": \"My major critique of the paper arises from it's conceptual model of the OTC marketplace and the additional insights it provides compared to existing literature. \\n\\n- In \\\"A Regret Analysis of Bilateral Trade\\\" (Cesa-Bianchi, 2021) at each time step a (buyer, seller) pair arrives, with the buyer having maximum valuation $b_t$ and seller having minimum valuation $s_t$. It is clear that a trade happens if the proposed price $p_t \\\\in [s_t, b_t]$. In this paper, however, the role of the buyer and seller are not determined. Two parties arrive, and depending on the p_t given, either could be a buyer or seller. This is quite strange and only really makes sense if both traders own the underlying asset - so either can be the seller. I am not sure how to justify this/be on board with this model and realistic this is in OTC markets.\\n\\n- In this model, both trader's valuation arise from a stochastic process, which in expectation, is equal to the market price, which is crucially consistent with the context observed by the learner. So $E[V_t] = E[W_t] = m_t = \\\\langle c_t, \\\\phi \\\\rangle$. This is also quite a strange and strong assumption; this notion of an expected ground truth market price agreed both buyer and seller parties is not present in (Cesa-Bianchi, 2021). In general, market price arises endogenously due to trading between different parties with possibly heterogenous expected valuations. Am I correct to say that if both traders are highly concentrated (low variance), then the GFT should be very small since they both have the same EV? Moreover, it requires consistency with the learner's context. On theoretical models, I am happy to be lenient with assumptions, but I worry that in this case, it does not provide any more natural insights or technical benefits over what is currently proposed in the literature (see below):\\n\\n- I am trying to understand the novelty or additional insight this paper provides over \\\"An Online Learning Theory of Brokerage\\\" (Bolic, 2024), which the authors cite. That paper does not make a contextual assumption, nor do they make an assumption about mean of the trader's distribution - however, they assume both traders valuations are from same fixed distribution. In this model, trader's don't need to have the same distribution, but the same mean, which is consistent with the market price the context reveals. Beyond these differences, the model is nearly identical and the bounds achieved are also identical. I am not sure if the different distributional assumption can truly be justified as loosening the model since it requires an additional sort of internal consistency with the context - $E[V_t] = E[W_t] = m_t = \\\\langle c_t, \\\\phi \\\\rangle$. I understand why this assumption is made from a technical/learning perspective, but conceptually, I don't see any immediate reasons to think this model is more natural than the one in (Bolic, 2024) or (Cesa Bianchi, 2021) which clearly delineates buyers and sellers, both of which give similar bounds. \\n\\n- Why use this strange notation for $a \\\\wedge b$ denoting $min(a, b)$ and $a \\\\vee b$ denoting $max(a,b)$? Makes it much harder to parse.\", \"Questions\": \"See the weaknesses mentioned.\"}"}]}
{"paper_id": "mnna9LUg7P", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nState Space Models (SSMs) have emerged as an appealing alternative to Transformers for large language models, achieving state-of-the-art accuracy with constant memory complexity which allows for holding longer context lengths than attention-based networks. The superior computational efficiency of SSMs in long sequence modeling positions them favorably over Transformers in many scenarios. However, improving the efficiency of SSMs on request-intensive cloud-serving and resource-limited edge applications is still a formidable task. SSM quantization is a possible solution to this problem, making SSMs more suitable for wide deployment, while still maintaining their accuracy. Quantization is a common technique to reduce the model size and to utilize the low bit-width acceleration features on modern computing units, yet existing quantization techniques are poorly suited for SSMs. Most notably, SSMs have highly sensitive feature maps within the selective scan mechanism (i.e., linear recurrence) and massive outliers in the output activations which are not present in the output of token-mixing in the self-attention modules. To address this issue, we propose a static 8-bit per-tensor SSM quantization method which suppresses the maximum values of the input activations to the selective SSM for finer quantization precision and quantizes the output activations in an outlier-free space with Hadamard transform. Our 8-bit weight-activation quantized Mamba 2.8B SSM benefits from hardware acceleration and achieves a 1.72 $\\times$ lower generation latency on an Nvidia Orin Nano 8G, with only a 0.9\\% drop in average accuracy on zero-shot tasks. When quantizing Jamba, a 52B parameter SSM-style language model, we observe only a $1\\%$  drop in accuracy, demonstrating that our SSM quantization method is both effective and scalable for large language models, which require appropriate compression techniques for deployment. The experiments demonstrate the effectiveness and practical applicability of our approach for deploying SSM-based models of all sizes on both cloud and edge platforms.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 3, \"Rating\": 5, \"Confidence\": 3, \"Strengths\": \"1. The paper presents a unique approach by applying quantization specifically to Selective SSMs, a topic with limited prior research in this area. The integration of percentile-based clipping and the Hadamard transform for managing outliers in SSMs represents an innovative combination of techniques. These methods are tailored specifically for the challenges of SSM quantization, marking a significant contribution to the field of model compression.\\n2. The paper demonstrates a thorough experimental setup, with well-defined quantization methodologies for activations. The authors support their approach with empirical evidence, clearly detailing the implementation of 8-bit static quantization and its impact on latency and accuracy. The careful construction of quantization techniques for hardware constraints is grounded in a rigorous understanding of SSM behavior, lending credibility to the study’s findings.\\n3. The proposed quantization approach has high potential significance, especially for applications involving SSMs in resource-limited environments. By addressing the specific challenges of quantizing SSMs, the paper extends the practical use of SSMs, making them feasible for deployment on low-power hardware without significant accuracy degradation.\", \"Weaknesses\": \"The paper is innovative in its approach and thorough experimentation. However, there are several critical questions that I raised in the \\\"Question\\\" section, which I believe are essential for the clarity and robustness of the findings. I hope the authors can provide insights on these points, and I look forward to further discussion.\", \"Questions\": \"1. As a researcher focused on large model quantization on edge devices, I have some concerns about the authors' claim regarding the lack of prominent outliers in transformers. Based on my own experiments and findings [1-2] from recent literature, larger language models (LLMs) actually tend to exhibit more significant outliers, especially in channel-wise activation. Can you clarify your claim about outliers in Transformers and provide evidence or citations supporting your view?\\n\\n2. Studies [3-4] on transformer quantization have shown that quantizing outliers can substantially impact model accuracy. This observation aligns with the authors' ablation study results. However, I am unclear on why certain techniques in this paper appear to alleviate the impact of outlier quantization. Additionally, shouldn’t each optimization step incrementally reduce accuracy? Surprisingly, the authors' ablation study shows an improvement in accuracy when all three techniques are applied together. Could you please provide a more detailed explanation of why your techniques, when combined, lead to improved accuracy rather than incremental reductions?\\n\\n3. In the introduction, the authors mention that this quantization method is applicable to both edge devices and cloud computing. However, the experiments only feature the high-compute edge device Orin Nano 8G (and the A5000, which would generally not be considered an edge device). There is no testing on cloud computing hardware, which would have been helpful.\\n\\n4. For the results in Table 1: Profiling Latency, I find some inconsistencies. As token length increases, both computation and memory should scale linearly, so I would expect a relatively stable speedup ratio. If anything, given the execution overhead of the nonlinear kernel within SSM, there might be a slight increase in latency with token length. However, the authors' data show an unusual spike in performance at $L=512$ and $L=1$. Could you please provide a more detailed explanation of the observed performance spikes, possibly including additional data points or experiments that could help clarify the relationship between token length and speedup ratio?\\n\\n5. Lastly, could the authors clarify how many hardware measurements were conducted to obtain the reported results? Given the inherent variability in hardware performance, multiple measurements are typically necessary to ensure stability and reliability. It would be helpful to understand the stability of the hardware results presented. Could you please provide details on the number of runs performed for each experiment, any measures taken to account for variability (e.g., averaging results, reporting standard deviations), and how you ensured the stability and reproducibility of your hardware measurements?\\n\\n[1] Shen, Xuan, et al. \\\"Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs on the Edge.\\\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 17. 2024.\\n[2] Xiao, Guangxuan, et al. \\\"Smoothquant: Accurate and efficient post-training quantization for large language models.\\\" International Conference on Machine Learning. PMLR, 2023.\\n[3] Lin, Yang, et al. \\\"Fq-vit: Post-training quantization for fully quantized vision transformer.\\\" arXiv preprint arXiv:2111.13824 (2021).\\n[4] Dong, Peiyan, et al. \\\"Packqvit: Faster sub-8-bit vision transformers via full and packed quantization on the mobile.\\\" Advances in Neural Information Processing Systems 36 (2024).\"}"}]}
{"paper_id": "3X3LuwzZrl", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nGraphs are a complex and versatile data structure used across various domains, with possibly multi-label nodes playing a particularly crucial role. \nExamples include proteins in PPI networks with multiple functions and users in social or e-commerce networks exhibiting diverse interests. \nTackling multi-label node classification (MLNC) on graphs has led to the development of various approaches. Some methods leverage graph neural networks (GNNs) to exploit label co-occurrence correlations, while others incorporate label embeddings to capture label proximity. However, these approaches fail to account for the intricate influences between labels in non-Euclidean graph data.\nTo address this issue, we decompose the message passing process in GNNs into two operations: propagation and transformation. \nWe then conduct a comprehensive analysis and quantification of the influence correlations between labels in each operation. \nBuilding on these insights, we propose a novel model, Label Influence Propagation (LIP). \nSpecifically, we construct a label influence graph based on the integrated label correlations. \nThen, we propagate high-order influences through this graph, dynamically adjusting the learning process by amplifying labels with positive contributions and mitigating those with negative influence.\nFinally, our framework is evaluated on comprehensive benchmark datasets, consistently outperforming SOTA methods across various settings, demonstrating its effectiveness on MLNC tasks.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"Pros:\\n1. The paper considers the positive and negative influence of different labels and encourages or suppresses labels that bring positive or negative influences, respectively.\\n2. The proposed model is a plug-and-play approach, which can be applied to various GNN backbones. \\n3. The paper offers a label correlation analysis by dissecting the pipeline into a forward and backward propagation segment.\", \"Weaknesses\": \"Cons:\\n1. What is the difference between the label propagation methods? (GMNN: Graph Markov Neural Networks, Combining Graph Convolutional Neural Networks and Label Propagation, Resurrecting Label Propagation for Graphs with Heterophily and Label Noise). The paper should cite and compare with them, and highlight the improvement of the model.\\n2. Some hyperparameters are important to the model. It is better to give some hyperparameter analysis about the model, such as \\\\alpha, \\\\beta. It is suggested to plot the results showing how performance varies with these parameters and report the chosen values.\\n3. How does the number of label categories k affect the model? It is recommended to study the effect of the performance.\\n4. It is highly recommended to give some examples, i.e., the visualization of the positive and negative influence of different labels in the case studies, showing how certain labels positively or negatively influence others and how this affects the model's predictions.\\n5. It is recommended to give other backbones, such as the most commonly used GIN, to show the effectiveness of the model.\\n6. It is better to check the label of the axis in the figure. i.e., fig 4c. The label of the x-axis is missing.\", \"Questions\": \"Please see the above weakness.\"}"}]}
{"paper_id": "IqaQZ1Jdky", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\n\\begin{abstract}\nNeural networks exhibit exceptional performance in processing complex data, yet their internal structures remain largely unexplored. The emergence of Kolmogorov-Arnold Networks (KANs) represents a significant departure from traditional Multi-Layer Perceptrons (MLPs). In contrast to MLPs, KANs replace fixed activation functions at nodes (``neurons\") with learnable activation functions on edges (``weights\"), enhancing both accuracy and interpretability.\nAs data evolves, the demand for models that are both flexible and robust minimizing the influence of input data variability continues to grow. Addressing this need, we propose a general framework for KANs utilizing a \\underline{\\textbf{V}}ariety \\underline{\\textbf{B}}ernstei\\underline{\\textbf{n}} Polynomial Function Basis for \\underline{\\textbf{K}}olmogorov-\\underline{\\textbf{A}}rnold \\underline{\\textbf{N}}etworks (VBn-KAN). This framework leverages the Weierstrass approximation theorem to extend function basis within KANs in theory, specifically selecting Bernstein polynomials ($B_n$) for their robustness, assured by the uniform convergence proposition. Additionally, to enhance flexibility, we implement techniques to vary the function basis $B_n$ when handling diverse datasets. Comprehensive experiments across three fields: multivariate time series forecasting, computer vision, and function approximation—demonstrate that our method outperforms conventional approaches and other variants of KANs.\n\\end{abstract}\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"- The authors extensively motivate the architectural modification of vanilla KANs\\n- The authors compare their method to various other forms of KANs and other ML models across a variety of tasks, including time series forecasting, image classification as well as general function approximation\\n- The manuscript is overall well-written\", \"Weaknesses\": \"- Table 1: VBn-KAN improvement over other KAN variants is very marginal\\n- Table 2 & 3: VBn-KAN is partly outperformed by vanilla KANs\\n- l. 520 “[...] 0.095 less than the average error [...]” - the authors should try to stay consistent with the use of relative performance improvements/degradations to a baseline. This makes it much easier for the reader to identify the significance of the result (as the authors correctly did when discussing results of Table 1 & 2, for example).\\n- ll. 532 - 534: “Furthermore, it reduces the influence of data on the model and provides a balanced approach in feature learning by minimizing error while managing computing costs.” - where do the authors show this explicitly in their experiments? To me there is no clear evidence of this in the manuscript.\\n- ll. 230-231: That the enhanced uniformity contributes to improved model generalization is in this form a claim that is not backed up by evidence (citation or experiments missing).\\n- Entire subsection 3.2 is filled with claims and theoretical properties of employing VBn-KANs which are not really investigated by experiments.\\n- While the authors provide a lot of comparison methods/baselines, they do not include SOTA methods for the specific datasets (e.g. for CIFAR-10/100). I understand that the authors just do a comparison of KAN based methods, but it would be useful to state the current SOTA in these benchmarks (based on non-KAN alternatives).\\n\\nOverall **I vote for reject**, as the paper lacks novelty and impact. For a ICLR conference paper the work lacks substance: The main feat of the paper consists of replacing a activation function in KANs by a, in theory, more expressive alternative. However, the actual gains by this modification are overall only marginal. Indeed, the VBn-KAN does not even consistently outperform vanilla KANs. I also think that there are many claims in the paper that are not backed up by (dedicated) experiments.\\n\\nMinor details/typos:\\n- l. 141 typo: “exits” -> “exists”\\n- ll. 230-231 This sentence needs revision: “This enhances uniformity significantly contributes to improved model generalization.”\\n- ll 39-40: typo \\\"attempte\\\"\\n- ll 113-114: typo \\\"interpretabilit\\\"\", \"Questions\": \"- Could the authors include the settings for n for the different curves in the legend of Fig. 1b?\\n- Could the authors demonstrate how the lower bound for $n$ stated in Theorem 3.3 could be used in practice? Having theoretical guarantees is valuable, but how they play out in practice is also very important. To me the practicality of Theorem 3.3 seems limited or not really investigated, as the authors fall back to (sophisticated) hyperparameter tuning to find the best $n$.\\n- I do not quite understand Table 4 & 5. What is the n used for VBn-KAN column? Is $n$ optimized by BO and different for each weight in the KAN? If so, could the authors provide some kind of summary statistic to compare VBn-KAN to the fixed $n$ columns?\\nAlso in Table 4 & 5, it seems that for fixed n, the setting $n=1$ generally performs better than $n=10$. Do we observe overfitting for higher values of $n$ here?\\n- what exactly is $\\\\xi$ in theorem 3.3?\\n- I assume the results of Table 1-6 are all based on test sets of the individual benchmarks? Please make this clear in e.g. the Table captions.\"}"}]}
{"paper_id": "OdMqKszKSd", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe address the challenge of creating 3D assets for household articulated objects from a single image.\nPrior work on articulated object creation either requires multi-view multi-state input, or only allows coarse control over the generation process.\nThese limitations hinder the scalability and practicality for articulated object modeling.\nIn this work, we propose a method to generate articulated objects from a single image.\nObserving the object in a resting state from an arbitrary view, our method generates an articulated object that is visually consistent with the input image.\nTo capture the ambiguity in part shape and motion posed by a single view of the object, we design a diffusion model that learns the plausible variations of objects in terms of geometry and kinematics.\nTo tackle the complexity of generating structured data with attributes in multiple domains, we design a pipeline that produces articulated objects from high-level structure to geometric details in a coarse-to-fine manner, where we use a part connectivity graph and part abstraction as proxies.\nOur experiments show that our method outperforms the state-of-the-art in articulated object creation by a large margin in terms of the generated object realism, resemblance to the input image, and reconstruction quality.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"1. The idea of training a diffusion model to generate parts conditioned on a part graph and input image is interesting, as it enables the generation of variations.\\n\\n2. The authors demonstrate that the proposed method outperforms the baseline and provide extensive ablation studies.\\n\\n3. Overall, the paper is presented clearly.\", \"Weaknesses\": \"1. The overall coarse-to-fine pipeline for articulated object generation is not uncommon.\\n\\n2. The proposed method only handles closed-domain objects and relies on ground-truth annotations for training. However, 3D datasets with fine-grained part annotations are extremely challenging to annotate. In the experiments, the authors focus on only six part categories and seven object categories, which may significantly limit the practical applicability of the proposed method in much more diverse and complex real-world scenarios.\\n\\n3. The inference of the part connectivity graph relies on GPT-4o, which lacks specific designs and may not be considered a major contribution of the paper. It may also be difficult to inject 3D bias or other priors into the pre-trained GPT-4o.\\n\\n4. The detailed geometry of parts is retrieved from an existing database. There are concerns about the visual quality and consistency of the parts, which may not be effectively captured by current quantitative metrics like IoU and Chamfer distance. Perceptual metrics may provide better ways to evaluate visual quality and consistency. Can the module retrieve complex and fine-grained parts in addition to primitive-like parts?\\n\\nAdditionally, this retrieval component relies heavily on and is adapted from a previous work.\\n\\n5. According to Table 2, some components bring minimal gains, such as the classifier-free training on the object category (cCF) and the foreground loss \\\\(L_{fg}\\\\).\", \"Questions\": \"1. What does `r_i` represent in line 200?\\n\\n2. I am unclear about the phrase, \\\"the graph determines the ordering of the parts to be generated so that the parts are organized correctly when articulating.\\\" Could you explain this in more detail?\\n\\n3. In line 331, could you clarify why \\\"graph accuracy\\\" for \\\"NAP-ICA-GTgraph\\\" is not 100%?\\n\\n4. Line 421: The sentence \\\"we report the accuracy (Acc% ↑) in terms of the percentage of correct graph topology\\\" is unclear to me. Could you explain this further?\\n\\n5. Do you use one token for each part in your transformer?\\n\\n6. What is the difference between \\\"image guidance (iCF)\\\" and \\\"image cross-attention (ICA)\\\"?\"}"}]}
{"paper_id": "LOBhVTtVnc", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nPhysical dynamics simulation plays a crucial role in various real-world applications. In this paper, we explore the potential of leveraging Transformers by framing the task as autoregressive next-graph prediction based on spatiotemporal graph inputs. To achieve this, we propose Geometric Spatiotemporal Transformers (GSTs), which adopt the expressive encoder-decoder architecture of traditional Transformers. At the core of GSTs are equivariant spatiotemporal blocks that alternate between spatial and temporal modules while preserving E(3) symmetries. Additionally, we introduce the Temporal Difference Graph (TDG), derived from the difference between the last two frames of historical input, to capture global dynamic patterns and mitigate cumulative errors in long-term prediction tasks. Unlike existing Graph Neural Network (GNN) methods, GSTs can process full input sequences of arbitrary lengths to effectively capture long-term context, and address cumulative errors over long-term rollouts thanks to the TDG mechanism. Our method achieves state-of-the-art  performance across multiple challenging physical systems at various scales (molecular-, protein-, and macro-level), demonstrating the robust dynamics simulation capabilities.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"- Predicting the delta to the next timeframe is a compelling strategy to mitigate error accumulation. This strategy is also commonly used in diffusion models and the paper shows that this strategy also works well on physical simulation rollouts.\\n- Using transformers instead of GNNs makes a lot of sense as their scalability is well established and their flexibility (e.g. like using the TDG to incorporate arbitrary many history timesteps) is desireable\\n- The method shows strong improvements over competitors.\\n- Clear mathematical and visual description of the method.\", \"Weaknesses\": \"- The paper lacks runtime/flops and parameter count comparisons. Even though the architecture and training procedure can be quite different between methods, a comparison of parameter counts and runtimes is essential to exclude performance gains simply due to investing more compute/parameters into the model/training. \\n- Processing the history (especially in the GST-V) could become quite costly, so the runtime necessary for a rollout should be reported.\\n- The considered models are extremely small (hidden dim 16 with 2 layers according to the Appendix). This limits the interaction capabilities of GNNs and therefore plays into the hand of transformers, which have global interactions in all layers. A comparison of deeper models or a justification why it is not limiting GNNs to be local should be provided (not sure how many message passing steps are common in these setups).\\n- The problem sizes should be stated in the paper/appendix, it is only stated how many samples are in a dataset, but not how many nodes a single sample has. \\n- Autoregressive models are commonly trained with next-step prediction. However due to the time aggregation and history components of the proposed method, a multi-step prediction during training is necessary which greatly limits scalability to larger models, longer rollouts and larger problem sizes (number of nodes)\\n- The considered datasets are at most 20 rollout timesteps, \\\"long-horizon\\\" seems a bit of a stretch for that.\\n- Given the similar performance of GST-F and GST-V, it would be interesting to visualize the attention maps to see if GST-V actually uses all of the history or only the recent ones.\", \"Questions\": \"- How do models compare in terms of runtimes/parameters/flops?\\n- Why are the models so small, are the datasets so small/simple that larger ones run into overfitting? Are larger models infeasible? You are using A100 cards so larger models should not be a problem in terms of compute. Could you elaborate more on the scaling properties of your method (in terms of compute and to larger problem sizes)? \\n- Is \\\"temporal position embedding with the sine function\\\" the standard transformer positional embedding with sine/cosine of variable frequencies?\\n- \\\"We collect all the long-term predictions\\\" makes it seem that long term predictions are emphasized over short term ones, however the MSE weights all predictions equally, right?\\n- How many timesteps are provided for GST-F?\\n- In Figure 2, why is $X'_T$ summed with the delta and not $X_T$. Is $X'_T$ just copied from $X_T$ for visualization?\\n\\nMinor:\\n- line 72: \\\"inFig\\\" space missing\\n- line 123: \\\"xpatiotemporal\\\"\\n- line 264: \\\"the decoder process\\\" should be \\\" the decoder processes\\\"\"}"}]}
{"paper_id": "oa5UeyUVMm", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nDiffusion probabilistic models (DPMs), widely recognized for their potential to generate high-quality samples, tend to go unnoticed in representation learning. While recent progress has highlighted their potential for capturing visual semantics, adapting DPMs to graph representation learning remains in its infancy. In this paper, we introduce **Graffe**, a self-supervised diffusion model proposed for graph representation learning. It features a graph encoder that distills a source graph into a compact representation, which, in turn, serves as the condition to guide the denoising process of the diffusion decoder. To evaluate the effectiveness of our model, we first explore the theoretical foundations of applying diffusion models to representation learning, proving that the denoising objective implicitly maximizes the conditional mutual information between data and its representation. Specifically, we prove that the negative logarithm of denoising score matching loss is a tractable lower bound for the conditional mutual information. Empirically, Graffe delivers competitive results under the linear probing setting on node and graph classification, achieving state-of-the-art performance on 9 of the 11 real-world datasets. These findings indicate that powerful generative models, especially diffusion models, serve as an effective tool for graph representation learning.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"The writing and visualization are pretty clear and the paper also includes core ablations. The usage of graph U-Net is well-motivated and clarified in the paper. The performance seems to be consistent in the ablations in 5.4. The theoretical insights about conditioning supports better the encoder part.\", \"Weaknesses\": \"1. Some key insights are missing from the analysis:\\n  * The effect of mask ratio seems to be very different for different datasets, which will lead to more tuning, as mentioned in the limitations. However, the insight about the impact of mask ratio is also missing in the discussions, and an intuitive guide for choosing this ratio would be helpful. \\n  * It is very intriguing that A reconstruction seems to only deteriorate the performance as mentioned in the 1st part of 5.4, since A contains richer information than node features for graphs without explicit node features. The insight about this is also missing.\\n2. While spectra are a key in related work, this is no further analysis in the experiments and in methods. The related sentence in Line 84 of the Introduction lacks supportive evidence or explanation.\", \"Questions\": \"One question I have is about the difference between the 'encoder' and 'decoder' part, where 'encoder' functions as a condition for the decoder. The mechanism of 'encoder' by masking nodes is very similar to another diffusion process which absorbs nodes sequentially until all nodes become noisy. So the process seems to be somehow a denoising process given 2 types of noising trajectory (one with t being dynamic, and another with t being fixed as the mask ratio). Would the performance change if the encoder/decoder designs switch, out of curiosity? Have you considered using both dynamic 't' as the mask ratio in the 1st part as well?\"}"}]}
{"paper_id": "5swfKRkCx7", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nRetrieval-augmented generation (RAG) of large language models (LLMs) has recently attracted significant attention owing to their ability to address knowledge gaps in generating reliable answers for specific questions. Existing RAG approaches typically optimize the knowledge processing by filtering out irrelevant or incorrect information and restructuring it for model input, improving the accuracy of answers to given questions. A general approach in doing so is to combine the retrieved knowledge with the input inquiry, which are then fed into the LLM to produce an answer. This approach requires the LLM to have strong knowledge comprehension and reasoning capabilities to effectively utilize the useful information, which may lead to errors when it fails to correctly interpret relevant knowledge. In this paper, we propose a novel approach to augmenting LLMs with external knowledge attention for question answering (QA), where the attention is functionalized as an extra head that integrated with the internal heads used in LLMs. We develop a memory-based mechanism that dynamically controls the degree of knowledge integration with the extra head based on the relationship between the question and the retrieved knowledge, and allows for differentiated fusion of external knowledge and LLM ability at its different layers. Experiments on both general and specific-domain QA tasks demonstrate the effectiveness of our approach, highlighting its potential to optimize LLMs for similar challenges.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"The approach of knowledge injection through latent vectors in a decoder-only model is innovative. Most prior studies have focused on incorporating latent knowledge into encoder-decoder models, such as T5, whereas this work applies it to a decoder-only model.\\n\\nAlthough the authors do not explicitly address efficiency, the model's use of latent knowledge suggests potential benefits for reducing inference latency and increasing throughput.\", \"Weaknesses\": \"The approach's intuition is not fully explained. The authors argue that standard RAG suffers from \\\"less converged integration of knowledge and LLMs\\\" due to concatenation-based methods, yet this claim lacks citation and evidence. Moreover, the experiments do not directly validate that the proposed approach addresses this issue.\\n\\nThe paper is poorly written, with the methodology lacking sufficient detail. Specific aspects remain unclear, as noted in the questions below.\\n\\nCertain methodological choices lack justification and intuitiveness, such as the attempt to align the BERT and LLAMA latent spaces without clear post-training evidence.\\n\\nThe approach seems closer to fine-tuning than instruction tuning. Given that LLMs are designed for multiple tasks, the authors should demonstrate that the approach preserves the model's performance on tasks beyond RAG.\", \"Questions\": \"In line 131, the authors mention removing positional embeddings. Could they clarify this choice? Was an ablation study conducted?\\n\\nHow is a single knowledge instance encoded as a single vector? If a pre-trained language model (PLM) like BERT was used, the output would typically be a sequence of latent vectors, not a single vector. The authors should clarify this process.\\n\\nWhy did the authors select BERT specifically? There are more advanced models available, and the choice of BERT requires justification.\\n\\n[Feedback]\\n1. Equation 2 has an error; it should be s_u instead of s_i\\n2. Several recent citations on memory use in RAG settings are missing, such as [1]\\n[1] https://arxiv.org/abs/2406.04670\"}"}]}
{"paper_id": "5s1qpjrNvZ", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nReinforcement learning-based solutions are increasingly being considered as strong alternatives to classical  system controllers, despite their significant sample inefficiency when learning controller tasks from scratch. Many methods that address this issue use prior task knowledge to guide the agent's learning, with several recent algorithms providing a guide policy that is sometimes chosen to execute actions instead of the learner policy. While this approach lends excellent flexibility as it allows the guide knowledge to be provided in any format, it can be challenging to decide when and for how long to use the guide agent. Current guide policy-based approaches typically choose a static guide sampling rate empirically, and do not vary it. Approaches that  transfer control use simple methods like linear decay, or require hyperparameter choices that strongly impact the performance. We show that under certain assumptions, the sampling rate of the guide policy can be calculated to guarantee that the mean return of the learning policy will surpass a user-defined performance degradation threshold. To the best of our knowledge, this is the first time a performance guarantee has been established for a\nguided RL method. We then implement a guided RL (GRL) algorithm that can make use of this sample rate, and additionally introduce a roll-back feature in guided RL with roll-back (GRL-RB) to adaptively balance the trade-off between performance degradation and rapid transfer of control to the learner. Our approach is simple to implement on top of existing algorithms, robust to hyperparameter choices, and effective in warm-starting online learning.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"I like the general idea of the paper & the derivation of guarantees under some (strong) assumptions are interesting on their own. To the best of my knowledge those are novel & could be helpful in some (limited) scenarios.\", \"Weaknesses\": \"Main weaknesses from my point of view:\\n\\n1) The empirical evaluation is not very comprehensive:\\nThere are 2 experiments in the CombinationLock environment, which are nice to get an intuitive understanding of the method, however are not very realistic RL tasks. Then there are 3 experiments on Antmaze, in which the LD baseline performs similarly well as the new algorithm. As the authors motivate the method from a quite applied perspective, I am wondering whether that means that there is not much expected gain from the method in practical scenarios. Also, I believe the positive dense reward setting is derived, but not experimented with.\\n\\n2) The assumptions leading to the derived sampling rates appear to be violated:\\nThe authors realise that in practice the assumptions they make for the derivations are violated & thus add the Roll-Back method in order to improve performance. While the derived results are of course interesting on their own, one has to ask from a practical standpoint whether deriving & using something based on wrong assumptions makes a lot of sense - especially when taking into account the not so convincing empirical evaluation.\\n\\n3) Slightly overstated claims:\\nE.g. in lines 67-69, you talk about \\\"a guided RL approach, [...] with a guaranteed online performance above a user-defined threshold\\\". This sounds like a broad claim which I think needs to be qualified further (only mean performance is above threshold, individual episodes can be below; limited to certain reward scenarios, i.e. not for general MDP / RL; only under questionable assumptions, i.e. convergence). The authors also still talk about guarantees when the Roll-Back approach is added in (\\\"A GRL with a roll-back algorithm (GRL-RB) that helps to retain the performance guarantee of GRL while relaxing its assumptions\\\"), even though at that point it becomes clear that there is no guarantee (Roll-Back happens exactly when guarantee is violated; plots show performance can be much below threshold for a long time). Generally I think one has to be more cautious with the term guarantee, e.g. in the abstract it is formulated better.\\n\\n4) Limited applicability when compared to all possible reward landscapes:\\nThis is not such a big issue in general since guarantees even in just a few environments would be helpful. It's also briefly mentioned by the authors in the discussion.\\n\\n5) I think Fig 4a might be misleading - it's not clear when something is rolled back, it just looks like violations occur in almost every step.\\n\\nIt may be that I am misunderstanding some issues, so I am prepared to raise my score if the points can be addressed.\", \"Questions\": \"- The evaluation sample rates in the bottom plots 1-3 don't align with what I expected, i.e. why are the percentages of the static baselines not exactly .25 & .75 (e.g. fig 2b has them below .2 & at .6)? I presume the variations (shaded region) of the baselines are the difference between true parameter and sampling? The LD baseline does not appear to really reduce alpha by the same amount every time step, why is that?\\n\\n- One thing I also don't understand: Why is the alpha not degraded much faster? What I mean is why is it always degraded by $(1-\\\\alpha_0)$ and not by $(1-\\\\alpha_c)$ (algo 1, line 18) - if the assumptions on convergence you make were to hold, the updated alpha should be used for the next degradation or am I missing something?\"}"}]}
{"paper_id": "WNb4P8aG66", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nConventional class-guided diffusion models generally succeed in generating images with correct semantic content, but often struggle with texture details. This limitation stems from the usage of class priors, which only provide coarse and limited conditional information. To address this issue, we propose Diffusion on Diffusion (DoD), an innovative multi-stage generation framework that first extracts visual priors from previously generated samples, then provides rich guidance for the diffusion model leveraging visual priors from the early stages of diffusion sampling. Specifically, we introduce a latent embedding module that employs a compression-reconstruction approach to discard redundant detail information from the conditional samples in each stage, retaining only the semantic information for guidance. We evaluate DoD on the popular ImageNet-$256 \\times 256$ dataset, reducing 7$\\times$ training cost compared to SiT and DiT with even better performance in terms of the FID-50K score. Our largest model DoD-XL achieves an FID-50K score of 1.83 with only 1 million training steps, which surpasses other state-of-the-art methods without bells and whistles during inference.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 1, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"1) From a theoretical level, I find the paper very nice. It is a) simple / elegant and b) fast. From a novelty perspective, I have no concerns.\\n\\n2) The paper includes multiple strong results concerning the practical usefulness of the method (num parameters, steps, GFLOPS)\\n\\n3) This paper is well-written, and well-presented\", \"Weaknesses\": \"Points are in order of my perceived importance (most to least), indicating how heavily they weigh in my rating.\\n\\n1) Table 5 (main results) seem to primarily compare against basic diffusion models, but miss comparisons against other post-hoc diffusion methods (e.g. MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer, Gao 2023 already cited in this paper; ReNO: Enhancing One-step Text-to-Image Models Through Reward-based Noise Optimization, Eyring 2024; ElasticDiffusion: Training-free Arbitrary Size Image Generation through Global-Local Content Separation, Haji-Ali 2023). These should be the true competing methods.\\n\\n2) LEM is a novel contribution, correct? There are other methods that use image features as conditioning (e.g. Diffusion Feedback Helps CLIP See Better, Wang 2024) and address the issue of making the task too easy if too much information is used--LEM should be justified by comparing to other methods of this type, both theoretically and quantitatively.\\n\\n3) In Table 5 (main results), DoD is only the best on 3 / 5 metrics. This in itself is not convincing to me--however, I would be more convinced if other results were provided to show that DoD is much more efficient (e.g. the GFLOP or num parameter experiments) than the better performing methods, for relatively little performance drop. At the moment, these efficiency experiments are not done on the out-performing methods (StyleGAN-XL, BigGAN-deep, LDM-4-G, Flag-DiT-G).\\n\\n4) Top-1 accuracy is included in Table 2--I believe it would be useful in the main results in Table 5 as well, as it is another way to show image generation quality.\\n\\n5) The main results comparing to other SOTA (table 5) are very hidden, only at the end of the experimental section. They are also very slim on analysis. These need to be brought out more. \\n\\n6) I have a hard time interpreting the qualitative results, as all images seem very similar. It would be helpful to provide the reader with some specific guidance as to what you perceive as the qualitative improvements.\", \"Questions\": \"In relation to my described weaknesses, the top areas that I see the most important for a strong submission and would need to be improved for me to raise my rating:\\n\\n1) provide experiments against SOTA comparable models, meaning a) other post-hoc diffusion methods for DoD and b) other image feature conditioning methods for LEM. See W1 and W2 for specific suggestions of comparison methods. I am not particularly tied to these exact methods, but just giving them as a starting place to further understand what kinds of methods I mean.\\n\\n2) Include better analysis within the main results (table 5), including a) more in-depth explanations in writing, b) better justification for why DoD is useful even though it is not the top-performing model on 3 / 5 metrics (without even including SOTA, as described in Q1)\\n\\nGiven convincing experiments, I would be included to greatly raise my rating, as I like the paper from a theoretical level.\"}"}]}
{"paper_id": "UfczlMudN6", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThe reliable deployment of deep reinforcement learning in real-world settings requires the ability to generalize across a variety of conditions, including both in-distribution scenarios seen during training as well as novel out-of-distribution scenarios. In this work, we present a framework for dynamics generalization in deep reinforcement learning that unifies these two distinct types of generalization within a single architecture. We introduce a robust adaptation module that provides a mechanism for identifying and reacting to both in-distribution and out-of-distribution environment dynamics, along with a joint training pipeline that combines the goals of in-distribution adaptation and out-of-distribution robustness. Our algorithm GRAM achieves strong generalization performance across in-distribution and out-of-distribution scenarios upon deployment, which we demonstrate on a variety of realistic simulated locomotion tasks with a quadruped robot.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 5, \"Strengths\": \"- The manuscript is extremely well written and provides clear statements to understand the proposed method.\\n- The authors demonstrate a successful implementation of recently introduced Epistemic Neural Networks for a relevant and important open problem in robot learning (i.e. generalization over unobservable environment contexts)\", \"Weaknesses\": \"- Missing recent related works: the authors should consider citing and discussing recent works [1] and [2] as they present themselves as state-of-the-art methods in Robust RL and Domain Randomization as of 2024. Specifically, DORAEMON [2] tackles the same problem setting as in this work where privileged information is available at training time, and a history of previous observations and actions is used to allow implicit system identification at test time and promote adaptive behavior.\\n\\n- Limited experimental evaluation:\\n  - While Domain Randomization is an extremely popular baseline for learning robust/adaptive behavior in sim2real settings, the authors provide little information to the implementation of this baseline and no comparison of GRAM vs. DR in fig. 4 and 5.\\n  - Implementation details of DR: I highly suggest the authors to compare GRAM against a DR baseline which also uses a history of previous state and actions, as this is the notorious way to implement DR [3]. Furthermore, DR may and should also leverage privileged information at training time, by using the notorious asymmetric actor-critic paradigm [2, 3, 4]. Conditioning the critic on the known context often drastically affects the results of DR methods vs. unprivileged critics, and does not require further assumptions.\\n  - The analysis is carried out on locomotion environments only, and simulated environments only. The generalization problem under unobservable dynamics is likely exacerbated and more challenging for manipulation and contact-rich settings, which would make the experimental evaluation more significant and relevant.\\n\\n[1] Reddi, A. et al. \\\"Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula.\\\" ICLR 2024.\\n\\n[2] Tiboni, G. et al. \\\"Domain Randomization via Entropy Maximization.\\\" ICLR 2024.\\n\\n[3] Peng, Xue Bin, et al. \\\"Sim-to-real transfer of robotic control with dynamics randomization.\\\" 2018 IEEE international conference on robotics and automation (ICRA). IEEE, 2018.\\n\\n[4] Handa, Ankur, et al. \\\"Dextreme: Transfer of agile in-hand manipulation from simulation to reality.\\\" 2023 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2023.\", \"Questions\": \"- Why is the performance of all baselines better in Fig. 3 (right) for the \\\"Base ID + frozen joints\\\" vs. the \\\"Base ID\\\" counterpart?\\n\\n- Regarding the statement at the end of Sec. 5 \\\"as the goal is to train the epinet in (5) to output estimates with low variance in ID contexts and high variance in OOD contexts.\\\". Does GRAM promote the learned encoder to output high variance in OOD contexts at training time? Judging from Eq. (7) alone, it seems to me that the encoder is only trained to provide low variance on ID contexts, whereas a higher OOD variance is a spontaneous effect that occurs at test time only.\"}"}]}
{"paper_id": "60Vd7QOXlM", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nCurrent techniques for privacy auditing of large language models (LLMs) have limited efficacy---they rely on basic approaches to generate canaries which leads to weak membership inference attacks that in turn give loose lower bounds on the empirical privacy leakage.\nWe develop canaries that are far more effective than those used in prior work under threat models that cover a range of realistic settings. \nWe demonstrate through extensive experiments on multiple families of fine-tuned LLMs that our approach sets a new standard for detection of privacy leakage. For measuring the memorization rate of non-privately trained LLMs, our designed canaries largely surpassing the prior SOTA. For example, on the Qwen2.5-0.5B model, our designed canaries achieves $26.0\\%$ TPR at $1\\%$ FPR, largely surpassing the prior SOTA of $1.3\\%$ TPR at $1\\%$ FPR. Our method can be used to provide a privacy audit of $\\varepsilon \\approx 1$ for a model trained with theoretical $\\varepsilon$ of 4. To the best of our knowledge, this is the first time that a privacy audit of LLM training has achieved nontrivial auditing success in the setting where the attacker cannot train shadow models, insert gradient canaries, or access the model at every iteration.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"While their approach for auditing LLMs is not unique, the paper provides extensive experiments to support their claims. The design of the canaries provides a better estimate of privacy risks of LLMs. Also, unlike previous studies where the insertion of canaries resulted in a decline in clean accuracy, their method maintains consistent accuracy levels.\\nImportantly, the paper is well written and easy to follow.\", \"Weaknesses\": \"The obvious weakness is in the use of a single dataset, which has already been pointed out by the authors. It would be good to see how different datasets behave, especially when the canaries are inserted. Does the different dataset cause more or less leakage? This analysis would make the paper stronger\", \"Questions\": \"I have the following concerns:\\n1. My major concern is that MI attack on LLMs is now a game of canary design. Previous works have shown the ineffectiveness of MI attack, as also pointed out by the authors. Hence, the authors are tying the success of MI attack to the goodness of canary design, which in some cases are not realistic / practical. \\nCan the authors provide guidelines, which could be considered standards to indeed follow, to effectively design the canaries?\\n\\n2. Inherent to existing works on MI attack is the problem of distribution shifts [c]. How did the authors deal with the problem of distribution shift in their audit? Or does it not exisit in the current setting? While the focus of the paper is not the design of MI attack, such inherent problem could affect the privacy leakage estimation of the models.\\n\\n3. The authors only considered the case of full fine-tuning, can the authors perform experiments using PEFT such as LoRA and prefix tuning?\\nWhat are the insights from using different PEFT than the current full fine-tuning? \\nAlso, this might address the limitation of the single dataset.\\n\\n4. In Figure 3, focusing on the \\\"new\\\" canary, what is the justification for the poor performance of pythia-1.4b, pythia-410m and gpt2-xl?\\n\\n5. I would like to point the authors to a concurrent work. Although the authors used a data extraction attack and considered language models fine-tuned with PEFT, it is important to take note of this work [a] which is closely related\\n\\n\\nRelated works:\\n[a] \\\"Evaluating Privacy Risks of Parameter-Efficient Fine-Tuning.\\\" https://openreview.net/forum?id=i2Ul8WIQm7\\n[b] \\\"Open LLMs are Necessary for Private Adaptations and Outperform their Closed Alternatives\\\" Vincent Hanke et al. (Neurips 2024)\\n[c] \\\"SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How to Fix It)\\\" Matthieu Meeus et al. https://arxiv.org/abs/2406.17975\"}"}]}
{"paper_id": "GqhvJ1o8m5", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe introduce \\textit{ImmersePro}, an innovative framework specifically designed to transform single-view videos into stereo videos. This framework utilizes a novel dual-branch architecture comprising a disparity branch and a context branch on video data by leveraging spatial-temporal attention mechanisms. \\textit{ImmersePro} employs implicit disparity guidance, enabling the generation of stereo pairs from video sequences without the need for explicit disparity maps, thus reducing potential errors associated with disparity estimation models.\nIn addition to the technical advancements, we introduce the YouTube-SBS dataset, a comprehensive collection of 423 stereo videos sourced from YouTube. This dataset is unprecedented in its scale, featuring over 7 million stereo pairs, and is designed to facilitate training and benchmarking of stereo video generation models. Our experiments demonstrate the effectiveness of \\textit{ImmersePro} in producing high-quality stereo videos, offering significant improvements over existing methods.\nCompared to the best competitor stereo-from-mono we quantitatively improve the results by 11.76\\% (L1), 6.39\\% (SSIM), and 5.10\\% (PSNR).\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 5, \"Strengths\": \"1. These paper introduces a large dataset for stereo video generation, which will benefit the research in this area.\\n\\n2. The design for the implicit disparity is reasonable, which is also consistent with the findings from Vimeo that the direct optical flow is not good for image systhesization.\", \"Weaknesses\": \"1. The dataset details are missing. \\n\\n(a) How many frames per video? Does the videos have the same length? If not, what's the length distribution?\\n\\n(b) Stereo videos often contain multiple scenes. These video clips are not consistent. The author only measured the spatial consistency between the left and right view. However, it seems that the author missed the temporal consistency, which is important for the stereo videos. How does the author handle it?\\n\\n(c) In Eq. 1, the authors leveraged the optical flow estimated by RAFT to measure the error. However, optical flow is not accurate in the stereo pairs as it containing the movement in the vertical direction. The author should only consider the horizential direction. Although authors claimed that \\\"We also evaluated STTR (Li et al., 2021) and RAFT-Stereo (Lipson et al., 2021), but these two methods produced worse results.\\\", the aurhors should find a more accurate disparity estimation method or constrain RAFT in the horizential direction.\\n\\n2. Experiments\\n\\n(a) For a fair comparison, the authors are required to re-train or finetune the state-of-the-art methods on the new datasets. \\n\\n(b) To check the effectiveness of the proposed dataset, the authors need to evaluate image-based models trained on the new dataset on the previous image-based dataset. \\n\\n\\nMinor\\n\\n1. \\\"6.39%(SSIM), and 5.10% (PSNR)\\\" is not professional. Most of the time, we only report the differences, e.g. 1.1 dB in term of PSNR. As PSNR is based on the log function, percentage is not correct.\", \"Questions\": \"Please refer to the weakness section.\"}"}]}
{"paper_id": "ua5MHdsbck", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThe goal of protein design typically involves increasing fitness (extrapolating) beyond what is seen during training (e.g., towards higher stability, stronger binding affinity, etc.). State-of-the-art methods assume that one can safely steer proteins towards such extrapolated regions by learning from pairs alone. We hypothesize that noisy training pairs are not sufficiently informative to capture the fitness gradient and that models learned from pairs specifically may fail to capture three-way relations important for search, e.g., how two alternatives fair relative to a seed. Building on the success of preference alignment models in large language models, we introduce a progressive search method for extrapolative protein design by directly distilling into the model relevant triplet relations. We evaluated our model's performance in designing AAV and GFP proteins and demonstrated that the proposed framework significantly improves effectiveness in extrapolation tasks.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 3, \"Strengths\": \"Overall this paper is a valuable contribution to the field.\\n* The problem of designing proteins with fitness value beyond the training range is an important problem and challenging in protein design e.g. lead optimization; the proposed work has high practical value.\\n* The proposed approach is well-motivated; the use of triplet-information with preference optimization for protein design makes a lot of sense and is (to my knowledge) new. The analysis of the importance of using difficult triplets is insightful. The experimental validation is thorough (including ablation studies) and shows that the proposed model outperforms alternatives in the extrapolation regime.\", \"Weaknesses\": \"* The preference optimization relies on a scorer function to define the triplets; in real-world setting, training such scorers is difficult and the scorer is often used in out-of-distribution settings where it does not generalize well. Adding some discussion on this topic would be valuable to the paper as it is not discussed to avoid settings where the proposed preference optimization would degrade the base pairwise model. In particular, could the authors explain how robust is the preference fine tuning model to noisy labels? How to avoid pathological cases where difficult triplets are defined by an imperfect scorer ? \\n* The presentation is at times confusing and difficult to understand (c.f. clarifying question).\", \"Questions\": \"* Some parts of this paper are dense and difficult to read; in particular the definition of triplets (defined in different parts of the paper in sections 3.4; 4.3 and 6.1). W.r.t. scorer distillation, what is defined as a hard triplet ranking wise (for the vanilla version, hardness is defined by the local editor) ? The term \\\"scorer distillation\\\" is confusing (if I understood correctly the vanilla version also uses a scorer).\\n* How important is the mask infilling step ? How frequently are the mask infilled samples represented in the challenging triplets (where the editor does not capture the right fitness ordering) ?\\n\\n\\n====Post rebuttal====\\nI thank the authors for the rebuttal; I recommend acceptance.\"}"}]}
{"paper_id": "56Zn3halhq", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nTime series forecasting models typically rely on a fixed-size training set and treat all data uniformly, which may not effectively capture the specific patterns present in more challenging training samples. To address this issue, we introduce AutoTSAug, a learnable data augmentation method based on reinforcement learning. Our approach begins with an empirical analysis to determine which parts of the training data should be augmented. Specifically, we identify the so-called marginal samples by considering the prediction diversity across a set of pretrained forecasting models. Next, we propose using variational masked autoencoders as the augmentation model and applying the REINFORCE algorithm to transform the marginal samples into new data. The goal of this generative model is not only to mimic the distribution of real data but also to reduce the variance of prediction errors across the model zoo. By augmenting the marginal samples with a learnable policy, AutoTSAug substantially improves forecasting performance, advancing the prior art in this field with minimal additional computational cost.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 4, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"- The paper proposes a interesting perspective on data augmentation by focusing entirely on high prediction variance samples.\\n- The paper is generally well written and the methods and results are presented well.\", \"Weaknesses\": \"- In the Related Works section, the paper presents other generative based and RL-based methods for time-series data augementation yet only compares their proposed method with the Gaussian noise augmentor. It would be nice to see more baseline comparisons (at least one  each from generative based and RL-based methods).\\n- It is not super convincing that augmenting only marginal samples results in consistantly significant improvements for the prediction model, as most of the results presented in Table 2 having  a <5% improvement with the augmented data, with the biggest improvement coming from the basic Transformer model.\\n- Moreover, it is not entirely clear that AutoTSAug is able to consistantly morph the marginal samples into samples that exhibit lower prediction variance in the model zoo.\", \"Questions\": \"- Are the marginal samples consistant across different training instances of the same model? E.g. if the model zoo is initialized with different parameters or trained with different hyperparameters does it affect which samples are considered marginal?\\n- Since the paper proposes an RL based training approach, does the proposed method use a multi-step training approach where the initial recontruction is fed into the encoder as the new \\\"state\\\" and policy model would then further augment the sample. Or do the proposed method use a single step approach and if so is that enough to significantly modify the samples towards the reward function?\"}"}]}
{"paper_id": "aPTGvFqile", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nContrastive Language--Image Pre-training (CLIP) has manifested remarkable improvements in zero-shot classification and cross-modal vision-language tasks. Yet, from a geometrical point of view, the CLIP embedding space has been found to have a pronounced modality gap. This gap renders the embedding space overly sparse and disconnected, with different modalities being densely distributed in distinct subregions of the hypersphere. In this work, we propose AlignCLIP, in order to improve the alignment between text and image embeddings, and thereby reduce the modality gap. AlignCLIP increases the cross-modal alignment, and yields gains across several zero-shot and fine-tuning downstream evaluations by sharing the learnable parameters between the modality encoders and a semantically-regularized separation objective function on the uni-modal embeddings.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. Technical solid paper with clear stated motivation and well organized content.\\n2. The proposed Intra-Modality Separation module is novel and is benefit to the community.\\n3. The proposed method surpassed the existing methods in most cases.\", \"Weaknesses\": \"1. The idea of shared transformer is less novel. From my understanding, since the shared transformer for CLIP has been proposed by You et. al., then extending it to the projection layer is just an incremental improvements. The paper should discuss why the extension to the projection layer is necessary comparing to the existing methods. For example, in terms of \\\"extend the sharing to the extent possible\\\" in line #168m, what should we do if using CLIP-ResNet instead of CLIP-ViT.\\n2. Since the paper claims the (i) SharedCLIP (ii) IMSep module. It is not clear that which module contributes more on the overall performance. Since the SharedCLIP is strongly dependent on transformer structure, while IMSep module is more related to the general multi-modality contrastive learning task, therefore, the IMSep moduel has better expansibility for various model structures. Therefore, an ablation study on this is necessary, i.e. (original_CLIP+)SharedCLIP vs original_CLIP+IMSep, if I missed this experiment, please point it out during the rebuttal.\\n3. It's necessary to add some discussion for Table.5, regarding the COCO T->I. It seems the SharedCLIP works better in the T->I scenario, but what reason cause the degradation while adding IMSep? Some discussion and analysis regarding why this degradation occurs would be benifit for researchers to understand the limitation of the proposed model, for example, is it due the complexity of COCO dataset itself, or due to the IMSep while performing T->I. How is the performance while applying original_CLIP+IMSep only on T->I?\\n\\n[You et. al] Learning visual representation from modality-shared contrastive language-image pre-training. In ECCV, pp. 69–87, 2022.\", \"Questions\": \"Please see weakness.\"}"}]}
{"paper_id": "GOwNImvCWf", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThe weights of neural networks (NNs) have recently gained prominence as a new data modality in machine learning, with applications ranging from accuracy and hyperparameter prediction to representation learning or weight generation. One approach to leverage NN weights involves training autoencoders (AEs) with contrastive and reconstruction losses. Indeed, such models can be applied to a wide variety of downstream tasks, and they demonstrate strong predictive performance and low reconstruction error. However, despite the low reconstruction error, these AEs reconconstruct NN models that fail to match the performance of the original ones. In this paper, we identify a limitation of weight-space AEs, specifically highlighting that structural weight reconstruction alone fails to capture some features critical for reconstructing high-performing models. To address this issue, we propose a behavioral loss for training AEs in weight space. This behavioral loss focuses on the features essential for reconstructing performant models, which are not adequately captured by structural reconstruction. We evaluate the capabilities of AE trained using this novel loss on three different model zoos: we demonstrate that when combining structural and behavioral losses, we can reconstruct and generate models that match the performance of the original models. With our exploration of representation learning in deep weight spaces, we show that a strong synergy exists between structural and behavioral features, and that combining them results in increased performance across all evaluated downstream tasks.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 5, \"Strengths\": \"- The paper is well written and easy to follow.\\n- The motivation for the proposed solution is well explained and investigated.\\n- Simple solution.\", \"Weaknesses\": \"- My main concern regarding this work is around its novelty the behavioral loss was already used in [1]. In [1] the authors calculated the loss based on the loss on the downstream task. In addition, there is no novelty (and it was not claimed) on the architecture side since the authors used SANE [2] for the weight space AE. How do the authors differentiate their work from [1]?\\n- Limited experimental section. Given the fact that this work is mostly empirical, I expect the experimental section to be more extensive both in scale and learning setups. The authors focused on discriminative models and specifically only on small CNNs. There is no diversity in the reconstructed model architecture or the downstream tasks.\\n- It would be interesting to see how significant are $\\\\beta$ and $\\\\gamma$ hyperparameters in the AE optimization.\\n- The authors mentioned in the appendix that training with behavioral loss nearly doubles the training duration, which poses a challenge for large models.\\n-Rather than using a common model zoo [3,4], the authors chose to create their own, which raises some questions.\\n- The authors did not include confidence intervals in the experimental section. Moreover, in Tables 5 and 6 the authors provide additional results which are inclusive due to high std values. The same should be reported in the main text results.\\n- The only augmentation used for $\\\\mathcal{L}_C$ is a random permutation, why the authors did not use augmentations from [5,6]? [6] should be cited in this work.\\n\\n--------------\\n[1] Equivariant Deep Weight Space Alignment, Navon et al.\\n\\n[2] Towards Scalable and Versatile Weight Space Learning, Schurholt et al.\\n\\n[3] Model Zoo: A Dataset of Diverse Populations of Neural Network Models, Schurholt et al.\\n\\n[4] Eurosat Model Zoo: A Dataset and Benchmark on Populations of Neural Networks and Its Sparsified Model Twins, Honegger et al.\\n\\n[5] Equivariant Architectures for Learning in Deep Weight Spaces, Navon et al.\\n\\n[6] Improved Generalization of Weight Space Networks via Augmentations, Shamsian et al.\", \"Questions\": \"- Based on the findings in Section 2, have the authors considered explicitly encouraging hybrid eigenvalue features? For example, they might incorporate a KL divergence loss relative to a predefined Beta distribution concentrated in the high and low values, effectively ignoring the intermediate range.\"}"}]}
{"paper_id": "C9BA0T3xhq", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nOffline Reinforcement Learning (RL) presents unique challenges, primarily due to the constraint of learning from a static dataset without additional environmental interaction. Traditional methods often face limitations in effectively exploiting the available data, particularly when navigating the exploration-exploitation trade-off inherent in RL. This paper introduces a novel algorithm inspired by Implicit Q-Learning, designed to extend the utility of the Bellman update to actions not explicitly present in the dataset. Our approach, termed Extended Implicit Q-Learning (EIQL), strategically incorporates actions beyond the dataset constraints by allowing selection actions with maximum Q. By doing so, it leverages the maximization capability of the Bellman update, while simultaneously mitigating error extrapolation risks. We demonstrate the efficacy of EIQL through a series of experiments that show its improved performance over traditional offline RL algorithms, particularly in environments characterized by sparse rewards or those containing suboptimal and incomplete trajectories. Our results suggest that EIQL enhances the potential of offline RL by utilizing a broader action spectrum.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"1. The paper is well structured. The proposed idea is simple and easy to implement.\\n2. Empirical results are provided on various robotics benchmarks, showcasing the effectiveness of the approach.\", \"Weaknesses\": \"1. The paper could benefit from a small discussion on model-based approaches for offline RL, such as MOReL[1] and MOPO[2]. \\nPenalizing OOD (Out-of-Distribution) actions is not the only way to handle action extrapolation in offline RL.\\n\\n2. The related work section is missing key references, particularly the omission of Sparse Q-learning (SQL) and Exponential Q-learning (EQL) [3], which is critical. These methods have outperformed IQL on suboptimal trajectories.\\n\\n3. The paper does not explain Implicit Q-Learning (IQL) in the preliminaries, making it difficult to follow Equation 1. It is important to describe the notations used with the equation to improve readability.\\n\\nMinor:\\n\\nTypo in quotes line 321\\n\\nNo hyperparameters have been provided in appendix making it challenging to reproduce the work\\n\\n[1] Kidambi, Rahul, et al. \\\"Morel: Model-based offline reinforcement learning.\\\" Advances in neural information processing systems 33 (2020): 21810-21823.\\n\\n[2] Yu, Tianhe, et al. \\\"Mopo: Model-based offline policy optimization.\\\" Advances in Neural Information Processing Systems 33 (2020): 14129-14142.\\n\\n[3] Xu, Haoran, et al. \\\"Offline rl with no ood actions: In-sample learning via implicit value regularization.\\\" arXiv preprint arXiv:2303.15810 (2023).\", \"Questions\": \"Q1. Why is the Bernoulli parameter required during policy extraction in Eq 3? How is a selected in second part of the equation where B' is used?\\n\\nQ2. I am confused about Theorem 4.1. The notations seem inconsistent. In Eq1 B is used  in theorem p is use. The proof states \\\"This proof highlights\\nthe influence of the parameter $\\\\beta$ in controlling the extent to which the new policy deviates from optimality\\\", However $\\\\beta$ as per my understanding denotes the behavior policy and is nota parameter?\\nIf the authors could provide clear explanation about each step and a notation table the contributions will be better understood.\\n\\nQ3 What was the choice of B for each environment during empirical evaluation? Why does EIQL have lower performance than some baselines in Table 1?\\n\\nKindly also refer to the weaknesses.\"}"}]}
{"paper_id": "EeqlkPpaV8", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nIn large-data applications, such as the inference process of diffusion models, it is desirable to design sampling algorithms with a high degree of parallelization. In this work, we study the adaptive complexity of sampling, which is the minimum number of sequential rounds required to achieve sampling given polynomially many queries executed in parallel at each round. For unconstrained sampling, we examine distributions that are log-smooth or log-Lipschitz and log strongly or non-strongly concave. We show that an almost linear iteration algorithm cannot return a sample with a specific exponentially small error under total variation distance. For box-constrained sampling, we show that an almost linear iteration algorithm cannot return a sample with sup-polynomially small error under total variation distance for log-concave distributions. Our proof relies upon novel analysis with the characterization of the output for the hardness potentials based on the chain-like structure with random partition and classical smoothing techniques.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"Deriving good lower bounds on query complexity is a central question in the area of log-concave sampling, and this paper makes solid progress towards understanding the optimal parallel query complexity in a natural setting, namely the high-accuracy regime. The lower bound construction is a nice blend between the techniques used to show adaptive complexity bounds in submodular optimization and the information-theoretic approach used in prior work of Chewi et al on query lower bounds for sampling. Additionally, it is interesting that they can derive a linear-in-$d$ lower bound even in the relatively low-accuracy regime in the box-constrained setting.\", \"Weaknesses\": \"While these results are only relevant in the setting where the dimension $d$ is quite large, it is not clear that the lower bounds really get at the fundamental question of why there should be a dimension dependence in the query complexity of log-concave sampling. In particular, the fact that the authors get a near-linear lower bound for the unconstrained sampling setting feels more like a by-product of the fact that they are working in the high-accuracy regime than of the fact that the distribution lives in high dimensions (in particular, their lower bound could be consistent with a world in which the true round complexity is $\\\\tilde{\\\\Theta}(\\\\log(1/\\\\epsilon))$). Admittedly the near-linear lower bound in the box-constrained setting applies in the regime of only $1/d^{\\\\omega(1)}$ error, but the argument seems almost verbatim the same as the argument in the unconstrained setting, suggesting that the fact they get such a lower bound in the relatively low error regime is more a quirk of the constrained setting than something fundamental about dimension dependence for log-concave sampling.\", \"Questions\": \"The writing could be clarified in various places, e.g:\\n- In Lemma 4.3, the terminology \\\"up to addictive error $O(t/2)$\\\" it is only clarified later in the proof to mean that every *coordinate* is off by at most $O(t/2)$ (also why is there a big-O with a factor of 1/2?)\\n- The definition of $X_i(\\\\mathbf{x}')$ seems off, as the subscript $i$ is then used to index over $i\\\\in[\\\\ell]$ in $\\\\cup_{i\\\\in[\\\\ell]} P_i$\\n- The terminology \\\"concentration of conditioned Bernoullis\\\" is a little confusing as it is unclear what is being conditioned on. A more standard phrasing could be \\\"concentration of linear functions over the Boolean slice\\n- When \\\"partition $\\\\mathcal{P} = (P_1,\\\\ldots,P_{r+1})$ over the ground set\\\" was introduced, it was not clear to me that the ground set was referring to the set of coordinates of the Euclidean space in which the target distribution lives\"}"}]}
{"paper_id": "oK1zJCWBqf", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe propose Soft Preference Optimization (SPO), a method for aligning generative models, such as Large Language Models (LLMs), with human preferences, without the need for a reward model. SPO optimizes model outputs directly over a preference dataset through a natural loss function that integrates preference loss with a regularization term across the model's entire output distribution rather than limiting it to the preference dataset. Although SPO does not require the assumption of an existing underlying reward model, we demonstrate that, under the Bradley-Terry (BT) model assumption, it converges to a softmax of scaled rewards, with the distribution's ``softness\" adjustable via the softmax exponent, an algorithm parameter. We showcase  SPO's methodology, its theoretical foundation, and its comparative advantages in simplicity and alignment precision.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"The approach of integrating preference loss with explicit regularization makes sense. The experimental results across different preference settings appear promising.\", \"Weaknesses\": \"1. While the authors claim that reward-model-free alignment methods offer advantages, these methods, which solely optimize a preference dataset, may overfit or overestimate out-of-distribution data. This can result in degraded performance during inference. Therefore, to convincingly demonstrate the effectiveness of the proposed method, it is crucial to compare it against RLHF approaches like PPO. This can be achieved by replacing the preference loss with an on-policy loss term for a fair comparison.\\n\\n2. The derivation of Theorem 1, as well as the subsequent theorems, does not account for the regularization term, which is typically present in the analytic solutions of PPO or DPO. This omission compromises the theoretical results, given that the proposed method essentially optimizes a combination of two loss terms.\\n\\n3. The design of $\\\\mu$ lacks intuition despite its complication, e.g., subtracting the average in a batch. Also the effect of $\\\\gamma$ would be clearer with an ablation study of sweeping this hyper-parameter.\\n\\n4. Missing data on the top of page 9: \\\"improved win-rate from xx% to xx%\\\".\\n\\n5. Missing reference to related alignment methods [1,2,3] that match the model's output distribution.\\n\\n[1] Sessa, Pier Giuseppe, et al. \\\"Bond: Aligning llms with best-of-n distillation.\\\" Arxiv (2024).\\n\\n[2] Gui, Lin, Cristina Gârbacea, and Victor Veitch. \\\"BoNBoN Alignment for Large Language Models and the Sweetness of Best-of-n Sampling.\\\" Arxiv (2024).\\n\\n[3] Ji, Haozhe, et al. \\\"Towards efficient and exact optimization of language model alignment.\\\" ICML (2024).\", \"Questions\": \"1. Could the authors provide a more detailed empirical comparison between PPO and SPO? Since SPO requires on-policy data sampling to compute the KL-regularization, introducing additional complexity that is typically avoided by off-policy alignment methods. Thereby, the key difference in performance between PPO and SPO might stem from the first term in Eq.(1). Would optimizing on off-policy preference data offer a significant advantage over on-policy sampled data, as in PPO, and could this be further explored? For example, training both methods on the same preference dataset, then evaluating them on a held-out test set (in-distribution) and a separate dataset from a different domain (out-of-distribution) respectively.\\n\\n2. Could the authors provide a clearer interpretation of the solution obtained by SPO when regularization is applied under the BT assumption and show how the regularizer affects the convergence properties of the algorithm, as this represents the actual objective being optimized. \\n\\n3. Could the authors conduct a more thorough analysis of the weighting function by breaking down its individual components and performing an ablation study, as it would help to justify the necessity of its complex form.\"}"}]}
{"paper_id": "Dq9VrVuLzV", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThe advancement of autonomous driving is increasingly reliant on high-quality annotated datasets, especially in the task of 3D occupancy prediction, where the occupancy labels require dense 3D annotation with significant human effort. In this paper, we propose SyntheOcc, which denotes a diffusion model that Synthesize photorealistic and geometric-controlled images by conditioning Occupancy labels in driving scenarios. This yields an unlimited amount of diverse, annotated, and controllable datasets for applications like training perception models and simulation. SyntheOcc addresses the critical challenge of how to efficiently encode 3D geometric information as conditional input to a 2D diffusion model. Our approach innovatively incorporates 3D semantic multi-plane images (MPIs) to provide comprehensive and spatially aligned 3D scene descriptions for conditioning. As a result, SyntheOcc can generate photorealistic multi-view images and videos that faithfully align with the given geometric labels (semantics in 3D voxel space). Extensive qualitative and quantitative evaluations of SyntheOcc on the nuScenes dataset prove its effectiveness in generating controllable occupancy datasets that serve as an effective data augmentation to perception models.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"1. SytheOcc offers finer and precise 3D geometric control, allowing for intricate manipulation of object shapes and scene geometry, which is crucial for tasks like 3D editing and dataset generation.\\n2. Experimental results demonstrate that the synthetic data generated by SytheOcc exhibit better recognizability, indicating a substantial advancement in image quality over existing methods.\\n3. The synthetic data produced by SytheOcc prove to be highly effective for data augmentation in 3D occupancy prediction tasks, enhancing the performance and robustness of perception models in such applications.\", \"Weaknesses\": \"1. The practicality of occupancy editing in 3D space should be addressed. It is crucial to automate or accelerate the editing process to make it feasible for practical applications requiring large amounts of data. The authors may report the time required to generate a new image through editing, and discuss possible solutions to scaling up data.\\n2. The paper use occupancy as a condition due to its spatial information. It would be beneficial to discuss the fundamental differences between using occupancy and using of depth&segmentation maps as conditions to control image generation [1]. Experimental comparisons between using depth&semantic maps versus occupancy as conditions could be conducted to evaluate metrics like FID and inference time.\\n3. The multi-view consistency appears not so good. In Figure 5 (b) (c), the color of the car in the first row changes in the second and third images. The authors could includsa comparative analysis of the generation results from different models (e.g., MagicDrive) within the same scene.\\n4. The concept of imbalance mentioned by the authors in Line 272 requires further clarification. It is essential for the authors to provide a detailed explanation of what this imbalance refers to and how it impacts their proposed framework.\\n5. The examples of editing provided in paper mostly revolve simple cars. In Figure 6, it would be beneficial to explore if the model can accurately move and position more complex, irregularly shaped vehicles or pedestrians to demonstrate the capability of the framework in generating new, diverse scenes.\\n6. While the paper discusses some designs related to temporal consistency, only qualitative results are presented. It would be valuable for the authors to report metrics like FVD compared to existing works such as DrivingDiffusion and Panacea to provide a more comprehensive evaluation of the proposed framework.\\n7. Missing reference: [2-4]\\n\\n[1] UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild\\n\\n[2] Generalized Predictive Model for Autonomous Driving\\n\\n[3] Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability\\n\\n[4] SimGen: Simulator-conditioned Driving Scene Generation\", \"Questions\": \"By conducting these expanded experimental comparisons, the authors can more comprehensively validate their claims and provide more compelling evidence for the effectiveness of the proposed SytheOcc framework.\"}"}]}
{"paper_id": "73Q9U0vcja", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe introduce _Diffusion Active Learning_, a novel approach that integrates a generative diffusion model with sequential experimental design to adaptively acquire data for solving inverse problems in imaging. We first pre-train an unconditional diffusion model on domain-specific data. The diffusion model is aimed to capture the structure of the underlying data distribution, which is then leveraged in the active learning process. During the active learning loop, we use the forward model of the inverse problem together with the diffusion model to generate conditional data samples from the posterior distribution, all consistent with the current measurements. Based on the generated samples we quantify the uncertainty in the current estimate in order to select the most informative next measurement. We showcase the proposed approach for its application in X-ray computed tomography imaging. Our results demonstrate significant reductions in data acquisition requirements (_i.e._, lower X-ray dose) and improved image reconstruction quality across several real-world tomography datasets.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 5, \"Confidence\": 5, \"Strengths\": \"The proposed method use half or less measurement to achieve the same performance with the compared methods.\", \"Weaknesses\": \"(1)\\tComparison with activate learning method is preferred, such as the method proposed in [1]. Please compare the reconstruction result and inference time  with use the same number of projection angle.\\n(2)\\tThe experiment is performed with parallel radon transform. More complex setting, such as fan-beam or 3D Cone beam, can verify the effectiveness of the Proposed method.  \\n(3)\\tThe inference time is a huge disadvantage for you need n round k times sampling and n times full view projection. During, the n\\\\times k sampling, the inversion problem cannot be avoided.  Please discuss potential ways to mitigate the computational cost. Please give  a more detailed analysis of the trade-off between computational cost and reconstruction quality.\\n(4)\\t The improvement of the result may come from the diffusion model.  Comparison with DPS or proposed method without active loop using sparse view projection data, i.e. uniform projection angles (27,15,18 angles), is necessary.  This can  help give the explanation of the benefits of  proposed method  from the active learning component or the diffusion model\\n\\n[1]Ce Wang, Kun Shang, Haimiao Zhang, Shang Zhao, Dong Liang, S. Kevin Zhou. Active CT Reconstruction with a Learned Sampling Policy, Proceedings of the 31st ACM International Conference on Multimedia, October, Pages 7226–7235, 2023\", \"Questions\": \"(1)\\tPlot the distribution of selected angle of different datasets.\\n(2)\\tThe shape of the objection has influence of the selected angel,  \\n(3)\\tThe setting of projection geometry must be given.\\n(4)\\tThe definition of the notation must be given such as x^* in algorithm 1.\\n(5)\\tTesting on real projection data can verify the value of the proposed method.\"}"}]}
{"paper_id": "UiEjzBRYeI", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThe Segment Anything model (SAM) has shown a generalized ability to group image pixels into patches, but applying it to semantic-aware segmentation still faces major challenges. This paper presents SAM-CP, a simple approach that establishes two types of composable prompts beyond SAM and composes them for versatile segmentation. Specifically, given a set of classes (in texts) and a set of SAM patches, the Type-I prompt judges whether a SAM patch aligns with a text label, and the Type-II prompt judges whether two SAM patches with the same text label also belong to the same instance. To decrease the complexity in dealing with a large number of semantic classes and patches, we establish a unified framework that calculates the affinity between (semantic and instance) queries and SAM patches, and then merges patches with high affinity to the query. Experiments show that SAM-CP achieves semantic, instance, and panoptic segmentation in both open and closed domains. In particular, it achieves state-of-the-art performance in open-vocabulary segmentation. Our research offers a novel and generalized methodology for equipping vision foundation models like SAM with multi-grained semantic perception abilities. Codes will be publicly available.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"1. I believe this task is important. Transforming the class-agnostic SAM into a usable semantic and instance segmentation is a valuable pursuit. This directly connects to the question of how to leverage the advance of large-scale vision foundation models into practical application.\\n\\n2. The proposed method demonstrates strong performance on commonly used open-world segmentation frameworks, achieving state-of-the-art (SOTA) results when trained on one dataset and tested on another. This includes benchmarks such as: COCO → ADE20K; ADE20K → COCO; COCO → Cityscapes\\n\\n3. The overall experinement and results presentation is good.\", \"Weaknesses\": \"# At a higher level:\\nThe advantage of SAM lies not only in its ability to segment an entire image but also in its prompt-based segmentation, which introduces more accurate masks.\\nI think this method uses SAM only as an initial “superpixel” generator, which somewhat overlook SAM’s full potential.\\n\\n# Generalization:\\nThe proposed method requires training on specific datasets to learn how to merge patches, which seems to be not very generalizable.\\nThis approach may not translate well from natural images to medical images, or even from natural images with large object segments to tasks requiring finer, more detailed segmentation. Is this the case in this setting. Would like to hear author feedback on this point. \\n\\n# Splitting and Merging:\\nThe proposed method only focuses on merging, which to some degree simplifies the problem. I believe splitting is equally important as merging, though it seems it is not within the scope of this method. \\n\\n# Comparison with Other Methods:\\nMost of the results are compared with pre-SAM methods. I wonder how this method compares with other SAM-based semantic segmentation/instance segmentation methods, such as Grounding SAM and SEEM etc. It would be interesting to see a comparison with other SAM-based methods and discuss the advantage of such approach.\", \"Questions\": \"1. At line 150, the authors state that the two prompts can be iteratively called when finer-level segmentation is required. I’m not entirely sure I understand this; my impression is that granularity is determined by SAM’s results. Could the authors clarify this point?\\n\\n2. How do the authors view this approach in comparison to SAM-based generalized segmentation? Most other approaches appear to be training-free and straightforward to use. It would be interesting to discuss the advantages that SAM-CP offers.\"}"}]}
{"paper_id": "lessla98Wp", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nAutomatic video colorization is inherently an ill-posed problem because each monochrome frame has multiple optional color candidates.\nPrevious exemplar-based video colorization methods restrict the user's imagination due to the elaborate retrieval process. Alternatively, conditional image colorization methods combined with post-processing algorithms still struggle to maintain temporal consistency. To address these issues, we present Language-based video Colorization for Creative and Consistent Colors (L-C4) to guide the colorization process using user-provided language descriptions. Our model is built upon a pre-trained cross-modality generative model, leveraging its comprehensive language understanding and robust color representation abilities. We introduce the cross-modality pre-fusion module to generate instance-aware text embeddings, enabling the application of creative colors. Additionally, we propose temporally deformable attention to prevent flickering or color shifts, and cross-clip fusion to maintain long-term color consistency.  Extensive experimental results demonstrate that L-C4 outperforms relevant methods, achieving semantically accurate colors, unrestricted creative correspondence, and temporally robust consistency.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 4, \"Strengths\": \"- Each component is well-motivated, with clear explanations of how they address specific challenges in video colorization. The paper is well-written, with logical organization and flow that makes it easy to understand.\\n\\n- The proposed Cross-Modality Pre-Fusion (CMPF) module enhances text embeddings with instance-aware capability, ensuring that the objects are assigned with desired colors, enabling creative and precise colorization given user input.\\n\\n- The Temporally Deformable Attention (TDA) and Cross-Clip Fusion (CCF) effectively maintain color consistency across frames in a video. These components help prevent flickering and color shifts, leading to smoother and more visually appealing results.\\n\\n- The experiments are thourough and well-designed, demonstrating superiority over state-of-the-art approaches.\", \"Weaknesses\": \"- Regarding the generation of instance-aware embeddings, the paper does not fully explain or justify the creation of color-related masks. This might limit the model's applicability in complex cases, such as when dealing with intricate or lengthy textual descriptions.\\n\\n- The paper lacks discussions on limitations. \\n\\n- Some typos: Line 311, \\\"cross-flip\\\" should be \\\"cross-clip\\\".\", \"Questions\": \"- What's the generation process of color-related masks? What if the text prompts are complicated or intricate? One example:\\n  \\\"The sunset painted the sky with hues of burnt umber, casting a surreal glow over the landscape.\\\" Could the model handle these cases successfully, and to what extent will the quality and type of text prompts influence its performance?\\n\\n- Temporally Deformable Attention (TDA) generates offset estimations for reference points. Would the performance get worse or better if we replace the offset estimation with an off-the-shelf model, such as an optical flow estimation model?\\n\\nThank the authors for the detailed explanation. My concerns have been fully addressed. Regarding the failure cases, I think that fine-grained color manipulation may be better controlled by other kinds of user interactions, such as reference images or strokes, given the high-level and semantic nature of text prompts. Overall, I think this is a paper that tackles text-guided video colorization problems with meaningful contributions and good demonstrations. I will raise my score.\"}"}]}
{"paper_id": "UstOpZCESc", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nLifelong learning algorithms enable models to incrementally acquire new knowledge without forgetting previously learned information. Contrarily, the field of machine unlearning focuses on explicitly forgetting certain previous knowledge from pretrained models when requested, in order to comply with data privacy regulations on the right-to-be-forgotten. Enabling efficient lifelong learning with the capability to selectively unlearn sensitive information from models presents a critical and largely unaddressed challenge with contradicting objectives. We address this problem from the perspective of simultaneously preventing catastrophic forgetting and allowing forward knowledge transfer during task-incremental learning, while ensuring exact task unlearning and minimizing memory requirements, based on a single neural network model to be adapted. Our proposed solution, privacy-aware lifelong learning (PALL), involves optimization of task-specific sparse subnetworks with parameter sharing within a single architecture. We additionally utilize an episodic memory rehearsal mechanism to facilitate exact unlearning without performance degradations. We empirically demonstrate the scalability of PALL across various architectures in image classification, and provide a state-of-the-art solution that uniquely integrates lifelong learning and privacy-aware unlearning mechanisms for responsible AI applications.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"- The paper studies an important problem and presents a novel solution. To the best of my knowledge, this work is the first to provide an exact unlearning solution in a lifelong setting of interleaved learned and unlearned tasks.\\n\\n- The paper is for the most part well-written and easy to follow.\\n\\n- The experimental evaluation covers various relevant baselines and ablations.\\n\\n- The proposed method performs well simultaneously in terms of several metrics and desiderata compared to the baselines considered.\", \"Weaknesses\": \"- It seems that the “independent subnetworks without knowledge transfer” ablation actually performs very similarly to the proposed approach (in Table 3), making it harder to motivate the significantly-more-complex variant for the additional 1% accuracy? Especially given that no confidence intervals are reported there, it’s hard to tell if these differences are significant and whether they justify the additional complexity. Are there perhaps other sequences of tasks / datasets where the “knowledge transfer” would be more “needed”, perhaps making this not the best “benchmark” to showcase the added benefits of knowledge transfer?\\n\\n- Some clarity issues when describing the method, metrics and setup. Specifically, A) I don’t understand the difference between m_t and \\\\bar m_t. The authors say the latter are the parameters specifically trained using data from D_t, but I don’t understand this statement. What does “specifically trained” mean? B) When describing the metric A_t, it’s unclear whether the final model checkpoint (after addressing the whole sequence) is used to compute accuracy on all tasks, or is a separate checkpoint (right after training on the particular task) used to evaluate the accuracy on each task? The text made me think the former but the notation a_{i,t} and explanation below made me think the latter. C) ““Regularization-based methods [...] were indifferent to task unlearning instructions, since the original methods are not adapted to unlearning” – how were these applied to unlearning tasks, then?\\n\\n- Insufficient description (in the main paper) for how various other methods were adapted from the standard lifelong setting to the privacy-aware lifelong setting. It is difficult to fully grok how this adaptation was done and why in that particular way (rather than applying other types of approximate unlearning from the literature, for example).\\n\\n- It is unclear how one should interpret the A_u metric. Having a network perform at chance level in terms of accuracy does not imply an unlearning guarantee, as the authors also acknowledged. It is not obvious that lower A_u is better (an accuracy that is “too low” can compromise privacy and cause vulnerability to attacks). Further, even when taking the right reference point (for how low accuracy should be) into consideration, accuracy-based metrics correlate poorly with more rigorous metrics for unlearning (see e.g. [1]). The authors seem to acknowledge this but still use this metric in the results and in discussions. It would be great to clarify in what way this information should be used and taken into consideration, given this caveat.\\n\\n- Missing an important baseline: training sequentially with Differential Privacy (DP). This would yield approximate (but theoretically sufficient) unlearning without the need for resetting and retraining any weights. Various DP baselines can be considered: a DP variant of “Sequential”, where all parameters are updated for all tasks, as well as a DP variant of a sub-networks architecture, like in the proposed approach, where each task gets to choose which parameters to update, but in this case addressing unlearning requests can be done trivially (via a “no op”). Depending on the desired level of privacy, I expect such methods to have lower accuracy, but this feels like an important and relevant baseline to include and capture these trade-offs.\\n\\n- Missing baselines from the unlearning literature. A plethora of approximate unlearning methods have been proposed (see e.g. [2-4]), that try to post-hoc modify a model to remove the influence of a subset of its training data. It feels like these would be readily combinable with the “Sequential” approach, for instance. \\n\\n- Building further on the above remarks, it would be very useful to build a comparison between the proposed method (and other exact solutions) with inexact unlearning. While the authors have considered some inexact methods, there aren’t proper metrics considered to empirically estimate the privacy of such methods. The only metric considered for this is the accuracy on unlearned tasks, which is a weak notion of privacy, as discussed above. I fully understand that adding empirical privacy auditing is a substantial amount of additional work and potentially difficult to do all of this within a single paper, but I do view this as a clear piece that is missing, or area for future work. \\n\\n- Another baseline can be training a model sequentially (without subnetworks), and when unlearning is needed, simply retrain the entire model from scratch (using the data in the buffers). I don’t expect this to perform well in terms of accuracy (and would also be less efficient at handling unlearning requests), but would be a useful data point for comparison; this is more akin to the “retrain from scratch” reference point in the unlearning literature. One may additionally consider an “oracle” version of this, that assumes access to all past data as another reference point (I understand that past data is assumed not to be available in life-long learning, hence referring to this as an “oracle”).\\n\\n- A limitation of this framework is that “user privacy” can only be addressed (via exact unlearning) if a user’s data is cleanly separated in terms of “tasks”. Other scenarios, where all users participated in all “tasks”, would make this framework unable to support users to request their data to be deleted. It would be great to discuss this.\\n\\nReferences\\n\\n[1] Are we making progress in unlearning? Findings from the first NeurIPS unlearning competition. Triantafillou et al. \\n\\n[2] Eternal sunshine of the spotless net: Selective forgetting in deep networks. Golatkar et al.\\n\\n[3] Towards unbounded machine unlearning. Kurmanji et al. NeurIPS 2023.\\n\\n[4] SalUn: Empowering machine unlearning via gradient-based weight saliency in both image classification and generation. Fan et al. ICLR 2024.\", \"Questions\": \"- For the “independent subnetworks without knowledge transfer” ablation, could you explain specifically in what way(s) “Dynamic Sparse Ind.” differs from PALL? It seems both have the learned mask for which parameters to update per task. The authors claim that PALL additionally supports knowledge transfer but it’s not obvious to me what the mechanism is for that, given that each new task only modifies (a chosen subset of) previously-unused weights? I previously assumed that the way that knowledge transfer is realized is that the other weights, even if not directly optimized by the specific task, are still used in the forward pass and therefore still influence the model applied to this task too. Is this correct? And how is this done differently in the “Dynamic Sparse Ind.” variation? Or is there some other difference between the two?\\n\\n- What is the worst-case sequence of interleaved learning and unlearning requests, w.r.t each metric considered here? Are there cases where the proposed method is no better than naive baselines? It would be great to discuss this in the paper.\"}"}]}
{"paper_id": "LnRegTxsa4", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nCross-view object geo-localization has recently gained attention due to potential applications. Existing methods aim to capture spatial dependencies of query objects between different views through attention mechanisms to obtain spatial relationship feature maps, which are then used to predict object locations. Although promising, these approaches fail to effectively transfer information between views and do not further refine the spatial relationship feature maps. This results in the model erroneously focusing on irrelevant edge noise, thereby affecting localization performance. To address these limitations, we introduce a **Cross-view and Cross-attention Module (CVCAM)**, which performs multiple iterations of interaction between the two views, enabling continuous exchange and learning of contextual information about the query object from both perspectives. This facilitates a deeper understanding of cross-view relationships while suppressing the edge noise unrelated to the query object. Furthermore, we integrate a **Multi-head Spatial Attention Module (MHSAM)**, which employs convolutional kernels of various sizes to extract multi-scale spatial features from the feature maps containing implicit correspondences, further enhancing the feature representation of the query object. Additionally, given the scarcity of datasets for cross-view object geo-localization, we created a new dataset called **G2D** for the \"Ground→Drone\" localization task, enriching existing datasets and filling the gap in \"Ground→Drone\" localization task. Extensive experiments on the CVOGL and G2D datasets demonstrate that our proposed method achieves high localization accuracy, surpassing the current state-of-the-art.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"The paper is generally well-written and organized. The experimental results seems strong.\", \"Weaknesses\": \"- The core components (CVCAM and MHSAM) are largely based on existing techniques like Transformer's cross-attention and basic convolution operations. It is better to Clearer explanation of technical innovations beyond existing methods with theoretical analysis of why the proposed approach works better. \\n\\n- How to justify the motivation of using multiple iterations of cross attention? How sensitive is the performance to the architecture choices? \\n\\n- Analyze what types of cases show improvement vs. where the method fails. \\n\\n- While one contribution of this paper is G2D dataset, however the descriptions of the dataset is too few. Such as, dataset collection and annotation process, comparison with existing datasets and potential biases or limitations etc.\", \"Questions\": \"Please refer to weaknesses part for more details on the questions.\"}"}]}
{"paper_id": "2ErS9Bkc3O", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nIn this paper, we study the adversarial robustness of deep neural networks for classification tasks. The adversarial robustness of a classification algorithm is defined as the smallest magnitude of possible additive perturbations that can change the output of the classification algorithm.  We provide a matrix-theoretic explanation of the adversarial fragility of deep neural network. In particular, our theoretical results show that neural network's adversarial robustness can degrade as the input dimension $d$ increases.  Analytically we show that neural networks' adversarial robustness can be only $1/\\sqrt{d}$ of the best possible adversarial robustness.  Our matrix-theoretic explanation is consistent with an earlier information-theoretic feature-compression-based explanation for the adversarial robustness of neural networks.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"A better understanding of adversarial attacks and robustness of neural networks remains an important topic.\", \"Weaknesses\": \"To the best of my knowledge, the paper's conclusion that adversarial robustness can only be $1/\\\\sqrt d$ is already known [1, 2] and has been shown in more general settings.\\n\\n- The theoretical analysis is weak, as all the theorems make important and unrealistic assumptions, i.e. normal distribution of the data, constraints on the weight matrices.\\n- $\\\\ell_2$ is the only distance considered, several other papers have proposed theoretical analysis with respect to the $\\\\ell_p$ norm (see [1, 2]).\\n- Theorem 1 spans 2 full pages to show a probabilistic bound over a linear network with several assumptions, but it's unclear why the authors came to all this work, since the distance to the decision boundary for a linear network can be computed in closed form. \\n- The paper proposes a total of 7 theorems, each of which is accompanied by a proof. \\n- The paper does not propose any related work\\n- The paper does not provide usable results \\n- The experimental section only proposes toy experiments \\n\\nSuggestions for improving the paper:\\n- Instead of presenting a list of theorems, the authors should motivate their analysis and explain why it's interesting. How can these results help the community? Even if the theoretical analysis has assumptions, how can it be useful for real-world applications?\\n- Authors should propose a related work section and compare their analysis with other work. How is their analysis better or novel than the competing work?\\n- Authors should propose real-world experiments, adversarial robustness is now a mature research topic, and large-scale (e.g. ImageNet) experiments should be performed.  \\n\\n[1] Yang et al. Randomised smoothing of all shapes and sizes. ICML 2020  \\n[2] Kumar et al. Curse of Dimensionality on Randomised Smoothing for Certifiable Robustness. ICML 2020\", \"Questions\": \"See suggestions for improving the paper.\"}"}]}
{"paper_id": "pK3oe2bubc", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nDue to their architecture and how they are trained, artificial neural networks are typically not robust toward pruning,  replacing, or shuffling layers at test time. However, such properties would be desirable for different applications, such as distributed neural network architectures where the order of execution cannot be guaranteed or parts of the network can fail during inference. In this work, we address these issues through a number of training approaches for vision transformers whose most important component is randomizing the execution order of attention modules at training time. With our proposed approaches, vision transformers are capable to adapt to arbitrary layer execution orders at test time assuming one tolerates a reduction (about 20\\%) in accuracy at the same model size. We analyse the feature representations of our trained models as well as how each layer contributes to the models prediction based on its position during inference. Our analysis shows that layers learn to contribute differently based on their position in the network. Importantly,  trained models can also be randomly merged with each other resulting in functional (\"Frankenstein\") models without loss of performance compared to the source models. Finally, we layer-prune our models at test time and find that their performance declines gracefully.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 1, \"Confidence\": 5, \"Strengths\": \"1. The paper method is well written.\\n2. The concept is interesting.\", \"Weaknesses\": \"1. The concept is interesting; however, the argument that the computing machine can fail at a time does not convince me to develop this method. The paper has weak motivation.\\n2. The paper evaluation is not sufficient.\\n3. There are several Transformer architectures which have not been evaluated. Currently, the evaluation is only done on ViT/DeiT, which is not convincing to me. \\n4. Hyperparameter study is not done.\\n5. Accuracy loss is significant (20%). This accuracy gap is very substantial.\\n6. I have particular concerns about Figure 1c. It is unfair to compare layer-drop or reduced depth with layer shuffle configuration at deployment because the two baselines are not trained with layer shuffling order. This figure is entirely misleading and should be dropped.\\n7. The only change made in the transformer block is the layer index, which is not a significant contribution.\\n8. Please include several recent transformer-based baselines such as Swin, EfficientVit, etc.\", \"Questions\": \"See weakness.\"}"}]}
{"paper_id": "sec09tLQUl", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nDeep learning models frequently exploit spurious features in training data to achieve low training error, often resulting in poor generalization when faced with shifted testing distributions. To address this issue, various methods from imbalanced learning, representation learning, and classifier recalibration have been proposed to enhance the robustness of deep neural networks against spurious correlations. In this paper, we observe that models trained with empirical risk minimization tend to generalize well for examples from the majority groups while memorizing instances from minority groups.\nBuilding on recent findings that show memorization can be localized to a limited number of neurons, we apply example-tied dropout as a method we term \\textit{FairDropout}, aimed at redirecting this memorization to specific neurons that we subsequently drop out during inference. We empirically evaluate FairDropout using the subpopulation benchmark suite encompassing vision, language, and healthcare tasks, demonstrating that it significantly reduces reliance on spurious correlations.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 1, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 5, \"Strengths\": \"The paper focuses on mitigating models' reliance on spurious correlations in a practical setting where no group annotations are available in the training and validation sets. Thus, the proposed method can be very useful in a wide range of settings where group annotations are hard to acquire.\", \"Weaknesses\": \"- The technical contribution of this paper is limited. The proposed method is a direct follow-up of the method in [1].\\n\\n- The paper is poorly written. Fixing typos (e.g., Line 189: Fig. 2 -> Fig. 1, and Line 145:$p_{tr}$), grammar errors (e.g., Line 161: there no -> there is no), and format issues (e.g., different font sizes in Fig. 1) would be a good starting point. More importantly, the method is not clearly described in the paper. Specifically, how to determine what neurons represent generalizing or memorizing features is unclear. \\n\\n- The proposed method needs to determine memorization neurons for each training example, which may be prohibitive when the dataset is large and there are many neurons in a model's internal layer. It would be helpful to provide the training time or an analysis on the computational complexity.\\n\\n- The experiments lack a comparison with some recent methods, e.g., [2] and [3]. Moreover, the reported performance of existing methods is not standard, making it difficult to assess the effectiveness of the proposed method, in comparison with other methods such as [2] or [3]. The effectiveness of the proposed method may be strengthened if the method is evaluated in the setting of [2] or [3].\\n\\n[1] Maini et al., Can neural network memorization be localized? ICML, 2023.\\\\\\n[2] LaBonte et al., Towards last-layer retraining for group robustness with fewer annotations, NIPS, 2023.\\\\\\n[3] Li et al., Bias Amplification Enhances Minority Group Performance, TMLR, 2024.\", \"Questions\": \"Without group annotations, how is it possible to determine whether a neuron represents a memorizing feature or a generalizing feature?\"}"}]}
{"paper_id": "96jZFqM5E0", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe present a framework for pre-training of 3D hand pose estimation from in-the-wild hand images sharing with similar hand characteristics, dubbed SiMHand. Pre-training with large-scale images achieves promising results in various tasks, but prior methods for 3D hand pose pre-training have not fully utilized the potential of diverse hand images accessible from in-the-wild videos. To facilitate scalable pre-training, we first prepare an extensive pool of hand images from in-the-wild videos and design our pre-training method with contrastive learning. Specifically, we collect over 2.0M hand images from recent human-centric videos, such as 100DOH and Ego4D. To extract discriminative information from these images, we focus on the similarity of hands: pairs of non-identical samples with similar hand poses. We then propose a novel contrastive learning method that embeds similar hand pairs closer in the feature space. Our method not only learns from similar samples but also adaptively weights the contrastive learning loss based on inter-sample distance, leading to additional performance gains. Our experiments demonstrate that our method outperforms conventional contrastive learning approaches that produce positive pairs sorely from a single image with data augmentation. We achieve significant improvements over the state-of-the-art method (PeCLR) in various datasets, with gains of 15% on FreiHand, 10% on DexYCB, and 4% on AssemblyHands. Our code is available at https://github.com/ut-vision/SiMHand.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"- The paper is well written and easy to follow.\\n- The motivation of finding similar hands derived from different video domains is technically sound, which can further benefit contrastive learning process from discriminating foreground hands in varying backgrounds.\\n- The experimental results in Table 3 demonstrate the generality of the proposed contrastive learning with adaptive weighting mechanism.\", \"Weaknesses\": \"- TempCLR [1] proposes a pre-train framework for 3D hand reconstruction with time-coherent contrastive learning, and shows better performance compared with PeCLR. Although TempCLR focuses on reconstruction tasks, the used parametric model can output 3D pose results. Therefore, more comparisons with TempCLR would be helpful.\\n\\n- In the second column of Figure 6, HandCLR demonstrates advanced performance in hand-object occlusion. Does the proposed method exhibit robustness in similar severe occlusion scenarios involving hand-object interactions? More qualitative analysis in datasets like DexYCB or in-the-wild scenarios would be helpful.\\n\\n- The proposed adaptive weighting mechanism is a straightforward approach that has proven effective; however, it lacks a clear articulation of its motivation, particularly regarding the challenges faced in 3D hand pose estimation tasks as mentioned in the introduction.\\n\\n[1] Tempclr: Reconstructing hands via time-coherent contrastive learning. In  3DV, 2022.\", \"Questions\": \"N/A\"}"}]}
{"paper_id": "uNd289HjLi", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nMagnetic resonance imaging (MRI) is a powerful noninvasive diagnostic imaging tool that provides unparalleled soft tissue contrast and anatomical detail. Noise contamination, especially in accelerated and/or low-field acquisitions, can significantly degrade image quality and diagnostic accuracy. Supervised learning based denoising approaches have achieved impressive performance but require high signal-to-noise ratio (SNR) labels, which are often unavailable. Self-supervised learning holds promise to address the label scarcity issue, but existing self-supervised denoising methods tend to oversmooth fine spatial features and often yield inferior performance than supervised methods. We introduce Corruption2Self (C2S), a novel score-based self-supervised framework for MRI denoising. At the core of C2S is a generalized ambient denoising score matching (GADSM) loss, which extends denoising score matching to the ambient noise setting by modeling the conditional expectation of higher-SNR images given further corrupted observations. This allows the model to effectively learn denoising across multiple noise levels directly from noisy data. Additionally, we incorporate a reparameterization of noise levels to stabilize training and enhance convergence, and introduce a detail refinement extension to balance noise reduction with the preservation of fine spatial features. Moreover, C2S can be extended to multi-contrast denoising by leveraging complementary information across different MRI contrasts. We demonstrate that our method achieves state-of-the-art performance among self-supervised methods and competitive results compared to supervised counterparts across varying noise conditions and MRI contrasts on the M4Raw and fastMRI dataset.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 4, \"Strengths\": \"1. The paper comprehensively analyzes and applies existing self-supervised and supervised denoising approaches in the context of MRI\\n\\n2. The paper is well written, original and provides great detail into the workflow of the Corruption2Self (C2F) framework.\\n\\n3. Incorporation to reparametrization (Table 4) and extensions to multi-contrast settings to improve denoising.\\n\\n4. Showcases robustness of methodology on varied noise level estimations compared to true noise (Table 9)\", \"Weaknesses\": \"### A. Detail refinement extension claim\\nAccording to the metrics in Table 1, it is unclear if the detail refinement extension is being effective. The improvements in PSNR / SSIM does not seem notable. It would be helpful to include an error bar (for the table), statistical significance test (to show notability) and visuals to show effectiveness.\\n\\n### B. Applicability and impact\\nThe paper can cover how their workflow can be used in practice while denoising. The following aspects can add more value-add in terms of real-world impact to the paper.\\n1. Estimation of $σ_{tdata}$ in real-time during inference.\\n2. Given that traditional methods such as BM3D work decently well (maybe 1-3 points less performant than C2S), how difficult is it to go about training / deploying C2S in the MRI denoising workflow than using non-learning based methods?\\n3. Would this methodology potentially result in MRI image acquisition?\", \"Questions\": \"1. Robustness of C2S (M4Raw):\\nIn the context of matching test-train SNR on M4Raw dataset, the authors claim that \\n    1. (Line 327-328) supervised methods such as SwinIR and Restormer perform better when the noise characteristics of train and test data are similar\\n    2. (Line 328-330) C2S achieves better generalization.\\nAccording to \\n    1. Table 3 (Results where test data SNR > train data SNR): C2S perform similar to SwinIR for eg.\\n    2. Table 7 (Results where test data SNR ~ train data SNR): C2S perform similar to SwinIR (although both have higher metrics here).\\n\\n    It seems that both methods perform similar to each other in both the conditions?\\n    Are the metrics higher in latter because the labels in Table 7 are noisier than in Table 3? I'm not sure if we can conclude that C2S is more generalized and supervised is not from the above data?\\n\\n2. I'd be interested to know the intuition behind why reparametrization works. Mathematically, it seems very similar except that we sample ${\\\\tau}$ ~ $U(0, T]$ rather than ${\\\\tau}$ ~ $U(0, T']$ due to $T >> T'$ . Does this approximation help in convergence?\\n\\n3. Does reparametrization and detail refinement extension help in the case of FastMRI dataset also? Curious as effectiveness for only M4Raw dataset have been reported.\\n\\n4. How would one estimate `T` (max corruption level) before training the model?\\n\\n5. Given that complementary pair of contrasts improve denoising, curious to know if all the 3 contrasts can be used (eg. T1, T2 and FLAIR) for instance to further improve denoising?\"}"}]}
{"paper_id": "e2ONKX6qzJ", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nClassifier-free guidance (CFG) is crucial for improving both generation quality and alignment between the input condition and final output in diffusion models. While a high guidance scale is generally required to enhance these aspects, it also causes oversaturation and unrealistic artifacts. In this paper, we revisit the CFG update rule and introduce modifications to address this issue. We first decompose the update term in CFG into parallel and orthogonal components with respect to the conditional model prediction and observe that the parallel component primarily causes oversaturation, while the orthogonal component enhances image quality. Accordingly, we propose down-weighting the parallel component to achieve high-quality generations without oversaturation. Additionally, we draw a connection between CFG and gradient ascent and introduce a new rescaling and momentum method for the CFG update rule based on this insight. Our approach, termed adaptive projected guidance (APG), retains the quality-boosting advantages of CFG while enabling the use of higher guidance scales without oversaturation. APG is easy to implement and introduces practically no additional computational overhead to the sampling process. Through extensive experiments, we demonstrate that APG is compatible with various conditional diffusion models and samplers, leading to improved FID, recall, and saturation scores while maintaining precision comparable to CFG, making our method a superior plug-and-play alternative to standard classifier-free guidance.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. APG is presented as a plug-and-play method with virtually no additional computational overhead, making it attractive for practical use in various diffusion models.\\n2. The method of down-weighting the parallel component in CFG is novel and interesting, effectively reducing oversaturation and preserving image quality at high guidance scales.\", \"Weaknesses\": \"1. In Figure 8, could the authors explain why the proposed APG shows lower precision and higher FID compared to CFG when the guidance scale  w  is below certain values (e.g.,  w = 2.5 , where APG precision is lower than CFG)?\\n2. While reverse momentum is introduced, the intuition behind why it improves the image generation quality could be expanded. More detailed theoretical or experimental exploration of this component would clarify its importance.\", \"Questions\": \"See the questions in the weakness section.\"}"}]}
{"paper_id": "a2eBgp4sjH", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe study nearest neighbor search with filter constraints (MultiFilterANN): given a query vector with a discrete set of labels $S$, retrieve the (approximately) closest vector from a dataset under the constraint that $S$ must be a subset of the labels of the retrieved vector. There has been a burgeoning interest in this problem on the practical side, due to its strong motivation from search and recommendation applications where vector labels correspond to real world attributes such as date, price, or color. On the theoretical side, this problem generalizes the subset query problem, which asks us to only determine if $S$ is a subset of some set in the dataset, without retrieving the closest vector.\n\nIn this work, we present a systematic study of MultiFilterANN,. Theoretically, we demonstrate the power of graph-based algorithms in two ways: \n\n-  We design provable algorithms with the best known space-time tradeoffs for \\mfann in the large filter regime by carefully incorporating ANN algorithms into known subset query algorithms.% to incorporate nearest neighbor search using graph-based algorithms.\n- We demonstrate lower bounds for popular algorithms for MultiFilterANN, showing that they can catastrophically fail even on simple data/label sets.\n\nOur theoretical results inspire our empirical approach, where we extend practical graph indices for standard nearest neighbor search to MultiFilterANN by augmenting the (greedy) search procedure with a penalized distance function that captures filter constraints. Our empirical algorithm is competitive with existing state of the art solutions which are tailored for one or two filters, while also seamlessly generalizing to any number of filters without any modifications. Lastly we release multiple novel datasets for MultiFilterANN, filling in a noticeable gap in literature.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"The idea of replacing the symmetric label distance with the asymmetric label distance on the greedy search of NHQ algorithm (Wang et al., 2024) is intuitive, and it self-evidently improves performance when the label constraint are subset queries ($S_q \\\\subset S_v$) instead of exact matches ($S_q = S_v$). \\n\\nWang, Mengzhao, et al. \\\"An efficient and robust framework for approximate nearest neighbor search with attribute constraint.\\\" Advances in Neural Information Processing Systems 36 (2024).\", \"Weaknesses\": \"The authors propose (in Section 6) a graph-based algorithm for MultiFilterANN problem (I explain my interpretation of the proposed method in Summary). However, it seems to this reviewer that the proposed algorithm is supported neither by (a) theoretical results, nor by (b) empirical evaluation. The theoretical results are for the different algorithm (described in Section 4) and it may be that the algorithm that is evaluated empirically in Section 7 is a yet different algorithm (described in Appendix E).\\n\\nSpecifically, the article starts by reviewing a CIP data structure (Charikar et al., 2002) for subset query problem and then proposing a MultiFilterANN algorithm that combines it with either a graph or LSH index structure. However, later in Section 6 it turns out that the authors propose a completely different graph-based empirical algorithm that does not use a CIP data structure at all. Thus it seems that theoretical analysis of Section 4 is disconnected from the rest of the article (except that MultiFilterANN problem is considered), and does not offer theoretical support for the proposed method. The authors should clarify what is the connection between the empirical algorithm and the theoretical discussion of Section 4.\\n\\nAnother part that must be clarified significantly is the empirical evaluation in Section 7. In particular, it is unclear whether the results are obtained by using the graph-based method proposed in Section 6 or the hybrid methodology described in Appendix E? According Appendix E, when the estimated number database points satisfying the constraints is small, either a brute force search after identification of these points, or a clustering-based approach is used instead of the graph-based method proposed in Section 6. If the hybrid methodology of Appendix E is used to generate the results of Section 7, this does not yet tell anything about the performance of the proposed graph method, since it is possible that the results are obtained using brute force search or a clustering-based approach.\\n\\nYou should include a direct comparison between the proposed graph method and the earlier filtered ANN methods (ParlayIVF$^2$ and ACORN) (assuming the results of Section 7 are for the hybrid method described in Appendix E). In particular, when the number of database points satisfying the constraints is small, I suspect that the brute force baseline is the fastest method, and if you enable this option for your method, but not for ParlayIVF$^2$ and ACORN, this distorts the results. In addition, you should include ablation experiments documenting in which regime your method outperforms this simple baseline (that has an additional benefit of producing exact results).\\n\\nIt is also not clear how relevant the studied problem (MultiFilterANN) is. I am not deeply familiar with literature on filtered ANN search, but it seems that the recent related works cited by the authors only consider the special cases of one or two filters. In particular, I suspect that when there are multiple filters (for instance, $|S_q| \\\\geq 3$), the simplest possible ad hoc approach (brute force search after finding the database points with correct labels) would often outperform more complicated filtered ANN methods, since in this case the set of database points matching all of query labels is probably quite small.\\n\\nPresentation is low quality. The article does not seem carefully finished. For instance, citations should be inside the parenthesis when the author names are not used as a part of the text. For instance, you should write \\\"we may use Locality Sensitive Hashing (Indyk & Motwani 1998a)\\\" instead of \\\"we may use Locality Sensitive Hashing Indyk & Motwani 1998a\\\". Just use citep-command if you are using natbib. As an another example, there is a list of 26 (!) consecutive citations in the beginning of Related work-section. It seems that the only relevance of these works is that they are connected to ANN search. You should be much more specific in Related work-section and do not use this kind of generic lists. \\n\\nCharikar, M., Indyk, P., & Panigrahy, R. (2002, June). New algorithms for subset query, partial match, orthogonal range searching, and related problems. In International Colloquium on Automata, Languages, and Programming (pp. 451-462). Berlin, Heidelberg: Springer Berlin Heidelberg.\", \"Questions\": \"Can clarify how the theoretical results of Section 4 are connected to the empirical algorithm you propose in Section 6? It seems to this reviewer that the algorithm considered in Section 4 (2-stage search where you first prune a candidate set on the label space $[m]$ with a CIP data structure, and then perform a nn-search on the continuous feature space $\\\\mathbb{R}^d$ with either LSH or a graph) is completely different than the one you propose in Section 6 (FilteredDiskANN graph from earlier work (Gollabudi et al., 2023) combined with greedy search penalized by asymmetric label distance)?\\n\\nAre the results of Section 7 for the graph-based approach of Section 6 or for the hybrid approach of Appendix E that also can use either brute force search or clustering?\\n\\nGollapudi, Siddharth, et al. \\\"Filtered-diskann: Graph algorithms for approximate nearest neighbor search with filters.\\\" Proceedings of the ACM Web Conference, p. 3406-3416. 2023.\"}"}]}
{"paper_id": "EIXZXPz7jU", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSingularities in the source functions of partial differential equations (PDEs) can pose significant challenges for physics-informed neural networks (PINNs), often leading to numerical instability and necessitating a large number of sampling points thereby increasing the computational time. In this paper, we introduce a novel sampling point selection method to address these challenges. Our approach is based on diffusion models capable of generative sampling from the distribution of PDE residuals. Specifically, we apply the optimal transport coupling flow-matching technique to generate more sampling points in regions where the PDE residuals are higher, enhancing the accuracy and efficiency of the solution. In contrast to existing approaches in the literature, our method avoids explicit modeling of the probability density proportional to residuals, instead using the benefits of flow matching to generate novel and probable samples from more complex distributions, thereby enhancing PINN solutions for problems with singularities.\nWe demonstrate that this method, in certain scenarios, outperforms existing techniques such as normalizing flow-based sampling PINN. Especially, our approach demonstrates effectiveness in improving the solution quality for the linear elasticity equation in the case of material with complex geometry of inclusion. A detailed comparison of the flow matching sampling method with other approaches is also provided.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 2, \"Strengths\": \"Resampling for PINNs makes sense and can help identify regions where the solver needs extra \\\"help\\\" to find the right solution.\", \"Weaknesses\": \"Overall, the method seems to be a fairly heuristic extension of existing works.  Although I see the authors are applying ideas from the flow matching work, they do not articulate important details of their algorithm, e.g. the distribution from which flow matching is attempting to draw samples.  The tests here show preliminary evidence that the method has some value but are far from conclusive (just 3 PDE examples total as far as I can tell).\", \"Questions\": \"I have also included comments in this section.\\n\\n***\\n\\nCareful with LaTeX formatting bugs --- e.g., in first paragraph of the introduction there is a stray period (line 38), backward quotation marks (line 42), and \\\\citet{} style citations that should be \\\\citep{}.  There are also some mild grammar issues (e.g., missing “the” before “PINN loss function” on line 43).  These didn’t impede understanding, but I would suggest a thorough edit before the final version of this paper is published.\\n\\nIn the unnumbered equation above (2), should the norms be squared?  And do you need a parameter trading off between the interior and boundary terms?\\n\\nShould the sums in (2)-(3) be integrals?  Are the samples x_i re-drawn in every iteration or kept fixed during the training procedure?\\n\\nThe last three paragraphs of section 3.1 seem like they’re missing a connection to what came before them.  In particular, these paragraphs describe generic methods for variational inference and sampling, but it’s not entirely clear how these methods are applied to PINNs specifically.\\n\\nLine 166:  “pf”\\n\\nLine 171, “the generative algorithm” --- one of many\\n\\nShould the loss in (6) be squared?\\n\\nIt seems a lot of section 3.1 is repeating what’s in the flow matching paper.  Is all of this discussion needed to describe the proposed new algorithm in the paper?\\n\\nExposition-wise, I would suggest reallocating the “real estate” in the paper’s discussion substantially.  In particular, the first 4 pages of the paper are background, then there is exactly 1 page describing the method, and then the remainder of the paper describes results.  It seems valuable to extend the discussion of the proposed method, making sure the algorithm is described in full detail and that appropriate properties of the sampling method (e.g., making sure it recovers solutions to the PDE as the neural network gets more neurons) are stated carefully.  The exposition of the algorithm in section 3.4.1 is quite terse --- for example, precisely what distribution is the flow matching method sampling from?\\n\\nEq (10) is deterministic other than the initial condition X_0 --- there is no Brownian motion term, for example.  Why use stochastic PDE notation?\\n\\nAlgorithm 2 seems to be standard “forward Euler” solution of an ODE and can probably be omitted.\\n\\nAlgorithm 1 has many vague steps.  For example, what algorithm is used for weighted bootstrap resampling?  How is the vector field “trained” and for how many steps?  Do you prune the set of points S_k in each step or does it get larger and larger in each iteration?\\n\\nFigure 1 did not help me understand the algorithm and seems quite abstract.\\n\\nIs it possible to replace the peaks in example (13) with true delta functions, or does the right-hand side of the Poisson equation in the proposed method need to be differentiable?\"}"}]}
{"paper_id": "QO4bF6MHza", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nRecent large language models (LLMs) have demonstrated versatile capabilities in long-context scenarios. Although some recent benchmarks have been developed to evaluate the long-context capabilities of LLMs, there is a lack of benchmarks evaluating the mathematical reasoning abilities of LLMs over long contexts, which is crucial for LLMs' application in real-world scenarios. In this paper, we introduce MathHay, an automated benchmark designed to assess the long-context mathematical reasoning capabilities of LLMs. Unlike previous benchmarks like Needle in a Haystack, which focus primarily on information retrieval within long texts, MathHay demands models with both information-seeking and complex mathematical reasoning abilities. We conduct extensive experiments on MathHay to assess the long-context mathematical reasoning abilities of eight top-performing LLMs. Even the best-performing model, Gemini-1.5-Pro-002, still struggles with mathematical reasoning over long contexts, achieving only 51.26\\% accuracy at 128K tokens. This highlights the significant room for improvement on the MathHay benchmark.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 2, \"Strengths\": \"- relatively written paper, easy to follow\\n- an automated and scalable way to construct a Denmark \\n- I like the way of using time-sensitive Q&As to mitigate the contamination problem\\n- the investigation is the impact of time period is interesting, which might motivate further research about the data contamination problem in LLMs.\", \"Weaknesses\": \"- More quantitative and qualitative evaluation may be needed on the quality of the automated generated corpus.\", \"Questions\": \"- I’m curious if the topics and tasks affect the mathematical reasoning performance of LLMs?\\n- In the classic Needle-in-a-Haystack paper (Kuratov et al., 2023), a pattern emerged where models struggled with retrieval when the ‘needle’ appeared near the beginning but not in the first sentence. However, I haven’t observed any similar pattern in mathematical reasoning—only a general decline in performance as the context window expands, regardless of the needle’s position. This is expected and not particularly insightful. Do you have any educated guesses as to why?”\"}"}]}
{"paper_id": "GULx8rzzjC", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nMachine learning (ML) models often require large amounts of data to perform well. \n   When the available data is limited, model trainers may need to acquire more data from external sources.\n   Often, useful data is held by private entities who are hesitant to share their data due to propriety and privacy concerns. \n   This makes it challenging and expensive for model trainers to acquire the data they need to improve model performance.\n   To address this challenge, we propose $\\texttt{Mycroft}$, a \n   data-efficient method that enables model trainers to evaluate the relative \n   utility of different data sources while working with a constrained data-sharing \n   budget. By leveraging feature space distances and gradient matching, $\\texttt{Mycroft}$ \n   identifies small but informative data subsets from each owner, allowing model \n   trainers to maximize performance with minimal data exposure. Experimental \n   results across four tasks in two domains show that $\\texttt{Mycroft}$ converges rapidly \n   to the performance of the full-information baseline, where all data is shared.\n   Moreover, $\\texttt{Mycroft}$ is robust to noise and can effectively rank data owners by \n   utility.  $\\texttt{Mycroft}$ can pave the way for democratized training of high performance ML models.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"- The problem of collaboration between model trainers and data owners is relevant in many contexts.\\n- The problem formulation, Equation (1), seems novel.\\n- The proposed approach, Mycroft, seems to solve the subset selection problem well (Section 4).\\n- Additionally, Mycroft seems to have additional regularization properties (Section 5).\\n- An observation that an earlier checkpoint is better for gradient matching (Section 4.3) is interesting.\", \"Weaknesses\": \"- RetrieveTopK function in Algorithm 3 is confusing. The textual explanation suggests that this function is a sorting \\\"greedy heuristic.\\\" However, it is hard to understand how this function is \\\"ensuring coverage of $D^{hard}$.\\\"\\n- Algorithms 4 and 5 are hard to understand without textual description.\\n- The inequality below Equation (5) in the proof of Theorem 3.1 does not match the definition of $e_\\\\lambda$ (Equation (1)). From what I see, the proof suggests that the first gradient-matching term in Equation (1) is squared.\\n- I do not clearly understand how sparsity implies the inequality below Equation (5).\\n- The definition of $f_{\\\\lambda}$ in the proof of Theorem 3.1 does not match the definition of $f_{\\\\lambda}$ in Section 3.\\n- The description of OMP by Elenberg et al. (2016, Algorithm 3) does not result in Algorithm 2 because Algorithm 2 does not account for the gradient of the feature-regularization term, $\\\\lVert \\\\Psi w \\\\rVert^2$.\\n- Section 4 does not specify the size of $D^{hard}$, which makes the interpretation of the results hard.\\n- Sections 4 and 5 evaluate the final model only on the subset of $D^{hard}$. While I see how this metric reflects data relevance, it is also important to know how the additional data affects the performance on the whole dataset $D^{val}$ or $D^{test}$, especially for experiments in Section 5.\\n- Similarly, it is unclear in which experiments the final evaluation happens on the held-out portion of $D^{hard}$ and in which experiments the evaluation happens on the whole $D^{hard}$. Thus, it is impossible to know whether the method overfits to $D^{hard}$.\\n- The paper does not conduct experiments in settings where data privacy is protected (e.g., with any technique from Appendix G). Since privacy is a key concern in data sharing, judging the method's efficacy without such experiments is hard.\", \"Questions\": \"- How does the RetrieveTopK function in Algorithm 3 work?\\n- Can the authors explain how they derive the inequality below Equation (5) in the proof of Theorem 3.1 in more detail?\\n- Why does Algorithm 2 in the paper differ from Algorithm 3 of Elenberg et al. (2016)?\\n- Is there some rationale behind the selection of the datasets for Section 4? Is there some relevant work that uses these datasets?\\n- What is the size of $D^{hard}$ in experiments?\\n- In which experiments does the evaluation occur on the held-out portion of $D^{hard}$?\\n- How might privacy protection quantitatively affect Mycroft's efficacy? Can the authors conduct some experiments with privacy protection techniques?\"}"}]}
{"paper_id": "PnZ2lbQaao", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nIn cross-domain recommendation systems, addressing cold-start items remains a significant challenge. Previous methods typically focus on maximizing performance using cross-domain knowledge, often treating the knowledge transfer process as a black box. However, the recent development of domain indexing introduces a new approach to better address such challenges. We have developed an adversarial Bayesian framework, Domain Indexing Collaborative Filtering (DICF), that infers domain indices during cross-domain recommendation. This framework not only significantly improves the recommendation performance but also provides interpretability for cross-domain knowledge transfer. This is verified by our empirical results on both synthetic and real-world datasets.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 5, \"Confidence\": 3, \"Strengths\": \"1. The method DICF combines Bayesian modeling and adversarial learning, allowing fine-grained feature separation. This ensures that only domain-invariant features contribute to the recommendation, reducing noise and improving prediction accuracy.\\n2. The probabilistic graphical model and ELBO-based training enhance DICF's ability to capture complex dependencies among features and improve model generalization across different domains.\", \"Weaknesses\": \"1. The introduction is too simple and not clear. Giving a toy example would be better to illustrate the problem of this paper. \\n2. This paper does not point out the challenges of problem or motivation of its method.\\n3. Other weaknesses can be found in Questions section.\", \"Questions\": \"1. I think there is a mistake in Figure 2. It should be $p(\\\\beta|\\\\gamma)$ instead of $p(\\\\gamma|\\\\beta)$, right? The input should be $\\\\gamma$ if my understanding is right.\\n\\n2. Results from two synthetic datasets are not convincing because they are generated from the assumption your model has. When synthetic data is generated with assumptions aligned to the model, it can indeed inflate performance results.\"}"}]}
{"paper_id": "AT64R0ivUO", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nLarge language models (LLMs) have demonstrated remarkable performance across various real-world tasks. However, they often struggle to fully comprehend and effectively utilize their input contexts, resulting in responses that are hallucinated. This difficulty increases for contexts that are long or contain distracting information, which can divert LLMs from fully capturing essential evidence. To address this issue, many works use prompting to help LLMs comprehend contextual information more reliably. For instance, iterative prompting highlights key information in two steps that first ask the LLM to identify important pieces of context and then derive answers accordingly. However, textual prompting methods are constrained to highlighting key information implicitly in token space, which is often insufficient to fully steer the model's attention. To improve model reading comprehension, we propose SteerPrompt, a method that automatically identifies key contextual information and explicitly highlights it by steering an LLM's attention scores. Like prompting, SteerPrompt is applied at inference time and does not require changing any model parameters. Our experiments on open-book QA demonstrate that SteerPrompt effectively enables models to grasp essential contextual information, leading to substantially improved problem-solving performance, e.g., an average improvement of 7.95% for LLAMA3-70B-Instruct. Code will be publicly available.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"- The integration of iterative prompting and attention steering is a creative solution to improve LLMs' comprehension without additional training, which is both resourceful and practical.\\n- The paper provides a thorough analysis of the effects of SteerPrompt's components and its sensitivity to different parameters, which adds depth to the understanding of the method.\", \"Weaknesses\": \"- The evaluation is focused on open-book question answering tasks, and it's unclear how well SteerPrompt would perform in other NLP tasks or scenarios.\\n- The performance of SteerPrompt is upper-bounded by the accuracy of key sentence identification, which may not always be perfect, especially with more complex or ambiguous contexts.\\n- The paper does not extensively discuss potential biases introduced by the model, especially since the method relies on the model's own predictions to identify key sentences.\", \"Questions\": \"- Could the authors provide differences in the performance of SteerPrompt on different types of questions, such as single-step vs. multi-step QA, and factual vs. inferential questions?\\n- Have the authors considered visualizing the decision-making process of SteerPrompt to enhance the model's interpretability?\\n- How does SteerPrompt perform with adversarial examples that are deliberately constructed to confuse the model?\\n- Do different LLMs require adjustments to SteerPrompt's strategies or parameters to achieve the best performance?\\n- Is the performance of SteerPrompt stable over long periods of inference? Are there any issues with performance degradation?\\n- How does the model ensure privacy and data security when dealing with sensitive data?\"}"}]}
{"paper_id": "nGiGXLnKhl", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nTransformers have revolutionized computer vision and natural language processing, but their high computational complexity limits their application in high-resolution image processing and long-context analysis. This paper introduces Vision-RWKV (VRWKV), a model that builds upon the RWKV architecture from the NLP field with key modifications tailored specifically for vision tasks. Similar to the Vision Transformer (ViT), our model demonstrates robust global processing capabilities, efficiently handles sparse inputs like masked images, and can scale up to accommodate both large-scale parameters and extensive datasets. Its distinctive advantage is its reduced spatial aggregation complexity, enabling seamless processing of high-resolution images without the need for window operations. Our evaluations demonstrate that VRWKV surpasses ViT's performance in image classification and has significantly faster speeds and lower memory usage processing high-resolution inputs. In dense prediction tasks, it outperforms window-based models, maintaining comparable speeds. These results highlight VRWKV's potential as a more efficient alternative for visual perception tasks. Code and models are available at~\\url{https://github.com/OpenGVLab/Vision-RWKV}.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 4, \"Contribution\": 2, \"Rating\": 8, \"Confidence\": 2, \"Strengths\": \"1.The paper is well-written and easy to follow;\\n\\n2.Extensive empirical evidence supports the effectiveness of the model, indicating its practical application potential;\\n\\n3.The adaptation of RWKV for visual tasks goes beyond mere transfer, incorporating modifications that enhance its suitability for image processing.\", \"Weaknesses\": \"Major：Although the paper discusses RWKV and mamba as prominent RNN-based linear attention models transitioning from NLP to computer vision, it lacks a direct comparison with the mamba (vision) model. Such a comparison would be valuable for assessing the respective strengths and weaknesses of each model in the field of computer vision.\\n\\nMinor：From an innovation perspective, the approach of adapting other domains' mature architectures to computer vision, similar to what was done post-transformer, appears somewhat incremental.\", \"Questions\": \"see weaknesses\"}"}]}
{"paper_id": "TBJCtWTvXJ", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nAdam has been widely successful in training deep neural networks (DNNs), yet the factors contributing to both its practical effectiveness and ineffectiveness remain largely underexplored. In this study, we  reveal that the effectiveness of Adam in training complicated DNNs stems primarily from its similarity to SignSGD in managing significant gradient variations, while we also theoretically and empirically uncover that Adam is  susceptible to loss spikes  due to potential excessively large updates. Building on these insights, we propose a novel optimizer,  SignSoftSGD (S3), which incorporates a generalized sign-like formulation with a flexible $p$-th order ($p\\ge 1$) momentum in the denominator of the update, replacing the fixed $2$-order momentum. We also integrate the memory-efficient Nesterov's accelerated gradient technique into S3, enhancing convergence speed without additional memory overhead. To minimize the risk of loss spikes, we utilize the same coefficient for the momentums in both the numerator and the denominator of the update, which also practically streamlines the tuning overhead.  We conduct a theoretical analysis of S3 on a general nonconvex stochastic problem, demonstrating that  S3 achieves the optimal convergence rate under weak assumptions. Extensive experimentation across various vision and language tasks demonstrates that  S3 not only achieves rapid  convergence and improved  performance but also  rarely encounters loss spikes even at a \\textbf{${10\\times}$} larger learning rate. Specifically, S3 delivers performance comparable to or better than AdamW}with ${2\\times}$ the training steps.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 4, \"Contribution\": 4, \"Rating\": 8, \"Confidence\": 3, \"Strengths\": \"1. The visualization in figure 2 is insightful where authors build a connection between mean update and train loss spikes.\\n2. The paper is nicely motivated.\\n3. Experiments are solid and results are strong.\\n4. Loss spikes in LLM training is a long-standing problem, and this possible explanation and solution should be immediately useful for the academic community.\", \"Weaknesses\": \"See questions\", \"Questions\": \"1. If p is not equal to 1, how will the wall clock time per iteration change? (compared to Adam and S3 p=1)\\n2. How is the learning rate for different optimizers determined? Are they properly tuned for baselines?\\n3. Will tuning betas for Adam (and getting a smoother loss curve) close the gap between Adam and S3?\"}"}]}
{"paper_id": "8gSrJOL2oc", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nCompositional zero-shot learning (CZSL) aims to recognize novel compositions of attributes and objects learned from seen compositions. Previous works disentangle attribute and object by extracting shared and exclusive parts between image pairs sharing the same attribute (object), as well as aligning them with pretrained word embeddings to improve unseen attribute-object recognition. Despite the significant achievements of existing efforts, they are hampered by three limitations: (1) the efficacy of disentanglement is compromised due to the influence of the background and the intricate entanglement of attribute with object in the same parts. (2) existing word embeddings fail to capture complex multimodal semantic information. (3) overconfidence exhibited by existing models in seen compositions hinders their generalization to novel compositions. Being aware of these, we propose a novel framework named Multimodal Large Language Model (MLLM) embeddings and attribute smoothing guided disentanglement (TRIDENT) for CZSL. First, we leverage feature adaptive aggregation (FAA) modules to mitigate the impact of background, and utilize learnable condition masks to capture multi-granularity features for subsequent disentanglement. Then, the last hidden states of MLLM are employed as word embeddings for their superior representation capabilities. Moreover, we propose attribute smoothing through leveraging auxiliary attributes generated by Large Language Model (LLM) for each seen composition, addressing the issue of overconfidence by encouraging the model to learn more attributes in one given composition instead of just fitting a fixed attribute-object combination. Extensive experiments demonstrate that TRIDENT achieves state-of-the-art performance on three challenging datasets: MIT-States, C-GQA, and VAW-CZSL, respectively.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"**1.** This work innovatively leverages multimodal large language model for CZSL, the idea is novel.\\n\\n**2.** The organization of this article is reasonable and well-written.\\n\\n**3.** Extensive experiments on three benchmarks show that the improvement in performance is noteworthy.\", \"Weaknesses\": \"**1.** The Figure 2 is ambiguous: the training and frozen modules are not clearly labeled, for example, the last hidden states of MLLM is trained but not the LLM, and the image embedder is trained but not the visual backbone; the graphical representation is inconsistent, for example, the network module image embedder is represented by a rectangle, but FAA and MLP are represented by text lines, which can easily be confused with other text such as “patches”; in the attribute-object disentanglement stage, some MLPs are not labeled.\\n\\n**2.** Some expressions are not accurate enough. For example, equation (12) uniformly represents with/without label smoothing, but $a/t$ is incorrect when $a$ and $t$ are both 0.\\n\\n**3.** The method section of this paper devoted a great deal of space to introducing attribute-object disentanglement and feature alignment, but these modules are not used in the final inference process. So, how can the author's proposed modules be helpful for the final prediction?\\n\\n**4.** Why isn't there a performance comparison with the latest works in 2024, such as Troika?\", \"Questions\": \"Pleas see \\\"Weaknesses\\\"\"}"}]}
{"paper_id": "yheQRc5xWB", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nTime-varying counterfactual prediction (TCP) from observational data supports the answer of when and how to assign multiple sequential treatments, yielding importance in various applications. Despite the progress achieved by recent advances, e.g., LSTM or Transformer based causal approaches, their capability of capturing interactions in long sequences remains to be improved in both prediction performance and running efficiency. In parallel with the development of TCP, the success of the state-space models (SSMs) has achieved remarkable progress toward long-sequence modeling with saved running time. Consequently, studying how Mamba simultaneously benefits the effectiveness and efficiency of TCP  becomes a compelling research direction. In this paper, we propose to exploit advantages of the SSMs to tackle the TCP task, by introducing a counterfactual Mamba model with Covariate-based Decorrelation towards Selective Parameters (Mamba-CDSP). Motivated by the over-balancing problem in TCP of the direct covariate balancing methods, we propose to de-correlate between the current treatment and the representation of historical covariates, treatments, and outcomes, which can mitigate the confounding bias while preserve more covariate information. In addition, we show that the overall de-correlation in TCP is equivalent to regularizing the selective parameters of Mamba over each time step, which leads our approach to be effective and lightweight. We conducted extensive experiments on both synthetic and real-world datasets, demonstrating that Mamba-CDSP not only outperforms baselines by a large margin, but also exhibits prominent running efficiency.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 5, \"Confidence\": 3, \"Strengths\": \"A substantive assessment of the strengths of the paper, touching on each of the following dimensions: originality, quality, clarity, and significance. We encourage reviewers to be broad in their definitions of originality and significance. For example, originality may arise from a new definition or problem formulation, creative combinations of existing ideas, application to a new domain, or removing limitations from prior results. You can incorporate Markdown and Latex into your review. See https://openreview.net/faq.\\n\\nOriginality\\nThe paper proposes a novel approach to capturing hidden heterogeneity in time series based counterfactual prediction, which is a significant domain problem in causal learning. The proposed Time-shared Heterogeneity Learning from Time Series method is a novel method that addresses this specific challenge by encoding the shared time-aware latent confounder and then utilizing them for counterfactual outcome forecasting.\\n\\nQuality\\nThe paper provides a clear and well-structured presentation of the proposed method, including a detailed explanation of the shared latent confounder variable encoding process via VAE and how to adapt to time series data.\\nThe experimental results basically demonstrate the effectiveness of the proposed method in improving the performance of mainstream models. \\n\\nClarity\\nThe paper is well-written and easy to follow, with clear explanations of technical concepts and methods. The authors provide an informative context in each section that effectively organizes the story and summarizes the paper contributions.\\n\\nSignificance\\nThe proposed THLTS method has the potential to improve the accuracy of counterfactual outcome in time-series data scenarios. The capture of hidden heterogeneity across time domains is a common challenge in many fields. The proposed method is flexible and can be easily inserted with arbitrary causal modeling framework, making it a valuable contribution to the field.\", \"Weaknesses\": \"Lack of Novelty in Methodology\\nThe proposed THLTS method is based on the use of variational encoders (VAE) to improve counterfactual prediction in time-series data, which has been explored in other works such as\\n1. https://doi.org/10.1145/3637528.3671950, \\n2. https://doi.org/10.48550/arXiv.2310.18615 . \\nWhile the shared latent factor encoding part is new, the underlying methodology is not entirely novel. To strengthen the contribution, the authors could provide a more detailed comparison with existing methods and highlight the specific advantages of their approach.\\n\\n\\nLimited Experimental Evaluation\\nThe paper only presents experimental results on (semi) synthetic datasets, which may not accurately reflect real-world scenarios. To demonstrate the practical applicability of the proposed method, it would be beneficial to include experiments on (or the connection to) real-world datasets .\", \"Questions\": \"Please list up and carefully describe any questions and suggestions for the authors. Think of the things where a response from the author can change your opinion, clarify a confusion or address a limitation. This is important for a productive rebuttal and discussion phase with the authors.\\n\\n\\n\\nBesides RMSE, it would be good to add other ablation study such as distribution analysis of the counterfactual prediction from utilizing the proposed method vs. baselines, which would provide more evidence to validate the the effectiveness of introducing the shared latent factor as illustrated in Figure 1\\nIn table1 and table2, could the author elaborate on more details of the baseline THLTS(v)? Why author think this would be fair baseline to justify the rationality of learning shared part of latent factors compared to the proposed method\\nIn Algorithm 1, what is the difference between forecast model pρ() and gρ()?\"}"}]}
{"paper_id": "HxKSzulSD1", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSuperalignment, where humans act as weak supervisors for superhuman models, has become a crucial problem with the rapid development of Large Language Models (LLMs). Recent work has preliminarily studied this problem by using weak models to supervise strong models, and discovered that weakly supervised strong students can consistently outperform weak teachers towards the alignment target, leading to a weak-to-strong generalization phenomenon. However, we are concerned that behind such a promising phenomenon, whether there exists an issue of weak-to-strong deception, where strong models deceive weak models by exhibiting well-aligned in areas known to weak models but producing misaligned behaviors in cases weak models do not know. We take an initial step towards exploring this security issue in a specific but realistic multi-objective alignment case, where there may be some alignment targets conflicting with each other (e.g., helpfulness v.s. harmlessness). We aim to explore whether, in such cases, strong models might deliberately make mistakes in areas known to them but unknown to weak models within one alignment dimension, in exchange for a higher reward in another dimension. Through extensive experiments in both the reward modeling and preference optimization scenarios, we find: (1) The weak-to-strong deception phenomenon exists across all settings. (2) The deception intensifies as the capability gap between weak and strong models increases. (3) Bootstrapping with an intermediate model can mitigate the deception to some extent, though its effectiveness remains limited. Our work highlights the urgent need to pay more attention to the true reliability of superalignment.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. Originality: The paper introduces the novel concept of \\\"weak-to-strong deception,\\\" which is an underexplored alignment issue where strong models exploit gaps in weak supervision by selectively misaligning in unknown areas. \\n\\n2. Quality: The research is methodologically strong, with diverse experimental settings involving various large models (e.g., GPT-2, OPT, Mistral, LLaMA) across reward modeling and preference alignment tasks. The introduction of a \\\"Deception Score\\\" and structured definitions for knowledge boundaries is interesting. Balanced discussions on the limitations of mitigation techniques (e.g., high-confidence filtering, bootstrapping) are also helpful. \\n\\n3. Clarity: The paper is well-organized, with clear definitions and diagrams that help understand the dynamics between weak and strong models. Concepts like knowledge spaces and the Deception Score are well explained, making complex ideas easy to understand.\\n\\n4. Significance: The study’s findings are significant for AI alignment, particularly as they highlight vulnerabilities in supervising increasingly powerful AI models. The weak-to-strong deception phenomenon underscores the need for improved supervision techniques in high-stakes applications, with implications for ethical AI and safety. \\n\\nIn summary, the paper’s originality in framing weak-to-strong deception, the quality and breadth of its experimental design, its clear presentation, and its implications for alignment make it a good contribution to the field.\", \"Weaknesses\": \"1. Synthetic scenarios used for controlled testing may not capture real-world complexities. Having interactive, dynamic environments (e.g., feedback systems) would improve generalizability. Did the authors consider testing with more complex, real-world environments? \\n2. The use of static thresholds to identify deception risks seems somewhat limiting. A dynamic thresholding or sensitivity analysis could be a better alternative.\\n3. Techniques like high-confidence filtering and bootstrapping show limited effectiveness in reducing deception. Exploring adaptive or meta-learning approaches may yield better solutions?\\n4. By focusing primarily on \\\"harmlessness,\\\" the study seems a bit narrow, and other alignment goals (e.g., \\\"honesty,\\\" \\\"fairness\\\") could improve generalizability.\", \"Questions\": \"See above in weaknesses.\"}"}]}
{"paper_id": "wH8XXUOUZU", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nWe present Deep Compression Autoencoder (DC-AE), a new family of autoencoder models for accelerating high-resolution diffusion models. Existing autoencoder models have demonstrated impressive results at a moderate spatial compression ratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for high spatial compression ratios (e.g., 64x). We address this challenge by introducing two key techniques: (1) Residual Autoencoding, where we design our models to learn residuals based on the space-to-channel transformed features to alleviate the optimization difficulty of high spatial-compression autoencoders; (2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases training strategy for mitigating the generalization penalty of high spatial-compression autoencoders. With these designs, we improve the autoencoder's spatial compression ratio up to 128 while maintaining the reconstruction quality. Applying our DC-AE to latent diffusion models, we achieve significant speedup without accuracy drop. For example, on ImageNet 512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup on H100 GPU for UViT-H while achieving a better FID, compared with the widely used SD-VAE-f8 autoencoder. Our code and models will be released upon publication.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"-\\tNovel autoencoder design for high compression ratios. The authors introduce additional non-parametric residual connections in the downsampling and upsampling layers, which facilitate the optimization of autoencoders in high spatial compression ratio scenarios.\\n-\\tThe authors carefully design a three-stage training recipe to mitigate the high-resolution generalization gaps by fine-tuning the trained AE on high-resolution data with minimal additional costs.\\n-\\tThe proposed DC-AEs show a substantial reduction in training and inference costs of latent diffusion models on various datasets.\", \"Weaknesses\": \"-\\tAlthough the VAE shows little FID loss as it progresses to a higher spatial compression ratio (DC-AE-f32 to DC-AE-f64), it does not translate to similar results in the corresponding latent diffusion models as shown in Table 3. The underlying reason is probably that a diffusion model with higher capacity is required when dealing with high compression ratio latents.\\n-\\tThe current submission lacks either theoretical analysis or illustrative toy examples on the proposed design choice of space-channel residual connection, e.g., comparisons on the loss landscapes.\", \"Questions\": \"-\\tCould you please clarify the experimental settings and AE architectures in Section 3.1? By Line 161 ‘… convert the latent to higher spatial compression…’, do you mean that the f8 to f64 AEs have the same output latent size initially, yet f32 and f64 AEs further squeeze the space dimension into channel dimension?\\n-\\tIn Table 5, the proposed method shows a lower CLIP score with the Pixart diffusion transformer, is it a typo?\"}"}]}
{"paper_id": "QWIg5e6mtT", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThe \\textit{ex ante} equilibrium for two-team zero-sum games, where agents within each team collaborate to compete against the opposing team, is known to be the best a team can do for coordination. Many existing works on \\textit{ex ante} equilibrium solutions are aiming to extend the scope of \\textit{ex ante} equilibrium solving to large-scale team games based on Policy Space Response Oracle (PSRO). However, the joint team policy space constructed by the most prominent method, Team PSRO, cannot cover the entire team policy space in heterogeneous team games where teammates play distinct roles. Such insufficient policy expressiveness causes Team PSRO to be trapped into a sub-optimal \\textit{ex ante} equilibrium with significantly higher exploitability and never converges to the global \\textit{ex ante} equilibrium. To find the global \\textit{ex ante} equilibrium without introducing additional computational complexity, we first parameterize heterogeneous policies for teammates, and we prove that optimizing the heterogeneous teammates' policies sequentially can guarantee a monotonic improvement in team rewards. \nWe further propose \\textbf{Heterogeneous-PSRO} (\\textbf{H-PSRO}), a novel framework for heterogeneous team games, which integrates the sequential correlation mechanism into the PSRO framework and serves as the first PSRO  framework for heterogeneous team games. \nWe prove that H-PSRO achieves lower exploitability than Team PSRO in heterogeneous team games. \nEmpirically, H-PSRO achieves convergence in matrix heterogeneous games that are unsolvable by non-heterogeneous baselines. \nFurther experiments reveal that H-PSRO outperforms non-heterogeneous baselines in both heterogeneous team games and homogeneous settings.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 1, \"Presentation\": 1, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 5, \"Strengths\": \"1. Numerical results are provided where the proposed algorithm is competing with several benchmark algorithms in relatively large-scale two team zero-sum games.\", \"Weaknesses\": \"1. This paper makes the claim that previous work [1] relies on the assumption that the two-team zero-sum has to be homogenous and a policy sharing mechanism that requires every player in the same team to play under the same strategy. (i.e. the policies of players in the same team are ($\\\\pi_{k, share}, \\\\pi_{k, share}, ..., \\\\pi_{k, share} )$. However, to the reviewer's best knowledge, the algorithm provided in [1] does not require such strong assumption and does not employ a policy sharing mechanism. Team PSRO algorithm in [1] directly optimize the team strategy over the team's joint strategy space, it outputs a joint policy of each team with potential correlation instead of outputting each players' strategy individually (in this case no correlation would be possible). I would appreciate it if the author specify where the policy sharing mechanism is posted in [1].\\n\\n2. The definition of set $E_c$ in definition 2 remains ambiguous. When considering possible deviations from an equilibrium in $E_c$, do we only consider possible deviations in $S_c$ or we consider all possible deviations in $S$? Consequently, the proof of proposition 2 regard $E_{share} \\\\subseteq E$ is also unclear.\\n\\n3. It is unclear how the authors reach the conclusion that $S_{share} \\\\subsetneqq S$. Further, in equation (3a) and (3b), the notation $\\\\sigma_{1, share} \\\\in \\\\Pi_1 \\\\backslash \\\\Pi_{1, share}$ remains confusing.\\n\\n4. Lemma 1 defines the advantage function $A_{\\\\pi_1}^{i_l}(o_1, a_1^{i_{1:l-1}}, a_1^{i_{l}}| \\\\pi_2) = Q_{\\\\pi_1}^{i_{1:l}}(o_1, a_1^{i_{1:l}}| \\\\pi_2) - Q_{\\\\pi_1}^{i_{1:l-1}}(o_1, a_1^{i_{1:l-1}}, a_1^{i_{l}}| \\\\pi_2)$. This notation remains extremely confusing and it's unclear what the value $Q_{\\\\pi_1}^{i_{1:l}}(o_1, a_1^{i_{1:l}}| \\\\pi_2)$ stands for.  The Q-value function in multiagent setting should be evaluated based on the reward of a joint action $a^{i_1:n}$ instead of the joint (or single) action of a subset of players.\\n\\n5. The authors claim that utilizing the advantage function would bypass the computational difficulty induced by the exponential growth of the the policy space. However, it is unclear how they update the advantage function to bypass this difficulty since the number of advantage function is also growing exponentially with the number of actions.\\n\\n6. The authors state that the proposed oracle sequential BRO, could efficiently compute the best responding joint policy of a team. However, due to the unclear definition of the advantage function, it's not clear if the oracle can have some monotonic value functions. Furthermore, even some monotonic increment over the value function was achieved by sequentially picking each player's action. It is not sufficient to show that oracle would output the optimal policy.\\n\\n\\n[1] Stephen Marcus McAleer, Gabriele Farina, Gaoyue Zhou, Mingzhi Wang, Yaodong Yang, and Tuo- mas Sandholm. Team-PSRO for learning approximate tmecor in large team games via cooperative reinforcement learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.\", \"Questions\": \"See weaknesses.\"}"}]}
{"paper_id": "kbSU5bwoRv", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSinging voice conversion (SVC) aims to convert a singer's voice to another singer's from a reference audio while keeping the original semantics. However, existing SVC methods can hardly perform zero-shot due to incomplete feature disentanglement or dependence on the speaker look-up table. We propose the first open-source high-quality zero-shot SVC model SaMoye that can convert singing to human and non-human timbre. SaMoye disentangles the singing voice's features into content, timbre, and pitch features, where we combine multiple ASR models and compress the content features to reduce timbre leakages. Besides, we enhance the timbre features by unfreezing the speaker encoder and mixing the speaker embedding with top-3 similar speakers. We also establish an unparalleled large-scale dataset to guarantee zero-shot performance, which comprises more than 1,815 hours of pure singing voice and 6,367 speakers. We conduct objective and subjective experiments to find that SaMoye outperforms other models in zero-shot SVC tasks even under extreme conditions like converting singing to animals' timbre.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 5, \"Strengths\": \"1. The paper presents a flow-based architecture designed specifically for singing voice conversion, demonstrating improved performance in transforming vocal timbres while maintaining naturalness and expressiveness.\\n2. The study introduces a novel method for converting non-human voices into human-like voices, addressing key challenges in voice synthesis and bridging the gap between synthetic and natural speech.\\n3. The paper releases a new dataset, providing valuable resources for further research in voice conversion and fostering advancements in related fields through the availability of high-quality data.\", \"Weaknesses\": \"1. The audio outputs are not sufficiently convincing, making them challenging to listen to and assess effectively.\\n\\n2. The concept of singing voice conversion has been extensively studied in the literature, particularly through the use of flow-based and diffusion models. Notable examples include:\\nReal-Time and Accurate: Zero-shot High-Fidelity Singing Voice Conversion with Multi-Condition Flow Synthesis [https://arxiv.org/abs/2405.15093]\\n\\nSingVisio: Visual Analytics of Diffusion Model for Singing Voice Conversion [https://arxiv.org/pdf/2402.12660]\\n\\n3. There is a potential issue of timbre leakage from the automatic speech recognition (ASR) model, which could affect the conversion quality.\", \"Questions\": \"1. **Why use SECS (Speaker Similarity) for non-human audio?** The effectiveness of speaker embeddings for non-human audio remains uncertain, raising questions about their reliability in such contexts.  \\n\\n2. **Incorporate a speaker classification model for enhanced evaluation.** Introducing a speaker classification model would provide a more robust assessment of performance, ensuring a comprehensive evaluation beyond speaker similarity metrics.\"}"}]}
{"paper_id": "KyqtKhv6q1", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nHuman drivers rarely navigate where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most computer vision systems act as if they are encountering each location for the first time. In this work, we present Differentiable Map Priors, a simple but effective framework to learn spatial priors from historic traversals. Differentiable Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs. We show that they lead to a significant and consistent improvement in 3D object detection and semantic map segmentation tasks on the nuScenes dataset across several architectures.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"- The key idea of learning a spatial priors for AVs is simple and powerful. It is great to see this work execute on this idea. The proposed approach is elegant and straight forward to add to existing systems. This enhances potential impact.\\n- The manuscript is well written and the illustrations are high quality and support the written text well.\\n- The experiments are illustrative especially the ablation with respect to number of traversals in training set and performance at different distances. Both of those support the claim that a map prior is learned by showing that (1) when more prior observations exist the learned prior leads to a higher performance boost and (2) when sensor observations are weak (because things are far away) the learned prior can compensate and lift performance substantially. \\n- The baseline experiments with NMP shows clearly the benefit of end-to-end learning the map prior during training with the model in the loop.\", \"Weaknesses\": \"- A slight weakness is that the improvements of adding the map prior seem to be relatively minor in the overall evaluation. Likely this is due to the observations at close range providing sufficient information to not really need the learned prior (as shown in Fig8). I do wonder what happens if the image information provided to the model gets degraded in some way. Like downscaling significantly or blacking-out chunks of the images, or dropping out all but one frame? A limit experiment would be to provide NO image information to understand how much the models can do without any observations only given the prior?\\n- The sparse voxel hashmap representation for the prior is a great choice for a scalable representation. It would be good to add some statistics into the paper as to the required memory footprint per distance traveled (for example). This would (1) give the reader a better sense for actual practical memory footprints of the map and (2) support the claim that the prior map is represented in a scalable way.\", \"Questions\": \"- It was not that obvious upon a first read how the sparse voxel datastructure is setup: \\n    - Is it 3D or only 2D (I assumed 2D but the word voxel was used?)? \\n    - How are the 4 levels spaced in voxel resolution 0.5m, ?, ?, 25m? \\n    - Am I right to assume that T=2^16 means that each side of the 2D grid is 2^8=256 pixels/voxels wide? so the highest resolution layer is 0.5m*256 = 128m wide?\\n- How does the approach handle dynamic objects?\"}"}]}
{"paper_id": "lTL4t68BNc", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nGraph Neural Networks (GNNs) have shown exceptional performance in learning node representations for node-level tasks such as node classification. However, traditional message-passing mechanisms solely based on graph structure in GNNs make them vulnerable to adversarial attacks. Attention-based GNNs have been utilized to improve the robustness of GNNs due to their capabilities to selectively emphasize informative signals over noisy or less relevant ones. However, existing works on robust graph attention methods do not realize the correlation between improved robustness and better adherence to the IB principle of attention-based GNNs. In this work, we find that the IB loss of attention-based GNNs is a strong indicator of their robustness against variant graph adversarial attacks. Attention-based GNNs with lower IB loss learn node representations that correlate less to the input training data while aligning better with the target outputs. Due to better adhering to the IB principle, attention-based GNNs with lower IB loss usually show stronger robustness against graph adversarial attacks. Inspired by such observation, we propose a novel graph attention method termed Robust Graph Attention inspired by Information Bottleneck, or RGA-IB, which explicitly minimizes the IB loss of a multi-layer GNN through a carefully designed graph attention mechanism.\nExtensive experiment results on semi-supervised node classification under variant graph adversarial attacks show that GNNs equipped with RGA-IB exhibit lower IB loss, which indicates better adherence to the IB principle, and show significantly improved node classification accuracy under graph adversarial attacks compared to existing robust GNNs. The code of RGA-IB is available at \\url{https://anonymous.4open.science/r/RGA-IB-A47F/}.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"1. This work connects the Information Bottleneck with the robustness of graph attention methods and proposes a novel Robust Graph Attention method. The experiments also provide evidence of a connection between lower IB loss and improved robustness.\\n\\n2. This work explains the differences between RGA-IB and other IB-based methods, highlighting that RGA-IB can capture global correlations, whereas others, like GIB, are limited by the local dependency assumption.\\n\\n3. The experiments include several datasets, attacks, and baselines.\", \"Weaknesses\": \"1. Limited Novelty: The model architecture is inspired by the Information Bottleneck, which I believe is similar in motivation to other IB-based models and not sufficiently novel. The only contribution of this method is actually the gradient decent of attention matrix B in Theorem 3.1.\\nAlthough the authors highlight differences between RGA-IB and other IB-based models, the distinction between local and global dependencies contributing to improved robustness is not entirely convincing. The robustness improvement might result from implementation details and hyperparameter tuning.\\n\\n2. Evaluation: The experiments are not comprehensive enough.\\n\\n* Baselines: How does the model compare to RUNG [1], ElasticGNN [2], SoftMedian [3], and TWIRLS [4]?\\n* Datasets: How does the model perform on heterophilic datasets?\\n* Attacks: How does the model perform under gradient-based local attacks and injection attacks?\\n\\n[1] Robust Graph Neural Networks via Unbiased Aggregation\\n\\n[2] Elastic Graph Neural Networks\\n\\n[3] Robustness of Graph Neural Networks at Scale\\n\\n[4] Graph Neural Networks Inspired by Classical Iterative Algorithms\\n\\n3. The evidence of the connection between lower IB loss and improved robustness needs further development. Since GIB, UGRL, and RG-GIB are all IB-based models, why is RGA-IB more effective in reducing IB loss? Additionally, in Table 5, the authors should include these baselines to demonstrate that RGA-IB is more effective in reducing IB loss.\\n\\n4. Minor suggestions: The presentation could be further enhanced. The method section appears somewhat disorganized, and the detailed computation of IB loss should be the main focus of this section. Equation (1) represents the gradient descent of matrix B and should not be formatted as a theorem. Additionally, Algorithm 1 lacks informativeness yet occupies excessive space. The experiment table's font is too small, making it inconsistent with the main text. In the experiment section, the authors should use a dedicated subsection for experimental settings to clearly present datasets, baselines, implementation details, and attacks, rather than introducing these aspects randomly within the main discussion.\", \"Questions\": \"Refer to weaknesses\"}"}]}
{"paper_id": "hWmwL9gizZ", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nImmunogenicity prediction is a central topic in reverse vaccinology for finding candidate vaccines that can trigger protective immune responses. Existing approaches typically rely on highly compressed features and simple model architectures, leading to limited prediction accuracy and poor generalizability. To address these challenges, we introduce ProVaccine, a novel deep learning solution with a dual attention mechanism that integrates pre-trained latent vector representations of protein sequences and structures. We also compile the most comprehensive immunogenicity dataset to date, encompassing over 9,500 antigen sequences, structures, and immunogenicity labels from bacteria, viruses, and tumors. Extensive experiments demonstrate that ProVaccine outperforms existing methods across a wide range of evaluation metrics. Furthermore, we establish a post-hoc validation protocol to assess the practical significance of deep learning models in tackling vaccine design challenges. Our work provides an effective tool for vaccine design and sets valuable benchmarks for future research.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 3, \"Strengths\": \"- novel model architecture\\n- contribution of the Immuno datasets\\n- ProVaccine achieves mostly top performance as reported in Table 1\", \"Weaknesses\": \"- It's not obvious what the contribution of any of the representations (sequence, fine, coarse, and descriptors) is to model performance. What if only the sequence representation is used as input? Doing ablation studies is essential for understanding these contributions, and should be included in this work.\\n- Figure 4 is hard to interpret, it would be easier to understand if instead the likelihood stats of the 11 determined immunogens under each model were reported.\\n- The appendix is missing:\\n  - page 7 in section 5.2.1 refers to Tables 4-6 in the appendix\\n  - page 8 in section 5.3.1 refers to recall and fold-enrichment metrics that do not appear in any table. Also reference is made to Table 10, which does not appear to exist.\\n  - page 9 in section 5.3.2 refers to Table 11 in the appendix, which does not exist\", \"Questions\": \"- I don't understand the approach to measuring accuracy described in the first paragraph of section 5.2.1. Are you doing hyperparameter optimization on the validation set for each split? Why randomly select \\\"50% of the test data to calculate the scores for each metric\\\" since you already have a validation set in your split?\\n- It's not clear what the generalizability of section 5.2.2 is measuring. Should a immunogenicity predictor generalize across bacteria, viruses and humans?\\n- For the three conclusions about ProVaccine in the final paragraph of subsection 5.3.1, I don't understand how the authors concluded the second and third - could you please explain these in greater detail?\"}"}]}
{"paper_id": "IL85Ebjg9j", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nResolving conflicts is essential to make the decisions of multi-view classification more reliable. Much research has been conducted on learning consistent and informative representations among different views,  often assuming that all views are equally important and perfectly aligned. However, real-world multi-view data may not always conform to these assumptions, as some views may express distinct information. To address this issue, we develop a computational trust-based discounting method to enhance the existing Evidential Multi-view framework in scenarios where conflicts between different views may arise. Its belief fusion process considers the reliability of predictions made by individual views via an instance-wise probability-sensitive trust discounting mechanism. We evaluate our method on six real-world datasets, using Top-1 Accuracy, Fleiss’ Kappa, and a new metric called Multi-View Agreement with Ground Truth that takes into consideration the ground truth labels, to measure the reliability of the prediction. We also evaluate whether uncertainty measures can effectively indicate prediction correctness by calculating the AUROC. The experimental results show that computational trust can effectively resolve conflicts, paving the way for more reliable multi-view classification models in real-world applications.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 2, \"Strengths\": \"The paper is well-written, clearly setting up the problem and explaining the original proposed method, with mathematical justifications provided. The approach introduces a dynamic weighting mechanism that adjusts the influence of each view based on the instance, a relevant adaptation in MVC contexts where view reliability can vary. This instance-wise adaptability demonstrates originality, improving upon  to static weighting systems commonly used in MVC. The method performs consistently well against several baselines, underscoring its robustness and flexibility across diverse scenarios. By prioritizing trustworthy views, this approach has significant potential to improve decision-making reliability in settings where the importance of each view shifts with changing conditions.  The paper mentions domains such as autonomous driving as examples where this technique could improve accuracy.\", \"Weaknesses\": \"The first weakness that stands out is the placement of the algorithm in the appendix. Understanding the method, as well as details about the training process are deferred to the end of the paper, making comprehension somewhat difficult. The process is key to understanding the paper and its results, and placing it in the appendix is a significant flaw, in my view.\\n\\nThe placement of the related work interrupts the flow of the paper - in my view, the context for MVCs and where this paper's contributions fit should come earlier.\\n\\nThe ablation study, while welcome, feels out of place without the inclusion of the algorithm within the body of the paper. The process loses significant clarity in doing so, and much of the results become harder to parse without it.\\n\\nThe original methods add significant time - with the exception of MGP, the author's methods take significantly longer to train.\\n\\nThe diversity of the instances of the datasets is not mentioned, making it difficult to know how well the trust mechanism works in diverse contexts.\\n\\nThere are minor spelling/grammatical errors, but none that affect understanding.\", \"Questions\": \"It's unclear how this work scales in dynamic situations, such as the autonomous driving example cited early on, where there may be a variety of instances that differ significantly. The appendix has characteristics of said datasets, but the paper does not discuss how similar or varied the instances are, apart from a brief reference to Caltech101 having lower conflict. Could such data be provided?\\n\\nThe information that Table 1 provides is not clear. Is there real data being used to generate the table?  If not, could you clarify what information the table is meant to convey?\\n\\nCould you clarify the impact of the warm-up epochs on the overall performance? Based on Figure 3, there appears to be limited improvement at best. If only 1 dataset shows improvement, the inclusion of the ablation study seems suspect. Are there simpler procedures that might be used if warm-up epochs do not significantly enhance results?\\n\\nCould you provide additional context on how MVAGT complements standard MVC metrics? It's explained in the appendix but I would appreciate further detail.\"}"}]}
{"paper_id": "cnKhHxN3xj", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nDisentangling polysemantic neurons is at the core of many current approaches to interpretability of large language models. Here we attempt to study how disentanglement can be used to understand performance, particularly under weight sparsity, a leading post-training optimization technique. We suggest a novel measure for estimating neuronal entanglement: the Wasserstein distance of a neuron's output distribution to a Gaussian. Moreover, we show the existence of a small number of highly entangled \"Wasserstein Neurons\" in each linear layer of an LLM, characterized by their highly non-Gaussian output distributions, their role in mapping similar inputs to dissimilar outputs, and their significant impact on model accuracy. To study these phenomena, we propose a new experimental framework for disentangling polysemantic neurons. Our framework separates each layer's inputs to create a mixture of experts where each neuron's output is computed by a mixture of neurons of lower Wasserstein distance, each better at maintaining accuracy when sparsified without retraining. We provide strong evidence that this is because the mixture of sparse experts is effectively disentangling the input-output relationship of individual neurons, in particular the difficult Wasserstein neurons.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 2, \"Strengths\": \"- Understanding the relationship between sparsity and entanglement is an important research area.\\n- The paper conducts extensive experiments to explore the connection between Wasserstein distance, entanglement, and their impact on sparsification.\", \"Weaknesses\": \"- The concept of using the Wasserstein distance has been addressed in prior work [1]. The authors could benefit from a broader literature review. It would be helpful to discuss how other works evaluate entanglement.\\n- The sparse expansion approach relies on prior knowledge of the distribution to support K-means clustering. How robust is this method for out-of-distribution data?\\n- Practical aspects of the sparse expansion, such as runtime and inference speed (e.g., with 16 experts), should be discussed more thoroughly.\\n- The writing could be improved; The reviewer finds that many phrases and sentences are difficult to parse.\\n\\n[1] You, Lei, and Hei Victor Cheng. \\\"Swap: Sparse Entropic Wasserstein Regression for Robust Network Pruning.\\\" The Twelfth International Conference on Learning Representations. 2024.\", \"Questions\": \"1. Directly normalizing the distribution to calculate the Wasserstein distance seems like a strong simplification. Is there a better approach that accounts for mean and variance?\\n2. In Equation (2), why is the mean used for mapping difficulty, the maximum for $N_x$ , and the median for $N_y$?\\n3. In Figure 4b, what does the \\\"normalized input/output L2\\\" represent?\\n4. On line 282, there is a missing word after “the.”\\n5. How is the weighted cluster distance calculated in Figure 6b?\\n6. Are the K-NN and evaluation conducted on the same training set of wikitext-2?\\n7. Could the authors explain why there is no correlation between the optimal number of Gaussians and relative improvement? Is this due to sparse expansion being applied directly to the weight matrix while the GMM is estimated for individual neurons? Is the relative improvement possibly influenced by the neurons with the largest GMM value? Could differences in measurement — one on the entire weight matrix, the other on individual neurons — lead to inconsistencies?\\n8. How do outlier weights (or neurons) overlap with neurons that have large Wasserstein distances?\\n9. How do neurons in the MoE model perform in terms of Wasserstein distance?\"}"}]}
{"paper_id": "dgR6i4TSng", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThis paper introduces Quantum-PEFT that leverages quantum computations for parameter-efficient fine-tuning (PEFT). Unlike other additive PEFT methods, such as low-rank adaptation (LoRA), Quantum-PEFT exploits an underlying full-rank yet surprisingly parameter efficient _quantum unitary parameterization_. With the use of Pauli parameterization, the number of trainable parameters grows only logarithmically with the ambient dimension, as opposed to linearly as in LoRA-based PEFT methods. Quantum-PEFT achieves vanishingly smaller number of trainable parameters than the lowest-rank LoRA as dimensions grow, enhancing parameter efficiency while maintaining a competitive performance. We apply Quantum-PEFT to several transfer learning benchmarks in language and vision, demonstrating significant advantages in parameter efficiency.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper introduces a parameterization based on quantum circuits that require only (2L+1)log₂(N)-2L parameters, a significant improvement over LoRA's 2NK parameters.\\n2. The reduction in parameters is experimentally verified.\\n3. The authors proposed generalized RY and CZ quantum gates for arbitrary dimensions beyond power-of-2.\\n4. The proposed method seems robust under quantization.\", \"Weaknesses\": \"1. Analysis of how L layers affect entanglement capacity is limited. There is no evaluation of entanglement entropy between layers.\\n\\n2. The paper only focuses on benchmarking against LoRA/adapter variants on small models (such as GPT2). Benchmarks on larger (and newer) models such as LLaMA seem to be quite standard and more related to practical use cases. \\n\\n1. Some of the recently proposed PEFT methods are not adequately addressed/discussed (at least mentioned somewhere in the paper), e.g.\\n\\n[1] https://arxiv.org/abs/2403.17919 (NeurIPS)\\n\\n[2] https://arxiv.org/abs/2404.03592 (NeurIPS)\\n\\n[3] https://arxiv.org/abs/2405.12130 \\n\\n[4] https://arxiv.org/abs/2406.00132 (NeurIPS)\\n\\nBoth [3] and [4] seem to be able to model high-rank matrices, and [4] appears to be also based on quantum circuit.\", \"Questions\": \"1. How does Eq. 4 work?\\n2. What is the optimal number of alternating entanglement layers L for different model scales?\\n3. For the quantum Shannon decomposition approach to handle non-power-of-two dimensions, how does the decomposition choice (N₁, N₂) affect model performance?\\n4. Does the proposed method have a large computational overhead from the entanglement layers?\\n5. How does the proposed method compare with other methods mentioned above? My understanding of the main difference between this method and [4] is the use of unitary and diagonal matrices. Is this correct?\\n6. The proposed method focuses on reduction in parameters. However, [2] and [4] claim both reduction in parameter and performance improvement. Does the proposed method use even fewer parameters?\\n6. How is the proposed method related to quantum machine learning?\"}"}]}
{"paper_id": "ye1mxb79lw", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nBilevel optimization, characterized by a two-level hierarchical optimization structure, is prevalent in real-world problems but poses significant challenges, especially in noisy, constrained, and derivative-free settings. To tackle these challenges, we present a novel algorithm for BILevel Bayesian Optimization (BILBO) that optimizes both upper- and lower-level problems jointly in a sample-efficient manner by using confidence bounds to construct trusted sets of feasible and lower-level optimal solutions. We show that sampling from our trusted sets guarantees points with instantaneous regret bounds. Moreover, BILBO selects only one function query per iteration, facilitating its use in decoupled settings where upper- and lower-level function evaluations may come from different simulators or experiments. We also show that this function query selection strategy leads to an instantaneous regret bound for the query point. The performance of BILBO is theoretically guaranteed with a sublinear regret bound and is empirically evaluated on several synthetic and real-world problems.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"- The paper proposes a new algorithm, BILBO, specifically tailored for general bilevel optimization problems, where simultaneous optimization at both levels is essential.\\n- The authors derive and prove a sublinear cumulative regret bound for the decoupled setting, enhancing the theoretical understanding of bilevel optimization.\\n- Experiments are conducted on both synthetic and interesting real-world scenarios, demonstrating the practical applicability of BILBO.\\n- The writing is generally clear and well-structured, making the paper accessible to readers.\", \"Weaknesses\": \"- While the algorithm is well-explained, the motivations for certain design choices, particularly the decoupled setting and the specific function query mechanisms ($\\\\mathcal{F}$ and $h_t$), are not sufficiently discussed. A deeper exploration of these choices would help readers understand the broader implications and advantages of BILBO’s design.\\n- The paper’s discussion of related work is somewhat limited. A more detailed comparison with existing bilevel optimization methods, particularly those offering theoretical guarantees or practical performance benchmarks, would provide a clearer picture of BILBO’s relative strengths and weaknesses.\\n- The baselines used in the experiments—TrustedRandom and Nested—are not the strongest available. Including comparisons with state-of-the-art bilevel optimization algorithms, such as those from Kieffer et al. (2017) or Dogan & Prestwich (2023), would offer a more rigorous evaluation of BILBO’s performance.\\n- No code is provided alongside the paper. This omission hampers the reproducibility of the results and limits the ability of the research community to build upon or validate the findings presented.\", \"Questions\": \"- Can you explain more about the motivations for studying the decoupled setting? And the reasons to consider $\\\\mathcal{F}$ and function query $h_t$ is the algorithm design and regret definition? For example, can we only focus on the upper and lower-level functions in the regret definition? \\n- For regret bound in Theorem 3.9, the authors discussed the relationship to constrained Bayesian optimization in Nguyen et al. (2023), is there any existing bilevel BO regret result that can be compared with? \\n- In experiments, BILBO is compared with TrustedRandom and Nested. As described in Appendix C.1, the Nested baseline used a nested approach with SLSDP. But the related works mentioned, e.g.  Kieffer et al. (2017); Dogan & Prestwich (2023) are not included. Can you compare it with the associated works directly? If not, can you explain the reasons that BILBO cannot compared with the related work? \\n- In Figure 1a, can you explain why BILBO has a sudden drop at around 150 queries? And what is the regret of BILBO after 150 queries (cannot observe the line afterwards)? The uncertainty level looks huge as well, I am wondering what would happen if you increase the number of runs (or change random seeds/initialisations, etc). \\n- In experimental results, we observe Nested is generally similar to or worse than TrustedRand (which is only a random sampling), can you explain the possible reason? Does it suggest Nested is not a strong baseline (as it is from a previous work)?\"}"}]}
{"paper_id": "1fwZJzGdKj", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nEfficient data selection is crucial to accelerate the pretraining of large language models (LLMs). While various methods have been proposed to enhance data efficiency, limited research has addressed the inherent conflicts between these approaches to achieve optimal data selection for LLM pretraining. To tackle this problem, we propose a novel multi-agent collaborative data selection mechanism. Each data selection method independently prioritizes data based on its specific criterion and updates its prioritization rules using the current state of the model, functioning as an independent agent for data selection. Additionally, an agent console is designed to adjust the impacts of different agents at various stages and dynamically integrate information from all agents throughout the LLM training process. We conduct extensive empirical studies to evaluate our multi-agent framework. The experimental results demonstrate that our approach significantly improves data efficiency, accelerates convergence in LLM pretraining, and achieves an average performance gain up to 10.5% across multiple language model benchmarks compared to the state-of-the-art methods.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 3, \"Strengths\": \"• A good analysis of how different aspects influence the performance of LLM training.\\n• The experiment seems to demonstrate this kind of scoring of data points can help to improve the data deficiency and performance.\", \"Weaknesses\": \"• The connection to agent or multi-agent paradigm seems weak to me. It might not be necessary to formulate the problem and the solution via \\\"agent\\\" concept. A direct stochastic optimization formulation might provide  more direct description and help audience better mastering what is the proposal.\", \"Questions\": \"1. Is it possible to not employ the agent or multi-agent metaphor to formulate the proposal? What is the truth power of the proposal? Is it a compossible and multi-step paradigm of stochastic optimization  based on 3 hand-crafted dimensions? \\n2. Ine line 161, what is the loss function l? Also please explain more regarding the definition of the reward function. How is it different o related to the loss function of LLM auto-regression loss or other kinds of losses (if any other).\\n3. In Algorithm 1, please clarify whether the sampling distribution of the data are different from iteration to iteration (line 3). \\n4. In line 275, 373M model is used in ablation study. It is pretty small a model. The conclusions drawn from it might not be transferrable to LLMs of billions of parameters. Please justify the study.\"}"}]}
{"paper_id": "pISLZG7ktL", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nData scaling has revolutionized fields like natural language processing and computer vision, providing models with remarkable generalization capabilities. In this paper, we investigate whether similar data scaling laws exist in robotics, particularly in robotic manipulation, and whether appropriate data scaling can yield single-task robot policies that can be deployed zero-shot for any object within the same category in any environment. To this end, we conduct a comprehensive empirical study on data scaling in imitation learning. By collecting data across numerous environments and objects, we study how a policy’s generalization performance changes with the number of training environments, objects, and demonstrations. Throughout our research, we collect over 40,000 demonstrations and execute more than 15,000 real-world robot rollouts under a rigorous evaluation protocol. Our findings reveal several intriguing results: the generalization performance of the policy follows a roughly power-law relationship with the number of environments and objects. The diversity of environments and objects is far more important than the absolute number of demonstrations; once the number of demonstrations per environment or object reaches a certain threshold, additional demonstrations have minimal effect. Based on these insights, we propose an efficient data collection strategy. With four data collectors working for one afternoon, we collect sufficient data to enable the policies for two tasks to achieve approximately 90\\% success rates in novel environments with unseen objects.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 8, \"Confidence\": 3, \"Strengths\": \"The paper is well written and easy to follow. The experiments are clear and the results are presented well. Insights into which data is most useful and how many demonstrations are required to solve a task are certainly very helpful. I particularly like that all experiments are executed on a real robot arm in reasonably cluttered environments.\", \"Weaknesses\": \"The analysis focuses mainly on two relatively simple tasks (pouring water and rearranging a computer mouse). While the paper would benefit from investigating more tasks and also including more challenging tasks, I am aware that it is quite an effort to set up additional experiments with real robots and collect large training sets.\\n\\nThe objects considered in the tasks are always objects of the same category (e.g., water bottles) and, thus, very similar. I believe that this is the reason why increasing the number of objects per environment in Figure 6 does not improve the task performance much. Essentially, the objects are always quite similar, while the environments differ quite significantly, and therefore, it is more important to collect data from more environments rather than with different objects in the same environment.\", \"Questions\": \"1. In Figure 6, sometimes increasing the number of objects per environment decreases the task performance quite considerably (e.g., right plot M=4). This seems quite counterintuitive. What could be the reason for this?\\n\\n2. What is exactly is the correlation coefficient r (e.g., line 380)?\\n\\n3. There are no standard deviations in the plots. Consider adding the standard deviations to make it easier to assess the empirical significance of the results.\\n\\n4. Caption 7: \\\"In the setting where we collect the maximum number of demonstrations, we examine whether the policy's performance follows a power-law relationship with the total number of demonstrations.\\\" I believe the first \\\"demonstrations\\\" should be something like \\\"environment-object combinations\\\".\\n\\n5. Line 47/48: \\\"[W]e aim to investigate the following fundamental question: Can appropriate data scaling produce robot policies capable of operating on nearly any object, in any environment\\\". In my opinion the statement that the paper investigates this fundamental problem is a bit too strong since the policies learn to manipulate only objects of the same category (e.g., water bottles) in environments with similar characteristics (tabletop environments), so these policies are quite far from handling any object in any environment.\"}"}]}
{"paper_id": "dML3XGvWmy", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThe rapid advancement of large language models (LLMs) has significantly enhanced the capabilities of AI-driven agents across various tasks. However, existing agentic systems, whether based on fixed pipeline algorithms or pre-defined meta-learning frameworks, cannot search the whole agent design space due to the restriction of human-designed components, and thus might miss the globally optimal agent design. In this paper, we introduce Gödel Agent, a self-evolving framework inspired by the Gödel machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. Gödel Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of Gödel Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 1, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 3, \"Strengths\": \"* The proposed method is conceptually simple and clear and provides and intriguing possibility of building self-improving agents with current LLM technology.\\n* The experiments include multiple benchmarks, a number of baselines and generally suggest strong results.\\n  * The authors run ablations of different components of their agent and find all of them improve performance.\\n* The qualitative analysis of the results is insightful and provides a good understanding of the strategies the self-improving agent implements.\", \"Weaknesses\": \"**Results**\\nI'm concerned about the presentation of the experiments and the **fairness of the empirical evaluation**. My key concerns are that the Godel agent uses significantly more inference compute than any of the other methods and that the description of the evaluation protocol is not sufficient to determine if the evalaution is fair.\\n\\nHere is my understanding of the evaluation setup (please correct me if I'm wrong):\\n* The Godel agent is run for N iterations on a validation set of samples. In each iteration is produces a new policy and a new learning function.\\n* After N iteration the policy is evaluated on held-out test problems and this result is reported.\\n\\nThis process gives the Godel agent significantly more inference compute than any of the hand-designed agent systems, which makes the comparison unfair. The only fair comparison in Table 1 is to Meta Agent Search which seems to typically be comparable in performance. Based on these results, I am not convinced the the Godel agent actually improves performance in a fair comparison.\\n\\nThis concern could be addressed by letting the baseline be a best-of-N method that applies N somewhat random perturbations to the policy and chooses the best of them. For example, this could be implemented by using GPT-4 to generate N different prompt variations and choose the best according to performance on the validation data.\\n\\nRelatedly, according to Appendix B the Godel agent uses GPT-4 for the learning algorithm but all methods only use GPT-3.5 for the policy. This makes the comparison additionally skewed in favor of the Godel agent which has access to GPT-4 in contrast to the other methods. A fair comparison would use GPT-4 for both the learning algorithm and the policy.\\n\\n\\n**Presentation**\\n\\nI also have some concerns about the presentation and framing of self-improving agents in the paper. The paper often uses the term \\\"self-awareness\\\" without qualification. I'm concerned that anthropomorphization leads to a less scientific discussions and I would recommend the authors try to rewrite the paper to remove phrases like \\\"Our Godel Agent achieves self-awareness\\\".\\n\\nMoreover, potential risks from self-improving AI are not appropriately discussed. There is a significant literature on risks from self-improving AIs and this is a key concern in the AGI safety community. I think this literature should be acknowledged in the paper and there should be a more complete discussion of broader impacts of this technique than currently the case.\", \"Questions\": \"**Clarification questions**: Please answer the following questions to help me better evaluate the paper.\\n\\n* Does the learning agent ever see the data the final policy will be evaluated on?\\n* For how many iterations do you run the Godel agent and how did you determine this hyperparameter?\\n* In general, how did you tune prompt variations and hyperparameters for this agent? How did you prevent overfitting to the test data?\\n* Could you please clarify the action space of the agent and how the agent learns about the possible interactions? Is it only given the prompt in Appendix A or is it also given few-shot samples for example?\\n* How does the agent execute the policy? Is this happening automatically each iteration, or does the agent manually chose to exit the policy? Is this different during iteration and during evaluation?\\n\\n**Concerns**: Addressing the following concerns would make me reconsider my score.\\n* Clarify the evaluation protocol.\\n* Justify the choice of having baselines that use less inference compute. Provide a best-of-n baseline or argue why this is not a good comparison.\\n* Clarify the comparison to Meta Agent Search and wheather your method produces qualitatively better solutions.\\n* Justify the choice to use GPT-3.5 for the policy models. If possible, provide some results using GPT-4 for the policies.\\n\\n**Overall assessment**\\nI'm intrigued by the premise of the paper, but quite concerned about the evaluation and reproducibility. If the authors can address my concerns and answer my questions, I'm willing to reconsider my score.\"}"}]}
{"paper_id": "xlxGsX1pc7", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nThe current evaluation of mathematical skills in LLMs is limited, as existing benchmarks are relatively small, primarily focus on elementary and high-school problems, or lack diversity in topics. Additionally, the inclusion of visual elements in tasks remains largely under-explored. \n\nTo address these gaps, we introduce **U-MATH**, a novel benchmark of \\textbf{1,100} unpublished open-ended university-level problems sourced from teaching materials. It is balanced across six core subjects, with  \\textbf{20\\% of multimodal problems}. Given the open-ended nature of U-MATH problems, we employ an LLM to judge the correctness of generated solutions. To this end, we release **$\\boldsymbol\\mu$-MATH**, an dataset to evaluate the LLMs' capabilities in judging solutions.\n\nThe evaluation of general domain, math-specific, and multimodal LLMs highlights the challenges presented by U-MATH. Our findings reveal that LLMs achieve a maximum accuracy of only 63\\% on text-based tasks, with even lower 45\\% on visual problems. The solution assessment proves challenging for LLMs, with the best LLM judge having an F1-score of 80\\% on $\\mu$-MATH.\n    \nWe open-source U-MATH, $\\mu$-MATH, and evaluation code on GitHub.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 5, \"Confidence\": 4, \"Strengths\": \"The paper demonstrates a high-quality collection of problems that are well-balanced across six core mathematical subjects. This ensures a comprehensive evaluation of LLMs across different areas of mathematics.\\nThe problems sourced from actual teaching materials add a layer of authenticity and practical relevance to the benchmark, ensuring that the skills assessed are applicable to real-world academic standards.\\nThe creation of µ-MATH for meta-evaluation is an innovative approach to assessing the ability of LLMs to evaluate mathematical solutions. This adds another layer of complexity and originality to the benchmarking process, focusing not just on problem-solving but also on the assessment capabilities of the models.\", \"Weaknesses\": \"While the inclusion of visual elements in 20% of the problems is a step forward, the remaining 80% are text-based. The paper could benefit from expanding the visual problem set to better assess and train LLMs in multimodal mathematical reasoning, which is increasingly important for real-world applications.\\n\\nThe paper focuses on university-level mathematics, but it is unclear how well the findings generalize to other levels or types of mathematical reasoning. Future work could explore the transferability of the models trained on U-MATH to other mathematical domains.\", \"Questions\": \"Why are there no examples of problems that require visual input?\\n\\nThe accuracy when using LLM as a judge is not provided, especially for higher mathematics problems where answers may be in different forms but are actually equivalent, indicating that it is easier to make mistakes compared to comparing a single form of answer.\"}"}]}
{"paper_id": "AjXkRZIvjB", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nRecent advancements in Large Language Models (LLMs) have sparked interest in their formal reasoning capabilities, particularly in mathematics. The GSM8K benchmark is widely used to assess the mathematical reasoning of models on grade-school-level questions. While the performance of LLMs on GSM8K has significantly improved in recent years, it remains unclear whether their mathematical reasoning capabilities have genuinely advanced, raising questions about the reliability of the reported metrics. To address these concerns, we conduct a large-scale study on several state-of-the-art open and closed models. To overcome the limitations of existing evaluations, we introduce GSM-Symbolic, an improved benchmark created from symbolic templates that allow for the generation of a diverse set of questions. GSM-Symbolic enables more controllable evaluations, providing key insights and more reliable metrics for measuring the reasoning capabilities of models. Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically, the performance of all models declines when only the numerical values in the question are altered in the GSM-Symbolic benchmark. Furthermore, we investigate the fragility of mathematical reasoning in these models and demonstrate that their performance significantly deteriorates as the number of clauses in a question increases. We hypothesize that this decline is due to the fact that current LLMs are not capable of genuine logical reasoning; instead, they attempt to replicate the reasoning steps observed in their training data. When we add a single clause that appears relevant to the question, we observe significant performance drops (up to 65%) across all state-of-the-art models, even though the added clause does not contribute to the reasoning chain needed to reach the final answer. Overall, our work provides a more nuanced understanding of LLMs' capabilities and limitations in mathematical reasoning.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 3, \"Confidence\": 4, \"Strengths\": \"- The study provides empirical evidence of the performance variance and fragility of LLMs when faced with different question instantiations and increased complexity in grade school math questions.\\n- The introduction of the GSM-Symbolic benchmark allows for the creation of diverse instances of the GSM8K dataset, which helps avoid data contamination and enables a more comprehensive evaluation of LLMs' reasoning capabilities.\", \"Weaknesses\": \"- The findings largely reconfirm known limitations of LLMs, such as their reliance on probabilistic pattern-matching and sensitivity to small changes in question statements, which have been explored in depth in previous works, notably in \\\"Are NLP Models really able to Solve Simple Math Word Problems?\\\"\\n- The methods used to curate the dataset, such as altering numerical values and adding irrelevant information, are not novel and have been employed in other studies, such as \\\"PAL: Program-aided Language Models,\\\" which introduces GSM8k-hard.\\n- The paper uses ambiguous terms like \\\"true logical reasoning,\\\" \\\"genuine mathematical reasoning,\\\" and \\\"formal [reasoning] in the common sense term\\\" without providing clear definitions of these terms.\\n- The paper’s findings on performance degradation with increasing question complexity have been similarly explored in other works as compounding errors in multi-step reasoning processes.\\n- The authors suggest that  performance of LLMs on GSM-Symbolic compared to their performance on GSM8k indicates significant limitations in LLMs’ ability to perform genuine mathematical reasoning. However,  performance of GPT4-o remains robust on GSM-Symbolic, as shown in figure 3, suggesting that the performance variance resulting from different numerical instantiation of the questions may be resolved with scaled training or model size and this limitations may not be inherent to all LLMs.\", \"Questions\": \"1. Can you clearly define \\\"true logical reasoning\\\"? What conditions need to be satisfied for a language model to demonstrate true logical reasoning?\\n2. Why was the performance of o1 not investigated in certain parts of the study, such as in Figure 3?\\n3. Given that some models like GPT4-o show robustness across numerical changes, do the authors believe that scaled training and model size can alleviate the identified limitations? If so, how does this impact the generalizability of the findings?\"}"}]}
{"paper_id": "IJiTI0fB0e", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nText-conditioned generation models are commonly evaluated based on the quality of the generated data and its alignment with the input text prompt. On the other hand, several applications of prompt-based generative models require sufficient diversity in the generated data to ensure the models' capability of generating image and video samples possessing a variety of features. However, the existing diversity metrics are designed for unconditional generative models, and thus cannot distinguish the diversity arising from variations in text prompts and that contributed by the generative model itself. In this work, our goal is to quantify the prompt-induced and model-induced diversity in samples generated by prompt-based models. Specifically, we propose the application of matrix-based information measures to address this task, decomposing the kernel-based entropy $H(X)$ of generated data $X$ into the sum of conditional entropy $H(X|T)$, given text variable $T$, and mutual information $I(X; T)$. We show that this information-theoretic approach decomposes the existing Vendi diversity score defined based on $H(X)$ into the product of the following two terms: 1) Conditional-Vendi score based on $H(X|T)$ to quantify the model-induced diversity, and 2) Information-Vendi score based on $I(X; T)$ to measure the statistical relevance between $X$ and prompt $T$. Our theoretical results provide an interpretation for this diversity quantification and show that the Conditional-Vendi score aggregates the Vendi scores within the modes of a mixture prompt distribution. We conduct several numerical experiments to show the correlation between the Conditional-Vendi score and the internal diversity of text-conditioned generative models.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 1, \"Rating\": 3, \"Confidence\": 3, \"Strengths\": \"* The idea is sound to separate different sources of diversity, i.e., prompt-induced and model-induced.\\n* The proposed diversity metric is reasonable for model-induced diversity, and have the advantage that do not need repeated sampling from a single prompt.\", \"Weaknesses\": \"The main weakness of this paper is its contribution. The proposed condtional-Vendi and information-Vendi score are just exponentials of the conditional entropy and mutual information defined by Sanchez Giraldo et al. (line 241, 246), and the calculation method seems to directly inherit from Vendi proposed by Friedman & Dieng (line 317). The combination is straightforward and I did not find any new challenges that is addressed by this paper. As a result, I view this paper as just an incremental work, and not enough for acceptance.\", \"Questions\": \"1. What's new of your conditional-Vendi compared with the conditional entropy proposed by Sanchez Giraldo et al., besides the exponential?\\n2. Follow which equation can the conditional-Vendi score be calculated? It's better to write an explicit algorithm, perhaps in the appendix.\\n3. What do you want to convey by Section 5 (the statistical interpretations)? Is it discussing the implementations, or just broader discussions? A better leading sentence may be necessary in the beginning.\"}"}]}
{"paper_id": "fs2Z2z3GRx", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nDiffusion and flow matching models have been recently used to solve various linear inverse problems such as image restoration. Using a pre-trained diffusion or flow-matching model as a prior, most existing methods modify the reverse-time sampling process by incorporating the likelihood information from the measurement. However, they struggle in challenging scenarios, e.g., in case of high measurement noise or severe ill-posedness. In this paper, we propose Flow with Interpolant Guidance (FIG), an algorithm  where the reverse-time sampling is efficiently guided with measurement interpolants through theoretically justified schemes. Experimentally, we demonstrate that FIG efficiently produce highly competitive results  on a variety of linear image reconstruction tasks on natural image datasets. We improve upon state-of-the-art baseline algorithms, especially for challenging tasks. Code will be released.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"The idea of measurements interpolants seems intuitively good and is clearly supported by the experiments (with state of the art performance especially in very challenging cases).\\nThe authors also introduce the background in both flow matching and diffusion models, and provide some theoretical proof that the proposed method is valid given that Assumption 1 holds.\\nThe proposed method in essence is quite simple and easy to implement (as a change to existing uses of pre-trained flow matching or diffusion models).\", \"Weaknesses\": \"The presentation could be improved to explain much more clearly the motivation behind FIG.\\nWhat are the issues that other methods could not address and that FIG does address? \\nMy current understanding is that one _can_ condition on the measurement interpolants and then in the conclusions there is a comment that it is easier to create the interpolants than to denoise the signal.\\nI would suggest to include a specific subsection that explains:\\n1) What limitations exist in how other methods condition on measurements\\n2) How measurement interpolants address those limitations\\n3) Why conditioning on interpolants is theoretically or empirically advantageous\\n\\nIt would then be necessary to demonstrate in the experiments how these limitations are not addressed\\nby other methods but are addressed by FIG.\", \"Questions\": \"1) I would like to know the motivation for the measurement interpolants. I have an intuition of why they are used, but I could not find that in the paper and I would like the authors to explain; More precisely, I am asking what was wrong with the conditioning of other methods and how this new approach makes that right.\\n2) I would like to have an explanation for what each of the theorems contributes. Possibly this is connected to the previous point. I suggest to 1) add a brief paragraph after each theorem explaining its practical implications; 2) include a discussion subsection that ties together how the theorems collectively justify or enable the proposed method; 3) provide intuitive explanations or examples to complement the formal mathematical statements.\"}"}]}
{"paper_id": "H4FSx06FCZ", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\n3D Gaussian splatting (3DGS) has emerged as a premier method for 3D representation due to its real-time rendering and high-quality outputs, underscoring the critical need to protect the copyright and privacy of 3D assets. Traditional NeRF steganography methods fail to address the explicit nature of 3DGS since its point cloud files are publicly accessible. Existing GS steganography solutions mitigate some issues but still struggle with reduced rendering fidelity, increased computational demands, and security flaws, especially in the security of the geometric structure of the visualized point cloud. To address these challenges, we propose a SecureGS, a secure and efficient 3DGS steganography framework inspired by Scaffold-GS's anchor point design and neural decoding. SecureGS utilizes a hybrid decoupled Gaussian encryption mechanism to embed offsets, scales, rotations, and RGB attributes of the hidden 3D Gaussian points within anchor point features, retrievable only by authorized users through privacy-preserving neural networks. To further enhance security, we propose a density region-aware anchor growing and pruning strategy that adaptively locates optimal hiding regions without exposing hidden information. Extensive experiments demonstrate that SecureGS significantly surpasses existing GS steganography methods in rendering fidelity, speed, and security, effectively concealing and accurately extracting 3D objects, images, and bits within original 3D scenes.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 4, \"Contribution\": 4, \"Rating\": 8, \"Confidence\": 4, \"Strengths\": \"(+) Previous steganography lacks a strategy for the explicit point cloud from 3DGS. The paper introduces an interesting and original approach to 3DGS steganography, emphasizing security and fidelity. This innovative framework could pave the way for advancements in the field, inspiring further research into secure 3D content transmission.\\n\\n(+) Overall, this paper is well-written and has a logical structure. The motivation and contributions are clearly articulated, making it accessible to readers. The figures and diagrams effectively illustrate complex concepts, enhancing reader comprehension.\\n\\n(+) The authors conduct comprehensive experiments that validate the generalizability and effectiveness of the proposed method across various scenarios. These experiments demonstrate the method's superiority and provide valuable insights into its practical applicability in different contexts.\", \"Weaknesses\": \"(-) The proposed methods, particularly the hybrid encryption and optimization strategies, may introduce complexity that could hinder practical adoption. This complexity might deter practitioners who require straightforward solutions for embedding and retrieving hidden information.\\n\\n(-) The enhancements in security and fidelity may come at the cost of increased computational requirements, which could limit real-time applications. If the computational demands are too high, they may negate the benefits of improved rendering fidelity in time-sensitive environments.\\n\\nMinor suggestions:\\n\\nMore vspace between Line 65 and Line 66.\", \"Questions\": \"1.\\tHow does SecureGS compare to traditional steganography methods in terms of computational efficiency and resource requirements?\\n\\n2.\\tWhat specific measures have you taken to ensure the robustness of your method against various types of attacks or degradation, especially in practical deployment scenarios?\\n\\n3.\\tGiven the complexity of the proposed methods, how do you envision simplifying the implementation for practitioners who may lack advanced technical expertise in 3D steganography?\"}"}]}
{"paper_id": "OGtUfA6Amo", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nMulti-scale information is crucial for multivariate time series modeling. However, most existing time series multi-scale analysis methods treat all variables in the same manner, which is not well adaptive to Irregular Multivariate Time Series (IMTS), where different variables have distinct original scales/sampling rates. Therefore, extracting temporal and inter-variable dependencies at multiple scales\nin IMTS remains challenging. To fill this gap, we propose a hierarchical patch graph network Hi-Patch. The key components of Hi-Patch are an intra-patch graph layer and several inter-patch graph layers. The intra-patch graph layer flexibly represents and fully captures both the local temporal and inter-variable dependencies of densely sampled variables at the original scale by employing fully connected graph networks within each patch, and obtains patch-level node representations through aggregation. Subsequently, several inter-patch graph layers are stacked to form a hierarchical architecture, where each layer updates specific patch-level nodes through scale-specific graph networks, progressively representing and extracting more global temporal and inter-variable features of both sparsely and densely sampled variables, and further aggregating to produce the next patch-level node representations. The output of the last inter-patch graph\nlayer is fed into task-specific decoders to adapt to different downstream tasks. Experimental results on 8 datasets show that Hi-Patch outperforms a range of state-of-the-art models in both IMTS forecasting and classification tasks. Code is available at this repository: https://anonymous.4open.science/r/Hi-Patch-F42E.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. This paper effectively integrates a patch strategy with a graph network in a hierarchical architecture, successfully addressing the challenges posed by irregularly sampled time series.\\n\\n2. The designed hierarchical architecture effectively models multi-scale features from fine-grained to coarse-grained.\\n\\n3. Experimental results validate the superior performance of the proposed model across eight datasets.\", \"Weaknesses\": \"1. The proposed model overlooks missing values, which may result in significant information loss. Additionally, the entanglement of spatial and temporal correlation modeling may increase the training complexity of the model.\\n\\n2. The presentation of core functional modules is mainly based on text description accompanied by snippets of equations that only show the intermediate transformation steps whereas the whole picture is lost. The authors are supposed to provide a precise mathematical description of the entire data transformation process, i.e., how the inputs are transformed into the output step by step. \\n\\n3. A complexity analysis of the proposed model, as well as comparisons with other baselines, should be included.\", \"Questions\": \"1. The framework of the Hi-Patch, as illustrated in Figure 2, is not easily understood.\\n\\n2. The references should follow a uniform style.\"}"}]}
{"paper_id": "ujpAYpFDEA", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nText watermarking for Large Language Models (LLMs) has made significant progress in detecting LLM outputs and preventing misuse. Current watermarking techniques offer high detectability, minimal impact on text quality, and robustness to text editing. \n    However, current researches lack investigation into the imperceptibility of watermarking techniques in LLM services.\n    This is crucial as LLM providers may not want to disclose the presence of watermarks in real-world scenarios, as it could reduce user willingness to use the service and make watermarks more vulnerable to attacks. This work is the first to investigate the imperceptibility of watermarked LLMs. We design an identification algorithm called Water-Probe that detects watermarks through well-designed prompts to the LLM. Our key motivation is that current watermarked LLMs expose consistent biases under the same watermark key, resulting in similar differences across prompts under different watermark keys. Experiments show that almost all mainstream watermarking algorithms are easily identified with our well-designed prompts, \n    while Water-Probe demonstrates a minimal false positive rate for non-watermarked LLMs. \n    Finally, we propose that the key to enhancing the imperceptibility of watermarked LLMs is to increase the randomness of watermark key selection. Based on this, we introduce the Water-Bag strategy, which significantly improves watermark imperceptibility by merging multiple watermark keys.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 3, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"- **Accuracy and Robustness**: The experimental results demonstrate the high accuracy and robustness of the Water-Probe algorithm across various LLMs, watermarking methods, and generation settings. The low false positive rate for non-watermarked LLMs further strengthens the algorithm’s reliability.\\n- **Practical Solution**: The proposed Water-Bag strategy offers a practical solution to improve the imperceptibility of watermarks, which is a critical concern for LLM providers.\", \"Weaknesses\": \"- **Concept Confusion**: The manuscript mislead concept of watermarking and fingerprinting, the proposed method should be categorized into fingerprinting instead of watermarking. see Question 1.\\n- **Lack of Controbution**: The authors inputs prompts to see the response of watermarked LLM and non-watermarked LLM, which is so called identification algorithm. The manuscript just defeines some concept, samples prompt to see similarity of the inspected models. \\n- **Limited Scope of Water-Probe**: The Water-Probe algorithm might be limited in its application to only certain types of watermarking schemes. The paper does not sufficiently explore how the algorithm would perform against a wider range of watermarking techniques, especially those that are more sophisticated or less predictable.\", \"Questions\": \"- **Concept Confusion**: the authors mislead watermarking concept.\\nLLM Watermarking is the process of injecting a invisible identifier into LLM, track unauthorized distribution, or indicate authenticity, withch contains two steps **injection** and **detection**. The author just talk about how to identify LLM output consistency, I never see any discussion about watermark injection in paper. The authors should clarify how their work relates to the injection and detection steps they have outlined, or explain why their approach focuses solely on identification without addressing injection.\\n\\n- **Unknown Key Sampling Strategy**: the author propose the watermark identification method using setected prompts.\\nStep 1-3 only discuss the object of identification key sampling, never talk about the detail of identification key sampling.\\n\\n- **Method Designed**: The author says “Research on the imperceptibility of watermarked LLMs should investigate whether watermarked and non-watermarked LLMs can be distinguished.”. However, in this paper, I never see the sampled prompts and identification method can solve this problem. The authors should clearly illustrate how the proposed method differentiates between watermarked and non-watermarked LLMs. I recommend including a specific experiment or analysis that directly addresses this assertion.\"}"}]}
{"paper_id": "7UKHNQIErp", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nRecent direct preference alignment algorithms (DPA), such as DPO, have shown\ngreat promise in aligning large language models to human preferences. While this has motivated the development of many new variants of the original DPO loss, understanding the differences between these recent proposals, as well as developing new DPA loss functions, remains difficult given the lack of a technical and conceptual framework for reasoning about the underlying semantics of these algorithms. In this paper, we attempt to remedy this by formalizing DPA losses in terms of discrete reasoning problems. Specifically, we ask: Given an existing DPA loss, can we systematically derive a symbolic expression that characterizes its semantics? How do the semantics of two losses relate to each other? We propose a novel formalism for characterizing preference losses for single model and reference model based approaches, and identify symbolic forms for a number of commonly used DPA variants. Further, we show how this formal view of preference learning sheds new light on both the size and structure of the DPA loss landscape, making it possible to not only rigorously characterize the relationships between recent loss proposals but also to systematically explore the landscape and derive new loss functions from first principles. We hope our framework and findings will help provide useful guidance to those working on human AI alignment.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 4, \"Presentation\": 4, \"Contribution\": 4, \"Rating\": 8, \"Confidence\": 3, \"Strengths\": \"- **S1:** Precise related work.\\n- **S2:** Strong mathematical formulation, which I greatly enjoyed.\\n- **S3:** New perspective on neural-symbolic interplay.\\n- **S4:** Great presentation and structure of the work.\", \"Weaknesses\": \"- **W1:** Given my unfamiliarity with the literature on DPA and similar, there seem to be exponential blowups. For example, to compute Eq 2, the weighted model counting must enumerate all $2^n$ propositional models ($\\\\mathbf{w}$).\\n- **W2:** I would have given more context around the notation $y_w \\\\succ y_l$ for those unfamiliar with the literature like me. I have interpreted $\\\\succ$ as \\\"the winner is preferred to the looser\\\", but again, this may be the wrong interpretation. Either way, please clarify.\\n- **W3:** Some references are wrong. For instance, the reference to Table 7 does not exist in line 416; maybe it should be Table 5 (from the Appendix). Similarly, the caption of Table 4 references Algorithm 5.1, but 5.1 is a Section.\\n\\nMinors:\\n- line 176: an a variant --> and a variant\\n- line 385 (and similar): Before the proposition's statement, the notation does not use parentheses around the superscripts, while the statement uses them (also in the Appendix). Please fix it for better readability.\\n- line 390: prefrence --> preference\\n- line 476: CEUNL --> CEUnl\\n- line 482: is much to learned by --> is much to *be* learned by?\\n- line 522: exactly these the losses --> exactly the losses?\\n- line 728: Table 5 is referred to in the proof, but Table 5 is the one with the translation rules\\n   - As a meta-observation, double-check all the other references (`\\\\ref{}`). Some are okay, but some are not (and I tried to point to some of those).\", \"Questions\": \"- **Q1:** I didn't get the number 4 in the double exponential form, i.e. $4^{2^n}$. Could you please be more specific or provide more context?\\n- **Q2:** Algorithm 1 uses \\\"Simplify\\\" to minimize (propositional formulas). As far as I am aware, the problem of minimizing propositional (logic) formulas by preserving equivalence is NP-hard. Thus, am I missing something here? Please clarify.\"}"}]}
{"paper_id": "CpgWRFqxhD", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Below are example prompts & responses:\n\nEXAMPLE 1 (USER):\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nSub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by natural language can achieve significant performance improvement and reduction of performance instability under sub-population shifts.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON.\n\nEXAMPLE 1 (ASSISTANT):\n{\"Soundness\": 3, \"Presentation\": 4, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The paper proposes an effective framework for debiasing subgroup information using aligned representations from Vision Transformers (ViT), which improves the subgroup robustness. This work could inspire future research in this domain.\\n2. The evaluation is comprehensive and systematic, showcasing effectiveness across multiple datasets and metrics, and providing a comparison with several state-of-the-art baselines. The Table 4 analysis of (dis)alignment within subgroups between the source and target is both innovative and inspiring.\\n3. The paper is well-organized and clearly presented.\", \"Weaknesses\": \"1. I’m concerned about the innovation w.r.t. proposing a new strategy for subgroup robustness. The concept of gaining robustness from language modality to enhance another is not novel [1], and the idea of learning debiased representations—where domain predictability is removed and task predictability is emphasized—is fairly common. \\n2.  While the method is motivated by the general notion that aligned representations from multimodal models can share robustness, the algorithm is restrictive — It primarily facilitates the use of text prompts to learn the debiased representation adapter for improved classification. Extending the algorithm to incorporate other combinations of modalities may be challenging, particularly for modalities where designing debiasing prompts (e.g., in vision) might be difficult.\", \"Questions\": \"1. Can L-DRO be adapted for combinations of modalities other than vision and language, or does the methodology intrinsically require assistance from the language modality?\\n2. Table 4 offers interesting insights. In the rows where the source and target are misaligned, the average accuracy is comparable to that of a zero-shot scenario, however, there is a significant divergence in worst-case accuracy. Does this suggest other subgroups are either adversely affected or disproportionately benefited (so that the average scores can remain similar)? Does this imply that the algorithm still works with other influential attributes even if they are not directly related to the target domain?\"}\n\n-----\n\nNOW PLEASE DO THE SAME FOR THIS NEW PAPER BELOW.\n\nPlease read the following paper abstract and produce reviewer scores.\n\n--- PAPER ABSTRACT ---\n\nAdvances in video diffusion models have unlocked the potential for realistic audio-driven talking video generation. However, it is still highly challenging to ensure seamless audio-lip synchronization, maintain long-term identity consistency, and achieve natural expressions aligned with the audio in generated talking videos. To address these challenges, we propose **M**emory-guided **EMO**tion-aware diffusion (MEMO), an end-to-end audio-driven portrait animation approach to generate identity-consistent and expressive talking videos. Our approach is built around two key modules: (1) a memory-guided temporal module, which enhances long-term identity consistency and smooth motion by developing memory states that store information from all previously generated frames and guide temporal modeling through linear attention; and (2) an emotion-aware audio module, which replaces traditional cross attention with multi-modal attention to enhance audio-video interaction, while detecting emotions from the audio to refine facial expressions via emotion adaptive layer norm. Moreover, MEMO is trained on a large-scale, high-quality dataset of talking head videos without relying on facial inductive biases such as face landmarks or bounding boxes. Extensive experiments demonstrate that MEMO generates more realistic talking videos across a wide range of audio types, surpassing state-of-the-art talking video diffusion methods in human evaluations in terms of emotion-audio alignment, identity consistency and overall quality, respectively.\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1–4):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1–10):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1–5):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 3, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1) An improvement over current diffusion-based talking face generation methods. Memory-guided temporal module is the main novelty. The multimodal attention module (combining the representations of audio and video), and the emotion-adaptive layer norm further add to the novelty. All along authors use already existing successful methods like Linear Attention, Adaptive Normalization, classifier-free guidance, rectified flow loss etc to make their work efficient and better.\\n2) Dynamic past frame training is an intelligent approach to adapt to longer past frames during inference.\\n3) Effort to filter the datasets using a new data processing pipeline and merging of emotion labels is appreciated. Talking face datasets with emotion labels are limited, and every dataset has some biases. So combining these datasets and filtering them can be really helpful in the training process. \\n4) Paper has a strong evaluation on Out-of-distribution dataset against relevant methods.\\n5) Ablation of classifier-free guidance for amount of emotion incorporation is interesting.\\n6) Supplementary material contains impressive results, especially on singing.\", \"Weaknesses\": \"1. Paper claims that emotion \\\"dynamically detected emotion from audio\\\" is always better than \\\"static emotion labels\\\". Accuracy of emotion-classifier used will implicitly determine the quality of talking face generation, no such problem exist with using emotion labels. Moreover If you have want a talking video with emotion different from the audio available, then static emotion label can be a better choice.\\n2.  Evaluation metric to analyze the emotion incorporation is missing (something like matching emotions detected from audio input and video generated).\\n3. Results included in supp. material are impressive in singing and english-audio, but when the audio-language is not english, methods like EchoMimic seem to generate better video.\\n4. Computational analysis can be included for inference speed and memory. It can be really useful for method's applications.\", \"Questions\": \"1. Will you make the dataset public? That will be helpful for community.\\n2. Please compare with more emotion-ware methods in the evaluation to better judge the emotion incorporation.\\n3. Its guessable from the paper that \\\"how emotion is included in adaptive layer norm\\\", Still including the exact method/equation will be helpful.\"}"}]}
