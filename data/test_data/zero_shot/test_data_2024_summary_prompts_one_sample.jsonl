{"paper_id": "Yp01vcQSNl", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Directed graphs are crucial for representing various real-world relationships such as social networks and paper citations. Traditionally, graph neural networks (GNNs) have been applied to these datasets to learn node and edge encodings. However, conventional graph transformers, which can potentially outperform GNNs due to their flexible attention mechanism, often fail to incorporate edge directionality effectively. Existing methods frequently rely on the static adjacency matrix or local computations, which do not fully exploit the potential of dynamic attentional relations that can be developed with transformers.\nGap: Current graph transformer architectures largely ignore or inadequately handle edge directionality, undermining their applicability to directed graphs. The core limitation is their reliance on structural assumptions like static adjacency matrices, which restrict their ability to leverage edge directions flexibly in learning tasks.\nHypothesis: The main hypothesis is that a graph transformer architecture that explicitly accounts for edge directionality using dual encodings and dynamic attention mechanisms can significantly enhance performance on learning tasks for directed graphs.\nMethod: The proposed method, Directed Graph Transformer (DiGT), introduces dual encodings representing each node's source and target role in directed edges. These are learned dynamically using a multi-head directional attention mechanism without relying on explicit graph structure. The DiGT leverages a novel attention matrix interpretable as a latent adjacency matrix, incorporating edge channels as a bias and focusing on k-hop neighborhood localization. DiGT also includes techniques to mask attention matrices based on k-hops and combines multiple heads to achieve final predictions. Additionally, the paper explores alternative ways to incorporate directionality into existing graph transformer architectures.\nConclusion: DiGT outperforms state-of-the-art models in graph learning when directionality is a key component, demonstrating that capturing the directional aspect of edges is crucial for certain directed graph datasets. The experiments on new directed graph datasets designed specifically where edge directionality is important further validate the effectiveness and promise of DiGT.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 3, \"Presentation\": 2, \"Contribution\": 2, \"Rating\": 6, \"Confidence\": 4, \"Strengths\": \"Strong Points:\\n- Dual node encodings in DiGT elegantly capture directionality throughout the model.\\n- Directional attention neatly exploits query/key asymmetry for modeling direction.\\n- DiGT significantly outperforms baselines on directional graphs.\\n- Quantifies dataset directionality via entropy measure.\\n- New directional graph datasets enable better evaluation, although it may be biased in the context of this work.\", \"Weaknesses\": \"Weaknesses and\", \"Questions\": \"included together with weaknesses\"}"}]}
{"paper_id": "LndMyiBl3n", "messages": [{"role": "system", "content": "You are a helpful assistant that extracts a structured summary from a paper. Please return only valid JSON with the following fields:\nSoundness, Presentation, Contribution, Rating, Confidence (all integers)\nStrengths, Weaknesses, and Questions (all strings).\nNo additional keys. No extra text."}, {"role": "user", "content": "Please read the following paper summary and produce reviewer scores.\n\n--- PAPER SUMMARY ---\n\nBackground: Graph Neural Networks (GNNs) have become popular across various applications. Despite their success, GNNs are vulnerable to adversarial attacks that involve structural modifications, i.e., adding or deleting edges. This vulnerability has led to the development of different types of attacks, categorized based on the attacker's knowledge (white-box, grey-box, black-box). The most strict setting is the restricted black-box attack (RBA), where attackers know only the node features and graph structure, not labels or model parameters.\nGap: Most previous studies on graph adversarial attacks assume conditions like low-rank node embeddings or graph homophily, which limits their applicability, especially for heterophilic graphs. Heterophilic settings, where nodes of different classes are more likely connected, pose a unique challenge for existing models since they often rely on the homophily assumption.\nHypothesis: The authors propose that evaluating the quality of graphs using a modified silhouette score (MSS) can effectively guide attacks under the RBA setting. MSS aims to serve as a more generalizable approach across graphs with varying levels of homophily and heterophily.\nMethod: The authors introduce SheAttack, guided by a Modified Silhouette Score (MSS) that evaluates the quality of node embeddings within graphs. MSS is calculated based on intra-class and inter-class distances, generalized by replacing the minimal inter-class distance with an average, thus widening the objective's scope. SheAttack employs Greedy Randomized Block Coordinate Descent to optimize edge perturbations guided by MSS, providing scalable computations and effectiveness across different graph settings without prior label or model knowledge.\nConclusion: SheAttack demonstrates strong performance in degrading GNNs across homophilic and heterophilic graphs, comparable to white-box attacks without relying on additional split information. It is efficient and scalable, achieving success without prior knowledge of node labels or victim models, and adapts to both poisoned and evasion settings effectively.\n\n\n--- REQUIRED CATEGORIES ---\nWe need the following fields in the output:\n1) Soundness\n2) Presentation\n3) Contribution\n4) Rating\n5) Confidence\n6) Strengths\n7) Weaknesses\n8) Questions\n\n--- POSSIBLE VALUES & DEFINITIONS ---\n\nSoundness, Presentation, and Contribution (1\u20134):\n- 1: poor\n- 2: fair\n- 3: good\n- 4: excellent\n\nRating (1\u201310):\n- 1: Trivial or wrong\n- 2: Strong rejection\n- 3: Clear rejection\n- 4: Ok but not good enough - rejection\n- 5: Marginally below acceptance threshold\n- 6: Marginally above acceptance threshold\n- 7: Good paper, accept\n- 8: Top 50% of accepted papers, clear accept\n- 9: Top 15% of accepted papers, strong accept\n- 10: Top 5% of accepted papers, seminal paper\n\nConfidence (1\u20135):\n- 1: The reviewer's evaluation is an educated guess\n- 2: The reviewer is willing to defend the evaluation, but might be wrong\n- 3: The reviewer is fairly confident that the evaluation is correct\n- 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n- 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the topic\n\n--- OUTPUT FORMAT ---\nPlease produce only a JSON object with this exact structure (no extra keys):\n{\n  \"Soundness\": <int>,\n  \"Presentation\": <int>,\n  \"Contribution\": <int>,\n  \"Rating\": <int>,\n  \"Confidence\": <int>,\n  \"Strengths\": \"<string>\",\n  \"Weaknesses\": \"<string>\",\n  \"Questions\": \"<string>\"\n}\n\nNo explanations or markdown formatting. Only valid JSON."}, {"role": "assistant", "content": "{\"Soundness\": 2, \"Presentation\": 2, \"Contribution\": 3, \"Rating\": 6, \"Confidence\": 3, \"Strengths\": \"1. The studied restricted black-box attack is a practical scenario and an important problem.\\n2. The motivation of this paper is clear and the idea of introducing the Silhouette Score to measure the quality of a graph is interesting.\\n3. Extensive experiments are conducted.\", \"Weaknesses\": \"1. The proposed SheAttack depends on various hyper-parameters, which may significantly affect the performance of the proposed method and lack detailed theoretical support or empirical analysis. For example, the number of clusters $k$, the propagation layer/time on the adjacency matrix, and the $\\\\lambda$ that balance the Shift Loss and Silhouette Score-based Loss. \\n2. The proposed method does not seem to be consistently effective in all scenarios in Tables 1&3.\\n3. The writing of this paper needs to be further improved. For example, the citation format of references in Introduction and Preliminaries seems strange. 'Aggreation function' should be 'Aggregation function\u2019. The definition of poison attacks and evasion attacks on page 3 is confusing.\", \"Questions\": \"1. In Figure 3, why do GRBCD and RandAttack show different Modified Silhouette Score at epoch 0?\\n2. How would the proposed method perform when the victim model is not a two-layer GNN? In other words, when the propagation layers/times in the proposed method and victim model are not the same, would the proposed method still be effective?\"}"}]}
