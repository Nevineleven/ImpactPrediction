{"paper_id": "B0OwtVEejJ", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper bridges two previously independent sub-communities in NAS, introducing a novel integration scheme that allows gradient-based methods to operate in weight-entangled spaces with several advantages.", "Weaknesses": "The abstract does not provide detailed empirical results or specific comparative metrics, making it difficult to fully assess the impact and effectiveness of the proposed method.", "Questions": "How does the proposed method quantitatively compare to existing approaches in terms of performance and efficiency? Are there specific datasets or tasks where the method particularly excels or falls short?"}}
{"paper_id": "ZlEtXIxl3q", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 3, "Strengths": "The paper introduces a novel approach using contrastive loss functions, such as the Bradley-Terry loss, to effectively extract sparse latent functions in global epistasis models, achieving improved performance over traditional MSE loss methods. The methodology is tested and validated on benchmark tasks, showing practical utility.", "Weaknesses": "The presentation could be improved to better elucidate the technical aspects and make it more accessible to a broader audience. Details on experimental settings and comparisons could be more thorough.", "Questions": "Can the authors provide more insights into the specific datasets and benchmarks used for validation? How does the performance of contrastive losses compare with other possible loss functions in different scenarios?"}}
{"paper_id": "6yJuDK1DsK", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces FEATHER, a novel and lightweight approach for lifelong TTA that improves efficiency by keeping most of the source model parameters frozen and adapting only a small number of additional parameters. It eliminates the need for source data during test-time adaptation and can be combined with other approaches for parameter efficiency. Extensive experiments demonstrate its performance benefits.", "Weaknesses": "The method's performance on benchmarks could be further explored in more diverse real-world scenarios beyond the tested CIFAR and ImageNet datasets.", "Questions": "How does FEATHER perform in terms of computational cost and memory usage in comparison to other lifelong TTA methods when deployed on edge devices?"}}
{"paper_id": "lt6xKGGWov", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach to feature selection that considers subsets of features as ensembles, potentially capturing complex interactions between features and targets.", "Weaknesses": "The abstract lacks specific details about the method's implementation and the comparative evaluation against existing methods.", "Questions": "How does the proposed feature selection method compare empirically with other established methods in terms of accuracy and computational efficiency?"}}
{"paper_id": "Bvrc6kobWd", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides a novel perspective on gradient analysis for margins in contrastive learning, backed by experimental results that demonstrate improvements in both seen and unseen datasets.", "Weaknesses": "The paper could explore more applications of margins across other domains besides face and speaker recognition to demonstrate the generality of the proposed insights.", "Questions": "How does the proposed method compare with other state-of-the-art self-supervised learning techniques not considered in the study?"}}
{"paper_id": "FJjHQS2DyE", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel approach, CASA, that addresses the limitations of existing UDA methods under label distribution shift and provides both a novel theoretical target risk bound and solid empirical results.", "Weaknesses": "The presentation, while adequate, might need additional clarity, especially for readers not deeply familiar with UDA frameworks or theoretical justifications.", "Questions": "How does CASA perform compared to existing methods in terms of computational efficiency? Are there specific scenarios where the proposed method may not be as effective?"}}
{"paper_id": "xelrLobW0n", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel benchmark, TRACE, which addresses a critical gap in the evaluation of continual learning for aligned LLMs. The integration of diverse and challenging tasks enhances the rigor of the assessment. Additionally, the paper proposes a credible solution (RCL) to mitigate the challenges identified, backed by empirical analysis.", "Weaknesses": "While the presentation of TRACE is clear, the paper could benefit from more detailed explanations of the datasets' selection criteria and the specific evaluation metrics used. There is also a need for more extensive comparison with other existing continual learning benchmarks to solidify its claims.", "Questions": "How does TRACE compare to existing benchmarks in real-world scenarios outside of the experimental setup? Are there plans to expand TRACE or update it regularly to include emerging tasks in LLMs?"}}
{"paper_id": "bYQkOPvgDw", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses an underexplored problem of label noise in graph neural networks and proposes a novel probabilistic graphical model framework. It demonstrates robustness across different noise types and rates, and performs well on heterogeneous graphs.", "Weaknesses": "The reliance on Bayesian networks might limit scalability to very large graphs. The methods are theoretically novel, but their practical application in real-world large-scale settings has not been fully evaluated.", "Questions": "How does PRGNN scale with extremely large graphs? Are there any specific real-world applications where this framework has been tested beyond the experiments presented? How does PRGNN handle dynamic graph scenarios where the structure might change over time?"}}
{"paper_id": "sKPzAXoylB", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach, Utility-based Perturbed Gradient Descent (UPGD), addressing both catastrophic forgetting and loss of plasticity in continual learning. It demonstrates superior performance over existing methods in a challenging setup.", "Weaknesses": "The abstract does not provide detailed information on the theoretical foundations or potential limitations of UPGD. The scalability and applicability to a wider range of problems are unclear.", "Questions": "How does UPGD perform in different domains or with diverse datasets? What are the computational overheads of implementing UPGD compared to traditional methods?"}}
{"paper_id": "H8Qg1IIMaR", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper identifies a specific vulnerability in popular language models related to permutation sensitivity, a previously underexplored aspect in multiple-choice question answering scenarios.", "Weaknesses": "The paper may lack thorough methodologies or extensive experiments to convincingly demonstrate why permutation sensitivity is a critical issue across a variety of real-world applications.", "Questions": "What specific methods or datasets were used to test permutation sensitivity in these models? How do these adversarial permutations impact the practical application of these models in real-world scenarios?"}}
{"paper_id": "tth2qXY7RU", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The paper presents a novel and impactful quantization method called Super Floating-Point (SuFP) that significantly improves memory footprint and computational efficiency while maintaining model accuracy. The method provides a compelling solution to handle outliers in deep neural networks and demonstrates substantial performance gains over existing techniques across various benchmarks.", "Weaknesses": "The paper may not have provided exhaustive details on how SuFP can be generalized across a wider array of models or data distributions. The hardware implementation specifics might need more elaboration on practical deployment considerations.", "Questions": "What are the potential limitations or constraints in implementing SuFP in existing hardware systems? Can SuFP be effectively integrated with current AI accelerators without significant modifications?"}}
{"paper_id": "fjf3YenThE", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a new algorithm that addresses and overcomes the limitations of the previous SZOHT method for handling zeroth-order gradients with hard-thresholding. The theoretical results demonstrate improved convergence rates and broader applicability, which are validated on real-world problems like portfolio optimization and adversarial attacks.", "Weaknesses": "The presentation of the paper could be improved to enhance clarity, especially in conveying complex theoretical parts and assumptions utilized in the convergence analysis.", "Questions": "How does the proposed algorithm perform in practice compared to first-order methods in terms of computational efficiency?"}}
{"paper_id": "H9DYMIpz9c", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach, Farzi, for data distillation in auto-regressive tasks that optimizes performance while using only a small fraction of the original dataset. The empirical results demonstrating 98-120% performance compared to full-data are impressive.", "Weaknesses": "The presentation of the methodology could be clearer, particularly in the explanation of how reverse-mode differentiation of the Adam optimizer is achieved. Additional comparative analysis with other distillation methods could strengthen the work.", "Questions": "How does Farzi performance compare over a broad range of datasets beyond the ones tested? Are there specific limitations in terms of sequence length or data types where Farzi may not perform well?"}}
{"paper_id": "4kLVvIh8cp", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a statistically optimal algorithm for nonlinear offline RL, which is a significant development in the field. The algorithm's design is well-structured with innovative components and achieves minimax optimal instance-dependent regret.", "Weaknesses": "The abstract does not provide detailed empirical results to support the theoretical claims, leaving the practical performance uncertain.", "Questions": "How does the algorithm perform in practical settings compared to existing nonlinear offline RL methods?"}}
{"paper_id": "CSpWgKo0ID", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to studying the interactive behavior of large language models using behavioral game theory. It offers insights into the cooperative and strategic behavior of LLMs in various game scenarios, highlighting their strengths in self-interest games and weaknesses in coordination tasks.", "Weaknesses": "The paper could benefit from a more detailed explanation of the experimental setup and results. There is room for improvement in the clarity of the game theory concepts applied. Also, further exploration into why LLMs struggle with coordination tasks would add depth to the findings.", "Questions": "How can the findings related to the iterated Prisoner's Dilemma and Battle of the Sexes be generalized to real-world applications involving LLMs? Are there other game types that could provide further insights into LLM behavior?"}}
{"paper_id": "gwbQ2YwLhD", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses an important issue in structure learning and provides theoretical conditions under which scale affects the performance of DAG learners. It is supported by extensive experiments on synthetic and real-world data.", "Weaknesses": "The focus on scale effects, while novel, may not fully represent the complexities that arise in varied real-world datasets. The presentation could be more engaging to highlight the impact of the findings.", "Questions": "How do the findings translate to practical applications in complex real-world datasets, particularly beyond the scope of the tested non-linear relations?"}}
{"paper_id": "eIYDKNqXuV", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The Village-Net Clustering algorithm introduces a novel approach to clustering complex manifold data by combining K-means and a network-based approach. It autonomously determines the optimal number of clusters and demonstrates competitive performance in benchmark tests.", "Weaknesses": "The abstract does not provide detailed comparisons with existing state-of-the-art methods or elaborate on the limitations of the approach. Furthermore, the complexity of the algorithm might not be suited for extremely high-dimensional data without further optimizations.", "Questions": "How does the Village-Net Clustering specifically compare to other advanced clustering algorithms on diverse datasets? What are its limitations regarding scalability and accuracy on very high-dimensional or sparse data?"}}
{"paper_id": "bAMPOUF227", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes a novel framework that enhances the reliability, generalizability, and factuality of large language models using task-specific fine-tuned language models. It demonstrates significant improvements in LLM performance and provides comprehensive resources and empirical analyses.", "Weaknesses": "The paper may lack discussion on the scalability of the proposed method and its application to other types of language models or additional tasks beyond those tested.", "Questions": "How does the proposed framework perform on domains not covered in the 16 datasets provided? Can the method be generalized to smaller models or those in different languages?"}}
{"paper_id": "eNoiRal5xi", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces an innovative objective for domain generalization, demonstrating significant empirical improvements over existing methods. Theoretical validation adds robustness to the proposed approach.", "Weaknesses": "The presentation could be clearer in parts, particularly in how the perturbation strategy is explained. More details on the practical implementation and computational overhead would enhance understanding.", "Questions": "How sensitive is the UDIM approach to the choice of perturbation parameters? Are there specific scenarios where UDIM may not perform as expected?"}}
{"paper_id": "uU0Adp7Sfo", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses the limitations of traditional GANs in multi-modal generation and image super resolution by introducing a novel CCGAN framework that integrates both competition and collaboration. The theoretical foundation for the model is well constructed, and the empirical results across multiple datasets demonstrate the model's efficacy.", "Weaknesses": "The paper may lack detailed explanations or examples of the specific use cases beyond image generation for regularly shaped objects. Moreover, the abstract does not clarify the potential computational cost or complexity associated with the proposed CCGAN framework.", "Questions": "How does the CCGAN framework perform in real-world applications involving complex data distributions outside of the tested datasets? What are the computational requirements and potential limitations in terms of scalability and speed?"}}
{"paper_id": "dKju7tbe6D", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel reasoning mechanism that effectively combines iterative and parallel computation, demonstrating strong reasoning capabilities and generalization across benchmarks. It achieves state-of-the-art results on multiple datasets while being more parameter-efficient.", "Weaknesses": "The abstract does not provide detailed insights into the experimental setup or potential limitations of the approach, such as possible complexities or trade-offs involved in implementing the IPRM.", "Questions": "What are the specific trade-offs or limitations associated with the IPRM compared to purely iterative or parallel approaches?"}}
{"paper_id": "DL7JWbdGr3", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel approach by leveraging pre-trained models in the context of epidemic time-series data, which allows for improved predictions across various datasets with better efficiency. It addresses significant challenges in handling heterogeneous epidemic dynamics and displays effectiveness by outperforming state-of-the-art methods.", "Weaknesses": "The approach might require extensive computational resources for the initial pre-training phase, and there may be limitations in the applicability of the model to entirely new and unseen epidemic patterns.", "Questions": "How does the model handle emerging diseases that have fundamentally different dynamics from those included in the pre-training phase?"}}
{"paper_id": "1PaDPHDhwe", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses the issue of trade-offs in robust accuracy and proposes a class-specific scaling strategy that can be directly applied to existing algorithms, potentially improving the performance without additional training. The introduction of a novel unified metric to evaluate the performance adds valuable insights.", "Weaknesses": "The abstract does not provide detailed experimental results or comparisons that substantiate the claims of improved performance. It is unclear how the instance-wise adaptive scaling technique affects diverse datasets or if there are limitations to its applicability.", "Questions": "How does the proposed technique perform across different datasets, particularly those outside of computer vision and NLP domains? Are there any specific limitations or failure cases observed in the experiments?"}}
{"paper_id": "iI7hZSczxE", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper addresses the important problem of disentangled representation learning for real-world time series with correlated attributes using a novel approach called DIOSC. Introducing the Time Disentangling Score (TDS) as a metric for evaluating the quality of disentanglement is a notable contribution.", "Weaknesses": "The abstract does not provide detailed information on the experimental validation or comparative results to demonstrate the superiority of the proposed method against existing techniques. The explanation of how l-variational inference layers and self-attention work together is brief and could be expanded.", "Questions": "How does the proposed method perform compared to traditional methods that do not consider attribute correlations? Are there specific scenarios where DIOSC struggles or excels in comparison to existing methodologies?"}}
{"paper_id": "qrGjFJVl3m", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 3, "Strengths": "The paper introduces the Qwen-VL series, a robust set of vision-language models with innovative components like a visual receptor and a 3-stage training pipeline. These models achieve state-of-the-art performance on various benchmarks and provide strong performance in visual-centered and multimodal tasks.", "Weaknesses": "While the paper presents impressive results, there is limited information in the abstract about the scalability of the proposed methods and their computational efficiency.", "Questions": "How does the training pipeline specifically enhance the model's multilingual and multimodal capabilities compared to existing models?"}}
{"paper_id": "qup9xD8mW4", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel approach to behaviour distillation in reinforcement learning that does not require access to expert data. The proposed method, HaDES, achieves impressive results with only four state-action pairs and demonstrates generalization across architectures and hyperparameters. It also shows improvements in neuroevolution for RL and provides interpretable insights through synthetic datasets.", "Weaknesses": "The abstract does not provide detailed information on the limitations or potential downsides of the HaDES method. In addition, the approach might be very specific to certain types of tasks or environments, which could limit its general applicability.", "Questions": "How does the performance of HaDES compare to other methods in diverse reinforcement learning environments beyond continuous control tasks? Are there limitations in terms of complexity or types of environments that HaDES can handle effectively?"}}
{"paper_id": "Zw8YxUWL4R", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel extension to textual conditioning in diffusion models, allowing for greater control and expressiveness in the text-to-image synthesis process. It also presents a new method, Extended Textual Inversion, which improves upon existing techniques in terms of expressiveness, precision, and convergence speed. Extensive experiments demonstrate the effectiveness of the new approach in personalizing models and achieving advanced object-style mixing capabilities.", "Weaknesses": "While the abstract highlights the novel contributions, it lacks detail on the potential limitations or challenges encountered in implementing the P+ space and XTI. Furthermore, there is no mention of the computational cost associated with the new approach compared to the baselines.", "Questions": "What are the computational requirements for the proposed method compared to existing models? Are there any limitations or potential drawbacks in terms of scalability or generalizability of the P+ space and XTI?"}}
{"paper_id": "3NXhwkZGjz", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel approach that addresses the challenging task of Source-Free Unsupervised Domain Adaptation by using multiple prediction hypotheses and consolidating them to improve model adaptation. The proposed method is innovative and achieves state-of-the-art performance according to extensive experimental results.", "Weaknesses": "The paper may lack detailed theoretical analysis on why the proposed hypothesis consolidation method specifically outperforms other similar approaches, and it would benefit from a discussion on the limitations of the method under different domain shift conditions.", "Questions": "How does the method handle cases where the consolidation of hypotheses is ambiguous, and does the performance degrade significantly in such scenarios?"}}
{"paper_id": "Fn655mJ4bv", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents a novel interpretation technique for explaining structured output models, effectively considering correlations among output variables.", "Weaknesses": "The explanation of the method and its energy-based training process could be clearer; it would benefit from more detailed comparisons with existing models.", "Questions": "How does the proposed method compare to existing interpretation techniques in terms of computational complexity and scalability?"}}
{"paper_id": "VyMW4YZfw7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper challenges the complexity of current GNN approaches and suggests simpler methods might perform as well or better. It provides a fresh perspective on evaluating the real improvements of GNNs.", "Weaknesses": "The abstract suggests that recent improvements in GNNs may be partly due to changes in evaluation methods, but it lacks detail on what these are. More clarity could be provided on how these simpler methods are implemented.", "Questions": "How do the authors propose handling various types of graphs with these simpler methods? Can the proposed techniques be applied across all benchmark datasets, or are there limitations?"}}
{"paper_id": "09xFexjhqE", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a significant issue in Robust Fine-Tuning by proposing a novel low-rank branch method that disentangles the optimization process, enhancing adversarial robustness with practical utility. Extensive empirical evaluations support the effectiveness of the method.", "Weaknesses": "The paper might lack detailed theoretical justifications for why the proposed low-rank branch effectively addresses the gradient divergence issue. Additionally, the empirical results need further validation across diverse domains to ensure generalizability.", "Questions": "What are the specific limitations of the proposed approach in terms of scalability and generalization to other types of neural network architectures? How does the computational cost of AutoLoRa compare to other state-of-the-art adversarial robustness approaches?"}}
{"paper_id": "nmBjBZoySX", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces an innovative framework called AdaGLT that addresses scalability and efficiency issues in Graph Neural Networks by offering an adaptive, dynamic, and automated approach for identifying graph lottery tickets. It provides theoretical proofs and demonstrates superior performance across diverse datasets.", "Weaknesses": "The paper may lack detailed empirical comparisons with baseline models in certain niche applications or may not cover all potential edge cases in the context of pruning strategies and restoration techniques.", "Questions": "How does AdaGLT perform in scenarios where both the graph and the dataset are subjected to continuous changes in a real-time dynamic environment?"}}
{"paper_id": "di52zR8xgf", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces Stable Diffusion XL, significantly improving over previous versions of Stable Diffusion by implementing a larger UNet backbone, innovative conditioning schemes, and a refinement model, achieving competitive results.", "Weaknesses": "The paper does not provide detailed insights into the computational costs or specific limitations of the proposed method compared to existing solutions.", "Questions": "How does SDXL perform in terms of computational efficiency compared to similar models? What are the specific trade-offs in terms of speed and resource usage?"}}
{"paper_id": "0b328CMwn1", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel concept, activation prompt (AP), which extends visual prompting beyond input-level perturbations, demonstrating superior performance to traditional VP methods. The comprehensive experimentation across 29 datasets strengthens the contribution.", "Weaknesses": "Theoretical explanations might lack depth for readers unfamiliar with the foundational concepts of normalization tuning and global feature analysis.", "Questions": "How does AP compare in terms of computational scalability and energy consumption relative to traditional fine-tuning and other PEFT methods across large-scale models?"}}
{"paper_id": "AMDKqZcZbi", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The proposed model effectively addresses the challenge of rapid and continual learning by utilizing biologically-inspired neural architectures and representations, showing superior performance against baseline methods.", "Weaknesses": "The paper could benefit from a deeper exploration of potential limitations or scalability issues of the model in more complex and varied tasks.", "Questions": "How well does the model perform in environments that are drastically different from those it was trained on? Are there any specific scenarios where it struggles?"}}
{"paper_id": "am7BPV3Cwo", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a critical issue in OOD detection and proposes a novel framework that demonstrates significant performance improvements on benchmark datasets.", "Weaknesses": "The presentation could be improved for clarity, and additional experiments could further validate the approach across different types of imbalanced datasets.", "Questions": "How does the ImOOD framework perform on real-world scenarios with varying degrees of data imbalance beyond the benchmarks tested?"}}
{"paper_id": "R1crLHQ4kf", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a straightforward yet highly effective method for detecting adversarial attacks on ASR systems. It achieves very high AUROC scores, indicating strong performance. The use of multiple binary classifiers and the adaptability of the detection strategy against adaptive attacks are commendable.", "Weaknesses": "The paper may rely on certain assumptions about the nature of the adversarial attacks, which could limit its applicability in more varied real-world scenarios.", "Questions": "How does the proposed system perform under different types of adaptive attacks, especially those that may exploit weaknesses not directly addressed by the detection characteristics?"}}
{"paper_id": "i7P2mK3x3o", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel flow-based model for optimal transport between arbitrary distributions accessed via samples, showing applicability in density estimation, generative models, and image translation.", "Weaknesses": "The paper lacks a detailed comparison with existing methods for flow-based models, and the practical implications of infinitesimal density ratio estimation are not fully explored.", "Questions": "How does the proposed model perform compared to state-of-the-art methods in terms of computational efficiency and accuracy in these tasks?"}}
{"paper_id": "YIls9HEa52", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel extension to the rSLDS model that improves its applicability to trial-varying data with flexible state cardinality. It leverages PDE theory for efficient computation and demonstrates significant results on both synthetic and real-world data.", "Weaknesses": "The presentation could be improved to better convey the complex mathematical derivations involved in the model. Some details about the implementation and specific challenges in applying the model to real data are unclear.", "Questions": "How does the proposed model perform in comparison to other state-of-the-art models for similar tasks? Are there limitations in the scalability of the approach to larger datasets?"}}
{"paper_id": "koYsgfEwCQ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "DynaVol introduces a novel 3D scene generative model that unifies geometric structures and object-centric learning. It significantly outperforms existing approaches and allows for additional capabilities beyond 2D methods, such as free editing of geometric shapes and manipulation of motion trajectories.", "Weaknesses": "The abstract does not detail potential limitations in scalability or computational complexity, which are common concerns in 3D scene generative models.", "Questions": "How does DynaVol handle complex scenes with many overlapping objects? What are the computational requirements for training the model?"}}
{"paper_id": "o6AN2ZoNw2", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a simple yet effective framework for open-vocabulary semantic segmentation that achieves state-of-the-art results on several benchmarks. The method is scalable and improves with self-training.", "Weaknesses": "The abstract does not mention any potential limitations or challenges faced by P-Seg, nor does it discuss any computational complexity or efficiency aspects.", "Questions": "How does P-Seg perform in terms of computational efficiency compared to other methods? Are there any specific scenarios where P-Seg does not perform well?"}}
{"paper_id": "HXZK1Z8tHa", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses significant challenges in transformer-based networks for image restoration by proposing a novel solution, ShareFormer, which reduces latency and improves trainability. The approach is thoroughly evaluated through lesion studies and experimental results, supporting its effectiveness.", "Weaknesses": "While the abstract claims improvements in latency and trainability, it does not provide quantitative comparisons or detailed insights into potential limitations or scenarios where the approach might underperform.", "Questions": "How does ShareFormer compare quantitatively to existing state-of-the-art methods in terms of specific metrics such as PSNR or SSIM on benchmark datasets?"}}
{"paper_id": "QO3yH7X8JJ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach to ASSR using pre-trained DGMs without additional training, demonstrating superior performance. The theoretical analysis leads to a metric (PRF) for optimal noise injection, which is innovative and experimentally validated.", "Weaknesses": "The paper might rely heavily on the specific pre-trained DGMs, limiting generalizability. The abstraction level of the PRF metric could be a concern for practical implementation across various models.", "Questions": "How well does the proposed method perform across different types of DGMs, and what are the implications if the pre-trained model's architecture deviates significantly from those tested?"}}
{"paper_id": "sNtDKdcI1f", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper identifies a significant factor influencing the effectiveness of RLHF, providing insights into how length correlates with reward in different models. It proposes interventions to test reducing output length without losing effectiveness.", "Weaknesses": "The interventions proposed do not uniformly solve the issue of increased response length across different settings. The findings suggest that current reward models may not fully capture attributes of helpfulness besides length.", "Questions": "How generalizable are the interventions proposed across different types of language tasks? Could similar trends be affecting other aspects of model outputs, such as coherence or creativity?"}}
{"paper_id": "HFtrXBfNru", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides a theoretical foundation for understanding representation distortions in evolving graphs and proposes a method that shows impressive empirical performance on real-world datasets. The analysis from an information theory perspective is a significant strength.", "Weaknesses": "The effectiveness of Smart might be heavily dependent on the specific graph datasets used, and the lower bound refinement for synthetic graphs may not fully generalize. There is limited discussion on computational costs or scalability of Smart.", "Questions": "How does Smart perform on different types of graph distributions not covered in this paper? Are there any computational or scalability concerns when applying Smart on very large-scale graphs?"}}
{"paper_id": "4u0ruVk749", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper addresses the important problem of learning individualized treatment effects with unobserved confounders. It proposes a novel method using a diffusion model which is an innovative approach in the field.", "Weaknesses": "The explanation of the model implementation and experimental setup might lack clarity. The reliance on certain assumptions about the apriori knowledge might not be fully justified.", "Questions": "How does the proposed method compare with traditional methods in terms of computational complexity? Are there any limitations or scenarios where the proposed approach does not perform well?"}}
{"paper_id": "Pa6SiS66p0", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a significant challenge in deep learning, specifically catastrophic forgetting, by exploring the use of multi-modal data. It introduces a new benchmark for multi-modal continuous learning, offering potential improvements in model robustness and accuracy. The method proposed for integrating and aligning information across different modalities is well-motivated and could become a strong baseline for future studies.", "Weaknesses": "The paper abstract does not provide detailed empirical results or comparisons with existing methods to fully support the claims of effectively mitigating forgetting or improving robustness. It would be beneficial to understand the potential computational overhead of the proposed multi-modal approach.", "Questions": "How does the performance of the proposed method compare quantitatively with existing single-modality continuous learning approaches? What specific datasets and modalities were used in the benchmark, and how well do they generalize to real-world applications?"}}
{"paper_id": "rkplYfqUr0", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel generative prompting framework Gen-Z for zero-shot text classification, which addresses issues of miscalibration and prompt brittleness. It effectively integrates contextual information to enhance performance.", "Weaknesses": "The paper lacks detailed analysis on the limitations or potential drawbacks of using the generative prompting approach in certain scenarios.", "Questions": "How does Gen-Z perform with non-standard datasets that do not fit well with typical label descriptions?"}}
{"paper_id": "pTU2X9mUBe", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents LaDe, the first publicly available last-mile delivery dataset of its kind, offering a large-scale and diverse set of data that is invaluable for researchers in related fields.", "Weaknesses": "The paper does not detail potential biases in the dataset that could affect research outcomes.", "Questions": "Are there any privacy or ethical considerations addressed in the release of such a comprehensive dataset?"}}
{"paper_id": "uhtQyRrTzY", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel dataset-curation method that does not require additional annotations, allowing the creation of multi-view datasets at scale from real-world videos. The proposed MIMIC datasets outperform other datasets on various dense geometric tasks. The approach is scalable and effective.", "Weaknesses": "The presentation could be improved for better clarity. More details on the method's limitations and potential weaknesses in specific scenarios would be helpful.", "Questions": "How does the method perform on other types of tasks beyond those mentioned? What are the limitations when scaling to even larger datasets?"}}
{"paper_id": "WZfatbNdLV", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel predictive model, TrASPr, that outperforms existing models and effectively predicts RNA splicing outcomes in a tissue-specific manner. The integration of generative modeling and Bayesian Optimization is innovative and contributes significantly to the RNA splicing prediction field.", "Weaknesses": "The presentation of the model details might lack clarity for audiences not familiar with transformer architectures and Bayesian Optimization, potentially limiting its accessibility.", "Questions": "How does TrASPr specifically handle cases with limited training data? Can the BO approach be scaled to other genomic prediction tasks?"}}
{"paper_id": "YkRwadXWHd", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel multi-modal framework for continuous sign language recognition, achieving state-of-the-art results. The use of hierarchical knowledge distillation effectively reduces computational burden while maintaining high performance.", "Weaknesses": "The abstract lacks detailed discussion on the limitations or potential downsides of the proposed approach, such as reliance on high-quality input data or the scalability of the method.", "Questions": "How does the model perform under less optimal conditions, such as low-quality video inputs? Are there any constraints on the types of sign languages that this framework can be applied to?"}}
{"paper_id": "q4Bim1dDzb", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "UniVoxel provides a novel and efficient method for inverse rendering by unifying the modeling of geometry, materials, and illumination. It significantly accelerates training times while maintaining high reconstruction quality.", "Weaknesses": "The paper may lack detailed explanation on the limitations of the UniVoxel approach. The abstract doesn't specify the comparative performance metrics against various baselines explicitly.", "Questions": "How does UniVoxel perform in terms of generalization to unseen scenes compared to traditional methods? Are there any particular types of scenes where UniVoxel struggles?"}}
{"paper_id": "39cPKijBed", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to mitigate dataset bias in diffusion models, introduces time-dependent importance reweighting, and demonstrates improved results on multiple benchmark datasets.", "Weaknesses": "The practicality of applying the method in real-world scenarios and the computational overhead of the approach have not been extensively discussed.", "Questions": "How does the approach perform with different types of biases not tested in this study? What is the computational cost compared to existing methods?"}}
{"paper_id": "aG3EARrrd1", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach to handle streaming multivariate scattered data effectively with Online Sparse Residual Tree (OSRT), showing improvements in both efficiency and accuracy over existing methods.", "Weaknesses": "The paper does not provide detailed comparisons with a broader range of competitive models beyond existing online RBF methods. Additionally, it lacks a comprehensive discussion on computational complexity.", "Questions": "How does the OSRT model perform on datasets with different characteristics, such as noise levels or dimensionality? Also, how does the computational cost scale with the dataset size?"}}
{"paper_id": "Ts95eXsPBc", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces Spatially-Aware Transformer models, which effectively incorporate spatial information into episodic memory representation, resulting in improved accuracy for various downstream tasks.", "Weaknesses": "The implementation details and computational complexity of integrating spatial dimensions with the transformer architecture are not extensively discussed.", "Questions": "How does the inclusion of spatial information impact the scalability and real-time performance of the memory model in large-scale environments?"}}
{"paper_id": "LfhG5znxzR", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel approach to make neural networks more interpretable by using sparse and discrete hidden states. It demonstrates the effectiveness of the approach on diverse datasets and shows minimal performance degradation.", "Weaknesses": "The paper might need more discussion on potential limitations or environments where the method doesn't work as effectively. Additionally, the impact on computation time and resource needs is not clearly outlined.", "Questions": "How does the approach scale with even larger models beyond the 410M parameter range? Are there specific applications where this method might be disadvantageous?"}}
{"paper_id": "bUGzjiUsIq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "Addresses the challenging problem of partially annotated multi-label classification with a novel approach combining reinforcement and supervised learning.", "Weaknesses": "The abstract does not provide sufficient detail on experimental validation or comparison with existing methods.", "Questions": "How does the proposed PAPG framework perform compared to state-of-the-art methods on standard benchmarks?"}}
{"paper_id": "uMAujpVi9m", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach to pocket pretraining that leverages high-resolution atomic protein structures and pretrained small molecule representations. It significantly expands the available data for training by simulating ligand-receptor interactions, resulting in improved performance across several tasks.", "Weaknesses": "The method relies heavily on the accuracy and relevance of the pseudo-ligand representations. The paper may lack detailed comparison with a broader range of existing methods.", "Questions": "How does the approach handle potential inaccuracies in the simulation of ligand-receptor interactions?"}}
{"paper_id": "uqxBTcWRnj", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel framework for implicit learning of symbolic knowledge and demonstrates its superiority over existing methods on multiple tasks.", "Weaknesses": "The presentation could be improved for clarity, and more details on model implementation and computational efficiency would be beneficial.", "Questions": "How scalable is the proposed framework, and how does it perform on larger and more complex datasets outside the tested scenarios?"}}
{"paper_id": "o4CLLlIaaH", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The introduction of a point-based rendering approach addresses key limitations in existing NeRF methods, showing improved performance and generalization. An innovative nonuniform log sampling strategy and the use of a learnable kernel for better feature aggregation are well-motivated and effectively enhance rendering quality.", "Weaknesses": "The abstract could provide more details on specific benchmarks and quantitative results to better illustrate the improvements claimed. Some of the proposed innovations may introduce increased computational complexity.", "Questions": "How does the GPF approach scale with very large datasets or complex scenes? Are there any significant trade-offs in terms of computational efficiency compared to traditional NeRF methods?"}}
{"paper_id": "KNzL1nglNB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses a significant issue of insufficient labels in real-world applications and proposes a novel method called Label-encoding Risk Minimization (LRM) to tackle it. Empirical results demonstrate the superiority of LRM across several scenarios.", "Weaknesses": "The theoretical analysis might not be exhaustive, and the explanation of the relationship between LRM and ERM could be clearer. The practical applicability in diverse scenarios is not fully detailed.", "Questions": "How does the proposed LRM specifically handle scenarios with extremely limited labeled samples? Can LRM be easily integrated into existing machine learning pipelines with minimal changes?"}}
{"paper_id": "pvhyBB86Bt", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper extends existing analyses of neural network initialization to the entire training process, providing a theoretical framework for understanding Jacobian stability. It utilizes recent advances in random matrix theory and can be applied to various scenarios including sparse networks and non-iid initialization.", "Weaknesses": "The presentation of the theoretical results could be more accessible to readers who are not well-versed in random matrix theory. There may also be a need for more empirical validation across different architectures and datasets.", "Questions": "How does the proposed framework perform empirically across different architectures? Are there specific limitations or assumptions in the theoretical model that might affect its applicability?"}}
{"paper_id": "Mylk5iamJC", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel Latent Gaussian Mixture Model for open-set recognition, which shows improvements over traditional methods. The combination of generative and discriminative approaches provides a strong basis for handling both CSR and OSR.", "Weaknesses": "The presentation could be improved for clarity. The descriptions of certain methodologies may be complex for readers not deeply familiar with the underlying concepts.", "Questions": "How does the L-GMM perform compared to state-of-the-art methods in terms of computational efficiency and scalability to larger datasets?"}}
{"paper_id": "MsOcVFzv8D", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a theoretical basis for analyzing multi-domain text classification (MDTC), which is often missing in existing approaches. The proposed MDAT method shows superior performance compared to state-of-the-art methods on benchmarks.", "Weaknesses": "While the theoretical analysis is strong, the presentation might be dense or technical, potentially limiting accessibility to a broader audience.", "Questions": "How does the margin discrepancy theoretically relate to the adversarial training approach, and can this relationship be further elucidated?"}}
{"paper_id": "fBlHaSGKNg", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel sample selection methodology (UPA) that addresses the often-overlooked area of efficient sample selection for annotation in semi-supervised learning. It offers a clear improvement over existing active learning methods by leveraging a unique $α$-Maximum Mean Discrepancy criterion, with empirical evidence showing enhanced performance across several popular SSL methods.", "Weaknesses": "The paper could provide more clarity on the scalability of the proposed method in different contexts and datasets. Additionally, the theoretical background for the proposed $α$-MMD criterion could be more thoroughly explored to strengthen the understanding of its impact on low-budget learning.", "Questions": "Could the authors provide more insights into how the modified Frank-Wolfe algorithm plays a crucial role in the proposed methodology? Are there any limitations observed for the proposed $α$-MMD criterion that could affect its applicability in diverse datasets?"}}
{"paper_id": "HwQ8NVvdmm", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel technique utilizing Hadamard transforms to enable low-precision training, achieving impressive results such as less than 0.5% and 3% accuracy degradation while using low-bit quantization. The approach addresses critical issues facing continual learning on edge platforms.", "Weaknesses": "The paper may not fully elaborate on the potential limitations or scenarios where the proposed method may not perform well. It may lack comprehensive comparisons with existing quantization techniques under various benchmarks.", "Questions": "How does the proposed technique perform under different distribution shifts or datasets not included in the study? Are there any scenarios where the accuracy degradation becomes significant?"}}
{"paper_id": "cZo6pDtDZr", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents new algorithms for estimating and testing collision probability with improved sample complexity, satisfying differential privacy requirements. It addresses a fundamental problem in the field and demonstrates practical benefits.", "Weaknesses": "The paper may lack clarity in some technical details or fail to effectively communicate the impact of the results outside the scope of the experiments conducted.", "Questions": "How do these algorithms compare in performance with other state-of-the-art methods in diverse real-world applications beyond the scope of the experiments conducted?"}}
{"paper_id": "F7QnIKlC1N", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel network, GTMGC, based on Graph-Transformer for predicting 3D molecular conformation from 2D structure, demonstrating superior performance on benchmark datasets.", "Weaknesses": "The paper does not discuss any potential limitations or challenges in applying the proposed model to a wider range of molecular structures.", "Questions": "How does the proposed MSRSA mechanism specifically improve performance over other self-attention mechanisms in molecular modeling?"}}
{"paper_id": "8JCn0kmS8W", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel framework, WavJourney, that effectively uses Large Language Models to integrate various audio generation models for creating complex audio compositions from textual descriptions, achieving state-of-the-art results in this area. The structured, interpretative approach, along with the introduction of a new benchmark, enhances its contribution to audio generation research.", "Weaknesses": "The reliance on Large Language Models might limit the framework's applicability if not adjusted for newer or domain-specific LLMs. The paper does not thoroughly discuss potential limitations or failure cases of the system. Additionally, details about the evaluation process, such as diversity of the subjective evaluations, might need further elaboration.", "Questions": "How does WavJourney handle cases where the LLMs might misinterpret textual instructions? Are there any mechanisms in place to deal with potential biases in the audio generation when using LLMs? What are the computational costs associated with running such a system in practice?"}}
{"paper_id": "XbLffB0T2z", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses the limitation of existing data poisoning attack strategies under varying learning paradigms, and provides a novel approach that enhances attack transferability across different learning methods and paradigms. The proposed method demonstrates significant improvement in transferability through experiments on benchmark datasets.", "Weaknesses": "The paper abstract lacks detailed information about the specific benchmarks and the quantitative improvements achieved by the proposed method. It is not clear how the approach performs relative to state-of-the-art methods.", "Questions": "How does the performance of the proposed transferable poisoning method compare quantitatively to existing state-of-the-art poisoning attacks in terms of test accuracy degradation? What specific benchmark datasets were used in the experiments?"}}
{"paper_id": "4y3GDTFv70", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "ODSgo2m8aE", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a relevant and modern challenge in AI fairness with the introduction of Lipschitz bounds for GNNs, which is novel and could significantly advance the fairness in relational data processing. The theoretical analysis and experimental validation strengthen the paper's contributions.", "Weaknesses": "The presentation might be complex for readers not familiar with the technical aspects of Lipschitz bounds or GNNs. The paper might benefit from clearer explanations and examples to improve accessibility.", "Questions": "How does the proposed Lipschitz bound compare with other fairness techniques in terms of computational cost and performance impact on GNNs?"}}
{"paper_id": "RlfD5cE1ep", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides a novel analysis of non-contrastive learning dynamics with feature normalization and contributes significantly to the understanding of how feature normalization prevents collapse in non-contrastive frameworks.", "Weaknesses": "The presentation could be improved for clarity, as the complexity of the analysis involving sixth-order dynamics may be hard to follow for readers not familiar with the specific mathematical framework.", "Questions": "How does the introduction of the sixth-order dynamics specifically impact practical implementations of self-supervised learning models in comparison to using third-order dynamics?"}}
{"paper_id": "18TfucMNTr", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses a significant issue in deep learning related to optimization challenges and provides a novel approach by framing noisy training as a form of optimization by continuation.", "Weaknesses": "The paper may lack extensive empirical validation on a wide array of architectures and tasks, and might not have addressed potential computational overheads of the proposed method.", "Questions": "Have experiments been conducted on large-scale datasets to ensure the generality of the approach? What specific form of regularization is used and how sensitive is the method to different types of noise?"}}
{"paper_id": "JGTC6WgO4T", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel training framework for multi-source black-box domain adaptation, providing theoretical support and demonstrating strong performance on benchmark datasets.", "Weaknesses": "The abstract does not specify any potential limitations or the complexity introduced by the proposed approach.", "Questions": "How does the proposed method handle cases where source domains are highly divergent from each other?"}}
{"paper_id": "fQHb1uZzl7", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel Transformer-based network for dense matching tasks that cleverly integrates both feature and cost aggregation using attention mechanisms. It demonstrates significant improvements over existing methods and provides a unifying architecture for these aggregation techniques.", "Weaknesses": "The abstract does not provide detailed insights into the complexity or computational cost of the proposed architecture. Further, while improvements are claimed, quantitative evaluations or comparisons are not included in the abstract.", "Questions": "How does the proposed network compare in terms of efficiency and computational requirements to existing methods? Are there any specific scenarios or datasets where the approach does not perform well?"}}
{"paper_id": "YjG29CIOP7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses important challenges in data-free meta-learning, namely Task-Distribution Shift and Task-Distribution Corruption. The proposed TEAPOT and ROSY strategies demonstrate strong performance and robustness improvements over existing methods.", "Weaknesses": "The paper may lack detailed experimental comparisons with a wide range of baseline methods, and the implications of the results are not fully explored. Additionally, the complexity of the proposed model might not be detailed enough for straightforward reproducibility.", "Questions": "How does the memory mechanism in TEAPOT handle scalability as the number of tasks increases? Are there specific types of tasks or datasets where the proposed methods perform suboptimally?"}}
{"paper_id": "DmDpu3r8iU", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel framework (VUM) for evaluating value understanding in LLMs, which addresses an important concern about AI alignment with human values. It provides a quantitative approach that separates 'know what' from 'know why', offering insights into the limitations of current LLMs.", "Weaknesses": "The framework requires further validation across more diverse datasets and LLM configurations. The potential risks highlighted are noted, but the paper could benefit from deeper exploration of mitigation strategies.", "Questions": "How can the VUM framework be adapted or expanded to cover a broader spectrum of human values beyond those in the Schwartz Value Survey?"}}
{"paper_id": "kXHEBK9uAY", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel and effective planning method that combines hierarchical and diffusion-based planning. It demonstrates superior performance and efficiency in standard benchmarks and shows improved generalization capabilities.", "Weaknesses": "While the approach is innovative, further details on the implementation and limitations in various settings could strengthen the soundness and general applicability of the method.", "Questions": "How does the method perform on a wider range of out-of-distribution tasks beyond the benchmarks evaluated in the paper? Are there specific scenarios where the method might not be as effective?"}}
{"paper_id": "i7LCsDMcZ4", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper tackles the problem of overfitting in event-based SNNs with a novel approach. It introduces new methods for saliency map extraction in SNNs and provides extensive evaluation demonstrating state-of-the-art performance.", "Weaknesses": "While the methods are innovative, the presentation could be improved for better clarity and accessibility. There is limited discussion on the limitations or potential drawbacks of the proposed approaches.", "Questions": "How does the method perform with different types of noise or variations in the input data? Are there any constraints or specific scenarios where the proposed method may not be effective?"}}
{"paper_id": "jHdz0CIS2y", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel training strategy for voice conversion that avoids explicit disentangling of speech attributes, thereby preserving finer nuances like accent and emotion. The proposed method uses self-synthesized examples to iteratively improve the model, leading to state-of-the-art results in zero-shot voice conversion.", "Weaknesses": "The paper does not provide exhaustive details on how the proposed method outperforms existing techniques in terms of computational efficiency or scalability for real-time applications.", "Questions": "How does the SelfVC framework handle variations in environmental noise or background sounds during training and synthesis?"}}
{"paper_id": "NkYCuGM7E2", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel approach by integrating Large Language Models as decision-makers in autonomous driving systems, which could significantly enhance understanding and handling of complex driving scenarios. The approach seems to improve upon existing methods in terms of safety, efficiency, and generalizability.", "Weaknesses": "Details on the integration process between high-level LLM decisions and low-level driving actions are limited. It is unclear how well this approach can be scaled for more diverse driving environments and how it compares with current state-of-the-art driving systems in real-world scenarios.", "Questions": "How does the performance of the proposed method compare with state-of-the-art models in varied and complex real-world driving situations? Are there any limitations regarding the computation cost and latency introduced by using LLMs in real-time driving systems?"}}
{"paper_id": "RtDok9eS3s", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a simplified transformer design that retains performance while increasing training speed and reducing parameter count. This has practical significance given the widespread use of transformers.", "Weaknesses": "The paper may lack a thorough exploration of potential edge cases or scenarios where the simplified model might underperform compared to standard transformers.", "Questions": "How does the simplified design perform across a wider range of tasks and datasets? Are there specific conditions where the performance degrades significantly?"}}
{"paper_id": "YCPDFfmkFr", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a unified and efficient approach to differentiating through both feasible and infeasible convex QP solutions, demonstrating improved predictive performance in learning tasks and offering numerical robustness and speed improvements. The open-source software package provides a concrete tool for practical implementation.", "Weaknesses": "The abstract does not mention experimental results or comparisons with existing methods, which raises questions about the empirical validation and generalization across different use cases.", "Questions": "How does the proposed method compare to existing differentiation techniques for QP layers in terms of computational complexity and accuracy? Are there specific applications in machine learning where this approach is particularly beneficial?"}}
{"paper_id": "ueTdErd5Ib", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The method provides robust solutions with strong theoretical guarantees of performance and demonstrates significant improvements in experiments, especially notable in worst-case scenarios.", "Weaknesses": "The presentation could be more detailed in explaining the discretization and integration process, as well as how the secondary optimization problem is constructed.", "Questions": "How does the approach scale with very large feasible regions or highly multivariate contexts? Are there specific limitations acknowledged in terms of computational complexity?"}}
{"paper_id": "sDmjlpphdB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents a novel approach, Mixture-of-Prompts (MoP), which improves the performance of LLMs by leveraging a Mixture-of-Expert paradigm. The method outperforms prior art on benchmark NLP tasks by a substantial margin, thus making a significant contribution to the field.", "Weaknesses": "The implementation details and the computational efficiency of the two-phase process for constructing the specialized experts are not thoroughly discussed, which makes it difficult to assess the scalability and practicality of the approach in real-world applications.", "Questions": "How does the MoP method scale with increasing numbers of experts and demos? What are the computational requirements for the joint search process for instruction assignment?"}}
{"paper_id": "Mdk7YP52V3", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a strong theoretical foundation for understanding instability issues in heteroskedastic neural regression models, using statistical physics to derive insightful results, such as phase transitions, that explain the need for careful regularization. The numerical solutions and their qualitative agreement with empirical data solidify its contributions.", "Weaknesses": "The paper may be inaccessible to practitioners unfamiliar with statistical physics, and the practical implementation details for the proposed optimization scheme could be more thoroughly explained.", "Questions": "How does the proposed regularization optimization scheme compare to other methods in terms of practical implementation complexity and computational cost?"}}
{"paper_id": "YGTSLDAPqb", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper proposes a novel method, Connect Later, which effectively improves out-of-distribution error rates in domain adaptation settings by using targeted augmentations. The results show significant improvements and state-of-the-art performance on multiple real-world datasets.", "Weaknesses": "The paper might not adequately address potential limitations or scenarios where the proposed method might not perform as well. Additionally, the dependency on designing targeted augmentations based on domain knowledge might limit the method's applicability to domains without clear distribution shifts.", "Questions": "What are the key factors that determine the success of targeted augmentations in improving OOD performance? How might this approach generalize to domains without intuitive or easily describable distribution shifts?"}}
{"paper_id": "JTcaziw7G1", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The paper presents a novel approach for private information retrieval using multi-party computation, ensuring privacy without requiring centralization of data. The proposed method is innovative and tackles a significant problem in the realm of LLMs and private data access.", "Weaknesses": "The paper might benefit from more extensive empirical validation of the proposed protocol's performance and scalability in various practical scenarios.", "Questions": "How does the performance of the proposed PRAG method compare to existing privacy-preserving retrieval methods in terms of speed and accuracy?"}}
{"paper_id": "lEkFq4RUCX", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel metric, Directional Distance Field (DDF), for comparing 3D point clouds, demonstrating superior accuracy and efficiency over existing metrics across several important applications.", "Weaknesses": "The abstract does not provide details on potential limitations or failure cases of the proposed metric compared to other methods.", "Questions": "How does the DDF handle noise and outliers in the 3D point clouds? Are there specific conditions under which the metric may perform poorly?"}}
{"paper_id": "Fq8tKtjACC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel large language model for code that is significantly smaller in size yet achieves high accuracy on benchmark tests, indicating an efficient training process and effective use of data.", "Weaknesses": "The abstract does not provide detailed information on the architecture modifications or innovations introduced compared to previous models. It also relies heavily on benchmark test results without discussing potential limitations or failure cases of the model.", "Questions": "What are the specific architectural differences or enhancements implemented in phi-1 compared to phi-1-base and phi-1-small? How does the model's performance vary with different types of coding tasks beyond the benchmarks?"}}
{"paper_id": "8fQlGQkj0S", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper offers a rigorous analytical approach to understanding in-context learning by proposing generative models. It provides a novel insight into task retrieval, indicating that an increase in in-context samples could degrade performance, supported by empirical validation using Transformer models.", "Weaknesses": "The presentation could be improved for better accessibility, particularly for readers less familiar with the mathematics underlying the analysis. There might also be concerns about the generality of the proposed models beyond the mean squared error risk measure.", "Questions": "How does the proposed model perform with different risk measures beyond the mean squared error? Are there specific types of tasks or Transformers for which the observed phenomena do not hold?"}}
{"paper_id": "hRos9WldRK", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel method, Learning to Bootstrap (L2B), which effectively addresses the problem of learning with noisy labels by dynamically adjusting weights between real and pseudo labels. The method significantly improves model robustness and is compatible with existing methods, showing competitive results on several benchmark datasets. Additionally, the availability of code and models adds to its practical applicability.", "Weaknesses": "The abstract does not provide detailed information on the limitations of the L2B method or the specific conditions under which it may not perform as well. It also lacks a comparison with recent baseline methods in terms of computational complexity or training time.", "Questions": "How does L2B perform in comparison to state-of-the-art methods in terms of computational efficiency? Are there specific scenarios or types of noise where L2B might not perform well?"}}
{"paper_id": "ttRSBZiCiu", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces an innovative approach to speech synthesis using probability flow models and adversarial training. It provides improved efficiency and competitive sample quality in fewer inference steps.", "Weaknesses": "The abstract does not provide specific details about the experiment setup or quantitative comparison metrics, which makes it difficult to fully assess the model's performance.", "Questions": "What specific metrics were used to evaluate the model's performance against previous vocoders, and what were the quantitative results of these comparisons?"}}
{"paper_id": "WYsLU5TEEo", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel unified framework to address both interpretability and robustness of neural image classifiers using GANs, providing a significant contribution to the field. The approach effectively merges concerns usually dealt with individually, demonstrating utility in both explainability and adversarial resilience.", "Weaknesses": "The evaluation may lack depth on larger and varied datasets, focusing only on specific tasks such as concrete crack segmentation and fruit defect detection. Further empirical validation on a broader set of problems is needed.", "Questions": "How does the unified framework perform across different domain-specific datasets? What are the computational costs associated with integrating the classifier and discriminator in practice?"}}
{"paper_id": "KKZaj2QS3G", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel sampling strategy and encoder architecture for time series analysis, demonstrating superior performance over state-of-the-art methods with fewer parameters.", "Weaknesses": "The paper lacks discussion on the potential limitations or trade-offs of the proposed method under specific conditions or datasets.", "Questions": "How does the approach handle time series with extremely high noise levels? Are there any specific types of noise where the method might underperform?"}}
{"paper_id": "LWDRiFzbHQ", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses an important problem in assessing the generalization ability of models on out-of-distribution test sets without requiring ground truth. The proposed vicinal risk proxy (VRP) method is innovative, building on existing generalization indicators and improving their correlation with accuracy. The presentation is clear, and the methodology is well-motivated.", "Weaknesses": "The paper might lack comprehensive experimental validation across various model types and datasets, which could give a broader perspective on the general applicability of the VRP method. There is also no detailed discussion on the potential computational overhead introduced by considering neighboring test samples in the evaluation process.", "Questions": "How does the VRP method scale with larger test datasets and more complex model architectures? Are there any conditions under which VRP might not perform well compared to traditional unsupervised indicators?"}}
{"paper_id": "Yp01vcQSNl", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel graph transformer architecture that accounts for edge directionality, demonstrating state-of-the-art results on new directional graph datasets. It effectively leverages dual encodings and a directional attention module.", "Weaknesses": "The paper does not mention any limitations or potential downsides of their proposed approach, nor does it discuss computational costs or scalability of the model.", "Questions": "How does the model perform on larger graphs, and what are the computational requirements? Are there any limitations in terms of model generalizability to non-directional graphs?"}}
{"paper_id": "LndMyiBl3n", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces the Modified Silhouette Score (MSS) as an innovative measure for graph quality and presents SheAttack, an effective black-box attack for various homophily levels, demonstrating results on synthetic and real-world graphs.", "Weaknesses": "The paper might lack comprehensive comparisons with a wide range of existing methods, especially in varying homophilic settings. Additionally, the computational complexity of the proposed method is not deeply explored.", "Questions": "How does MSS compare with existing graph quality metrics in computational efficiency and effectiveness? Are there specific scenarios where SheAttack underperforms compared to traditional white-box attacks?"}}
