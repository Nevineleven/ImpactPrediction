{"paper_id": "B0OwtVEejJ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper effectively bridges two significant subdomains in NAS, combining gradient-based methods with weight-entangled search spaces, which were previously considered incompatible.\n2. TangleNAS demonstrates substantial improvements in both memory efficiency and computational performance across various benchmark tasks.\n3. The study is comprehensive, covering different search spaces and demonstrating the adaptability of the proposed method.", "Weaknesses": "1. The methodology, although innovative, may have its effectiveness diminished in more complex real-world settings where extensive architectural parameters are involved.\n2. The paper provides strong empirical results but lacks more theoretical insights into why TangleNAS performs better than the individual approaches.", "Questions": "1. How does TangleNAS perform under different hyperparameter settings? Are there more results to demonstrate its robustness across varying initializations?\n2. Would the current approach scale effectively to even larger models and datasets beyond those examined, such as some of the very large transformer models?"}}
{"paper_id": "ZlEtXIxl3q", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach using contrastive losses to estimate fitness functions affected by global epistasis, which is shown to be more effective than traditional MSE loss.\n2. It provides a compelling argument with the fitness-epistasis uncertainty principle, highlighting the limitations of existing models in sparse representation.\n3. The practical application of contrastive losses in biological sequence prediction is demonstrated with improved performance on benchmark tasks.", "Weaknesses": "1. The paper makes logical extensions from existing knowledge without formal theoretical proofs for all claims, particularly the applicability of compressive sensing scaling laws to neural network training.\n2. While the experimental results are robust, the potential impact of realistic measurement noise scenarios on the proposed method is not fully explored, which may limit real-world applicability.", "Questions": "1. How does the performance of contrastive loss methods compare when subjected to various realistic noise conditions typical in biological assays?\n2. Can the theoretical basis for why contrastive losses exhibit robustness to dense representations from global epistasis be further expanded?"}}
{"paper_id": "6yJuDK1DsK", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. FEATHER addresses the key issues of parameter efficiency and forgetting in lifelong test-time adaptation effectively by introducing lightweight adapters that disentangle domain knowledge.\n2. The framework is robust and performs well across various benchmark tasks such as CIFAR-10C, CIFAR-100C, ImageNetC, and ImageNet3DCC.\n3. Extensive experiments validate the effectiveness of FEATHER, showing significant reductions in trainable parameter count with similar or better test-time adaptation performance.\n4. The paper is well-organized and presents the concepts and results clearly.", "Weaknesses": "1. The dependency on hyperparameter tuning is not thoroughly discussed, which might affect the generalizability of the proposed solution across different tasks and settings.\n2. The approach focuses on vision tasks with convolution-based architectures; it would be valuable to see its applicability in other domains like NLP or more complex multimodal settings.", "Questions": "1. How sensitive is FEATHER to the choice of lightweight adapters and the specific configuration of the chosen adapters?\n2. Is there any specific reason why identity initialization of adapters works particularly well in this context compared to warm-starting with source data?\n3. Can this methodology be extended effectively to non-vision tasks, and what challenges might arise in doing so?"}}
{"paper_id": "lt6xKGGWov", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper proposes a novel feature selection method utilizing the neural estimation of mutual information, which can capture complex relationships between features and targets.\n2. MINERVA, the proposed method, is capable of performing exact feature selection where other methods fail, as demonstrated in synthetic experiments.\n3. The method is model-independent and applies a new approach by evaluating subsets of features as an ensemble rather than individually.", "Weaknesses": "1. The evaluations are conducted solely on synthetic datasets, which may limit the external validity and practical applicability of the findings.\n2. The paper lacks a comprehensive comparison with other recent feature selection methods beyond the ones mentioned, which could provide a better assessment of its relative effectiveness.\n3. The practical computational efficiency and scalability of the approach are not discussed in detail, making it hard to evaluate its use on large real-world datasets.", "Questions": "1. Can the proposed method be efficiently scaled to handle large real-world datasets with high-dimensional feature spaces?\n2. How does MINERVA compare to other state-of-the-art feature selection methods not covered in the experiments?\n3. Are there plans to test this method on real-world datasets to validate its efficacy and reliability in practical scenarios?"}}
{"paper_id": "Bvrc6kobWd", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper presents a novel perspective on understanding contrastive learning through the lens of margins using gradient analysis, providing significant insights that were not addressed by existing decision-boundary-based explanations.\n2. The separation and detailed experimental analysis of the effects of margins suggest practical ways to improve contrastive learning, showing clear improvements in both seen and unseen datasets.\n3. The paper is well-structured, making it easy to follow the theoretical developments and experimental evaluations which are comprehensive and systematic.", "Weaknesses": "1. The assumptions based on cosine similarity and one-hot target probability, while suitable for many SSL methods, may limit the generalization of the findings to methods that deviate from these assumptions. \n2. The ratio (pij − βqij)/(pij − βq^ij) was not deeply analyzed due to its non-separability. A more thorough examination could potentially uncover additional insights.", "Questions": "1. Can the proposed analysis and recommendations for margins transfer to contrastive learning methods that do not use cosine similarity or one-hot target probabilities?\n2. What specific challenges are anticipated if attempting to separate or analyze the non-separable gradient scaling ratio in further detail?\n3. How do the authors envisage adapting the gradient analysis framework to non-cosine-similarity-based SSL frameworks?"}}
{"paper_id": "FJjHQS2DyE", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach, Conditional Adversarial Support Alignment (CASA), which effectively handles unsupervised domain adaptation under label distribution shift. \n2. Empirical results consistently show that CASA outperforms multiple state-of-the-art methods across various benchmark datasets and label shift conditions. \n3. Theoretical contributions include a new target risk bound based on conditional symmetric support divergence (CSSD), providing a grounded justification for the approach.\n4. The paper is well-structured and clearly presents the methodology and experimental results.", "Weaknesses": "1. The approach might be limited by its reliance on assuming the existence of the well-defined support in both source and target domains, which might not hold in all practical scenarios.\n2. The complexity of the model could be a hindrance to applying it in real-time or large-scale applications where computational efficiency is critical.\n3. The use of pseudo-labels could lead to error accumulation, particularly under significant domain shifts.", "Questions": "1. How does the approach perform in real-time applications with large-scale datasets where computational efficiency becomes a constraint?\n2. Is there any particular domain or dataset where the assumptions for CASA do not hold, and how would it affect the performance?\n3. How sensitive is CASA to the choice of hyperparameters, and what guidelines can be provided for their selection?"}}
{"paper_id": "xelrLobW0n", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper introduces TRACE, a new benchmark designed to challenge aligned large language models (LLMs) on continual learning tasks that include domain-specific knowledge, multilingual capabilities, code generation, and mathematical reasoning.\n2. The thorough evaluation across multiple LLMs and training methodologies sheds light on the challenge of catastrophic forgetting and the importance of balancing performance on new tasks while maintaining general abilities.\n3. The Reasoning-augmented Continual Learning (RCL) approach presents a promising strategy for reducing catastrophic forgetting by leveraging reasoning paths and task-specific cues.", "Weaknesses": "1. The paper relies heavily on existing tasks and datasets, which may not cover all aspects of catastrophic forgetting and resilience in LLMs comprehensively.\n2. There is a lack of diversity in the evaluation metrics and tasks that might not fully capture the practical applications of continual learning in broader NLP scenarios.\n3. The impact of long-term continual learning using TRACE remains to be seen, as the current results primarily focus on immediate effects rather than durability over extended learning sequences.", "Questions": "1. How does TRACE compare with other benchmarks in terms of scalability and applicability to various types of language models, especially smaller-scale models?\n2. What considerations were made to ensure that the selected tasks in TRACE remain relevant and challenging as LLMs evolve?\n3. Is RCL adaptable to different types of reasoning that might be present in tasks beyond those explicitly included in the benchmark, and what are the results for such scenarios?"}}
{"paper_id": "bYQkOPvgDw", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel probabilistic graphical model-based framework (PRGNN) that addresses the problem of noisy labels in graph neural networks, which are often overlooked in research. 2. PRGNN is robust, applicable to both homophilous and heterophilous graphs, and shows superior performance under high noise-rate scenarios. 3. The paper is well-organized and clearly presented with extensive experimental validation across various datasets and conditions.", "Weaknesses": "1. While PRGNN outperforms existing techniques, the model's complexity and computational cost in large-scale applications are not clearly discussed. 2. The reliance on an additional small clean label set for training might limit the applicability of the approach in domains where acquiring clean labels is costly or impractical.", "Questions": "1. Can you elaborate on the computational overhead introduced by PRGNN compared to standard GNNs? 2. How sensitive is PRGNN to the size or quality of the clean label set used during training? Can it still perform well if the clean set is reduced significantly?"}}
{"paper_id": "sKPzAXoylB", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper provides a novel approach to simultaneously address both catastrophic forgetting and loss of plasticity in continual learning, which are significant challenges in the field. 2. UPGD is validated through comprehensive experiments across multiple datasets and methods, showing its effectiveness in various scenarios including streaming learning and reinforcement learning. 3. The presentation of the paper is clear and well-organized, making the methods and results accessible.", "Weaknesses": "1. The applicability of UPGD might be limited by the requirement for utility scaling and specific setup for streaming learning, which may not be directly applicable to all continual learning scenarios. 2. While the necessity of utility scaling is discussed, more detailed exploration on its impact could strengthen the method validation.", "Questions": "1. Can the utility-based approach of UPGD be extended to other domains or tasks where catastrophic forgetting and loss of plasticity are present, outside of the problems tested? 2. How sensitive is UPGD to the hyperparameters such as the noise standard deviation and utility decay rate across different tasks?"}}
{"paper_id": "H8Qg1IIMaR", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides a comprehensive empirical analysis of the sensitivity of large language models (LLMs) and large vision-language models (VLLMs) to simple permutation attacks in multiple-choice question answering (MCQA) tasks. This study highlights a critical but overlooked vulnerability and suggests the importance of considering adversarial robustness as a significant concern in model deployment. It offers an intriguing view into the brittleness of current popular models and calls for attention to robustness evaluation.", "Weaknesses": "While the identification of permutation sensitivity is significant, the paper does not propose a novel or effective mitigation method to address the discovered vulnerability. The suggested post-hoc strategies such as majority voting and contextual calibration do not fully resolve the issue. Additionally, the analysis provides a detailed look at the problem but lacks depth in exploring underlying causes or practical solutions for improving robustness.", "Questions": "How can the findings on permutation sensitivity impact the future development and deployment of LLMs and VLLMs? Are there specific characteristics of the models or datasets that make them particularly vulnerable to permutation attacks, and how can model developers address these to enhance robustness?"}}
{"paper_id": "tth2qXY7RU", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "SuFP introduces an innovative data type utilizing multi-region piecewise quantization and tensor-wise scalable bias, achieving significant improvements in memory footprint and computational efficiency without compromising accuracy. The method is well-supported by comprehensive experiments across various domains such as vision, language, and generative models, demonstrating better performance and energy efficiency compared to state-of-the-art methods.", "Weaknesses": "The paper assumes that the tensor-wise distribution closely aligns with the channel-wise distribution, which might not always hold across all model architectures or datasets. The adaptation to dynamic data distributions may require further validation. Additionally, the implementation complexity of integrating SuFP into existing hardware architectures is not extensively discussed.", "Questions": "How does SuFP perform on a wider range of model architectures beyond those tested? Can SuFP be seamlessly integrated into existing hardware accelerators, or does it require significant modifications? What are the limitations when applying SuFP to models with highly irregular data distributions?"}}
{"paper_id": "fjf3YenThE", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses a significant limitation of the existing SZOHT algorithm by proposing a variance reduction technique that removes constraints on the number of random directions.\n2. Theoretical analysis is thorough, providing insights into variance reduction's dual role in enhancing convergence rates and mitigating conflicts in zero-order hard-thresholding algorithms.\n3. Experimental results on both ridge regression and adversarial attacks demonstrate the practical advantages and effectiveness of the proposed method over existing algorithms.", "Weaknesses": "1. Although the paper introduces a novel approach to variance reduction in ZO hard-thresholding, the concept of variance reduction itself is not new, and the contribution is incremental rather than a fundamental breakthrough.\n2. The presentation could be improved for better readability and understanding, particularly the notation and mathematical derivations, which could be more intuitive.", "Questions": "1. How does the choice of variance reduction methods and parameter tuning affect the overall performance and applicability of the proposed algorithm?\n2. Can the proposed variance reduction approach be efficiently extended to other zero-order optimization problems beyond those covered in the experiments (e.g., reinforcement learning)?"}}
{"paper_id": "H9DYMIpz9c", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper proposes a novel data distillation technique, FARZI, specifically for autoregressive tasks, showing significant efficiency by reducing the dataset size drastically while maintaining or even improving model performance.\n2. It introduces an efficient reverse-mode differentiation of Adam, which significantly reduces memory usage and is essential for the scalability of the technique.\n3. Empirical results demonstrate that FARZI DATA can achieve 98-120% of full-data performance, suggesting strong potential for transforming how autoregressive models are trained.", "Weaknesses": "1. While FARZI is demonstrated on sequential recommendation and language modeling tasks, the paper acknowledges limitations in scaling to naturally long sequences like video or music without linear parameterization.\n2. The paper does not fully address the computational and optimization challenges associated with applying FARZI to larger models and datasets, which it recognizes as a crucial area for future work.", "Questions": "1. How does the quality of FARZI DATA compare to traditional data augmentation techniques besides compression? Are there any qualitative evaluations?\n2. What are the potential impacts of using pre-trained trajectories on the interpretability and transparency of models trained on FARZI DATA?\n3. How might the method be adapted or extended to handle very long sequences efficiently without linear scaling in sequence length?"}}
{"paper_id": "4kLVvIh8cp", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "CSpWgKo0ID", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper uses a unique approach to evaluate the social behavior of large language models by applying behavioral game theory. This helps add a new dimension to understanding LLMs in interactive settings.\n2. Robust methodology and comprehensive robustness checks ensure that the observed behaviors are consistent and not dependent on specific prompt formulations.\n3. The experiments cover a significant amount of models, providing a comparative assessment of LLMs. Additionally, the results provide valuable insights into the strengths and weaknesses of current LLMs in cooperation and coordination tasks.", "Weaknesses": "1. The paper may overly focus on game-theoretic approaches, which might not capture all the nuances of LLM interactions in more naturalistic settings.\n2. The interpretation of LLMs as agents with cognitive capabilities might be problematic, given that their behaviors derive from statistical patterns rather than genuine theory of mind capabilities.\n3. Although robust, the experiments are still limited to specific types of games, possibly not reflecting a broader range of social interactions LLMs might encounter in real scenarios.", "Questions": "1. How might the LLMs' performance and strategies change when considering games with more complex structures or involving more agents?\n2. Could the inclusion of more nuanced social contexts or objectives impact the results, and to what extent would these changes reflect on the LLMs' ability to engage in genuinely social behavior?\n3. How do the authors envision applying the insights derived from the game-theoretic analysis to improve LLMs' performance in real-world, interactive applications?"}}
{"paper_id": "gwbQ2YwLhD", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper provides a comprehensive theoretical foundation that shows how measurement scales can influence the prediction of Directed Acyclic Graphs (DAGs) using various loss functions. \n2. It extends previous results on variance sensitivity to more complex, d-dimensional cases and non-linear dependencies, providing new insights and potential pitfalls for structure learning algorithms.\n3. The theoretical findings are robustly supported with thorough empirical evaluations using both synthetic and real-world data.\n4. The paper ensures reproducibility by providing access to code and datasets, which is critical for scientific validation.", "Weaknesses": "1. The work maintains some strong assumptions (like the noise model and function invertibility) which may limit its general applicability to highly complex real-world scenarios.\n2. There aren’t concrete solutions offered for the identified issues, particularly for continuous structure learners which suffer scaling bias. Suggestions such as the Scale Robust Loss (SRL) address only discrete learners.\n3. While the work covers many cases, it does not fully consider the influence of regularization techniques and other dynamics of the optimization processes in structure learners.", "Questions": "1. Are there potential strategies or adjustments to loss formulations that could inherently mitigate the influence of variable scale during structure learning?\n2. How do these findings and recommended strategies perform when integrated or tested with hybrid or more recent structure learning approaches which may not strictly fall in the categories discussed (e.g., involving deep neural networks with different architectures)?"}}
{"paper_id": "eIYDKNqXuV", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The proposed Village-Net Clustering algorithm offers a novel approach to unsupervised clustering by integrating K-Means with a community detection algorithm, showing competitive performance in terms of NMI scores on various datasets. It is also computationally efficient with a time complexity of O(N * k * d), making it suitable for large-scale datasets.", "Weaknesses": "The clustering accuracy is notably limited by the capacity of the K-Means algorithm, which can be a restraining factor for datasets with intrinsic clusters that K-Means cannot effectively partition. Additionally, the results heavily depend on the choice of hyperparameters like k and r, and the sensitivity analysis provided is somewhat limited.", "Questions": "1. How does the method perform in scenarios where intrinsic clusters are significantly non-linearly separable or where K-Means struggles to provide a good initial partitioning?\n2. Can the approach be adapted to dynamically determine the optimal hyperparameters k and r based on a dataset's specific characteristics or initial feedback from the clustering process?"}}
{"paper_id": "bAMPOUF227", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper introduces a novel approach called SuperContext that systematically integrates supervised knowledge from smaller models into large language models, enhancing their performance, especially in OOD settings.\n2. Extensive empirical results demonstrate significant improvements in generalizability and factuality across multiple datasets and tasks.\n3. The paper provides a comprehensive suite of resources, including datasets and model outputs, which could be highly beneficial to future research in this area.", "Weaknesses": "1. The paper does not sufficiently address potential scalability issues or how SuperContext might perform with models larger than Llama2-7B-chat or ChatGPT.\n2. The dependence on selecting appropriate smaller task-specific models might limit the generalizability of the approach across all potential use cases.\n3. While the method is demonstrated to work well in controlled settings, its effectiveness in more dynamic real-world scenarios is uncertain.", "Questions": "1. How does SuperContext handle scenarios where task-specific fine-tuned models (SLMs) are not available or hard to obtain?\n2. Could SuperContext be extended to work with modalities other than natural language, such as image or audio inputs?\n3. How would SuperContext's approach scale with much larger LLMs like GPT-4 or PaLM? Would there be diminishing returns in performance improvement?"}}
{"paper_id": "eNoiRal5xi", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper proposes a novel method, UDIM, for domain generalization by using both parameter and data perturbations, which is well-grounded theoretically and empirically validated.\n2. The authors provide a thorough theoretical analysis, proving that the integration of SAM and UDIM provides an upper bound for the true generalization objective.\n3. The empirical results demonstrate substantial improvements over prior methods across various benchmark datasets, showing the robustness of the proposed approach.", "Weaknesses": "1. The paper relies heavily on the assumption that perturbation in both parameter and data space can emulate unknown domains, which may not hold in more complex real-world scenarios.\n2. Although the approach is validated on multiple datasets, further experiments or comparisons with a broader range of methods could strengthen the generalizability of the findings.", "Questions": "1. Can the proposed UDIM method be easily extended or adapted for other tasks, such as regression, or to other types of data, not just image classification?\n2. How does the method handle situations where the domain differences are more semantic rather than just differences in data distribution caused by corruption or noise?"}}
{"paper_id": "uU0Adp7Sfo", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper introduces a novel framework, CCGAN, which incorporates a collaboration-competition mechanism to address limitations of traditional GANs. This approach theoretically preserves the equilibrium point and provides a performance guarantee.\n2. CCGAN is shown to effectively reduce training collapse issues and improve the quality of generated data, especially in scenarios where additional generation requirements are needed.\n3. Comprehensive experiments validate the efficacy of CCGAN across various domains including image and power data, demonstrating adaptability and robustness.", "Weaknesses": "1. The integration of the collaboration mechanism, while innovative, lacks sufficient explanation regarding its broader applicability and limitations, particularly in more complex real-world applications.\n2. The theoretical guarantees, while present, are primarily demonstrated through specific tasks and datasets. The paper does not fully address potential scalability and adaptability issues in diverse or larger-scale datasets.\n3. Though the paper discusses performance guarantees, the practical implications, such as computational overhead and convergence time of the proposed method compared to baselines, are not deeply explored.", "Questions": "1. How does the CCGAN framework perform when applied to datasets that are considerably larger or exhibit more dynamic variability than those tested?\n2. What are the computational overheads associated with implementing the collaborative mechanism in comparison to standard GANs or other competitive-collaborative GAN models?\n3. Can the proposed method be extended or adapted to other types of generative models beyond GANs, and are there potential challenges in such adaptations?"}}
{"paper_id": "dKju7tbe6D", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper presents a novel reasoning module that integrates both iterative and parallel computation, enhancing the flexibility and efficiency in visual reasoning tasks.\n2. The proposed IPRM shows superior performance across several benchmarks, including state-of-the-art zero-shot results, demonstrating its effectiveness and generalizability.\n3. The method is elegantly presented, with clear illustrations of the computation flow and extensive experimental evaluation.\n4. The mechanism's ability to adjust its operation strategies depending on the task demands can significantly benefit various visual and language reasoning applications.", "Weaknesses": "1. While the integration of iterative and parallel reasoning is well-motivated, the theoretical backing of why this combination specifically outperforms existing methods could be more deeply explored.\n2. The adaptability of this mechanism to tasks beyond visual reasoning is mentioned but not empirically validated, which could limit its perceived applicability breadth.\n3. The method heavily relies on optimal tuning of parameters such as the number of operations and steps, which might need detailed attention in practical settings.", "Questions": "1. How sensitive is the performance of IPRM to the choice of hyperparameters such as the number of parallel operations and reasoning steps?\n2. Can the proposed IPRM framework be effectively adapted for non-visual reasoning tasks, and are there any preliminary results to support this claim?\n3. How does IPRM handle scaling when applied to larger and more complex datasets compared to current evaluations?"}}
{"paper_id": "DL7JWbdGr3", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach to pre-training epidemic time-series models using self-supervised learning (SSL), which is a significant advancement in epidemic forecasting.\n2. It effectively leverages a wide range of datasets from different diseases, illustrating the versatility and applicability of the proposed model in diverse environmental conditions.\n3. The work demonstrates a comprehensive evaluation across multiple datasets, showcasing clear improvements over state-of-the-art methods in terms of prediction accuracy and data efficiency.", "Weaknesses": "1. The dependency on historical datasets for pre-training may limit the model's applicability in scenarios where such data is unavailable or incomplete.\n2. The paper may have benefited from further exploration on seamlessly integrating additional multimodal data sources such as geographic or mobility data.", "Questions": "1. How does the model deal with scenarios where new diseases emerge without any closely related historical data for pre-training?\n2. Can the SSL tasks be easily adapted or extended to incorporate other types of time-series data such as financial or climate data, and what would be the challenges in doing so?"}}
{"paper_id": "1PaDPHDhwe", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a simple yet effective approach to balance robust and average accuracy through class-specific and instance-wise scaling strategies, which do not require additional training.\n2. The proposed method offers flexibility to existing debiasing techniques and allows the optimization of various objectives along the trade-off curve.\n3. Extensive experiments demonstrate the effectiveness of the approach across multiple datasets and domains, providing insights into inherent trade-offs in debiasing algorithms.", "Weaknesses": "1. The reliance on validation sets with group annotations may not be practical in real-world scenarios where such annotations are scarce or costly to obtain.\n2. The method mainly serves as a post-processing step and may not address deeper layers of bias inherent in the initial training data or models.\n3. While the paper provides a unified metric, it may not fully capture the complexity of trade-offs involved in model performance across different domains.", "Questions": "1. How does the approach perform in cases where group annotations are limited to very sparse or noisy\n2. Is there a potential for extending this method to unsupervised scenarios where group annotations are completely unavailable?\n3. Can the proposed scaling strategies be integrated into the training process rather than being applied as post-processing?"}}
{"paper_id": "iI7hZSczxE", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses the crucial need for disentangled time series representation in the context of Non-Intrusive Load Monitoring, tackling real-world correlated data challenges. \n2. It presents a novel framework integrating contrastive learning with variational autoencoder, demonstrating improved disentanglement in the presence of correlations. \n3. The experimental evaluation is thorough, leveraging multiple datasets and providing robust comparisons against baseline methods across various scenarios.", "Weaknesses": "1. While the independence-of-support is a viable relaxation of the independence assumption, it is not universally applicable, and some scenarios may deviate from this assumption. \n2. Although the paper thoroughly evaluates its method against baselines, exploration into a broader scope of conditions or a wider variety of domains could further validate its generalizability.", "Questions": "1. Could the proposed method handle scenarios where causal relationships exist between latent factors, or would additional modifications be needed?\n2. How sensitive is the method to the hyperparameters such as those used in empirical support factorization?"}}
{"paper_id": "qrGjFJVl3m", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The Qwen-VL series introduces a comprehensive vision-language model with state-of-the-art performance on an extensive suite of tasks including image captioning, visual question answering, and grounding.\n2. The paper provides detailed methodology and systematic training pipeline, contributing a solid setup for future research in multimodal models.\n3. Qwen-VL's multilingual support, multi-image capability, and fine-grained visual understanding are significant advancements over existing models.", "Weaknesses": "1. There could be a discussion on the potential limitations or challenges in scaling the model further, especially regarding computational resources and efficiency.\n2. The study might benefit from a deeper investigation into the model's robustness across highly variable real-world data and environments.", "Questions": "1. How does Qwen-VL perform in terms of model efficiency and computational requirements compared to its predecessors and other state-of-the-art models?\n2. What are the potential challenges in expanding Qwen-VL's capabilities to include additional modalities like video and speech?"}}
{"paper_id": "qup9xD8mW4", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "1. Introduces a novel concept of behaviour distillation extending dataset distillation to reinforcement learning.\n2. The HaDES method effectively generates small synthetic datasets for policy training with impressive results across various tasks.\n3. Demonstrates strong empirical performance, sometimes exceeding state-of-the-art, while being widely applicable, including for supervised learning distillation.\n4. Offers open-source implementations, promoting reproducibility and further research in the field.", "Weaknesses": "1. High computational demands due to evolutionary strategies, especially with a large population required for effectiveness.\n2. The method introduces a number of hyperparameters which can complicate tuning and adaptation to new settings.", "Questions": "1. How does the computational cost of HaDES compare to training traditional reinforcement learning agents in terms of wall-clock time?\n2. Can this methodology be adapted to more complex environments, especially those with high-dimensional observations beyond pixel-based inputs?"}}
{"paper_id": "Zw8YxUWL4R", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces an innovative Extended Textual Conditioning space for text-to-image generation, offering greater expressivity and control over the synthesis process.\n2. The proposed Extended Textual Inversion (XTI) is shown to be more expressive, precise, and faster in convergence compared to the original Textual Inversion.\n3. Comprehensive experiments and analysis are provided, demonstrating the effectiveness of XTI in improving personalization of text-to-image models, and conducting novel object-style mixing.", "Weaknesses": "1. Despite the improvements, XTI does not achieve perfect reconstruction, and the disentanglement among U-net layers is not perfect, which limits control over prompt mixing.\n2. While faster than TI, the XTI process is still relatively slow, which might be a limitation for certain applications.\n3. The requirement for model-specific setups and user study preferences might raise concerns on the generalizability and unbiased evaluation of the proposed methods.", "Questions": "1. Can the Extended Textual Conditioning and XTI methods be adapted to non-diffusion text-to-image models, or are they limited to diffusion-based architectures?\n2. What are potential strategies to further improve the speed of XTI while maintaining its accuracy and editability?\n3. How do the results vary across different underlying datasets and domains beyond those reported in the paper?"}}
{"paper_id": "3NXhwkZGjz", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper effectively addresses a challenging task in unsupervised domain adaptation – Source-Free Unsupervised Domain Adaptation (SFUDA) – without source data access, by introducing an innovative approach that consolidates prediction hypotheses based on their rationales.\n2. The proposed method is shown to integrate well with existing approaches, enhancing their performance, which adds practical value and demonstrates flexibility.\n3. Experimental results on benchmark datasets demonstrate state-of-the-art performance, confirming the method's efficacy.", "Weaknesses": "1. The reliance on entire target training data for key adaptation steps poses a limitation in real-world applications where data may be streamed or otherwise constrained.\n2. There's a need for further experiments to understand how various components contribute to results beyond the context of the presented datasets.", "Questions": "1. Can the method be effectively adapted for online domain adaptation, where full target datasets aren’t available at once?\n2. How does the performance of the proposed method compare with non-source-free methods in SFUDA, especially in terms of computational efficiency and scalability?"}}
{"paper_id": "Fn655mJ4bv", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel energy-based method, SOInter, specifically designed for interpreting structured output models, which addresses an underexplored area in interpretability research.\n2. The methodology is well-founded, leveraging energy functions and deep neural networks to incorporate structural dependencies between output variables, enhancing interpretability.\n3. Proposed method outperforms general interpretation techniques like Lime and Kernel-Shap on both synthetic and real-world datasets, showing robustness and scalability.\n4. SOInter provides a computationally efficient solution with constant explaining time, offering practical advantages in real-world applications with large feature sets.", "Weaknesses": "1. The explanation primarily targets structured output models and may not be easily applicable to simpler models or scenarios with less complex output structures.\n2. The dependence on the quality of the energy function simulation could impact the reliability of the interpretations.\n3. Perturbation-based feature selection, which zeros out non-important features, may not be suitable if zero values hold special significance in certain datasets, potentially affecting interpretation accuracy.", "Questions": "1. How does SOInter perform in scenarios where the structured model contains non-linear dependencies that are not well-represented by the energy function?\n2. Can SOInter be adapted or extended to also provide explanations at the level of coarse conceptual elements rather than just feature-level analysis, and how feasible would this adaptation be?\n3. Given that the performance and generalization of the energy function are critical, how sensitive is SOInter to errors in the energy network's outputs?"}}
{"paper_id": "VyMW4YZfw7", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper proposes a simplification of GNN approaches using low-rank kernel models for semi-supervised node classification and achieves state-of-the-art performance on various benchmarks.\n2. The approach reduces complexity while maintaining or exceeding performance, suggesting that some of the complexity in current GNN models may be unnecessary.\n3. A thorough ablation study on hyperparameters and evaluation setups is conducted, providing insights into the impact of different evaluation practices on GNN performance.", "Weaknesses": "1. While the paper presents a compelling simplification, the novelty mainly lies in the application of existing spectral methods to GNNs rather than entirely new methodology.\n2. The impact of kernel choice on performance is dataset-specific, and the paper does not provide a clear, generalized guideline for selecting appropriate kernels across different datasets.\n3. The proposed approach's applicability to other types of graph learning tasks beyond SSNC is not explored, which may limit its broader impact.", "Questions": "1. How well do these simplified spectral approaches perform on tasks other than semi-supervised node classification? Would these methods be applicable and effective?\n2. Can the proposed method's success with specific kernel functions be generalized to understand their effectiveness on other types of networks or graphs?\n3. How significant is the choice of evaluation splits on the actual model performance, and should this influence the adoption of new GNN models in practical applications?"}}
{"paper_id": "09xFexjhqE", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The proposed AutoLoRa framework addresses a significant issue in robust fine-tuning (RFT) by accurately disentangling natural and adversarial objectives using a low-rank branch. This leads to improved adversarial robustness without the need for hyperparameter tuning. Empirical results across various tasks and datasets demonstrate the effectiveness of the method in achieving state-of-the-art results.", "Weaknesses": "While the method addresses convergence issues and hyperparameter sensitivity, it primarily focuses on adversarial robustness without exploring other potential benefits of the disentangled approach. Furthermore, the dependence on the pre-trained feature extractor limits insights into adaptability across diverse architectures.", "Questions": "How does AutoLoRa perform in environments with more diverse types of adversarial attacks? Could the low-rank branch be expanded to improve other aspects of fine-tuning, such as interpretability or robustness against other forms of model attacks?"}}
{"paper_id": "nmBjBZoySX", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel framework, AdaGLT, which addresses key limitations of existing Graph Lottery Ticket methods by offering adaptive, dynamic, and automated ticket identification. \n2. The approach integrates pruning and training, providing a dynamic workflow that enhances elasticity and scalability, particularly for deep GNNs.\n3. Extensive experiments verify the framework's superiority over existing methods across various datasets and GNN architectures.", "Weaknesses": "1. While the paper provides extensive empirical validation, the complexity of the approach and the reliance on specific configurations might limit its straightforward applicability.\n2. The presentation of theoretical aspects is limited and could be expanded to offer more detailed insights, particularly for interdisciplinary readers unfamiliar with the specifics of graph neural tangent kernel.", "Questions": "1. How does AdaGLT handle edge cases or extreme configurations where traditional methods fail, and are there scenarios where AdaGLT might also struggle?\n2. Can the proposed framework be extended to other types of neural networks beyond GNNs and, if so, how might the methodology need to be adapted?"}}
{"paper_id": "di52zR8xgf", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents significant improvements in the Stable Diffusion model, notably through enhanced architecture and innovative conditioning techniques. It demonstrates competitive performance with state-of-the-art black-box models while maintaining an open-source approach, fostering reproducibility and further research in the field.", "Weaknesses": "While the model improvements are significant, they come with increased computational costs, which may limit accessibility. The paper could benefit from a more comprehensive examination of potential biases introduced by these improvements.", "Questions": "1. How do the computational demands of SDXL affect its usability compared to existing black-box models, especially in resource-constrained environments?\n2. Could the proposed improvements be adapted to other diffusion models or tasks beyond text-to-image synthesis, and what modifications might be necessary?"}}
{"paper_id": "0b328CMwn1", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a novel concept of activation prompting (AP), which provides a significant improvement over visual prompting (VP) in terms of accuracy and efficiency. \n2. Extensive experiments across 29 datasets demonstrate the effectiveness of AP, showing its superiority over previous state-of-the-art PEFT methods. \n3. The paper includes both empirical evidence and theoretical analysis to support the proposed method, making the claims well-founded.", "Weaknesses": "1. The theoretical analysis is mostly centered on ViTs, and there is limited depth of theoretical exploration for CNNs, even though empirical results are extensive. \n2. The applicability of AP may be limited by its dependence on the size of the pretrained models, as noted with compact models like ResNet-18 and ViT-Tiny, where it did not outperform certain other techniques.", "Questions": "1. How does AP cope with datasets that significantly differ from the pretrained domain, and does this affect its efficiency and accuracy? \n2. Can the method be generalized to other types of neural networks beyond CNNs and ViTs, and how well does it fare with those architectures?"}}
{"paper_id": "AMDKqZcZbi", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces an innovative model inspired by biological systems, specifically the entorhinal-hippocampal circuit, to address both rapid learning and catastrophic forgetting in machine learning.\n2. The implementation of the MESH architecture in the Sequential Morris Water Maze task demonstrates a compelling application of neural structures for continual learning and memory preservation.\n3. The experimental results show significant improvements over baseline methods, indicating the model's potential effectiveness in real-world applications.", "Weaknesses": "1. The reliance on the MESH architecture may present scalability issues or challenges in transferring the approach to other domains or tasks outside spatial navigation.\n2. While the paper presents a novel task and model, it lacks a detailed explanation of the limitations and potential issues in applying the proposed method across different scenarios.\n3. The evaluation primarily focuses on specific tasks, and the generalizability of the model to more complex environments is not comprehensively addressed.", "Questions": "1. Can the proposed model be adapted to tasks outside the spatial navigation domain, or is it specifically tailored to mimic spatial memory functions?\n2. What are the potential challenges in scaling the model to more complex environments with additional variables and constraints?\n3. How does the model handle conflicting associations in environments where sensory inputs are highly similar but require different actions?"}}
{"paper_id": "am7BPV3Cwo", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses a critical issue in OOD detection for imbalanced data, which is relevant to real-world applications.\n2. It introduces a novel statistical framework, ImOOD, that effectively explains and mitigates the performance gap caused by data imbalance.\n3. The method proposed achieves significant improvements over existing techniques, as demonstrated across multiple datasets.", "Weaknesses": "1. The requirement for full-data training, including auxiliary OOD samples, may hinder practical deployment in dynamic environments.\n2. While the approach provides theoretical insights, the reliance on auxiliary OOD data might limit generalized application across varied datasets or use cases.\n3. The impact of ImOOD's requirement for extensive auxiliary data is not fully addressed.", "Questions": "1. How sensitive is the method to the choice of auxiliary OOD training samples?\n2. Could the proposed framework be adapted to scenarios where collecting auxiliary OOD samples is challenging?\n3. How does ImOOD perform when rapid adaptation to new environments is required without new data?"}}
{"paper_id": "R1crLHQ4kf", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper presents a novel and effective method for detecting adversarial examples in automatic speech recognition systems by leveraging the characteristics of the output distribution. This is a practical solution with high applicability across various ASR systems.\n2. The extensive empirical evaluation across different datasets and ASR models demonstrates the efficacy of the approach, with the proposed detectors achieving robust performance even in challenging scenarios.\n3. The method does not require modifications to existing ASR architectures or additional data preparation steps, making it easy to implement and adopt.", "Weaknesses": "1. While the approach is effective, the reliance on the specific characteristics of the output distribution might limit the generalizability to other kinds of attacks beyond those considered in the study. Adaptive attacks, while addressed, still pose a challenge to the effectiveness of the classifier.\n2. The empirical evaluation, while thorough, might not fully capture real-world scenarios where attackers could devise new strategies unknown to the current detection mechanisms.\n3. The method's scalability when dealing with very large datasets or in real-time applications has not been discussed, which could be a concern given the computational requirements outlined in the study.", "Questions": "1. How would the proposed method handle new types of attacks that might target characteristics of the output distribution not considered in this work?\n2. Is the solution scalable for real-time detection in practical applications where the computational budget might be constrained?\n3. Can the proposed characteristics be used to assess other aspects of speech, such as quality or intelligibility, as hinted at in the conclusion?"}}
{"paper_id": "i7P2mK3x3o", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper proposes a novel flow-based model for learning dynamic optimal transport maps between arbitrary distributions, which generalizes the idea of normalizing flows to a broader setting where both distributions P and Q are only accessible via finite samples.\n2. The Q-flow model is empirically validated on several tasks, including mutual information estimation, energy-based generative models, and image-to-image translation, demonstrating competitive performance.\n3. The methodology is clearly presented, with detailed explanations of the training procedure, inner-loop, and outer-loop iterations, as well as computational complexity considerations.", "Weaknesses": "1. While the paper addresses high-dimensional optimal transport, the experimental results focus largely on specific tasks and setups. More diverse and larger-scale experiments could strengthen the empirical validation.\n2. The approach relies heavily on initial flow approximations, and the choice of initialization could significantly impact the model's performance. More discussion and analysis on this aspect would be beneficial.\n3. The paper mentions that the model's performance scales with the number of time steps in the trajectory, which could be a computational bottleneck for very high-dimensional data or real-time applications.", "Questions": "1. How sensitive is the proposed Q-flow model to the choice of initial flow approximations, and how does it affect convergence speed and quality?\n2. Can the Q-flow framework be adapted to handle discrete distributions or mixed-type data, and if so, what challenges might arise in such adaptations?\n3. Are there specific applications or domains where the proposed method is expected to significantly outperform existing optimal transport or flow-based models?"}}
{"paper_id": "YIls9HEa52", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel extension of recurrent switching linear dynamical systems by incorporating a semi-Markov discrete state process and a PDE-based prior, enhancing the flexibility and geometry of the model.\n2. The methodology is well-grounded in theoretical principles, improving upon traditional methods and providing a more robust framework for modeling non-stationary neural dynamics.\n3. The experimental validation, including synthetic and real neural data, is thorough and demonstrates the model's ability to uncover complex dynamics and improve interpretability compared to existing models.", "Weaknesses": "1. While the proposed method is innovative, the explanation of its implementation and potential computational overhead may not be easily accessible to practitioners less familiar with PDEs or advanced state-space modeling techniques.\n2. The model's dependence on careful tuning of hyperparameters, such as the geometry of discrete states, could limit its accessibility and applicability across different datasets without significant user expertise or additional computational resources.", "Questions": "1. How does the proposed irSLDS model perform when dealing with datasets with more complex or unknown underlying dynamical structures? Are there any limitations observed when the real data significantly deviates from the assumptions made by the model?\n2. How sensitive is the model to the choice of the diffusion coefficient and other hyperparameters in practice, and what strategies would you recommend for selecting these in the absence of prior knowledge about the dataset?"}}
{"paper_id": "koYsgfEwCQ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach, DynaVol, for unsupervised 3D scene decomposition using object-centric voxelization, which integrates geometric structures and object-centric learning in a differentiable volume rendering framework.\n2. It showcases strong experimental results, consistently outperforming existing methods like SAVi, uORF, HyperNeRF, and D2NeRF for both synthetic scenes and real-world datasets in terms of PSNR, SSIM, and FG-ARI.\n3. The approach allows for additional capabilities such as dynamic scene editing and novel view synthesis, highlighting its flexibility and potential for practical applications.", "Weaknesses": "1. The reliance on voxel representations may pose scalability challenges for very large or extremely detailed scenes due to computational demands.\n2. While the method shows improved results, the detailed theoretical reasons for why the combination of object-centric voxelization and volume rendering outperforms other methods are less discussed.\n3. The evaluation does not explore certain complex real-world scenarios where highly irregular motion or occlusion is prevalent, which might impact the applicability of DynaVol in all realistic settings.", "Questions": "1. How does DynaVol handle occlusions or cases where objects are in contact over extended periods? \n2. Can the approach be adapted or extended to handle more complex dynamics, such as non-linear motion trajectories or interactions between multiple dynamic objects effectively?\n3. What are the computational trade-offs in terms of memory and processing power for training and utilizing DynaVol compared to other methods?"}}
{"paper_id": "o6AN2ZoNw2", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The method proposed, P-Seg, is conceptually simple and effective, relying solely on pseudo-masks and language for open-vocabulary segmentation, which makes it a highly accessible framework for the community.\n2. It achieves state-of-the-art performance on multiple benchmark datasets, demonstrating robustness and capability in generalized settings without the need for manual annotations or large-scale pretrained models.\n3. The paper includes comprehensive experiments showing consistent improvements with scalable data and effective use of self-training, proving the method's scalability and adaptability.", "Weaknesses": "1. The approach may rely heavily on the quality of pseudo-masks, and despite outperforming other methods, the details of how pseudo-mask generation might fail in diverse contexts is not extensively covered.\n2. The paper, while highly performant with its approach, indicates that some conditions e.g., self-training might represent an overhead in certain use-cases where immediate prediction rather than iterative improvement is necessary.", "Questions": "1. How does P-Seg handle semantic categories that are extremely close in appearance and difficult to differentiate visually?\n2. Can the method be adapted for other tasks beyond segmentation, such as object detection or panoptic segmentation, using similar principles in pseudo-label generation?\n3. How much does the choice of image-text dataset (e.g., Conceptual Captions) impact the generalizability and real-world performance of the model?"}}
{"paper_id": "HXZK1Z8tHa", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. ShareFormer introduces an innovative approach to reduce latency and improve trainability simultaneously by sharing attention maps among neighboring blocks and adding residual connections to the 'Value' in self-attention. \n2. The paper provides comprehensive experiments across various image restoration tasks, showing superior performance and efficiency compared to state-of-the-art methods.\n3. The method achieves a balance between efficiency, performance, and trainability in Transformer-based networks, demonstrating its practicality for real-world applications.", "Weaknesses": "1. While the ShareFormer achieves impressive results, the method's reliance on specific architectural designs such as the combined shared attention unit (CSAU) and the gated-Dconv feed-forward network (GDFN) may limit its adaptability to tasks beyond the ones evaluated.\n2. The effectiveness of SPSA might be tied closely to the specific setup used, such as the NVIDIA RTX 3090 GPU, and might need adjustments for different hardware setups or configurations.", "Questions": "1. How does the performance of ShareFormer maintain if experimented with different hardware configurations, especially in resource-constrained environments?\n2. Are there any specific limitations to the CSAU configuration that might impede the adaptation of ShareFormer to tasks involving very high-resolution images or other domains not explored in the paper?"}}
{"paper_id": "QO3yH7X8JJ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces Diff-SR, an innovative method leveraging pre-trained diffusion generative models for target-resolution super-resolution (TRSR) without additional training or fine-tuning, allowing for effective adaptation to different upscaling scenarios.\n2. The theoretical underpinning based on the Perceptual Recoverable Field (PRF) is robust, providing a clear methodology to determine noise injection amounts for optimal image recovery.\n3. Extensive experiments showcase the superior performance of Diff-SR across multiple datasets, demonstrating its effectiveness and adaptability in diverse settings.", "Weaknesses": "1. While the theoretical foundation is strong, the exploration of different noise schedulers may reflect a certain sensitivity of the proposed method to these parameters, requiring careful selection and tuning of noise levels.\n2. The approach mainly focuses on the advantages over other diffusion-based methods, and broader comparisons to more recent transformer-based or other state-of-the-art super-resolution techniques could be beneficial.", "Questions": "1. How do different architectures of pre-trained DGMs, like Stable Diffusion or other backbone structures, impact the performance of Diff-SR in TRSR tasks?\n2. Can Diff-SR be extended to real-time applications, and what are the computational implications for implementing it on embedded devices with limited resources?\n3. How can the approach be adapted or improved to handle extremely high compression rates (e.g., beyond 8×) where PRF doesn't yield acceptable outputs?"}}
{"paper_id": "sNtDKdcI1f", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper offers a comprehensive analysis of the influence of output length on reinforcement learning from human feedback (RLHF) outcomes, revealing that length is a significant factor in reward model optimization. 2. The exploration of various intervention strategies provides valuable insights into the limitations of current reward modeling approaches and opens a path for future enhancements in RLHF.\n3. The paper promises to release code and models, which can support further research in the community.", "Weaknesses": "1. While length is identified as a significant factor, the paper does not thoroughly explore other possible features that could contribute to RLHF's improvement, leaving the analysis somewhat incomplete about the full range of influencing factors. 2. The reliance on open-source datasets and models may limit the generality of findings, as these may not capture the complexities of larger, closed-source systems or different objectives such as harmlessness. 3. The paper's exploration remains within the constraints of existing reward modeling paradigms, potentially overlooking more substantial changes to the RLHF framework that could address identified biases.", "Questions": "1. How can the proposed findings be generalized to objectives beyond helpfulness, such as harmlessness? 2. Does the influence of length on reward model optimization suggest changes solely at the intervention stage, or could alterations in initial reward model design play a more substantial role? 3. What strategies might advance the identification and integration of meaningful features beyond length that stakeholders care for in outputs?"}}
{"paper_id": "HFtrXBfNru", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper addresses a relevant problem in evolving graphs where Graph Neural Networks (GNNs) are challenged by representation distortion over time. \n2. The theoretical foundation is strong, establishing a lower bound for representation distortion and showing its inevitable increase over time. \n3. The proposed method, SMART, offers a self-supervised solution that improves temporal generalization estimation significantly. \n4. The extensive experiments on both synthetic and real-world datasets convincingly demonstrate the effectiveness of the proposed method.", "Weaknesses": "1. The reliance on graph reconstruction might be sensitive to the quality and type of data augmentation, which is not extensively discussed in the paper. \n2. Although the theoretical contributions are solid, the practical performance gain over existing baselines is not revolutionary, merely showing moderate improvements in some cases.", "Questions": "1. How does SMART perform in scenarios where the graph evolves very rapidly or the changes in the graph structure are more drastic compared to the real-world datasets used in the paper? \n2. Are there other augmentation strategies that could potentially enhance the self-supervised signals, and how do different augmentation choices affect performance? \n3. Could SMART be extended to handle heterogeneous graphs or those with dynamic label changes more effectively, and if so, how?"}}
{"paper_id": "4u0ruVk749", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. Introduces a novel approach to use diffusion models for modeling unobserved confounders in causal inference tasks, which is a promising direction given the limitations of existing methods like GAN and VAE.\n2. The empirical results demonstrate consistent improvements over state-of-the-art methods on both synthetic and benchmark datasets.\n3. The paper provides a solid theoretical basis for the approach, with a closed-form derivation of the variational lower bound used in training.", "Weaknesses": "1. The practical applicability of the method may be limited by the need for carefully setting hyperparameters and understanding the diffusion process, which can be complex and computationally intensive.\n2. The paper's presentation, while comprehensive, could be improved for clarity and accessibility, especially for readers who might not be familiar with diffusion models.\n3. The assumptions required for the method to hold, such as the ability to perfectly model the unobserved confounders, might not be easily met in real-world scenarios.", "Questions": "1. How sensitive is the model's performance to the choice of hyperparameters in the diffusion process, and what strategies are recommended for their tuning?\n2. Can the diffusion model approach be justified in terms of providing additional insights into the data or the unobserved confounders, beyond improved estimation accuracy?\n3. What are the computational costs associated with training this model compared to traditional methods like GANITE or CEVAE, and are there practical limits to its scalability?"}}
{"paper_id": "Pa6SiS66p0", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a novel benchmark for multimodal continual learning, addressing a well-recognized gap in the field of continual learning.\n2. The proposed SAMM method shows strong potential for improving multimodal learning performance by effectively integrating and aligning information from various modalities.\n3. The study provides a comprehensive evaluation framework and baseline results, facilitating future research in multimodal continual learning.\n4. The work effectively demonstrates that leveraging multiple modalities can mitigate catastrophic forgetting, showing promising results across different CL scenarios.", "Weaknesses": "1. The paper might benefit from a deeper exploration of the underlying reasons why certain modalities provide better performance and retention in continual learning settings.\n2. The applicability of the proposed method is somewhat restricted to scenarios where multimodal datasets are available, and it may not directly translate to environments where data is predominantly unimodal.\n3. More empirical evaluation on diverse datasets could strengthen the generality claims of the benchmark.", "Questions": "1. How does the method perform when one modality is significantly more noisy or less informative than the others?\n2. Is there a mechanism to dynamically determine the importance or contribution of each modality in real-time during inference?\n3. Have you considered examining the use of this approach in purely unimodal settings to assess its versatility further?"}}
{"paper_id": "rkplYfqUr0", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "GEN-Z introduces a novel generative approach for zero-shot text classification that addresses issues related to prompt sensitivity and lack of robustness in existing methods by using contextualized label descriptions. The paper provides a comprehensive evaluation strategy across multiple datasets, demonstrating the advantages of the method over traditional zero-shot and few-shot techniques.", "Weaknesses": "While GEN-Z shows promising results, the dependency on manually curated label descriptions and the need for multiple paraphrases per label may limit its scalability. Additionally, the approach primarily focuses on English datasets, which restricts its generalizability to other languages.", "Questions": "How well does GEN-Z perform on tasks that require understanding of nuanced linguistic phenomena beyond binary classification, such as irony detection? How much effort is required to create these contextualized labels, and can this process be automated more efficiently?"}}
{"paper_id": "pTU2X9mUBe", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. LaDe is the first publicly available last-mile delivery dataset, providing a large-scale, comprehensive, and diverse dataset that is significant for the research community.\n2. The dataset includes data from various contexts such as package pick-up and delivery across multiple cities, which supports a wide range of logistics and supply chain management tasks.\n3. The authors offer thorough data analysis and benchmark the dataset on three representative tasks, showcasing its utility and potential to support diverse research endeavors.", "Weaknesses": "1. While the paper presents and validates the dataset effectively, it could further explore additional novel applications or methodological advancements informed by the dataset.\n2. Some details about the privacy measures taken in data collection could be further elaborated to ensure sufficient anonymity and compliance with regulations.", "Questions": "1. Given the dynamic nature of the dataset, what are the authors' suggestions for efficiently updating or expanding LaDe as more data becomes available or as the last-mile delivery environment evolves?\n2. How do the authors envision addressing potential challenges with data bias that might arise from focusing on specific urban areas or demographic characteristics?"}}
{"paper_id": "uhtQyRrTzY", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel method for creating multi-view image datasets that do not require annotations, filling a significant gap in the current methods reliant on 3D metadata.\n2. The methodology is scalable, leveraging classical computer vision techniques to automate dataset curation, demonstrating promise for representation learning in dense vision tasks.\n3. The experimental results show that models trained on the MIMIC datasets outperform those trained on traditionally curated datasets like ImageNet and synthetic datasets such as MULTIVIEW-HABITAT in various dense vision tasks.\n4. The paper is well-organized with clear explanations of the methodology, experiments, and results, making it accessible to the reader.", "Weaknesses": "1. The reliance on static scenes limits the potential for broader applications, and the method's effectiveness on dynamic scenes remains unexplored.\n2. The focus on dense vision tasks might narrow the range of applications, with object-centric tasks still relying significantly on curated datasets.\n3. The paper does not address the potential risks or biases introduced by web-scale data sources or the ethical considerations of using internet-sourced videos extensively.", "Questions": "1. How would the methodology perform on dynamic scenes or videos with significant motion, which are not covered in this study?\n2. Is there a plan to include more diverse object-centric sources to enrich the dataset further for tasks requiring detailed object understanding?\n3. How can the method be adapted to ensure ethical considerations and address possible biases, especially if expanded to web-scale data collection?"}}
{"paper_id": "WZfatbNdLV", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces TrASPr, an innovative multi-Transformer based model that significantly outperforms existing models in predicting tissue-specific RNA splicing.\n2. The application of TrASPr as an oracle in Bayesian Optimization (BOS) for RNA sequence design shows a novel approach to achieving user-defined splicing outcomes effectively.\n3. TrASPr integrates complex genomic and splicing features, enhancing predictive accuracy and offering insights into regulatory elements.", "Weaknesses": "1. The presentation could be more organized and clearer for readers unfamiliar with RNA splicing; some parts of the explanation and figures are dense.\n2. The model's dependency on high-quality labels and potential noise in biological datasets could challenge its generalizability and real-world application.\n3. There is limited discussion on integrating the model's outputs into practical applications, like clinical or broader biological research settings.", "Questions": "1. How does the model handle instances where known RBP motifs or splice sites are not well defined or show considerable variation among different biological datasets?\n2. Can the generative model be adapted to other scenarios or types of genetic modification, beyond splicing outcomes?\n3. How could the model be adapted or improved to better handle low RNA-Seq coverage in rare transcripts?"}}
{"paper_id": "YkRwadXWHd", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel multi-modal approach for CSLR that effectively combines video, keypoints, and optical flow modalities, showing significant improvements on benchmark datasets. 2. The introduction of a hierarchical knowledge distillation framework to reduce computational costs while maintaining high performance is innovative. 3. The experiments are thorough and demonstrate state-of-the-art performance across multiple benchmark datasets.", "Weaknesses": "1. The proposed method's dependency on the availability of keypoint and optical flow data might limit its applicability in some scenarios where extracting such data is not feasible. 2. While the hierarchical knowledge distillation is effective, the paper does not fully explore its limitations, such as when it may fail to distill knowledge effectively.", "Questions": "1. How does the performance of the multi-modal model change with varying numbers of available modalities during testing? 2. Have the authors considered the impact of noisy data on keypoints or optical flow, and how robust is the model under such conditions?"}}
{"paper_id": "q4Bim1dDzb", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper presents a novel and efficient framework for inverse rendering that significantly reduces training time while maintaining high reconstruction quality. 2. The integration of Spherical Gaussians for illumination modeling effectively enhances computational efficiency, setting a new benchmark for speed in this domain. 3. The quantitative and qualitative results demonstrate the superiority of the proposed method over existing state-of-the-art approaches.", "Weaknesses": "1. The approach's dependency on Spherical Gaussians may limit its adaptability to certain lighting conditions where other methods could potentially perform better. 2. While the data efficiency is commendable, the paper might lack discussion on scalability when applied to extremely large or complex scenes.", "Questions": "1. How does the method perform in highly dynamic scenes where both lighting and geometry frequently change? 2. Can the framework be easily adapted or extended to other modalities beyond visual scenes, such as audio or sensor data?"}}
{"paper_id": "39cPKijBed", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel method, Time-dependent Importance Reweighting (TIW), which addresses dataset bias in diffusion models effectively and outperforms existing methods.\n2. The theoretical connections between TIW and traditional score-matching objectives are clearly established, and the paper demonstrates convergence to an unbiased distribution.\n3. The experimental validation is thorough, covering multiple datasets and demonstrating superiority over baselines even in challenging settings.\n4. Implementation details and code availability enhance reproducibility.", "Weaknesses": "1. While TIW shows significant improvements, the scalability to larger, more complex datasets and real-world bias types remains to be fully tested.\n2. The method's reliance on a time-dependent density ratio could introduce computational overhead compared to simpler approaches.", "Questions": "1. How does the computational complexity of TIW compare to time-independent methods, and is this feasible for large-scale datasets?\n2. Can the approach be easily extended to handle bias in other types of generative models, like GANs, or is it specifically optimized for diffusion models?"}}
{"paper_id": "aG3EARrrd1", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper introduces a novel Online Sparse Residual Tree (OSRT) algorithm that effectively handles streaming multivariate scattered data with higher efficiency and accuracy compared to existing methods.\n2. The implementation of online tree decomposition and adaptive radial basis function exploration is a noteworthy contribution to improving online learning models.\n3. The evaluation on various datasets demonstrates the practicality and effectiveness of OSRT in improving predictive performance.", "Weaknesses": "1. The explanation of the adaptive RBF exploration process and its mathematical details is quite complex and may be difficult for readers unfamiliar with the domain.\n2. Though the proposed OSRT is promising, the experiments are limited to two datasets and do not provide extensive insights into its scalability or generalization across diverse real-world scenarios.\n3. The paper lacks a thorough discussion on possible limitations or constraints of the OSRT model, which might impact its applicability.", "Questions": "1. What are the potential limitations or drawbacks of the OSRT model when applied to large-scale, high-dimensional streaming data?\n2. How sensitive are the model's performance and efficiency concerning the choice of hyperparameters, such as the maximum depth of the tree or the shape parameter for RBF?\n3. Can the OSRT framework be extended to incorporate other types of basis functions or integrate additional modalities?"}}
{"paper_id": "Ts95eXsPBc", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a novel framework for incorporating spatial awareness into transformers, enhancing their applicability for embodied agents. This is a unique approach in the context of memory and reasoning, potentially offering substantial improvements in various downstream tasks. 2. The proposed models and methods, Spatially-Aware Transformers and Adaptive Memory Allocator, exhibit clear benefits across multiple applications, including spatial reasoning, image generation, and reinforcement learning. 3. The paper includes comprehensive experiments demonstrating the practical utility and advantages of the approach, and open-sourcing the code further bolsters its contribution.", "Weaknesses": "1. The reliance on explicit spatial annotations may limit the applicability of the proposed models to scenarios where such data is not readily available. 2. The Adaptive Memory Allocator, while more flexible than existing FIFO strategies, still depends on a predefined set of strategies rather than discovering strategies in a more autonomous manner. This might restrict adaptability and the scope of optimal solutions. 3. The theoretical foundation, though robust, might not be easily generalizable to non-spatial tasks or tasks without a direct spatial component.", "Questions": "1. How does the model performance scale with increasing complexity in environments beyond those tested, especially when spatial annotations are noisy or incomplete?\n2. To what extent can the Adaptive Memory Allocator be adapted to scenarios where spatial information is present but sparse or indirect, and how does that affect the efficiency of spatial reasoning tasks?"}}
{"paper_id": "LfhG5znxzR", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper presents a novel method for incorporating discrete, interpretable representations in neural networks, improving interpretability and enabling controlled interventions.\n2. The extensive validation across multiple datasets demonstrates the potential of codebook features for neural network interpretability and control.\n3. The presentation of the method and results is clear, with well-structured sections that are easy to follow.", "Weaknesses": "1. The approach, while promising, has limited exploration beyond Transformer architectures and specific language modeling tasks, potentially limiting the immediate applicability to other models.\n2. The dependency on high-quality, fine-tuned models for successful implementation might limit the accessibility of the method for non-pretrained models.\n3. The method's applicability to other types of data, such as visual datasets, is not addressed, leaving much of its versatility in question.", "Questions": "1. Can the codebook features be applied to other neural network architectures beyond Transformers? How might this method generalize to models like CNNs or RNNs?\n2. How do the codebook features perform in tasks involving visual data? Are there any plans to extend this work to vision-related datasets?\n3. What are the factors that determine the optimal codebook size and sparsity for different tasks, and how sensitive is the approach to these hyperparameters?"}}
{"paper_id": "bUGzjiUsIq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses a significant challenge in multi-label classification, particularly for datasets with partial annotations, by proposing a novel reinforcement learning framework.\n2. The proposed PAPG method effectively combines reinforcement learning with local and global rewards to address class imbalance and label scarcity issues, which is demonstrated to outperform existing methods on various tasks and datasets.\n3. The experiments are thorough, covering different domains and providing clear evidence of the framework's superiority over baseline methods.", "Weaknesses": "1. The reliance on reinforcement learning makes the framework potentially complex and challenging to implement and tune, especially in terms of hyperparameters and reward functions.\n2. While the framework shows promise, the scalability and efficiency of the method in real-world large-scale settings are not fully addressed or tested.\n3. The necessity of the chosen setup and the specific design of local and global rewards could benefit from further theoretical justification and exploration.", "Questions": "1. How does the method perform with extremely large datasets where the label space is vast? Are there considerations for scaling the approach?\n2. Can the approach generalize to other weakly-supervised scenarios beyond partial annotations, such as semi-supervised or unsupervised tasks?\n3. How sensitive is the framework to the choice of policy gradient algorithm and associated hyperparameters?"}}
{"paper_id": "uMAujpVi9m", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach to generating large-scale pocket-ligand data using protein fragment-surroundings alignment, addressing a significant data scarcity issue in the field.\n2. The proposed contrastive learning method effectively transfers biochemical knowledge from small molecule encoders to pocket representations.\n3. The method achieves state-of-the-art results in multiple benchmark tasks, demonstrating its robustness and generalization capabilities.\n4. The work is presented with clear experiments and thorough ablation studies that confirm the efficacy of the approach.", "Weaknesses": "1. The reliance on predefined small molecule encoders might limit the generality of the method if those encoders are not representative of broader chemical spaces or are not available.\n2. While the paper claims the potential applicability to large predicted structure datasets like AlphaFold2, it does not provide empirical results on such datasets, leaving these claims unverified.\n3. The method's performance might heavily depend on the quality of the initial protein segmentation, which the paper does not extensively address in terms of error handling or optimization.", "Questions": "1. How does the performance of ProFSA change when using small molecule encoders other than the ones tested? Are there specific characteristics of these encoders that are crucial for the success of ProFSA?\n2. Can the proposed method be extended to other applications such as protein-protein interaction modeling without significant modifications?\n3. What are the potential biases introduced by the pseudo-ligand creation process, and how might these affect downstream application in real ligand-binding scenarios?"}}
{"paper_id": "uqxBTcWRnj", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces the Transitional Dictionary Learning (TDL) framework, a novel approach to bridging neural and symbolic representations, showing substantial improvements over state-of-the-art unsupervised part segmentation methods.\n2. The proposed metrics for evaluating learned representations, such as the Clustering Information Gain and heuristic shape score, are innovative and demonstrated to be consistent with human evaluations.\n3. Comprehensive experiments on multiple datasets demonstrate the model's potential to successfully learn and utilize compositionality in abstract objects without supervision.", "Weaknesses": "1. The dependency on abstract dataset evaluations may not generalize well to real-world applications, where data often has more complex and noisier visual features.\n2. While the paper introduces a novel framework, the conceptual leap in terms of what new symbolic capabilities this offers neural networks is still somewhat exploratory and not fully realized in practical tasks.", "Questions": "1. How well does the Transitional Dictionary Learning framework apply to more real-world datasets with less abstract forms and noisier backgrounds?\n2. Can the proposed methods and metrics for evaluating representation be generalized to modalities other than imagery, such as text or audio data?"}}
{"paper_id": "o4CLLlIaaH", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach, Generalizable neural Point Field (GPF), which successfully transitions neural radiance fields from image-based rendering to point-based rendering, addressing several key limitations like occlusions and geometric variances.\n2. Strong experimental results showcasing state-of-the-art performance in terms of geometry consistency, rendering quality, and speed across multiple datasets, providing empirical evidence for the proposed paradigm's effectiveness.\n3. The method also supports interactive manipulation of scenes, adding practical value beyond conventional applications.\n4. Detailed descriptions and illustrations of methodology components and their interrelationships enhance understanding and reproducibility.", "Weaknesses": "1. The dependency on PatchmatchMVS for initial point scaffolding may limit the generalizability and adaptability of the model, potentially hindering efficiency in cases where easier or more integrated initialization methods could be advantageous.\n2. Though the point-based paradigm holds promise, it is nascent in comparison to well-established image-based methods, which might imply unforeseen challenges or inefficiencies.\n3. While interactive manipulation is a beneficial byproduct, its demonstration is limited to a few examples, making it difficult to gauge its real-world applicability and efficiency on larger scales.", "Questions": "1. How might the proposed GPF handle extremely sparse datasets where initial point cloud accuracy is significantly compromised?\n2. Could the methodology be adapted to dynamically update the point cloud scaffold in real-time scenarios where scene changes occur frequently, and if so, how would that affect computational efficiency?"}}
{"paper_id": "KNzL1nglNB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper addresses an important problem of handling label insufficient scenarios, which is relevant to various real-world applications.\n2. The proposed Label-encoding Risk Minimization (LRM) method demonstrates effectiveness across different scenarios such as semi-supervised learning, unsupervised domain adaptation, and semi-supervised heterogeneous domain adaptation.\n3. The approach provides a new perspective by leveraging the neural collapse phenomenon and label encodings to guide the learning of unlabeled samples.", "Weaknesses": "1. The theoretical analysis, while providing insights into neural collapse and its relation to LRM, might benefit from stronger experimental backing to validate its claims in real-world settings.\n2. The proposed method is primarily compared with EntMin and BNM, but comparisons could be expanded to include more diverse approaches or baselines.\n3. The dependency on accurate estimation of class means for unlabeled samples could be a limitation in cases where the feature space is highly irregular.", "Questions": "1. How sensitive is the LRM to the choice of initialization for model parameters in various label insufficient scenarios?\n2. Can the LRM be extended to scenarios where both labels and features are imbalanced?\n3. How does the LRM handle cases with high noise levels in unlabeled data, more so compared to existing approaches like EntMin?"}}
{"paper_id": "pvhyBB86Bt", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. This work significantly extends prior theoretical analyses of the input-output Jacobian by considering its behavior beyond initialization and during the training of neural networks.\n2. The paper introduces a broad theoretical framework leveraging recent advances in random matrix theory to explain instability during training and after network pruning.\n3. The analysis not only addresses initialization stability but also explains different phases of Jacobian norm behavior during training, providing empirical support for theoretical findings.", "Weaknesses": "1. The paper's analysis is restricted to MLP architectures, which limits its immediate applicability to modern deep learning architectures such as CNNs and Transformers. \n2. The assumptions and approximations, though justified, might not hold in practical settings with complex datasets and architectures, potentially limiting the generalizability of the results.", "Questions": "1. How might the proposed theoretical insights be extended to more complex and modern architectures like CNNs or Transformers?\n2. Can the dependence on certain approximations such as independence between weights be relaxed in future analyses to enhance applicability?"}}
{"paper_id": "Mylk5iamJC", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel integration of latent generative models with a collaborative training scheme for both closed-set and open-set recognition, offering a unified framework for both tasks. \n2. The proposed L-GMM model demonstrates superior performance in both CSR and OSR compared to baseline and competing methods on several challenging benchmarks.\n3. The theoretical formulation aligns with the empirical evidence provided, and the experiments are robust, showing clear improvements across diverse datasets.", "Weaknesses": "1. The paper could further elaborate on the computational overhead of L-GMM compared to purely discriminative approaches to highlight practical considerations.\n2. While the generative model's benefits are well presented, the paper may have limited discussions about potential challenges or limitations in modeling very high-dimensional latent spaces or complex distributions.", "Questions": "1. How does the complexity of the latent space model impact the training time and the convergence rate compared to purely discriminative models?\n2. Are there specific scenarios or dataset characteristics where L-GMM might underperform compared to conventional methods?"}}
{"paper_id": "MsOcVFzv8D", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper presents a novel theoretical analysis for multi-domain text classification (MDTC) using margin discrepancy, providing a new generalization bound based on Rademacher complexity, filling significant gaps in the theoretical understanding of MDTC. \n2. The proposed MDAT method is well-founded on the theoretical analysis, offering robust performance improvements on two benchmark datasets, surpassing several state-of-the-art methods.\n3. The paper provides detailed empirical validation and theoretical exposition, including generalization bounds, enhancing the work's credibility and robustness.", "Weaknesses": "1. The reliance on margin discrepancy and Rademacher complexity might limit applicability to problems where these frameworks are well understood but might not translate directly to other types of classification tasks or domains without further investigation.\n2. The proposed method and its evaluation focus heavily on the provided benchmarks, which can limit insights into performance in diverse real-world scenarios with different domain complexities.", "Questions": "1. How well does the MDAT method scale with the increasing number of domains or larger datasets?\n2. Can the theoretical insights derived in the margin discrepancy approach be generalized to address other domain adaptation tasks beyond text classification, such as image classification or other modalities?\n3. Are there potential limitations when applying this method to MDTC tasks that involve complex domain relationships not well-captured by margin discrepancy?"}}
{"paper_id": "fBlHaSGKNg", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a novel methodology for sample selection in semi-supervised learning that is both efficient and effective under constrained annotation budgets.\n2. The innovation lies in the proposed α-MMD criterion for selecting representative and diverse samples, which is both theoretically grounded and practically validated with empirical results.\n3. The UPA method demonstrates significant improvements over existing active learning and semi-supervised active learning methods, even with less annotation budget.", "Weaknesses": "1. While the method is promising, the dependency on pre-trained models like CLIP for feature extraction may limit its applicability to domains where such models are unavailable or ineffective.\n2. The theoretical assumptions, such as those concerning RKHS, might not hold universally, potentially limiting the generalizability of the results.\n3. The impact and significance of the trade-off parameter α could have been explored in more depth to provide further understanding and guidance on its selection.", "Questions": "1. How does the α-MMD method compare to other diversity measures not explored in the paper?\n2. Can the UPA method be adapted to other domains where different types of unlabeled data or modalities are prevalent?\n3. What are the potential limitations when extending UPA to very large-scale datasets beyond CIFAR and SVHN?"}}
{"paper_id": "HwQ8NVvdmm", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach for applying fully quantized training to class-incremental learning, thus addressing energy-efficiency on resource-constrained devices. 2. It leverages Hadamard transforms and quantized operations to reduce computational requirements without significant loss in accuracy. 3. The technique achieves promising results on various datasets, including CIFAR100, while maintaining competitive performance with much lower bit-width.", "Weaknesses": "1. The methodology relies on Hadamard transforms, which might have specific limitations or overheads not covered extensively in the evaluation, such as the potential increase in computation time due to transformation and inverse transformation. 2. The approach might not generalize to all types of CL techniques or datasets, as it is primarily demonstrated on a subset of popular datasets without discussing potential limitations in other contexts.", "Questions": "1. How well does the proposed quantization approach generalize to other continual learning scenarios outside of class-incremental learning? 2. What are the potential computational trade-offs introduced by employing Hadamard transforms in terms of execution time and power consumption in real-world edge devices?"}}
{"paper_id": "cZo6pDtDZr", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces new private estimation and sequential testing algorithms for collision probability that are near-optimal and improve significantly over previous methods.\n2. The algorithms have practical advantages in terms of sample complexity, making them suitable for applications with privacy constraints and large distribution support.\n3. The paper provides rigorous theoretical guarantees and comprehensive experiments showing effectiveness over existing approaches.", "Weaknesses": "1. The presentation could be improved, as some technical details might be challenging to understand without extensive background knowledge in differential privacy and statistical estimation.\n2. The algorithms primarily focus on scenarios where collision probability is the measure of interest, which may limit applicability to broader statistical estimation tasks.", "Questions": "1. How does the performance of the proposed algorithms degrade as the privacy parameters become more stringent (e.g., as α and β get smaller)?\n2. Can the sequential testing approach be adapted or extended to work with other types of distributional properties beyond collision probability?"}}
{"paper_id": "F7QnIKlC1N", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper presents a novel method, GTMGC, which effectively predicts molecular ground-state conformations from 2D topological structures using a transformer-based approach. \n2. The inclusion of a unique self-attention mechanism, Molecule Structural Residual Self-Attention (MSRSA), which enhances the model's ability to capture molecular structures.\n3. The approach demonstrates superior performance over existing methods across multiple benchmarks, indicating strong empirical results.", "Weaknesses": "1. While the paper provides strong empirical results, the novelty in the transformational architecture and attention mechanism might be seen as iterative rather than ground-breaking. \n2. There is a heavy reliance on transformer's global attention mechanism which, although effective, may come with high computational cost.", "Questions": "1. How does GTMGC handle large-scale datasets or very large molecules considering the computational complexity of transformers?\n2. Can the MSRSA attention mechanism be generalized or adapted to other types of graph data beyond molecular structures?\n3. How significant is the impact of the input format, and could further improvements be possible by refining the tokenization process?"}}
{"paper_id": "8JCn0kmS8W", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. WavJourney integrates large language models (LLMs) with various expert audio generation models, presenting a novel and effective framework for compositional audio creation from textual descriptions.\n2. The approach leverages LLMs to provide a structured audio script, enhancing the interpretability and control over audio generation, which is a significant advancement over end-to-end methods.\n3. The framework demonstrates strong performance in both objective and subjective evaluations on recognized benchmarks, outmatching current state-of-the-art in generating realistic audio aligned with complex text descriptions.", "Weaknesses": "1. The dependency on structured audio scripts and a script compiler might limit the extensibility and scalability of the framework when incorporating new functionalities or adapting to emerging audio generation tasks.\n2. As the framework decomposes and remixes audio clips, it risks producing artificial compositions that may diverge from natural sound distributions, especially in nuanced music compositions that require a holistic understanding of harmony and melody.\n3. The reliance on external LLMs and audio generation models may introduce computational inefficiency, hindering real-time applications or large-scale deployments.", "Questions": "1. Could you provide insights on how WavJourney handles synchronization and coherence issues when combining outputs from different task-specific audio models?\n2. What strategies are in place for scaling WavJourney's framework to accommodate an extensive library of audio effects, music genres, and spoken languages beyond the initial setup?\n3. Is there potential for enhancing the efficiency of WavJourney for applications requiring quick generation of complex audio content, and what future directions could address these efficiency concerns?"}}
{"paper_id": "XbLffB0T2z", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel method, Transferable Poisoning, which effectively addresses the limitations of existing data poisoning attacks in terms of transferability across different learning paradigms.\n2. Extensive experimental results demonstrate the method’s superiority in creating poisoned samples with high transferability and effectiveness across supervised, semi-supervised, and unsupervised learning paradigms.\n3. The theoretical insights into frequency-level characteristics of perturbations provide a deeper understanding of the transferability issue, contributing to the literature on adversarial attacks in machine learning.", "Weaknesses": "1. The study primarily focuses on vision classification tasks, raising questions about the generalizability of the findings to other domains such as natural language processing or time-series analysis.\n2. The method relies heavily on PGD and may face computational challenges when scaling to larger datasets or more complex models, potentially limiting its applicability in real-world scenarios.", "Questions": "1. How might the proposed method extend to domains beyond image classification, such as natural language processing or tasks involving sequential data?\n2. Can any improvements in computational efficiency be achieved to make Transferable Poisoning more scalable for larger datasets and more complex models?\n3. How does the method perform against recent defenses specifically designed to counteract transferability of adversarial attacks?"}}
{"paper_id": "4y3GDTFv70", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper presents a novel theoretical framework to explain emergent abilities in large language models (LLMs), categorizing languages into unambiguous and ε-ambiguous categories.\n2. It introduces the idea of LLMs as universal density approximators of marginal distribution, providing a new perspective on their capabilities.\n3. The use of synthetic language experiments to validate theoretical propositions is a strong point, reinforcing the paper's theoretical analysis with empirical validation.", "Weaknesses": "1. The study heavily relies on the assumption that language is generated from a latent intention space, which may not fully encapsulate the complexity of natural language evolution and usage.\n2. While the theoretical basis is solid, the paper may lack immediate practical applications or guidelines for improving current LLM architectures.\n3. The connection between theoretical results and real-world LLM behavior could be better established.", "Questions": "1. How can the proposed latent space theory be used to improve the design or training of future language models?\n2. Are there any practical implications or applications of this theory in areas outside of language modeling?\n3. How robust are the models to variations in language ambiguity, especially in practical scenarios given the theoretical emphasis on ε-ambiguity?"}}
{"paper_id": "ODSgo2m8aE", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. This paper addresses a significant challenge in relational learning by integrating Lipschitz bounds to mitigate the effects of input bias on GNN outputs, thereby promoting fairness.\n2. The work offers a novel theoretical framework and introduces a plug-and-play solution, JacoLip, which integrates seamlessly with existing GNN architectures.\n3. Empirical results demonstrate the effectiveness of Lipschitz bounds in enhancing fairness across several real-world datasets.", "Weaknesses": "1. While the introduction of Lipschitz bounds to GNNs is innovative, the paper does not sufficiently address the potential computational cost, particularly for very large graphs.\n2. The reliance on pre-existing train/test splits and lack of diverse datasets might limit the generalization of the model across various domains.", "Questions": "1. How does the implementation of JacoLip scale with very large datasets, and what are the computational overheads associated with it?\n2. Can the Lipschitz bound approach extend to other types of biases beyond those tested, such as those related to different data modalities or more complex network structures?"}}
{"paper_id": "RlfD5cE1ep", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper provides a novel theoretical extension to the understanding of non-contrastive learning dynamics by considering feature normalization. This extension is significant in providing an explanation for why feature normalization prevents representation collapse, addressing a gap in previous analyses.\n2. The work utilizes a thermodynamical limit approach to handle complex nonlinear dynamics, which could be a valuable technique for future research in self-supervised learning.\n3. Numerical simulations support the theoretical findings, strengthening the credibility of the proposed approach.", "Weaknesses": "1. The paper is focused primarily on theoretical insights and does not provide extensive experimental validation on real-world datasets beyond synthetic simulations, which might limit the practical applicability of the results.\n2. The framework for analyzing cosine loss dynamics might be complex for readers unfamiliar with the deep mathematical context provided in the thermodynamical limit settings and may require additional background for comprehensive understanding.", "Questions": "1. How robust are the theoretical predictions when applied to more complex and practical datasets outside of synthetic environments?\n2. Can the approach described for feature normalization be generalized to other forms of regularization or different types of non-contrastive learning models beyond SimSiam and BYOL?"}}
{"paper_id": "18TfucMNTr", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach by applying Gaussian continuation to the training of deep neural networks, which shows promise in accelerating training and reducing sensitivity to initialization. The theoretical insights are supported by empirical results across different types of tasks, including image classification and learning dynamics with neural ODEs. The presentation is clear and well-structured, making the proposed methodology and results easy to follow.", "Weaknesses": "The assumptions required for the continuation path to exist and be Lipschitz continuous might limit the applicability of the method in real-world problems that do not meet these conditions. Additionally, the computational cost of Monte Carlo continuation, due to the repeated function evaluations, is a concern, although partially mitigated by using only one sample.", "Questions": "How does the performance and efficiency of Gaussian continuation compare to other noise-based and regularization techniques in terms of both speed and final model accuracy? Could the method be combined with other architectural improvements like skip connections for better efficacy?"}}
{"paper_id": "JGTC6WgO4T", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper addresses the novel and challenging task of multi-source black-box domain adaptation (MSBDA), which is significant in practical applications where privacy and security constraints prevent access to source data and models.\n2. It proposes a pseudo-label refinery network (PRN) that utilizes attention mechanisms to effectively refine pseudo labels and explore positive knowledge transfer from multiple sources.\n3. The experimental evaluation on four benchmark datasets demonstrates the proposed method's competitive performance compared to state-of-the-art methods in various domain adaptation settings.", "Weaknesses": "1. The theoretical analysis may require further justification or simplification to enhance clarity and accessibility for readers unfamiliar with the domain.\n2. While the experimental results are comprehensive, the paper would benefit from additional ablation studies to evaluate the impact of different components on the overall performance more thoroughly.", "Questions": "1. How sensitive is the proposed method to the choice of initial pseudo labels, and how does this sensitivity impact its practical application?\n2. Could the attention mechanism used in the pseudo-label refinery network be further optimized, and if so, what approaches might prove beneficial?"}}
{"paper_id": "fQHb1uZzl7", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper presents a new approach that effectively unifies feature and cost aggregation using a Transformer-based architecture for dense matching tasks. This method elegantly combines self- and cross-attention mechanisms, showing significant improvements over previous methods in various dense matching benchmarks.\n2. The experiments clearly demonstrate the superior performance of the proposed approach, establishing new state-of-the-art results on multiple datasets.\n3. The architecture is both simple and effective, leveraging the strengths of Transformers to enhance feature and cost aggregation, which is crucial for various computer vision applications.", "Weaknesses": "1. Although the paper provides thorough experimental validation, the dependency on high computational resources for implementing the proposed Transformer-based methods may limit accessibility to researchers with less access to such resources.\n2. The method might require careful tuning of hyperparameters, such as the depth of the attention layers and the pyramidal processing, as well as efficient implementation techniques to ensure real-time performance, which are not extensively discussed.", "Questions": "1. Can the proposed method be extended or adapted to operate efficiently in real-time applications where computational resources are limited?\n2. Are there specific scenarios where the unified aggregation may not perform as expected, such as extremely large images or scenes with substantial amounts of repetitive patterns and high occlusion levels?"}}
{"paper_id": "YjG29CIOP7", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach to address two critical vulnerabilities in data-free meta-learning (DFML): Task-Distribution Shift (TDS) and Task-Distribution Corruption (TDC).\n2. TEAPOT and ROSY present innovative solutions for improving robustness against TDS and TDC, respectively, with strong empirical results demonstrating effectiveness across multiple datasets.\n3. The introduction of the model poisoning attack (MPA) provides a realistic threat model that enriches the robustness analysis of DFML methods.", "Weaknesses": "1. While the paper discusses the vulnerabilities of DFML to TDS and TDC extensively, the practical feasibility of detecting and handling more sophisticated and less obvious forms of model poisoning remains unclear.\n2. The dependency on a memory bank and interpolation mechanisms in TEAPOT might introduce additional complexity, and their scalability with respect to model and task diversity is not thoroughly explored.\n3. The assumption that all models have reliable domain information might limit the framework's applicability in environments where domain information is incomplete or incorrect.", "Questions": "1. How does the performance of the proposed methods scale with increasing diversity and size of the pre-trained model pool?\n2. Are there any specific scenarios or domains where TEAPOT and ROSY might fall short or require significant adaptations?\n3. Can ROSY be extended to handle black-box pre-trained models where internal features are not accessible?"}}
{"paper_id": "DmDpu3r8iU", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper introduces a novel framework for assessing the understanding of values by LLMs through the Value Understanding Measurement (VUM) framework, which is innovative and could inspire future research into value alignment in AI.\n2. The paper is well-organized and clearly presented, providing comprehensive background and methodology sections.\n3. The evaluation of multiple LLMs is thorough and the use of a dataset based on the Schwartz Value Survey is appropriate and well-motivated.", "Weaknesses": "1. The definition of 'know what' and 'know why' is somewhat abstract and could benefit from clearer articulation or examples.\n2. While the method is innovative, its practical implications for improving LLM alignment or safety are not fully explored. The experimental results highlight interesting phenomena but don't lead to actionable insights or clear applications.\n3. The reliance on GPT-4 for judgment of semantic similarity in values might introduce biases inherent in this model, which are not addressed or mitigated.", "Questions": "1. How feasible is it to apply the VUM framework to other sets of values or alternative cultural contexts outside of those described by the Schwartz Value Survey?\n2. Would integrating additional contextual data or utilizing multi-modal inputs impact the effectiveness of VUM in assessing value understanding in LLMs?\n3. Are there plans to extend the dataset to cover more complex or controversial values that are not easily defined by single survey responses?"}}
{"paper_id": "kXHEBK9uAY", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a novel Hierarchical Diffuser model that combines the strengths of hierarchical reinforcement learning and diffusion-based planning methods, achieving impressive performance on long-horizon and generalization tasks.\n2. The proposed model demonstrates significant performance improvements over existing diffusion-based methods in various benchmark environments, showing good empirical results.\n3. The approach enhances computational efficiency, reducing training and planning times compared to non-hierarchical methods.", "Weaknesses": "1. The model's effectiveness is highly dependent on the quality and coverage of offline datasets, potentially limiting its applicability in scenarios with poor data quality.\n2. The use of fixed sub-goal intervals may not be optimal for all real-world tasks, requiring task-dependent tuning of hyperparameters, which may limit flexibility.\n3. The paper could improve in terms of presentation clarity, particularly in explaining the technical details and theoretical underpinnings more comprehensively.", "Questions": "1. How sensitive is the performance of Hierarchical Diffuser to the choice of sub-goal interval K, and how can it be optimized effectively for different tasks?\n2. In what ways can the model be extended to handle more complex real-world scenarios where fixed sub-goal intervals might not suffice?\n3. What additional measures can be taken to improve the robustness of Hierarchical Diffuser when facing unseen trajectories?"}}
{"paper_id": "i7LCsDMcZ4", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces innovative methods SLTRP and SLRP that successfully adapt relevance propagation techniques to spiking neural networks (SNNs) for generating saliency maps and CAMs, which are crucial for interpretability and improving data augmentation. 2. EventRPG, proposed in this work, leverages relevance propagation for effective data augmentation, addressing overfitting in event-based datasets and leading to state-of-the-art performance on several benchmarks. 3. The experimental results are comprehensive, demonstrating significant improvements on multiple datasets and valuable insights into the computational efficiency of the methods.", "Weaknesses": "1. While the methods are highly effective for classification tasks, their application is currently limited to this domain. The potential application to other tasks or learning paradigms like self-supervised learning is not demonstrated. 2. The reliance on annotated datasets for guidance in data augmentation might limit scalability to scenarios where labeling is expensive.", "Questions": "1. Can the proposed relevance propagation methods be adapted for tasks beyond classification, such as detection or segmentation tasks in event-based neural networks? 2. How do the augmentation strategies perform under different neural network architectures or less common event-based datasets? 3. What considerations are necessary to adapt EventRPG to a self-supervised learning setting?"}}
{"paper_id": "jHdz0CIS2y", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. SelfVC presents an innovative training strategy using self transformations to enhance voice conversion models, resulting in significant improvement in speaker similarity metrics.\n2. The paper demonstrates state-of-the-art results in zero-shot voice conversion on key metrics of naturalness, speaker similarity, and intelligibility.\n3. The approach can be applied without text, making it versatile for multiple languages and potential application across various datasets.", "Weaknesses": "1. The concept of utilizing self-synthesized examples in training is relatively unexplored, but may require more extensive investigation across different data domains to fully understand its limitations.\n2. The dependency on the specific architectures used (such as Conformer-SSL and TitaNet) might limit the flexibility of the solution across other architectures.\n3. Although SelfVC outperforms prior approaches, the fine-tuning process might necessitate significant computational resources.", "Questions": "1. How does SelfVC perform in extremely low-resource language settings?\n2. Can the proposed self transformation training strategy enhance voice conversion tasks in real-time applications?\n3. How adaptable is the system when applied to completely unseen and drastically different languages from the training set?"}}
{"paper_id": "NkYCuGM7E2", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper introduces an innovative approach leveraging Large Language Models (LLMs) for decision-making in autonomous driving, providing a fresh perspective on enhancing interpretability and decision-making capabilities in complex scenarios.\n2. The method effectively combines high-level reasoning with low-level control through Model Predictive Control (MPC), offering a comprehensive solution to managing intricate driving tasks, including multi-vehicle coordination.\n3. The approach is demonstrated through extensive experiments, showcasing improved performance over baseline methods in both single-vehicle and multi-vehicle tasks.", "Weaknesses": "1. While the integration of LLMs into decision-making processes for AD systems is novel, the practical implementation in real-world scenarios might face challenges due to the computational demands and latency issues of current LLMs.\n2. The reliance on textual input for guidance and decision-making may limit the approach's applicability in fast-paced or dynamic environments where rapid adaptation and decision-making are required.\n3. The paper might benefit from a more detailed discussion on the scalability and limitations of the proposed method, particularly in diverse driving conditions and environments.", "Questions": "1. How does the system handle the latency and potential computational overhead introduced by integrating LLMs into real-time decision-making processes?\n2. Are there any specific scenarios or conditions where the proposed method might struggle or require additional enhancements to ensure reliability?\n3. How does the proposed approach ensure the safety and robustness of decisions made by LLMs, especially in unpredictable or rapidly changing driving environments?"}}
{"paper_id": "RtDok9eS3s", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper successfully demonstrates that transformer blocks can be simplified by removing certain components without compromising performance, resulting in increased training throughput and reduced parameter count.\n2. The proposed modifications are backed by both theoretical insights using signal propagation theory and empirical observations, providing a comprehensive understanding of the underlying mechanisms.\n3. The work is relevant and timely, addressing the computational efficiency crucial for large-scale transformer models used in practice.", "Weaknesses": "1. The paper primarily tests the simplifications on relatively small-scale transformer models, and it remains to be seen how well these modifications scale to very large models commonly used in industry.\n2. The study focuses on training speed and parameter efficiency but does not deeply explore the implications of the simplifications on transferability or adaptability to various downstream tasks.", "Questions": "1. How do the simplified transformers perform on larger datasets and with larger architectures commonly used in real-world applications?\n2. Are there any potential drawbacks or limitations to the removal of normalisation layers that the study might not have fully captured?\n3. How does the simplification affect the ability to transfer learning to other tasks beyond those tested in the paper?"}}
{"paper_id": "YCPDFfmkFr", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "ueTdErd5Ib", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper proposes a robust and novel method for contextual stochastic optimization that seamlessly integrates learning with the downstream optimization task, which could potentially improve decision-making under uncertainty.\n2. Theoretical guarantees are provided for the regret bounds and stability, adding credibility to the framework.\n3. Computational experiments demonstrate competitive performance and robustness improvements, especially in worst-case scenarios, across diverse real-world applications.\n4. The method's flexibility to be applied to various optimization problems, including linear, nonlinear, and discrete, without constructing uncertainty sets is a significant advancement.", "Weaknesses": "1. While the paper provides a strong theoretical and experimental foundation, it lacks detailed descriptions about potential computational challenges or limitations that might arise in large-scale applications.\n2. The selection of epsilon and its practical implementation can be complex and may require ad hoc strategies like binary search or cross-validation, indicating a potential need for further methodological support.\n3. The dependence on the discretization strategy might limit the approach's applicability or lead to reduced effectiveness in problems where an appropriate discretization is difficult to establish.", "Questions": "1. How does the method scale with very large datasets or complex problem instances? Are there known limitations on computational resource requirements?\n2. What are the guidelines for choosing the value of epsilon in practice, and how sensitive is the method to this parameter?\n3. The paper suggests that future work could involve uncertainty in constraints. Are there current limitations when dealing with constraints under uncertainty?"}}
{"paper_id": "sDmjlpphdB", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces an innovative approach called Mixture-of-Prompts (MoP), which extends the Mixture of Experts paradigm into prompt optimization, effectively addressing the limitations of previous methods by incorporating both instructions and demos.\n2. It provides a comprehensive framework for optimizing prompts using a two-phase process that effectively clusters demos based on semantic similarity, applying a region-based joint search for optimal instruction assignment.\n3. The experimental evaluation is robust, demonstrating significant performance improvements across a variety of NLP benchmark tasks, notably achieving up to 43% improvement over existing methods.", "Weaknesses": "1. The dependence on clustering accuracy implies a potential limitation in the performance if clustering does not match the inherent structure of the problem space well.\n2. The framework requires a careful selection of hyperparameters and the embedding model, which may limit the generalizability across different datasets and tasks without extensive fine-tuning.", "Questions": "1. How sensitive is the Mixture-of-Prompts framework to the choice of text encoder for clustering demos in terms of overall performance?\n2. Can the proposed framework be scaled or adapted to work efficiently with tasks that might require a very different number of experts than those the framework was specifically tested with?\n3. What are the specific limitations discussed in Appendix G, and how might they impact the broader applicability of the Mixture-of-Prompts approach?"}}
{"paper_id": "Mdk7YP52V3", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper addresses a challenging problem in deep heteroskedastic regression and proposes a theoretical explanation for the pathologies encountered in overparameterized models. The use of field theory from statistical physics offers a novel perspective on this issue. \n2. By providing a phase diagram and nonparametric free energy analysis, the paper adds theoretical grounding to understanding overfitting in heteroskedastic regression models. \n3. Empirical results validate theoretical findings, showing consistency across datasets and models, which supports the proposed theory.", "Weaknesses": "1. While the paper provides a solid theoretical foundation, it might benefit from a deeper exploration of practical applications or solutions to mitigate the identified pathologies beyond regularization tuning. \n2. The numerical methods used to solve the NFE might not scale well to real-world large datasets, potentially limiting the applicability of the findings.", "Questions": "1. How does the proposed approach for tuning regularization compared to existing state-of-the-art methods in terms of computational efficiency and effectiveness?\n2. Are there any plans to extend this analysis to classification tasks or include both epistemic and aleatoric uncertainties for a more comprehensive approach?"}}
{"paper_id": "YGTSLDAPqb", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper presents a compelling and effective framework, Connect Later, that leverages pretraining with targeted augmentations to improve robustness for out-of-distribution (OOD) generalization. \n2. The methodology of using targeted augmentations to better connect source and target domains is innovative and shows state-of-the-art improvements across multiple real-world datasets including ASTROCLASSIFICATION and IWILDCAM-WILDS.\n3. The presentation is clear and well-structured, making the methodology and results accessible and understandable.", "Weaknesses": "1. The effectiveness of targeted augmentations heavily relies on existing domain knowledge, potentially limiting the applicability in scenarios lacking such expertise. \n2. While the methodology is comprehensive for the tasks presented, the scalability to other domains or tasks without substantial domain-specific insights could be challenging.\n3. The paper could benefit from deeper discussions on potential limitations or scenarios where Connect Later might not work as effectively.", "Questions": "1. Can the methodology of Connect Later be extended or modified to work more effectively in completely novel domains without prior domain-specific insights?\n2. How sensitive is the framework's performance to the choice of targeted augmentations and the preprocessing steps involved?\n3. What potential methods could be employed to automate the design of targeted augmentations in the absence of detailed domain knowledge?"}}
{"paper_id": "JTcaziw7G1", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces PRAG, a novel and secure approach for distributed information retrieval, addressing privacy concerns in neural information retrieval.\n2. The use of Multi-Party Computation (MPC) to protect both queries and database contents in a distributed setting is a novel contribution to the field.\n3. The approach supports both exact and approximate retrieval, demonstrating promising performance with negligible accuracy losses compared to non-MPC methods.\n4. The paper provides a robust theoretical and empirical evaluation, highlighting significant improvements in communication efficiency.", "Weaknesses": "1. While innovative, the proposed method presents significant computational overhead, especially for large databases, which could limit its practical applications.\n2. The security claims are based on semi-honest models and do not address potential adversarial settings.\n3. The trade-off between speed and privacy in the 'leaky' protocol needs further exploration and validation, particularly in sensitive real-world applications.", "Questions": "1. How does PRAG perform under adversarial settings where data owners or servers might not be semi-honest?\n2. Can the proposed methods be integrated into existing secure ML frameworks without significant re-engineering?\n3. How does changing the privacy budget in the 'leaky' protocol affect the accuracy and speed of information retrieval?"}}
{"paper_id": "lEkFq4RUCX", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel and efficient metric, Directional Distance Field (DDF), which provides a robust method for measuring differences in 3D point clouds by focusing on the underlying surfaces rather than point-to-point correspondences. \n2. DDF showcases significant improvements in accuracy across various tasks including shape reconstruction, rigid registration, and scene flow estimation compared to existing metrics.\n3. It demonstrates memory and computational efficiency, which is crucial for large-scale applications.\n4. The method is well-supported by rigorous experiments and comprehensive ablation studies, ensuring the robustness of the claims.", "Weaknesses": "1. The proposed method relies on reference points and their optimal selection can significantly influence the outcome, yet this aspect seems to require more detailed exploration and guidelines.\n2. While the paper performs extensive evaluations, the dependency on hyperparameters like β and their influence on performance under different conditions could have been analyzed more thoroughly.", "Questions": "1. How sensitive is the DDF metric to the choice and distribution of reference points, and how can one ensure the robustness of this selection?\n2. Can the DDF be adapted or extended to other types of data representations beyond point clouds, such as meshes or voxel grids?"}}
{"paper_id": "Fq8tKtjACC", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper presents phi-1, a highly efficient large language model for code, achieving state-of-the-art performance with a smaller model size and less data. \n2. It emphasizes the importance of high-quality, textbook-like training data, which leads to significant improvements in model performance, challenging traditional scaling laws.\n3. The approach involves creative data generation strategies, such as using synthetic 'textbook' data, offering a novel direction in language model training.\n4. The evaluation across unconventional and standard benchmarks robustly supports the model's effectiveness.", "Weaknesses": "1. The reliance on data quality for achieving high performance poses challenges for scalability across broader or more diverse datasets and tasks.\n2. The model's specialization in Python reduces its applicability across different programming languages or domains.\n3. The absence of detailed methodologies for synthetic dataset generation may hinder reproducibility and evaluation of the model by others.", "Questions": "1. How can the approach be extended to multiple programming languages, and what challenges might arise?\n2. Could there be potential biases introduced by the textbook-like data selection, and how might this influence different coding tasks or domains?\n3. What are the limitations or drawbacks in moving from GPT-3.5 to potentially better data generation models like GPT-4 in future iterations?"}}
{"paper_id": "8fQlGQkj0S", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper provides a rigorous theoretical framework for understanding in-context learning by introducing generative models and deriving risk bounds for task retrieval and learning. 2. The authors successfully demonstrate a unique U-shaped phenomenon in task retrieval, providing new insights into when and how in-context examples can improve or hinder task retrieval. 3. The study’s findings are validated through numerical computations and experiments on Transformer models, showcasing practical applicability.", "Weaknesses": "1. The theoretical assumptions are quite specific, such as assuming Gaussian/Linear models, which might limit the generalizability of the findings to more complex and real-world tasks that involve non-linear dynamics. 2. While the paper claims to have validated the findings through Transformer experiments, the existence of the U-shaped phenomenon in real-world scenarios is not entirely proven or verified.", "Questions": "1. Can the results observed within the limited scope of Gaussian/Linear assumptions be extended plausibly to more complex tasks in natural language processing? How can the U-shaped behavior be identified in real-world scenarios with complex language models? 2. The paper introduces task learning and retrieval definitions separately—how would the findings change if these modes were considered in tandem or in more dynamically evolving settings?"}}
{"paper_id": "hRos9WldRK", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach with L2B for handling label noise through adaptive instance and label reweighting, guided by a meta-learning framework. It shows practical implications by eliminating the need for clean validation sets.\n2. Comprehensive experiments on canonical datasets such as CIFAR-10, CIFAR-100, ISIC2019, and Clothing 1M under different noise conditions validate the method's efficacy and robustness over state-of-the-art methods.\n3. Theoretical analysis is provided to ensure the understanding and validation of convergence and improvement under noise scenarios.", "Weaknesses": "1. While the reduction in reliance on clean validation sets is a significant advantage, it is unclear how sensitive the approach is to the quality and size of the meta-validation set in real-world datasets.\n2. The ablation study could be further elaborated or detailed in terms of parameter settings and the stability across more diverse settings.\n3. Some clarity is required in the wider context of how easily L2B integrates or conflicts with other advanced methods outside the adapted techniques illustrated in the paper.", "Questions": "1. How does L2B perform in scenarios with high asymmetric noise across different domains, not just the tested datasets?\n2. Can the method be extended effectively to domains outside image classification, such as text or more complex structured data?\n3. Does L2B have limitations or potential drawbacks in terms of computational requirements compared to simpler methods, especially when scaling to larger datasets?"}}
{"paper_id": "ttRSBZiCiu", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach for speech synthesis based on adversarial training and fluid partial differential equations, presenting a new architectural design with promising results in terms of sampling quality and efficiency. The separation into two stages, including a deterministic upsampler and a stochastic refiner, provides an effective way to handle mel-spectrogram conditions and improves training efficiency.", "Weaknesses": "The explanation of the underlying fluid equation and its relation to generative modeling may be overly complex and hard to grasp for readers unfamiliar with these concepts. Additionally, it's unclear how well the method generalizes beyond the provided datasets, and the specific advantages over existing state-of-the-art models could be better highlighted.", "Questions": "Could the proposed approach be extended to other forms of data beyond speech synthesis, or are there intrinsic limitations? What is the robustness of the model when applied to datasets with significantly different characteristics or noise levels than those tested?"}}
{"paper_id": "WYsLU5TEEo", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper presents a novel approach that combines adversarial robustness and interpretability into a single unified framework using GANs. \n2. Extensive experiments on benchmark datasets demonstrate the effectiveness of the proposed method in improving classification robustness and generating high-quality saliency maps.\n3. The integration of the classifier and discriminator into a single model is a significant contribution that enhances both interpretability and robustness.", "Weaknesses": "1. The approach is currently limited to binary classification tasks, restricting its application scope.\n2. The requirement for balanced datasets to ensure stable training could pose challenges in real-world scenarios where datsets are often imbalanced.\n3. There's a lack of exploration into scalability and performance across larger, more complex datasets or tasks beyond binary classification.", "Questions": "1. How could this framework be extended to multi-class classification tasks effectively?\n2. Are there any plans to test this framework on datasets with inherent imbalance to assess its robustness in such conditions?\n3. How sensitive is the model to hyperparameter settings, particularly the weighting factors and update frequency strategies?"}}
{"paper_id": "KKZaj2QS3G", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper presents the CoInception framework, which appears to be a significant advancement in time series representation learning by addressing the challenges of noise resilience and computational efficiency. \n2. The proposed combination of a noise-resilient sampling strategy and a robust encoder architecture aligns well with the paper's objectives of enhancing performance across multiple tasks.\n3. The experimental results demonstrate clear empirical advantages over state-of-the-art methods across forecasting, classification, and anomaly detection tasks, showcasing its effectiveness.", "Weaknesses": "1. The presentation of some methodological aspects, such as the hierarchical triplet loss and specific technical details of the Inception-based design, could benefit from more clarity, as these sections are dense and may be challenging for readers unfamiliar with the domain.\n2. The necessity of certain hyper-parameters and the potential effort required for tuning them on specific tasks or datasets could be a limitation to the practical applicability and generalization of the proposed framework.", "Questions": "1. How sensitive is the proposed CoInception framework to the choice of hyper-parameters, and what guidance can be provided for tuning them efficiently for different applications?\n2. Can the proposed framework be extended or adapted easily for other types of sequential data beyond time series, such as event sequences or categorical sequences?"}}
{"paper_id": "LWDRiFzbHQ", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces the Vicinal Risk Proxy, an innovative method for assessing model generalization by incorporating responses from neighboring test samples, thereby improving the accuracy of risk estimates on out-of-distribution data. The experimental evaluation is comprehensive, covering a wide array of risk proxies and datasets, and illustrating significant improvements in correlation with OOD accuracy.", "Weaknesses": "One potential limitation of the study is its reliance on vicinal distributions, which may not be straightforward to define in all contexts or with all types of datasets. Furthermore, while the method improves unsupervised risk estimation, it still requires careful setup of the vicinal distributions and parameter tuning, as highlighted in sensitivity analyses.", "Questions": "Can the proposed vicinal assessment strategy be effectively applied in domains where it is challenging to define or compute vicinal distributions, such as for certain types of sequential or temporal data?"}}
{"paper_id": "Yp01vcQSNl", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. Introduction of a novel transformer architecture (DiGT) that effectively captures directionality in graphs using dual node encodings.\n2. Thorough experimentation demonstrating the architecture's superior performance on newly proposed datasets where directionality is crucial.\n3. Provides insights into the importance of directionality in benchmark datasets, and the creation of new datasets to better test this feature.\n4. Suggestions for directionality-enhanced strategies applicable to existing graph transformers.", "Weaknesses": "1. The quadratic complexity of the attention mechanism means the proposed model does not scale well to larger graphs.\n2. The reliance on synthetic or novel datasets might limit immediate applicability to real-world tasks if such datasets are not representative.", "Questions": "1. How well does DiGT perform on massive real-world directed graphs from different domains as opposed to synthetic datasets?\n2. Could incorporating sparse attention mechanisms be a viable solution to the scalability issue of the model?\n3. How transferable are the proposed directionality-based strategies to real-world applications outside of graph datasets?"}}
{"paper_id": "LndMyiBl3n", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper proposes a novel and efficient restricted black-box attack on graphs, SheAttack, which utilizes the Modified Silhouette Score as a measure of graph quality. This approach is applicable to graphs of varying homophily levels.\n2. The authors provide a thorough theoretical analysis of SheAttack’s effectiveness and validate their approach through extensive experiments on synthetic and real-world datasets.\n3. The method shows comparable performance to white-box attacks even without access to labels or the victim model, indicating its potential for practical applications.", "Weaknesses": "1. The effectiveness of SheAttack heavily relies on the clustering process, and the paper primarily uses Kmeans, which may be suboptimal for node clustering tasks. The choice of k for clustering can significantly impact the performance, which could be challenging to determine accurately.\n2. The performance gap between SheAttack and more optimal methods, like white-box attacks with full knowledge, still exists, which the paper acknowledges. Thus, the application may be limited given contexts requiring very high performance.\n3. The paper could improve in presenting some sections more clearly, especially the explanation of the Modified Silhouette Score and how it incorporates into the attack mechanism.", "Questions": "1. How sensitive is SheAttack to the choice of the hyperparameter k in Kmeans, and what would be the best strategy for selecting this in practice?\n2. Could the authors clarify potential ways to improve node clustering effectiveness beyond Kmeans for better attack performance? Are there any specific advanced clustering algorithms considered?\n3. How does SheAttack perform when applied to larger real-world graphs compared to smaller datasets? Are there scalability concerns that need addressing?"}}
