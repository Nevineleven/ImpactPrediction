{"paper_id": "u3xwwfHmBC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to traffic forecasting by introducing the Tri-Tense Former model, which effectively captures spatio-temporal relationships through three tense-specific attention modules. The model demonstrates superior performance compared to baseline models on real traffic datasets and addresses the challenges of incomplete traffic data using innovative contrastive learning techniques.", "Weaknesses": "The paper could provide more detailed experimental comparisons with a broader range of baseline models. Additional insight into the computational efficiency and scalability of the proposed model in comparison to existing models would be beneficial. Furthermore, a detailed analysis of the model's limitations is lacking.", "Questions": "How does the computational complexity of the Tri-Tense Former model compare with existing transformer-based models in practice? Can the approach be generalized to other domains with similar spatio-temporal dependencies beyond traffic forecasting?"}}
{"paper_id": "YKvBiRWdQC", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel benchmark for assessing generalization in multi-agent reinforcement learning, specifically focusing on zero-shot cooperation. This addresses a significant gap in the existing literature, where agents are typically not evaluated on novel partners or environments. The benchmark is open-source, allowing for broad community engagement.", "Weaknesses": "The paper could improve in the clarity of presentation, especially in terms of defining specific evaluation metrics and experimental setup. Some explanations about the limitations of current methods could be more detailed, particularly why they struggle with the proposed benchmark.", "Questions": "How does the Overcooked Generalization Challenge compare to existing benchmarks in terms of computational requirements and scalability? Are there plans to expand the types of environments and tasks included in the benchmark?"}}
{"paper_id": "tePFpDgyqg", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses the challenge of data scarcity for training large language models with long context understanding. It introduces a novel method, LongPack, to scale high-quality long-context training data using long-distance referrals. The experimental results demonstrate a notable improvement over previous state-of-the-art methods, indicating a significant contribution to the field.", "Weaknesses": "The presentation could be clearer, especially in explaining the technical details of the LongPack method and the experimental setup. Additionally, the paper heavily relies on web pages as a data source, which may limit the generalizability of the approach to other types of data.", "Questions": "1) How sensitive is the performance of LongPack to the choice of hyper-links used for document packing? 2) Can LongPack be effectively applied to other domains or data sources beyond web pages, such as scientific papers or code repositories? 3) What are the computational costs associated with implementing LongPack at a large scale?"}}
{"paper_id": "gx3LMRB15C", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a novel self-supervised learning method adapted for tabular data that does not require augmentation, which is a significant challenge with this data type. The approach demonstrates improved performance on multiple datasets, often outperforming traditional methods like Gradient Boosted Decision Trees. The method also effectively identifies relevant features without the use of target labels.", "Weaknesses": "The paper's novelty is somewhat incremental as it builds on established JEPA architectures. Even though the method is promising, the experiments primarily compare it against baselines without sufficient exploration of why it outperforms certain models. The theoretical underpinning of why non-contrastive self-supervised learning effectively identifies key features is not deeply explored.", "Questions": "How well does T-JEPA perform with imbalanced datasets? Are there any specific scenarios in which this method may not be effective compared to traditional models?"}}
{"paper_id": "kTH3bEH6hW", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces an innovative range-limited augmentation method for contrastive learning in tabular data, demonstrating significant performance improvements in few-shot learning scenarios. Additionally, the creation and use of the comprehensive FESTA benchmark with 42 datasets and 31 algorithms enhance the method's evaluation rigor.", "Weaknesses": "The paper primarily focuses on numerical features, with limited discussion on augmentations for categorical data. Additionally, while the range-limited augmentation is effective, the paper could further explore the balance between preserving task-relevant information and diversifying views.", "Questions": "How does the range-limited augmentation perform specifically with categorical data, and are there plans to extend the study to include tasks beyond classification and regression, such as time-series prediction or anomaly detection?"}}
{"paper_id": "EqcLAU6gyU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper proposes a novel framework for agent-oriented planning in multi-agent systems, introducing design principles and mechanisms like a reward model and feedback loop. It shows significant improvements over baseline methods.", "Weaknesses": "The paper's experimental evaluation could be more comprehensive; it primarily relies on a single dataset before extending to others in the appendix. Additionally, more insights into potential limitations of the proposed method and its generalization capability would strengthen the study.", "Questions": "How does the proposed method perform across a diverse set of tasks beyond the ones evaluated? What are the theoretical trade-offs or limitations of integrating the proposed principles into an existing multi-agent system?"}}
{"paper_id": "qrTrnrEi9d", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel framework, TransFusion, which effectively improves zero-shot cross-lingual information extraction by using machine translation to enhance low-resource language processing. The experimental results are promising, showing significant improvements over baseline models and the examination of various configurations provides a comprehensive evaluation.", "Weaknesses": "While the methodology and experiments are sound, the paper does not provide a detailed discussion on potential scenarios where the fusion model might fail, particularly in the context of translation quality and annotation errors. Additionally, the reliance on English as an intermediate language may limit applicability in scenarios where high-quality translation resources are not available.", "Questions": "Could the authors provide more insights into how the quality of machine translation impacts the overall performance of the TransFusion framework, particularly in languages with very low translation quality?"}}
{"paper_id": "Bp0HBaMNRl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel differentiable causal discovery method for latent hierarchical causal models, which is shown to outperform existing methods. The approach is scalable to high-dimensional datasets like images and relaxes previous restrictive assumptions about structural equation models.", "Weaknesses": "The paper does not address structures where measured variables have children. The necessity of certain conditions, such as the two pure children requirement, remains a limitation. Additionally, some evaluations, especially concerning practical applicability, could be more comprehensive.", "Questions": "What specific limitations prevent the current method from accounting for structures where measured variables have children? Are there any plans to address this in future work?"}}
{"paper_id": "JzLcKWtGnl", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel approach to enhance spatial perception in 3D vision-language models, incorporating a progressive spatial awareness scheme. The introduction of new tasks and a large dataset contributes significantly to the field.", "Weaknesses": "The computational demands of the proposed model may hinder practical applications, and the presentation could be clearer in some sections to improve readability.", "Questions": "How does the model perform in real-time applications given the computational demands? Are there plans to further optimize the model for environments with limited processing power?"}}
{"paper_id": "hXJrQWIoR3", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses an important topic in explainable graph representation learning and proposes innovative methods using both graph kernels and GNNs. The theoretical analysis provided adds value by establishing the robustness and generalization ability of the proposed methods.", "Weaknesses": "The paper might be dense for readers unfamiliar with graph kernels, as it requires in-depth understanding to fully grasp the proposed methods. Additionally, the computational complexity of the proposed ensemble kernel method could be a limiting factor for scalability.", "Questions": "How does the method perform on graphs with more complex structures beyond those tested? Can the framework be extended to incorporate edge features in addition to node features?"}}
{"paper_id": "67sSPPAZiG", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel multimodal language model, MM-Ego, specifically designed for egocentric video understanding. It presents a large-scale dataset, a challenging benchmark, and an innovative model architecture with a Memory Pointer Prompting mechanism. The model shows strong performance on egocentric video understanding tasks.", "Weaknesses": "The paper lacks detailed discussions on potential limitations and robustness of the proposed model against various types of egocentric video inputs. The results heavily rely on the newly introduced benchmark and data, which may need further validation.", "Questions": "How does the proposed Memory Pointer Prompting mechanism perform compared to other known memory-based approaches in similar settings outside egocentric video understanding?"}}
{"paper_id": "kjmLabjSE2", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a significant advancement in the privacy analysis of Noisy-SGD by relaxing assumptions on loss functions to Hölder continuity, thus extending the applicability of differential privacy guarantees. The introduction of techniques like forward Wasserstein distance tracking, optimal shift allocation, and the Hölder reduction lemma further strengthen the analysis.", "Weaknesses": "The presentation could be improved for clarity, particularly in explaining complex mathematical concepts. Some sections, such as the proof details and comparisons with existing work, are dense and may be challenging for readers not deeply familiar with the topic.", "Questions": "How does the proposed method compare to recent advances in DP-FTRL in terms of privacy-utility trade-off? Are there experimental results that can verify the theoretical improvements in practical settings?"}}
{"paper_id": "I18MA5DjoP", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 5, "Confidence": 3, "Strengths": "The paper introduces a novel analytical framework, the Neuron Predictability Lens (NPL), to better understand the inner workings of transformer-based language models. It demonstrates that neuron activations can be predicted and exposes interesting insights into the roles of different layers and neurons, such as 'background neurons'.", "Weaknesses": "The experimental validation, while extensive, could benefit from additional clarity in presentation and more diverse model examples. The implications of neuron predictability on model efficiency and performance improvements are suggested but not fully explored, leaving some questions about practical applications unanswered.", "Questions": "How does the NPL framework compare to other existing methods in terms of computational cost and accuracy? Can the findings related to background neurons be extended to practical optimization strategies for neural networks beyond the analyzed models?"}}
{"paper_id": "qpDqO7qa3R", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel zero-shot video restoration method leveraging pre-trained image restoration diffusion models without additional training. It effectively addresses temporal consistency issues and demonstrates superior performance across various video restoration tasks and extreme degradations.", "Weaknesses": "The methodology's complexity may pose challenges in implementation and understanding. The paper's presentation could be enhanced for clarity, particularly concerning the technical details of the proposed modules.", "Questions": "How does the proposed method compare in computational efficiency with other state-of-the-art methods? Can this framework be adapted for real-time applications in existing production pipelines?"}}
{"paper_id": "dSQtMx6dPE", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces novel privacy-preserving methods for graph prompt learning, addressing significant privacy concerns identified through membership inference attacks. It proposes innovative use of the PATE framework tailored for graph data, achieving high utility at strong privacy guarantees.", "Weaknesses": "The presentation occasionally lacks clarity, particularly in the technical details of the algorithms and their implementation. The empirical evaluation, while extensive, could benefit from more diverse dataset choices to better establish the generality of the proposed solutions.", "Questions": "How does DP-GPL+W perform in more practical, large-scale settings with varying node centrality? Are there real-world applications where the proposed approach has been or could be trialed effectively?"}}
{"paper_id": "GbgCRJedQ7", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes a novel Sparse Matrix Tuning method that significantly reduces computational costs and memory requirements while achieving performance on par with or better than existing parameter-efficient fine-tuning methods such as LoRA and DoRA. The methodology is well-validated through extensive experiments across various models and tasks, demonstrating improvements in accuracy and efficiency.", "Weaknesses": "While the paper presents a strong empirical evaluation, the presentation could be clearer in some sections, especially regarding the explanation of the methodology. Additionally, the ablation studies could be more detailed, particularly in terms of providing deeper insights into why certain vectors (like V vectors) are more crucial.", "Questions": "How does the performance of SMT compare with other state-of-the-art methods on a broader range of datasets beyond those tested? Are there any potential trade-offs in accuracy for specific types of tasks when using SMT instead of full fine-tuning?"}}
{"paper_id": "ZZVOrId3yN", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 3, "Strengths": "The introduction of CrossModalNet offers a novel architecture for multimodal medical image segmentation with strong theoretical foundations and superior performance metrics. It effectively combines advanced mathematical frameworks with innovative design, showing outstanding results in MM-WHS dataset tests.", "Weaknesses": "While the theoretical claims are robust, the paper may benefit from a broader range of datasets to further validate its domain adaptability. The presentation could be enhanced with clearer visual aids and more intuitive explanations of complex mathematical concepts.", "Questions": "How does CrossModalNet handle cases with missing modality data during the testing phase? Could the authors provide more insights into the practical computational cost in real-world clinical settings?"}}
{"paper_id": "gLHuAYGs6a", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper proposes a novel structural multi-view clustering approach using heterogeneous random walks and demonstrates its effectiveness over existing methods. Extensive experiments show the superiority of the method, and the incorporation of multi-step random walks is a significant innovation.", "Weaknesses": "The presentation of the method could be improved for better clarity, especially the detailed explanation of the random walk strategy and the construction of the heterogeneous graph. The evaluation is centered on clustering metrics without a deeper exploration of computational efficiency.", "Questions": "How does the complexity of the proposed method scale with the number of views and samples? Are the hyperparameters used in the experiments optimal for all datasets?"}}
{"paper_id": "x5l5PRtvul", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents a novel variant of SVGD that addresses the variance collapse problem without additional computational cost. The authors develop a theoretical framework for h-SVGD and demonstrate its practical benefits through experiments.", "Weaknesses": "The paper's theoretical analysis is focused primarily on the specific case where k2 = ck1, and does not fully explore the general hybrid kernel setting. The practical implications of the mean field fixed point not aligning with the target distribution could be further investigated.", "Questions": "What specific guidelines can be provided for selecting the scaling factor c and the kernels k1 and k2 in practice? How does the performance of h-SVGD compare with other SVGD variants that also alleviate variance collapse, in situations where computational resources are limited?"}}
{"paper_id": "pOUAVXnOQP", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces a novel and theoretically well-justified approach for improving implicit neural representations through the use of sinusoidal trainable activation functions. The approach addresses spectral bias and achieves higher accuracy and faster convergence compared to existing methods, validated through experimental results.", "Weaknesses": "The paper could benefit from clearer explanations in some technical sections and more detailed comparisons with existing models. The emphasis on theoretical contributions might overshadow practical validations and discussions on potential limitations in real-world applications.", "Questions": "How does the training time of STAF compare to other methods in larger-scale problems? Are there specific tasks or signal types where STAF may not perform as well?"}}
{"paper_id": "iN64nSYt0z", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents a novel method called GUIDE that improves the accuracy of instruction-following in Large Language Models without requiring additional training. It introduces a new metric, Influence, which helps in adjusting attention scores, thus enhancing LLM performance. Experiments support the claimed improvements.", "Weaknesses": "The effectiveness of the GUIDE method heavily relies on the appropriate selection of bias values for attention scores, which might need further tuning for different models and tasks. Although the Influence metric is introduced, its applicability and limitations in various contexts are not fully explored.", "Questions": "How well does the Influence metric generalize across different model architectures and tasks? Are there any limitations in the approach when applied to real-world tasks with noisy or incomplete user instructions?"}}
{"paper_id": "gRuZkEy49k", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper leverages Monte Carlo Tree Search (MCTS) to improve sampling efficiency in Generative Flow Networks (GFlowNets), demonstrating empirical improvements across different tasks. The paper provides theoretical support for the method and explores its application across various environments and GFlowNet parameterizations.", "Weaknesses": "The paper may be lacking in clarity in some sections, and the theoretical foundations, while solid, might not be novel. Furthermore, the scalability of the approach with larger environments and more complex tasks remains a question.", "Questions": "How does the proposed method scale to larger and more complex environments? Are there specific scenarios where MCDS fails compared to traditional MCTS? Additionally, have other sampling methods like replay buffers or Thompson sampling been considered alongside MCDS?"}}
{"paper_id": "d23EVDRJ6g", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces MotionDreamer, a novel localized generative masked modeling paradigm for motion synthesis, demonstrating significant improvements in both diversity and expressiveness of generated motions from a single reference. The method effectively tackles challenges like overfitting and codebook collapse, and performs well in various downstream tasks such as temporal editing, crowd animation, and beat-aligned dance synthesis.", "Weaknesses": "The methodology relies heavily on novel architectural components, which may introduce complexity and limit the reproducibility or accessibility of the approach. Evaluation mostly relies on constructed datasets which may not fully represent challenging real-world scenarios. Some claims about performance improvements are not backed by extensive user studies or evaluations on a broad range of datasets.", "Questions": "How does MotionDreamer perform on more varied and complex datasets beyond SinMotion? Are there any existing limitations on the types of motions or skeletons it can effectively model? Can the approach handle real-time synthesis or editing applications efficiently?"}}
{"paper_id": "kQ5s9Yh0WI", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper identifies a critical gap in current long context LLMs’ ability to generate very long outputs. It introduces a novel agent-based pipeline, AgentWrite, to facilitate this task and constructs a significant dataset, LongWriter-6k, which effectively trains models to generate ultra-long outputs. The comprehensive benchmark, LongBench-Write, provides a good evaluation framework.", "Weaknesses": "The evaluation largely hinges on automatic metrics and comparisons against proprietary systems, which may not capture all facets of generation quality. The experiments rely heavily on one methodology (AgentWrite) without significant exploration of alternative methods.", "Questions": "How well would the model perform on tasks requiring both extensive reasoning and long text generation beyond the current benchmarks? Are there potential limitations or failings in scenarios not covered by the current dataset or evaluation?"}}
{"paper_id": "9CqkpQExe2", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents a novel Ada-K routing strategy that dynamically adjusts expert activation based on token importance, improving computational efficiency and model performance. The approach integrates well with existing MoE-based LLMs and demonstrates significant reductions in FLOPs and inference times across multiple models and benchmarks.", "Weaknesses": "The use of reinforcement learning and the resulting complexity could pose challenges for reproducibility and understanding for those unfamiliar with the approach. Additionally, while results are promising, there may be concerns about the generalization of these improvements to other model architectures beyond MoE.", "Questions": "How does Ada-K routing compare to other dynamic routing strategies beyond numerical metrics, such as in practical scenarios? Are there any situations where Ada-K routing might underperform compared to static Top-K routing?"}}
{"paper_id": "PpYy0dR3Qw", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents LoCoDL, a novel algorithm for communication-efficient distributed learning with a combination of local training and compression. The proofs and theoretical analysis are robust and indicate a doubly accelerated communication complexity, which is reflected in the strong empirical results.", "Weaknesses": "The paper focuses heavily on the convex setting. Extensions to non-convex problems are mentioned as future work, but no preliminary results or detailed approaches are suggested. Moreover, the challenges of combining stochastic gradient estimates and partial participation with compression are acknowledged but not addressed.", "Questions": "Are there specific technical barriers preventing the proposed method from adapting to a non-convex setting? What potential challenges are expected when implementing bidirectional compression in LoCoDL?"}}
{"paper_id": "UatDdAlr2x", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper provides a thorough analysis of the ability of transformer architectures to implement specific counting tasks. It explores the intricate relationship between transformer components, offering theoretical constructions, and empirically verifying them. The investigation into the roles of softmax and token-mixing mechanisms is detailed and highlights the adaptive nature of transformer models.", "Weaknesses": "The paper focuses on a highly specific task (the histogram task) which may limit the broader applicability of its findings. The experimental setup uses simplifications like no positional embeddings, which might overlook complexities in real-world applications. Furthermore, while the analysis is thorough, the presentation is dense and may be difficult for readers to follow without substantial background.", "Questions": "How would the inclusion of positional embeddings or causal masks affect the outcomes of the study? Could the findings regarding the interaction between model components be extended to more complex tasks or datasets?"}}
{"paper_id": "IwgmgidYPS", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces MedTrinity-25M, an innovative large-scale multimodal dataset for medical applications, with a wide variety of image modalities and diseases covered. It provides detailed multigranular annotations that could significantly benefit the development of largescale pretraining for multimodal medical AI models. The use of an automated pipeline to generate these annotations from unpaired images is a notable advancement.", "Weaknesses": "The presentation of the paper could be further improved for clarity, making it easier to understand the technical details of the proposed methods. Additionally, the comparisons with existing datasets and models could have been more exhaustive to strengthen the claims about performance improvement.", "Questions": "How do the authors ensure the quality and accuracy of the multigranular annotations, especially when relying on automated pipelines without human verification? Are there plans to evaluate the dataset's effectiveness in real-world clinical settings?"}}
{"paper_id": "WG7GzGx3G9", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents a novel plug-and-play activation smoothing method for INT4 inference, showing significant improvement in perplexity scores on multiple large language models. The authors provide a comprehensive comparison with state-of-the-art methods and demonstrate the generalization of the method across different models.", "Weaknesses": "The paper requires further clarity in the presentation of the methodology, specifically in the explanation of the rotation operations and the kernel fusion process. While the proposed method shows improvements, detailed analysis on computational trade-offs and potential limitations in specific LLM configurations would strengthen the claim.", "Questions": "How does Rotated Runtime Smooth specifically impact latency and computational efficiency compared to existing methods in practical large-scale deployments? Are there specific scenarios where the method might not perform as well?"}}
{"paper_id": "BhECSDSkAE", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach for one-shot image-to-video segmentation in the medical field, addressing the challenge of limited annotated video data by leveraging static image datasets. The proposed method involves a smart use of temporal-aware test-time training and self-distillation integrating spatiotemporal context, effectively showing improved results with minimal data requirements.", "Weaknesses": "The method's reliance on the newly introduced OS-I2V-Seg dataset may limit its generalizability across different types of video data. There could be a more thorough comparison with other state-of-the-art test-time training and video segmentation methods that employ different model architectures to evaluate competitiveness comprehensively.", "Questions": "How does the method compare against state-of-the-art methods on larger-scale datasets or non-medical videos to ensure its scalability and generalization? Can the memory mechanism be further optimized to enhance computational efficiency without compromising performance?"}}
{"paper_id": "mnB4hDTIDr", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses the under-explored area of diversity evaluation in LLM-generated datasets and proposes a novel method, DCScore, which demonstrates correlations with various diversity pseudo-truths and is computationally efficient.", "Weaknesses": "The method relies on theoretical verification of axioms without extensive practical validation outside correlation with pseudo-truths. Some aspects of the experimental setup, such as the choice and diversity of datasets, could be more robust.", "Questions": "How well does DCScore generalize to different types or domains beyond the tested LLM-generated datasets? Are there specific limitations or scenarios where DCScore might not perform as expected?"}}
{"paper_id": "Y0qmwm6tgy", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel pruning algorithm, MoreauPruner, with a solid theoretical foundation for robustness against weight perturbations. It effectively addresses a notable gap in existing literature on pruning stability under minor weight changes, especially important for large language models. The empirical results are extensive and demonstrate the method's superior performance over baselines.", "Weaknesses": "The study is limited to models up to 13 billion parameters due to hardware constraints. The applicability and performance of MoreauPruner on larger models remain unexplored. Furthermore, the methods for integrating MoreauPruner with other compression techniques for more comprehensive model optimization are not fully developed.", "Questions": "How does MoreauPruner perform on extremely large models, beyond 13 billion parameters? What is the potential interplay between MoreauPruner and other compression techniques for even greater efficiency in model deployment?"}}
{"paper_id": "aAcOaJYbUg", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel benchmark, LAION-C, specifically designed to test out-of-distribution robustness of state-of-the-art vision models trained on web-scale datasets. The empirical evaluation showcases significant challenges posed by the new benchmark, and compares human performance against models, marking a paradigm shift where models can outperform humans under certain conditions.", "Weaknesses": "The paper does not fully explore why certain models underperform on specific distortions, nor does it delve into the particular visual cues that models rely on. Additionally, the paper's results might not directly translate to real-world scenarios due to the synthetic nature of the distortions, raising questions about the benchmark's direct applicability to practical applications.", "Questions": "How do the distortions in LAION-C relate to real-world scenarios, and can the benchmark results be generalized beyond the specific challenges it presents? Are there plans for investigating the specific strategies or visual cues used by models when handling these novel distortions?"}}
{"paper_id": "duGygkA3QR", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel integration of Dynamic Mode Decomposition with Graph Neural Networks. It effectively leverages DMD to approximate underlying graph dynamics which provides enhanced feature propagation in GNNs. The study's results demonstrate improved performance across various tasks.", "Weaknesses": "Complexity might hinder the interpretability of the model. The paper could benefit from a more extensive theoretical justification and analysis of the limitations of integrating DMD with GNNs.", "Questions": "How does the model handle very large-scale graphs beyond the tested datasets? Are there specific scenarios where this integration might not outperform traditional GNN models?"}}
{"paper_id": "s6nYndMwG7", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides a comprehensive analysis of hyperparameter selection for the LiSSA algorithm, grounded in the spectral properties of the Gauss-Newton Hessian. It offers both theoretical insights and empirical validation, making the approach feasible for large models.", "Weaknesses": "The presentation could be clearer in certain sections, and the paper may benefit from more examples to demonstrate practical applications. It assumes a reader with a strong background in machine learning and numerical methods.", "Questions": "How does the proposed hyperparameter selection method compare with automated hyperparameter tuning methods like Bayesian optimization or grid search in terms of efficiency and results?"}}
{"paper_id": "9BVMD3keG8", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a thorough and rigorous analysis of the contextual online learning problem of brokerage between traders, contributing novel insights and tight regret bounds under both full and two-bit feedback models. The results are robust, covering scenarios both with and without regularity assumptions on noise distributions. The paper is well-motivated and addresses an important problem in online learning with clear explanations and mathematical rigor.", "Weaknesses": "While the results are comprehensive and mathematically rigorous, the paper might be challenging for readers who are not deeply familiar with online learning and regret analysis, due to the technical depth and complexity of the analysis presented.", "Questions": "How can the proposed algorithms be adapted to practical real-world scenarios, and what are the potential challenges in their implementation? Are there specific contexts or types of assets for which the assumptions and the proposed model may not hold well?"}}
{"paper_id": "mnna9LUg7P", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a well-defined and novel method for quantizing State Space Models, which is crucial for efficient deployment on resource-limited devices. The proposed Quamba method effectively reduces latency and memory usage while maintaining accuracy, demonstrating strong empirical results. The paper's experiments are comprehensive, covering a range of platforms and models, reinforcing the scalability and applicability of the approach.", "Weaknesses": "While the proposed method is effective, the novelty could be perceived as incremental since it builds upon existing quantization techniques and adapts them specifically for SSMs. Further theoretical insights could strengthen the understanding of why Quamba performs well under different conditions. The clarity of some technical sections, especially around the implementation details, could be improved to broaden accessibility.", "Questions": "How does the method perform on other types of neural network architectures outside of Mamba-based SSMs? Can Quamba be generalized or adapted for different state space model variations, and how robust is it across diverse hardware configurations?"}}
{"paper_id": "3X3LuwzZrl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach to understanding and leveraging label influence correlations on graphs, addressing the multi-label node classification task effectively. The proposed LIP method demonstrates empirical improvements over state-of-the-art methods across multiple datasets.", "Weaknesses": "The paper could benefit from clearer explanations of complex concepts, particularly for readers less familiar with multi-label graph neural networks. Some experimental results lack detailed analysis and comparison with existing methods in varying settings. Additionally, scalability concerns in very large datasets might not be fully addressed.", "Questions": "How does LIP performance compare when altering hyperparameters such as the teleport probability beta? Are there specific scenarios or datasets where LIP might not perform as well, and what are the underlying reasons?"}}
{"paper_id": "IqaQZ1Jdky", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents a novel general framework for Kolmogorov-Arnold Networks (KANs) with variable function basis, specifically utilizing the Variety Bernstein Polynomial Function Basis, which enhances both flexibility and robustness in neural networks. Comprehensive experiments demonstrate the method's superiority over traditional KANs and other approaches in multivariate time series forecasting, image classification, and function approximation.", "Weaknesses": "The presentation of the results could be clearer, as some of the figures and tables are hard to interpret due to lack of sufficient explanation. Additionally, while the theoretical framework is robust, the paper does not delve deeply into the potential computational overhead introduced by the variable function basis, which could be relevant for real-world applications.", "Questions": "How does the proposed method perform in real-world applications where computational resources are limited? Is there any significant computational overhead when using Bayesian Optimization for the variable function basis compared to other approaches?"}}
{"paper_id": "OdMqKszKSd", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel method for generating 3D articulated objects from a single image, overcoming previous limitations that required multi-view or multi-state inputs. The approach introduces a diffusion model for capturing shape and motion variations and demonstrates excellent results compared to state-of-the-art methods. The paper is well-structured and provides a comprehensive evaluation.", "Weaknesses": "The approach may not handle objects with very complex geometries or highly detailed parts effectively. The reliance on a predefined part library for geometry retrieval might limit the reconstruction of finer details.", "Questions": "How does the method perform on objects with highly non-cuboid geometries, and are there plans to extend the approach to handle more complex shapes?"}}
{"paper_id": "LOBhVTtVnc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel approach leveraging Transformers for long-term physical dynamics simulation, effectively integrating spatiotemporal and geometric considerations. The proposed GST model achieves state-of-the-art performance across several benchmarks, particularly in reducing cumulative errors with its TDG component.", "Weaknesses": "While the approach is promising, the paper could provide more insights into the limitations of the current model and how it compares to similar architectures in terms of computational efficiency. Additionally, some sections, such as the detailed workings of the TDG and its novelty compared to prior methods, could be expanded.", "Questions": "How does the computational efficiency of GST compare with existing baseline models? Are there specific scenarios or datasets where GST may underperform or face challenges?"}}
{"paper_id": "oa5UeyUVMm", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel framework, Graffe, which integrates diffusion probabilistic models into graph representation learning, achieving state-of-the-art results on multiple datasets. It provides a theoretical foundation by relating the denoising objective to conditional mutual information, extending the InfoMax principle.", "Weaknesses": "The empirical results are promising but limited to the specific datasets tested. The paper does not extensively address potential limitations or future work in extending the applicability of the framework to different graph structures or tasks beyond classification.", "Questions": "How does the performance of Graffe vary with different graph types or non-classification tasks? Are there any known limitations when applying this model to real-world large-scale datasets?"}}
{"paper_id": "5swfKRkCx7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to integrating external knowledge into large language models using a memory-based mechanism and an additional attention head. It shows strong empirical results across a variety of QA datasets, demonstrating the effectiveness of the approach.", "Weaknesses": "The paper could benefit from a clearer explanation of the technical implementation details and the potential limitations of the proposed method. Additionally, it would be helpful to have more detailed analysis on cases where the method does not perform well.", "Questions": "How does the model performance vary with different types and amounts of external knowledge? Are there any domains where this approach performs significantly worse, and if so, what might be the cause?"}}
{"paper_id": "5s1qpjrNvZ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel guided reinforcement learning approach with theoretical guarantees for performance thresholds. The approach is flexible, easy to implement on existing algorithms, and addresses the sample inefficiency of RL methods effectively.", "Weaknesses": "The theoretical derivations have a limited scope, and GRL-RB can only roll back after a violation has occurred, rather than preventing it. Some assumptions, such as convergence between updates, may not hold in all environments.", "Questions": "How generalizable are the derived sampling rates to other types of environments and reward schemes? Can the roll-back mechanism be made proactive to prevent performance threshold violations?"}}
{"paper_id": "WNb4P8aG66", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel multi-stage diffusion model framework, Diffusion on Diffusion (DoD), that significantly improves image generation quality by incorporating visual priors from previously generated samples. It demonstrates state-of-the-art performance with reduced training costs and model parameters. The methodology for extracting semantic information through a compression-reconstruction approach is innovative. The experiments are extensive and show the model's efficacy over existing methods.", "Weaknesses": "The presentation could be clearer, especially in explaining the process and benefits of visual priors. More detailed comparisons with existing methods in terms of specific architectural differences and training techniques could provide additional insights. The paper assumes familiarity with certain advanced topics, which could be difficult for some audiences.", "Questions": "How does the proposed method generalize to other datasets or domains beyond ImageNet? What are the potential limitations or challenges in scaling this approach to larger resolutions or different types of data?"}}
{"paper_id": "UfczlMudN6", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The proposed framework GRAM shows strong results for both in-distribution and out-of-distribution generalization in deep reinforcement learning. The integration of a robust adaptation module and a joint training pipeline is novel and well-executed, demonstrating effectiveness across various tasks.", "Weaknesses": "The dependence on the choice of adversary for robust RL training might limit generalizability to other OOD contexts. The experiments are limited to simulated environments, and it remains to be validated in real-world applications.", "Questions": "How would GRAM perform with different adversarial settings, and can the method handle other forms of generalization beyond dynamics, such as visual differences in environments?"}}
{"paper_id": "60Vd7QOXlM", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach to privacy auditing for large language models by developing more effective canaries, showing significant improvements over previous methods. The methods presented could be valuable for understanding and mitigating privacy risks in real-world LLM applications. The extensive experimentation on multiple model families strengthens the validity of the results.", "Weaknesses": "The paper could further elaborate on the scalability of the proposed methods to even larger models beyond those tested. The reliance on new token canaries as a primary method may limit direct applicability to other contexts where introducing new tokens is not feasible.", "Questions": "How do the proposed methods perform on larger models beyond those tested, and what are the challenges associated with scaling these methods?"}}
{"paper_id": "GqhvJ1o8m5", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces ImmersePro, an innovative framework for end-to-end stereo video synthesis that uses implicit disparity learning. It includes a novel dual-branch architecture and leverages spatial-temporal attention mechanisms, resulting in significant improvements in stereo video generation. Additionally, the introduction of the large-scale YouTube-SBS dataset is a valuable contribution to the field.", "Weaknesses": "The method may not perform well with strong stereo effects due to limitations in dataset variety and inpainting capabilities. The paper acknowledges a lack of convergence without implicit disparity, which may suggest reliance on specific techniques without exploring alternatives. The generalization to different styles of videos is not thoroughly evaluated.", "Questions": "How does ImmersePro perform on types of videos not included in the YouTube-SBS dataset, such as VR content? Additionally, how does the model handle varying levels of stereoscopic effects across different sections of a video?"}}
{"paper_id": "ua5MHdsbck", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a novel method for improving extrapolative protein design by utilizing triplet preference learning, which is demonstrated to perform well on benchmark datasets. The results show significant improvement over existing methods in several tasks, showcasing the potential effectiveness of the proposed approach.", "Weaknesses": "The explanation of experiments could be more concise, and the reliance on in-silico evaluations may limit the scope of the method's perceived effectiveness. The method's reliance on complex data distillation processes could also pose practical challenges in real-world applications.", "Questions": "How would the proposed method perform with wet-lab validation? What are the computational costs associated with creating preference datasets compared to conventional methods?"}}
{"paper_id": "56Zn3halhq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to time series data augmentation using reinforcement learning and pre-trained model ensembles, which improves forecasting performance with minimal computational overhead.", "Weaknesses": "The approach relies heavily on the composition of the model zoo, and poor-performing models could adversely affect the quality of augmented data. The paper does not address how to handle this potential issue thoroughly.", "Questions": "How does the choice of models in the model zoo affect the performance of AutoTSAug? Are there any plans to test with different configurations of the model zoo to assess robustness?"}}
{"paper_id": "aPTGvFqile", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The approach in AlignCLIP is well-founded and effectively addresses the modality gap in CLIP, demonstrated by significant improvements in alignment scores and downstream tasks across various datasets. The paper's experiments and results are thorough and convincingly demonstrate the benefits of the proposed method over existing ones.", "Weaknesses": "While the approach is innovative, the reliance on semantic regularization might not generalize well across all types of datasets, especially those with less semantic clarity between samples. Some qualitative analyses could be expanded further to illustrate potential limitations or specific scenarios where the method might not perform as expected.", "Questions": "How does the proposed semantic re-scaling mechanism handle datasets with significant semantic overlap in labels? Are there scenarios where AlignCLIP's performance drops due to its regularization techniques?"}}
{"paper_id": "GOwNImvCWf", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel behavioral loss for training autoencoders in weight space, improving reconstruction and generation of high-performing neural network models. It presents a well-designed experimental evaluation, demonstrating that the combination of structural and behavioral losses enhances performance in various tasks.", "Weaknesses": "The approach is primarily evaluated on smaller model zoos and may have scalability issues when applied to larger neural networks. The computational overhead required for testing generated models during training is significant.", "Questions": "How does the performance of the proposed approach change with larger models or different architectures? What is the impact of the choice of queries on the resulting models, specifically in different domains or with different data distributions?"}}
{"paper_id": "C9BA0T3xhq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "EIQL successfully incorporates both in-sample and out-of-sample actions, effectively addressing challenges in offline RL with minimal added complexity over IQL. It demonstrates robust performance across multiple benchmarks including D4RL, outperforming traditional methods.", "Weaknesses": "The paper could provide more theoretical backing and clarity regarding the impact of expectile regression parameters. Some experimental results lack detailed statistical analysis to bolster claims.", "Questions": "How does EIQL handle scenarios with extreme action outliers in the dataset? What is the impact of varying expectile levels on different environments in more detail?"}}
{"paper_id": "EeqlkPpaV8", "review": {"Soundness": 3, "Presentation": 2, "Contribution": 3, "Rating": 5, "Confidence": 3, "Strengths": "The paper tackles a significant problem of adaptive complexity in parallelized log-concave sampling, and provides novel lower bounds for both unconstrained and box-constrained settings. The approach leverages innovative techniques related to chain-like structures and smoothing operations.", "Weaknesses": "The presentation of the paper is dense and can be difficult to follow, especially for those not deeply familiar with the field. Some proofs and technical details are deferred to appendices, making it hard to assess the completeness and correctness within the main body of text. The results are applicable primarily to high-dimensional settings, and the implications for practical, lower-dimensional tasks are unclear.", "Questions": "How do the established lower bounds compare to practical implementations in terms of performance? Are there existing algorithms that meet these bounds in specific cases? Can the techniques used be adapted to broader classes of problems beyond the scope of the paper?"}}
{"paper_id": "oK1zJCWBqf", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel method, Soft Preference Optimization (SPO), which effectively aligns generative models with human preferences without requiring a reward model. It presents a clear theoretical foundation and demonstrates favorable comparison to existing methods. The paper also offers robust theoretical insights into the behavior of SPO under specific assumptions.", "Weaknesses": "The computational complexity associated with the SPO regularizer could be a limitation, requiring online sampling from the model, which may not be feasible for very large models or datasets. The presentation could be improved with more intuitive explanations of the concepts for broader accessibility. Additionally, more empirical exploration on diverse tasks beyond win-rate metrics could strengthen the claims.", "Questions": "How does the performance of SPO compare to other methods as the preference dataset increases in size or becomes noisier? Can the SPO framework be integrated with other model architectures outside of language models?"}}
{"paper_id": "Dq9VrVuLzV", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel framework, SyntheOcc, that allows for the generation of photorealistic and geometrically controlled street view images by using 3D semantic MPIs. It contributes to the field by enabling the synthesis of unlimited diverse datasets, which is highly beneficial for autonomous driving training modules. The method offers precise 3D geometric control and effectively incorporates comprehensive 3D geometric information.", "Weaknesses": "The limitation of the approach is that it relies on existing data annotations and thus might not generalize to entirely new scenes without some form of user editing. There could also be concerns regarding the scalability and computational resources required for implementing the proposed methods in a real-time setting.", "Questions": "How does the model perform in terms of speed and computational efficiency? Are there practical scenarios where user editing of occupancy labels would be required, and how might this affect workflow?"}}
{"paper_id": "73Q9U0vcja", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The method provides a novel integration of generative diffusion models with active learning to significantly reduce data acquisition in computed tomography while maintaining reconstruction quality. It is evaluated thoroughly on multiple datasets.", "Weaknesses": "The approach's reliance on pre-trained models may limit applicability in domains with scarce data. Diffusion models may introduce artifacts, making them unsuitable for certain high-stakes applications, such as medical imaging.", "Questions": "How does the performance of Diffusion Active Learning compare with other state-of-the-art methods in terms of artifact or hallucination reduction in sparse reconstruction settings?"}}
{"paper_id": "UiEjzBRYeI", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a novel integration of the Segment Anything Model (SAM) with composable prompts, enabling versatile segmentation including semantic, instance, and panoptic segmentation. SAM-CP achieves state-of-the-art performance in open-vocabulary segmentation.", "Weaknesses": "The efficiency of SAM-CP is limited by the SAM's capabilities, especially in closed-domain segmentation. SAM may fail to detect small objects or incorrectly merge objects, affecting the overall segmentation accuracy. The inference speed is restricted by the SAM process.", "Questions": "How does SAM-CP perform with other vision foundation models that are more efficient than SAM? What are the impacts of different proposal types on the segmentation results in various domains?"}}
{"paper_id": "lessla98Wp", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel framework, L-C4, for language-guided video colorization, enhancing current methods by providing a creative and consistent colorization approach. The proposed methods, such as temporally deformable attention and cross-clip fusion, effectively address the identified limitations of previous approaches, achieving semantically accurate colors and maintaining temporal consistency. Extensive experiments demonstrate superior performance on various metrics.", "Weaknesses": "The approach depends on complex models like diffusion models, which could lead to high computational costs during training and inference. There might be concerns about the diversity of the language dataset used for training, which may affect generalization to real-world applications.", "Questions": "How does the method perform on language descriptions that are more ambiguous or poetic in nature? Are there any limitations regarding the types or complexity of language cues that L-C4 can handle effectively?"}}
{"paper_id": "UstOpZCESc", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel framework that addresses lifelong learning with privacy-aware unlearning, integrating both with a scalable and memory-efficient solution. The empirical results are strong and demonstrate the effectiveness of the method across various datasets and settings, highlighting its practicality and potential impact on responsible AI applications.", "Weaknesses": "The paper does not yet address more complex scenarios like class- or domain-incremental learning settings. Additionally, the approach is currently focused on complete task unlearning rather than selective data unlearning, which limits its applicability in certain privacy demanding contexts.", "Questions": "How could the proposed method be adapted to class-incremental learning scenarios where task IDs are not available? Are there plans to extend the approach to handle selective data unlearning within tasks?"}}
{"paper_id": "LnRegTxsa4", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces a novel approach to cross-view object geo-localization using a dual attention mechanism, which shows improved results over state-of-the-art methods. The creation of the G2D dataset is also a valuable contribution.", "Weaknesses": "The complexity of the proposed method and the necessity for further validation on diverse datasets could be limitations. Additionally, while good, the paper's presentation could be clearer in some areas, particularly in explaining the methodology.", "Questions": "How does the proposed method generalize to different types of images beyond the G2D and CVOGL datasets?"}}
{"paper_id": "2ErS9Bkc3O", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides a novel matrix-theoretic explanation for the adversarial fragility of neural networks and supports the explanation with both theoretical analysis and numerical experiments. It also connects existing information-theoretic and feature-compression-based hypotheses.", "Weaknesses": "The analysis may lack generalization across diverse neural network architectures and data distributions. Numerical experiments are limited, and the scope is confined to certain theoretical settings. The paper could benefit from a deeper exploration of the relationship between adversarial robustness and network parameters.", "Questions": "How do the findings generalize to different neural network architectures and data distributions? What is the impact of varying the number of layers or types of activation functions on adversarial robustness?"}}
{"paper_id": "pK3oe2bubc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces a novel approach, LayerShuffle, which enhances robustness of vision transformers to arbitrary layer execution orders, pruning at test time, and ad-hoc model merging. The method is well-explained and includes experiments that demonstrate its efficacy over existing methods.", "Weaknesses": "The performance drops compared to the baseline for sequential execution, and there is a significant performance drop when layers are shuffled. The analysis could be deeper, particularly concerning the limitations and potential pitfalls of the proposed method.", "Questions": "How does LayerShuffle compare in computational efficiency to traditional methods, particularly when deployed on edge devices? Are there specific scenarios or applications where LayerShuffle's benefits clearly outweigh its drawbacks?"}}
{"paper_id": "sec09tLQUl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces FairDropout, a novel application of example-tied dropout to handle spurious correlations, particularly benefiting minority groups without requiring explicit group labels. It demonstrates that FairDropout can improve worst-group accuracy in various tasks across image, language, and healthcare datasets, offering a practical solution with broad applicability.", "Weaknesses": "The study might overestimate the general capability of FairDropout without sufficient exploration of scenarios where memorization might be beneficial. The results on datasets like Waterbirds suggest inconsistencies in its effectiveness. The hypothesis regarding generalizing vs memorizing neurons, while interesting, lacks thorough investigation within the paper.", "Questions": "How generalizable are the results of FairDropout across different types of neural networks, beyond those tested in the paper? Are there situations where FairDropout may unintentionally harm generalization due to its reliance on dropping memorized neurons?"}}
{"paper_id": "96jZFqM5E0", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces an innovative approach to pre-training for 3D hand pose estimation by leveraging a large-scale dataset of hand images from in-the-wild videos. The use of contrastive learning with adaptively weighted losses based on inter-sample distance is novel and results in significant improvements compared to existing methods. The authors provide comprehensive experimental results demonstrating the effectiveness across multiple datasets.", "Weaknesses": "The approach may rely heavily on the quality of the initial hand detections and keypoint estimates, which could affect performance in scenarios with noisy or incomplete input data. The scalability of the proposed method to other domains or tasks beyond 3D hand pose estimation remains to be tested.", "Questions": "How does the method handle situations where the 2D keypoint estimates are highly inaccurate? Are there any plans to apply this framework to other pose estimation tasks, such as 3D human body pose estimation?"}}
{"paper_id": "uNd289HjLi", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel self-supervised framework for MRI denoising, achieving state-of-the-art performance in self-supervised methods. It effectively handles label scarcity and has a strong theoretical foundation with practical clinical relevance.", "Weaknesses": "The presentation could be improved; some sections are dense and could be clearer. There might be a reliance on external noise estimation tools.", "Questions": "How does the method perform in real-world settings with varying acquisition protocols and instruments? Are there plans to improve the clarity of the presentation for better accessibility?"}}
{"paper_id": "e2ONKX6qzJ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel method called adaptive projected guidance (APG) which effectively reduces oversaturation and artifacts in diffusion models using high guidance scales. It provides a clear theoretical foundation by connecting the CFG update rule with gradient ascent and proposes practical extensions like rescaling and reverse momentum. The method is easy to implement, adds negligible computational overhead, and is experimentally validated across multiple models with improved metrics like FID and recall.", "Weaknesses": "While the paper is strong in its theoretical and experimental setup, it does not address potential limitations or scenarios where APG may not perform as well. A more in-depth discussion on the limitations of APG or specific cases where it might fail would strengthen the paper. Additionally, the impact of APG on other aspects of generative models, such as training stability and model interpretability, could be explored.", "Questions": "How does APG perform in scenarios outside of high guidance scales? Are there any specific failure cases or preferences for tuning the hyperparameters like momentum strength or rescaling radius in different models?"}}
{"paper_id": "a2eBgp4sjH", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a systematic study of MultiFilterANN, introduces an innovative practical algorithm based on DiskANN, and releases novel datasets for MultiFilterANN.", "Weaknesses": "The paper may lack clarity in explaining some complex theoretical concepts, and the empirical results could include more comprehensive comparisons with other state-of-the-art methods.", "Questions": "How well does the proposed method scale with extremely large datasets or a high number of filters beyond what was tested? Are there ways to improve the query planning component for better efficiency?"}}
{"paper_id": "EIXZXPz7jU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a novel sampling method for improving PINN solutions for PDEs with singularities. It demonstrates improved solution quality in tested scenarios, particularly over existing methods like normalizing flow-based sampling.", "Weaknesses": "The implementation details, such as parameter settings and model architecture specifics, require clarification. Further, a more comprehensive comparison with a broader range of existing methods would be beneficial.", "Questions": "How does the computational cost of the proposed method compare to other adaptive sampling strategies for PINNs? Is the method scalable to even higher-dimensional PDE problems?"}}
{"paper_id": "QO4bF6MHza", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces MATHHAY, a novel benchmark aimed at evaluating long-context mathematical reasoning capabilities of large language models. The methodology used to construct the benchmark is thorough, comprising document collection, question generation, quality control, and haystack construction. The paper identifies a significant gap in existing benchmarks and addresses it with a structured approach. The experiments provide a clear indication of the challenges faced by current models, highlighting significant room for improvement.", "Weaknesses": "The evaluation of the models on the benchmark could be more comprehensive with additional analysis on noise handling and deeper insights into why certain models perform better. Although the benchmark is automated, the paper does not mention extensive human validation aside from the verification statistic, which might raise concerns on the reliability of unverified data. Some sections of the paper might benefit from clearer explanations and more concise presentation.", "Questions": "1. How does the benchmark ensure fairness given the varying lengths and complexities of tasks, especially between verified and unverified datasets? 2. Are there plans to expand the benchmark with more diverse mathematical reasoning tasks or datasets beyond mathematical reasoning? 3. How do the authors plan to continuously update the benchmark to remain relevant as LLM architectures evolve?"}}
{"paper_id": "GULx8rzzjC", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach, Mycroft, for effective external data augmentation by evaluating the usefulness of different data sources without acquiring their entire datasets. Mycroft is robust to data and label noise, quickly converges to full-information performance, and efficiently ranks data owners in various settings.", "Weaknesses": "The paper assumes that model trainers have a well-defined hard dataset (Dhard) which might not be well-aligned with all real-world applications. There is a potential limitation in situations where the hard dataset is either too small or not representative enough.", "Questions": "How does Mycroft perform when there is a large discrepancy in the feature distributions of the model trainer's dataset and the data owner's dataset?"}}
{"paper_id": "PnZ2lbQaao", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel adversarial Bayesian framework, DICF, which provides interpretability in cross-domain recommendations, addressing cold-start problems effectively. It outperforms state-of-the-art methods across multiple datasets and offers insightful visualizations of domain indices.", "Weaknesses": "The approach might depend heavily on accurate initial domain indices, and its adaptability to domains with rapidly changing user preferences or characteristics is not thoroughly tested.", "Questions": "How does the DICF framework perform when user preferences and domain characteristics evolve dynamically over time? Are there plans to extend the approach to handle such scenarios?"}}
{"paper_id": "AT64R0ivUO", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel method, SteerPrompt, that effectively combines iterative prompting and attention manipulation to enhance reading comprehension in large language models. The experimental results demonstrate significant improvements in open-book QA tasks across various models and conditions.", "Weaknesses": "The explanation of SteerPrompt and its integration with existing techniques could be more detailed, especially regarding how the attention manipulation is precisely implemented. Additionally, some parts of the mathematical formalization and algorithm description lack clarity.", "Questions": "Can the SteerPrompt method be generalized to other NLP tasks beyond open-book QA? How computationally intensive is the coarse-to-fine head selection process, and can it be further optimized?"}}
{"paper_id": "nGiGXLnKhl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces Vision-RWKV, a promising model that adapts the RWKV architecture for visual tasks. It effectively reduces computational complexity while maintaining high performance across a range of vision tasks.", "Weaknesses": "The paper lacks detailed explanations about the limitations of the proposed modifications, and it could benefit from more thorough comparisons with a wider range of existing architectures.", "Questions": "How does the quad-directional token shift operation specifically contribute to performance improvements, and are there any task-specific variations in its effectiveness?"}}
{"paper_id": "TBJCtWTvXJ", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel optimizer, SignSoftSGD (S3), which offers improvements over the widely-used Adam optimizer in terms of training speed, performance, and stability. The experiments across various tasks demonstrate its advantages, particularly in minimizing loss spikes even with larger learning rates.", "Weaknesses": "The presentation can be improved as some sections are dense and complex, potentially making it difficult for readers to fully grasp the nuances without substantial effort. Additionally, certain claims about theoretical and experimental results might require more detailed explanation and clear delineation between empirical observations and theoretical underpinnings.", "Questions": "How does S3 compare with other state-of-the-art optimizers not tested in this paper? Are there particular scenarios where S3 might underperform compared to Adam or other methods?"}}
{"paper_id": "8gSrJOL2oc", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel framework, TRIDENT, which effectively addresses the limitations in existing compositional zero-shot learning methods, achieving state-of-the-art results on challenging datasets. The use of MLLM embeddings and attribute smoothing enhances attribute-object disentanglement, improving the recognition of unseen compositions.", "Weaknesses": "The presentation could be improved for clarity, as the paper contains complex technical details that may be hard for some readers to immediately grasp. The ablation studies could be more comprehensive in demonstrating the impact of each component under various conditions.", "Questions": "How does the approach handle cases where the auxiliary attributes generated by the LLM are not representative or are misleading? Are there any limitations to the scalability of the framework, especially with larger datasets or more complex compositions?"}}
{"paper_id": "yheQRc5xWB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach to time-varying counterfactual prediction using state-space models which is a promising direction. It demonstrates improvements in both prediction performance and running efficiency compared to baseline models.", "Weaknesses": "While the approach is novel, it's specifically tailored for linear state-space models which might limit its applicability. The theoretical analysis, although present, is not as rigorous or comprehensive as it could be.", "Questions": "Can the proposed approach be generalized to non-linear or other types of models beyond state-space models? What are the limits of applicability of the proposed method in real-world scenarios?"}}
{"paper_id": "HxKSzulSD1", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper thoroughly explores the weak-to-strong deception phenomenon and provides empirical evidence across various model sizes and setups. It introduces a novel potential security issue in the alignment of strong models.", "Weaknesses": "While the study presents interesting cases and results, it might benefit from a more structured exploration into mitigation strategies. The experiments are limited to specific models and setups, lacking exploration of spontaneous deception scenarios.", "Questions": "How can we determine if the alignment deception persists across even more advanced models or across different domains beyond language processing? What specific mechanisms cause strong models to identify and exploit knowledge gaps in weak models?"}}
{"paper_id": "wH8XXUOUZU", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces Deep Compression Autoencoder (DC-AE), achieving high spatial compression ratios up to 128 with maintained reconstruction quality. The proposed techniques improve the efficiency of high-resolution diffusion models significantly.", "Weaknesses": "The paper could provide more detailed ablation studies to isolate the effects of each proposed technique. It also relies on synthetic benchmarks, and might benefit from additional real-world applications", "Questions": "How does the model perform on other image datasets aside from ImageNet in terms of generalization? Are there any implications for tasks other than image synthesis, such as video or 3D models?"}}
{"paper_id": "QWIg5e6mtT", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a significant limitation of existing PSRO methods in heterogeneous team games and proposes a novel framework, Heterogeneous-PSRO, which empirically achieves lower exploitability and better performance in various benchmark games. The theoretical analysis supporting the advantages of the proposed method is solid.", "Weaknesses": "The reliance on sequential optimization may limit the framework's efficiency in highly complex games with a large number of agents. Additionally, the scalability of the method to games with continuous action spaces is not fully explored.", "Questions": "How does H-PSRO perform in environments with continuous action spaces? Can the efficiency of sequential optimization be improved for games with a larger number of agents?"}}
{"paper_id": "kbSU5bwoRv", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces SaMoye, a zero-shot singing voice conversion model that can handle both human and non-human timbres. It provides a large-scale open-source dataset, which is a significant contribution to the community. The model shows superior performance in both objective and subjective tests compared to baseline models.", "Weaknesses": "The paper lacks a detailed comparison or analysis of its limitations in specific scenarios. Additionally, more clarity is needed in the explanation of some technical aspects, such as the feature disentanglement methods and the training process of the speaker encoder.", "Questions": "How does the model perform with unseen datasets not covered in the open-source compilation? Are there any ethical considerations for using non-human timbres that the authors foresee?"}}
{"paper_id": "KyqtKhv6q1", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces Differentiable Map Priors (DMP), which demonstrate consistent improvements in 3D object detection and semantic map segmentation across various architectures. The approach is simple, effective, and computationally efficient.", "Weaknesses": "The novelty might be questioned as it builds upon existing concepts, somewhat limiting the perceived innovation. The evaluation primarily focuses on the nuScenes dataset, which may limit generalizability.", "Questions": "How well does the method generalize to other datasets beyond nuScenes? Are there any specific limitations or challenges when applying DMP to non-urban environments?"}}
{"paper_id": "lTL4t68BNc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel method, RGA-IB, which shows strong robustness against adversarial attacks in GNNs by leveraging the Information Bottleneck principle. It provides theoretical insights connecting IB loss to the robustness of attention-based GNNs and demonstrates significant improvements over baseline methods in experimental evaluations.", "Weaknesses": "The paper might lack detailed explanations or theoretical justifications for certain empirical choices, such as specific parameter settings in the experiments or the design of RGA-IB layers, possibly affecting the reproducibility and clarity of the proposed approach.", "Questions": "How does the proposed method perform in terms of computational efficiency compared to the baseline methods? Are there any limitations in the approach related to scalability on larger datasets?"}}
{"paper_id": "hWmwL9gizZ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The paper presents a novel deep learning framework, PROVACCINE, with a dual attention mechanism for immunogenicity prediction, showcasing significant improvements over existing methods. It introduces the largest immunogenicity dataset to date and new, practical evaluation protocols. The extensive experiments demonstrate strong performance and generalizability.", "Weaknesses": "The reliance on predicted protein structures may introduce biases, given that predictions from even the best models can be inaccurate. Additionally, while the dataset is comprehensive, the performance of the model across less common or novel pathogens remains unclear.", "Questions": "How does PROVACCINE handle significantly mutated proteins or novel pathogens not covered in the Immuno dataset? Are there any considerations for the robustness of the model in the face of rapid viral evolution?"}}
{"paper_id": "IL85Ebjg9j", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses the important issue of resolving conflicts in multi-view classification by introducing a novel trust-based discounting mechanism. The proposed approach is thoroughly evaluated on six real-world datasets, showing improved accuracy and consistency compared to baseline methods.", "Weaknesses": "The paper could benefit from a more detailed explanation of the theoretical foundations of the trust-based method. Additionally, while the experimental results are promising, the paper lacks a comprehensive discussion on the limitations and potential drawbacks of the proposed approach.", "Questions": "How does the model perform when the view-specific predictions are highly unreliable? Are there any specific cases where the trust discounting mechanism fails to resolve conflicts effectively?"}}
{"paper_id": "cnKhHxN3xj", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel metric using the Wasserstein distance to measure neuronal entanglement, which is a significant contribution to understanding large language model interpretability and performance under sparsity. The work is comprehensive, providing both theoretical insights and empirical evidence to support their claims. The introduction of the Sparse Expansion framework is another notable strength, showing potential for inspiring future work in model sparsification.", "Weaknesses": "While the paper introduces new ideas, the concepts might be difficult to grasp without thorough background knowledge. The methodology of measuring 'mapping difficulty' and the implications of the Wasserstein neurons could be better clarified. Additionally, the practical applicability of the Sparse Expansion framework might be limited without further optimization to address increased computational costs.", "Questions": "How does the proposed Wasserstein distance metric compare with existing methods for identifying important neurons in networks? Are there specific limitations or scenarios where the Sparse Expansion framework might not perform well? Could the authors provide more details on how the computational complexity of the Sparse Expansion framework might be mitigated in practical applications?"}}
{"paper_id": "dgR6i4TSng", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel method, Quantum-PEFT, for parameter-efficient fine-tuning using quantum-inspired methods. It presents significant improvements in parameter efficiency and provides extensive experimental evidence across multiple benchmarks.", "Weaknesses": "The complexity of the quantum-inspired model might pose challenges in understanding and replicating for those not familiar with quantum parameters. Some aspects related to practical implementation details, such as computational cost, are less emphasized compared to parameter efficiency.", "Questions": "How does the computational overhead of quantum parameterization scale with model size in real-world scenarios? Are there specific cases where Quantum-PEFT would not be suitable compared to traditional PEFT methods?"}}
{"paper_id": "ye1mxb79lw", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "BILBO introduces a novel approach to bilevel optimization using Bayesian methods, offering a sample-efficient and theoretically grounded algorithm. The paper provides a sublinear regret bound with rigorous theoretical analysis and effectively demonstrates BILBO's performance through comprehensive experiments.", "Weaknesses": "Scalability to high-dimensional spaces remains a challenge, as acknowledged by the authors. The experiments, while extensive, use a limited number of real-world scenarios.", "Questions": "How does BILBO perform in very high-dimensional spaces compared to other state-of-the-art methods? Are there plans to improve its scalability using the suggestions mentioned in future work?"}}
{"paper_id": "1fwZJzGdKj", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents a novel multi-agent collaborative data selection mechanism for efficient LLM pretraining, which outperforms several state-of-the-art methods. The empirical results demonstrate significant improvements in data efficiency and model performance.", "Weaknesses": "The description of the implementation details and the specific algorithms used for the agent collaboration and updates could be more detailed. The complexity of the system might make it difficult to reproduce without additional clarification.", "Questions": "How do the authors ensure that the dynamic weighting of the agents consistently leads to optimal data selection throughout the entire training process?"}}
{"paper_id": "pISLZG7ktL", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a comprehensive empirical study on data scaling in imitation learning for robotic manipulation, revealing important insights and proposing an efficient data collection strategy. The work is sound, well-presented, and offers valuable contributions to the field.", "Weaknesses": "The study focuses only on single-task policies and does not explore task-level generalization. It also does not account for reinforcement learning, which could potentially enhance policy capabilities.", "Questions": "How does the scaling of task variety impact generalization in imitation learning? Would reinforcement learning alter the data scaling laws identified in this study?"}}
{"paper_id": "dML3XGvWmy", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a novel framework for recursive self-improvement in AI agents, leveraging the concept of the Gödel machine to eliminate human design priors and enhance agent adaptability and performance across various tasks.", "Weaknesses": "The results, while promising, are largely proof-of-concept and might lack robustness when applied in real-world scenarios. The dependency on the capabilities of current LLMs could limit the practical application of the framework.", "Questions": "How does the Gödel Agent ensure safety and stability during recursive self-modification? Are there specific real-world applications where this agent framework has been tested?"}}
{"paper_id": "xlxGsX1pc7", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a comprehensive university-level benchmark for evaluating the mathematical skills of large language models, addressing a significant gap in existing benchmarks that focus on school-level problems. The inclusion of a meta-evaluation dataset is a notable contribution, allowing for more rigorous assessment of LLMs as evaluators.", "Weaknesses": "The benchmark may not cover the full range of advanced topics and might introduce biases by favoring certain problem types or difficulty levels. Additionally, the reliance on LLMs for evaluation introduces potential for error in assessments.", "Questions": "How does the benchmark handle the biases introduced by using LLMs for judging solutions? Are there plans to expand the range of topics covered to further test the LLMs on less represented mathematical areas?"}}
{"paper_id": "AjXkRZIvjB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces a novel benchmark, GSM-Symbolic, to provide more reliable evaluation metrics for assessing the mathematical reasoning capabilities of large language models (LLMs). It highlights significant performance variability and the sensitivity of LLMs to question variations, providing valuable insights into the limitations of current evaluations.", "Weaknesses": "The study reveals that LLMs are fragile and prone to performance drops when questions are slightly altered or increased in complexity. Despite identifying issues with current benchmarks, it stops short of offering concrete solutions for developing models capable of genuine mathematical reasoning.", "Questions": "How can the findings from this study be leveraged to improve the capabilities of LLMs in terms of genuine mathematical reasoning? Are there any plans to release GSM-Symbolic for wider experimentation by the academic community?"}}
{"paper_id": "IJiTI0fB0e", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel information-theoretic method for evaluating diversity in prompt-based generative models, providing a new perspective on decomposing diversity into prompt-induced and model-induced components.", "Weaknesses": "The presentation of the theoretical contributions could be clearer, and some technical details require more intuitive explanations.", "Questions": "How does the proposed method perform when the text prompts are not clearly separable into distinct modes?"}}
{"paper_id": "fs2Z2z3GRx", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a novel algorithm, FIG, that improves upon existing state-of-the-art methods for linear inverse problems, demonstrating competitive performance on challenging tasks. The presentation is clear and well-structured, and the authors provide a thorough theoretical justification along with empirical validation.", "Weaknesses": "The method is limited to linear inverse problems and cannot directly apply to nonlinear scenarios or pre-trained models with latent encodings. Although the FIG algorithm is efficient, it approximates the posterior rather than providing exact samples. More experiments could explore these limitations in greater depth.", "Questions": "Is there a potential pathway, theoretically or empirically, to extend FIG to nonlinear inverse problems or to work with latent model encodings?"}}
{"paper_id": "H4FSx06FCZ", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel and efficient 3DGS steganography framework, SecureGS, which enhances security and fidelity in 3D asset protection. It presents a hybrid Gaussian encryption mechanism and a region-aware density optimization, achieving significant improvements in rendering fidelity, speed, and security over previous methods.", "Weaknesses": "The paper could have provided more comprehensive comparisons with a broader range of existing methods and explored more diverse datasets to solidify claims about generalization and performance. Potential challenges in real-world deployment scenarios were not deeply discussed.", "Questions": "How does SecureGS handle real-time changes in 3D scenes, and what are its limitations in dynamic environments? Could the proposed framework maintain its performance if applied to different types of 3D content not covered in the experiments?"}}
{"paper_id": "OGtUfA6Amo", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel hierarchical patch graph network for modeling irregular multivariate time series, effectively capturing multi-scale features allowing for both fine-grained and coarse-grained analysis. Experimental results on multiple datasets demonstrate the proposed method's superior performance over various state-of-the-art baselines. The hierarchical design is well-motivated and addresses a critical challenge in time series analysis by avoiding previous methods' pitfalls.", "Weaknesses": "While the proposed Hi-Patch method appears robust, its computational complexity when scaling up or dealing with very large datasets is not thoroughly discussed. The paper could benefit from more real-world use-case discussions and comparison with non-parametric approaches. The evaluation primarily focuses on classification and forecasting tasks, leaving out other potential applications.", "Questions": "How does the method scale with increasing data size or number of variables? Are there any practical limitations observed? Can the proposed method be applied or adapted to other domains beyond those tested, such as financial time series or sensor data analytics?"}}
{"paper_id": "ujpAYpFDEA", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces Water-Probe, a novel method to detect watermarked LLMs, and provides comprehensive experiments demonstrating its effectiveness across various watermarking algorithms. The proposal of Water-Bag strategy to improve watermark imperceptibility is a valuable contribution to the field.", "Weaknesses": "The paper does not extensively cover potential weaknesses or limitations of the Water-Probe method and the specific scenarios where it might fail. Additionally, the proposed Water-Bag strategy reduces robustness in detection, which raises concerns about its practical applicability.", "Questions": "How can the Water-Probe and Water-Bag methods be further improved to address the trade-off between detection robustness and imperceptibility? Are there specific use-cases or industry scenarios where these methods are particularly advantageous?"}}
{"paper_id": "7UKHNQIErp", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The paper presents a novel formalism for characterizing preference alignment algorithms, providing a clear semantic framework to compare and develop new loss functions. It demonstrates the utility of the proposed approach with rigorous formalization and insightful analysis of existing and new algorithms, supported by empirical evaluations.", "Weaknesses": "While the framework is robust, the paper could expand on the limitations and potential computational overhead of applying the proposed methods to very large models. Additionally, more detailed comparison with alternative approaches in the empirical section would enhance the discussion.", "Questions": "How does the proposed framework scale with significantly larger datasets and models? Are there specific challenges anticipated in such scenarios?"}}
{"paper_id": "CpgWRFqxhD", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes a novel approach for audio-driven talking video generation using memory-guided and emotion-aware diffusion, addressing challenges like identity consistency and emotion alignment. Extensive experiments demonstrate that the method outperforms state-of-the-art techniques.", "Weaknesses": "While the paper claims integration into broader applications, the scope and potential limitations in such integrations are not deeply discussed.", "Questions": "How does the method perform in dynamically changing lighting or occluded face scenarios?"}}
