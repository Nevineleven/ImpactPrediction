{"paper_id": "B0OwtVEejJ", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The integration between gradient-based NAS and weight-entangled spaces is novel and addresses a key gap in the field. TangleNAS provides a more efficient approach by leveraging the strengths of both paradigms, which results in improved performance, reduced memory usage, and high accuracy across various search spaces.", "Weaknesses": "The paper may lack details on potential limitations or edge cases where the methodology may not perform as expected. Additionally, the complexity of implementing the proposed approach could be a barrier for some practitioners.", "Questions": "How does TangleNAS handle edge cases where weight entanglement might introduce conflicts or marginal improvements? Can it be adapted for other configurations beyond the tested search spaces?"}}
{"paper_id": "ZlEtXIxl3q", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper effectively applies the concept of contrastive loss to a novel domain, offering a potentially impactful alternative to traditional MSE loss for protein fitness prediction. The method is demonstrated to be more data-efficient and robust, even in noisy conditions, which is essential for real-world applications.", "Weaknesses": "The reliance on simulations and limited real-world validations (e.g., only using FLIP benchmarks) may not fully capture the versatility of the approach across diverse biological datasets. Further empirical evaluation on a broader set of datasets would enhance the validity of the conclusions.", "Questions": "Could the proposed method be applied to different biological contexts beyond protein fitness prediction, or extend to other types of biological data analysis? Are there limitations in the types of nonlinearities that can be tackled using contrastive loss?"}}
{"paper_id": "6yJuDK1DsK", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "FEATHER introduces a novel lightweight adapter framework capable of efficient lifelong test-time adaptation with reduced computational requirements. Its approach of separating source and target domain knowledge is innovative and practical for hardware-constrained environments. The method does not require access to source data, which is advantageous in real-world scenarios.", "Weaknesses": "The performance compared to full adaptation methods like CoTTA could be further clarified. The applicability of the proposed adapter solution beyond CNNs is not addressed, potentially limiting its generalizability. The parameter efficiency claim, while strong, could benefit from a more detailed analysis of the precise computational savings and any possible trade-offs in terms of performance.", "Questions": "Can the adapter mechanism be effectively extended to transformer architectures or other neural network structures beyond CNNs? How does FEATHER's adaptation performance compare to methods requiring full model adaptation, particularly in highly dynamic test environments? What specific scenarios or datasets would most benefit from the proposed parameter reduction without a performance compromise?"}}
{"paper_id": "lt6xKGGWov", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces MINERVA, a novel feature selection filter, which effectively captures complex non-linear relationships between features and targets using neural estimation of mutual information. The methodological approach is clearly presented and demonstrates improved accuracy on synthetic benchmarks.", "Weaknesses": "While the method shows promise on synthetic datasets, it remains to be seen how it performs on real-world data. The reliance on neural networks may introduce complexity in tuning parameters and the potential for overfitting, which is not fully explored in the experiments.", "Questions": "1. How does MINERVA perform on real-world datasets compared to synthetic ones?\n2. What strategies are in place to prevent overfitting of the neural network model used in feature selection?\n3. How sensitive is MINERVA to different neural network architectures or hyperparameter settings?"}}
{"paper_id": "Bvrc6kobWd", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides a new perspective on understanding the role of margins in contrastive learning through gradient-level analysis, which is novel and could lead to further insights in improving contrastive learning methods. The experimental results are robust, using multiple datasets to validate the findings.", "Weaknesses": "The connection between the gradient-level analysis and practical improvements in contrastive learning is not fully explored. The theoretical exposition could be clearer, as some parts may be too dense for readers not already familiar with the intricacies of contrastive learning and the role of margins.", "Questions": "How do the proposed gradient-level effects of margins translate into practical guidelines for optimizing contrastive learning? Could the insights gained from the gradient analysis be applied to other types of self-supervised learning tasks beyond the ones considered?"}}
{"paper_id": "FJjHQS2DyE", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces a novel approach, CASA, for addressing unsupervised domain adaptation under label shift by focusing on conditional support alignment. The method is theoretically grounded with a new risk bound, which adds strength to its empirical success across multiple benchmark datasets.", "Weaknesses": "The paper primarily focuses on datasets with clear label shifts, leaving questions on its performance in more complex real-world scenarios or with more diverse distributions unaddressed. Additionally, the reliance on pseudo-labels may introduce biases, particularly when initial pseudo-labels are incorrect.", "Questions": "How does the CASA framework perform in real-world, complex domains beyond the benchmark datasets tested? Is the method robust to initial pseudo-label errors, and if not, how can this be mitigated in practice?"}}
{"paper_id": "xelrLobW0n", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "bYQkOPvgDw", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The PRGNN framework effectively addresses the challenge of label noise in GNNs, a relatively underexplored area, using a probabilistic graphical model without relying on label smoothness.\n2. The method is robust, performing well across both homophilous and heterophilous graphs and in scenarios with high noise levels.\n3. The use of variational inference and contrastive loss provides a strong methodological contribution to handling noisy labels in GNNs.", "Weaknesses": "1. The paper may lack clarity in explaining the practical implementation of PRGNN, particularly the steps involved in the variational inference process and the integration of Bayesian networks in the model.\n2. Although the approach is novel, the evaluation datasets might not be diverse enough to fully demonstrate its robustness across different real-world scenarios.\n3. The paper does not explore the potential limitations or failure cases of the method.", "Questions": "1. Can PRGNN be effectively extended to inductive learning scenarios where new nodes appear after the initial training phase?\n2. How sensitive is the PRGNN framework to the choice of hyperparameters, especially in heterophilous graphs?\n3. Are there any real-world datasets or applications where PRGNN has been tested beyond synthetic noise settings?"}}
{"paper_id": "sKPzAXoylB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses an important gap in continual learning by proposing a novel approach that simultaneously tackles catastrophic forgetting and loss of plasticity, making it highly relevant for real-world streaming learning applications.\n2. The proposed UPGD method is innovative, leveraging utility-based gradient updates to dynamically manage neural network weights, which is a promising direction for improving learning adaptability in non-stationary environments.\n3. The methodology is thoroughly evaluated on multiple datasets and tasks, including both supervised and reinforcement learning scenarios, demonstrating its versatility and effectiveness.", "Weaknesses": "1. The explanation of UPGD's mechanism, particularly the utility-based perturbations and their impact on weight updates, could be more detailed to better convey its soundness.\n2. The experiments mainly focus on common benchmark datasets, and the applicability of UPGD to more complex, real-world datasets remains to be thoroughly demonstrated.\n3. The reliance on Taylor series approximation for utility computation might limit scalability to larger models, and this limitation is not adequately discussed.", "Questions": "1. How does UPGD perform on more complex, real-world datasets or tasks beyond the benchmark datasets used in the paper?\n2. What considerations are needed when scaling UPGD to larger networks, particularly in terms of computational overhead caused by utility weight computations?"}}
{"paper_id": "H8Qg1IIMaR", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 2, "Rating": 6, "Confidence": 4, "Strengths": "The paper highlights a critical vulnerability in LLMs and VLLMs, specifically to permutation attacks, which is an important aspect of robustness that has not been thoroughly explored before. Investigating these models across multiple benchmarks provides a comprehensive overview of the issue.", "Weaknesses": "The study reveals a significant flaw but does not offer substantial solutions or mitigation strategies, leaving the reader with unanswered concerns about practical applicability. The exploration of why permutation attacks are effective lacks depth, potentially limiting the utility of these findings for robust model design.", "Questions": "How can the insights from this sensitivity to permutations inform the development of more robust LLMs and VLLMs? Are there specific architectural changes that could mitigate this vulnerability?"}}
{"paper_id": "tth2qXY7RU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. Introduction of a novel quantization method, SuFP, which effectively combines multi-region piecewise quantization with a tensor-wise scalable bias, providing significant improvements in efficiency and accuracy.\n2. The method demonstrates strong experimental results, achieving superior computational capability and energy efficiency compared to existing methods while maintaining accuracy.\n3. SuFP's hardware implementation offers practical benefits, ensuring the approach is scalable and applicable in real-world scenarios.", "Weaknesses": "1. The paper may lack detailed comparisons with other contemporary quantization methods, such as examining trade-offs in precision and efficiency across different domains.\n2. The evaluation could provide more insight into how the multi-region quantization impacts various types of DNN data distributions, particularly with a deeper analysis of extremely dense or sparse data.\n3. Potential challenges in the method's adaptability to rapidly evolving and diverse architectures of DNNs might be insufficiently addressed.", "Questions": "1. How does SuFP perform specifically on large-scale language models or emerging model architectures not covered in the current experiments?\n2. Can the proposed method be integrated with existing quantization pipelines without significant overhead or need for retraining models?\n3. What are the potential limitations in extending SuFP's hardware design for next-generation neural network models with more complex data distributions?"}}
{"paper_id": "fjf3YenThE", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper presents a novel variance-reduced zeroth-order hard-thresholding algorithm detailed with solid theoretical analysis, addressing the practical limitations of existing methods for solving ℓ0 constrained optimization problems.\n2. The algorithm significantly improves convergence rates and applicability, tackling the restriction on the number of random directions, which is crucial for high-dimensional sparse learning tasks.\n3. Experiments validate the improved performance of the new method on both portfolio optimization and black-box adversarial attack tasks, showcasing its practical impact.", "Weaknesses": "1. While the algorithm demonstrates substantial theoretical and practical contributions, its practical impact or real-world applicability beyond the given applications might need further elaboration or examples.\n2. The performance results focus largely on the improvements over a single existing algorithm (SZOHT), which may limit the perceived novelty or range of tested applicability.\n3. Some minor details about the experimental setup, such as the choice of datasets or parameters, are not thoroughly discussed, leaving questions on the generalizability of the results.", "Questions": "1. Are there potential applications of the proposed algorithm in domains beyond portfolio optimization and adversarial attacks where the removal of zeroth-order gradient restrictions might be beneficial?\n2. The theoretical analysis relies on certain assumptions like restricted strong smoothness and convexity; how robust is the algorithm to violations of these assumptions in complex, real-world datasets?\n3. How sensitive is the method to the choice of parameters during execution, and is there guidance for selecting these parameters optimally?"}}
{"paper_id": "H9DYMIpz9c", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents an innovative method (FARZI) that effectively synthesizes compact, high-quality datasets for autoregressive tasks, demonstrating impressive performance gains with significantly reduced data size. The approach addresses a gap in data distillation for large discrete token spaces.", "Weaknesses": "The practical scalability of FARZI for very large datasets and models is not thoroughly explored, and the paper lacks detailed analysis on real-world time savings compared to traditional training methods.", "Questions": "How does FARZI scale when applied to very large language models or datasets? Could more empirical analysis on time savings and computational efficiency be provided?"}}
{"paper_id": "4kLVvIh8cp", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a novel algorithm for offline RL with non-linear functions and provides statistically optimal instance-dependent regret guarantees. The translation of concepts from linear to non-linear contexts is well-executed, and the paper contributes to the theoretical understanding of offline RL in more complex environments.", "Weaknesses": "The method assumes strong coverage which may limit its practical applicability, and the paper lacks empirical validations which would demonstrate real-world applicability and performance of the proposed approach. Additionally, assumptions used for theoretical results could be perceived as restrictive.", "Questions": "How does the algorithm perform with practical data where assumptions such as full coverage may not hold? Are there practical scenarios or specific domains where assumptions are satisfied? Could empirical evaluations help to illustrate potential performance in real-world settings?"}}
{"paper_id": "CSpWgKo0ID", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper explores an important aspect of LLMs by examining their behavior in social interactive contexts using game theory, which could have significant implications for their use in cooperative environments. The use of behavioral prompts to simulate interactions adds a novel layer to the evaluation.", "Weaknesses": "The study's findings might be limited by the current experimental setup, which focuses on specific game types and does not extensively explore the diversity of possible LLM behaviors in varied interactive contexts. Additionally, improvements suggested for LLM behavior could benefit from more in-depth exploration and testing.", "Questions": "How do the findings from the 2x2 games generalize to more complex, real-world interactions involving multiple strategies and participants? Are there plans to test LLMs in environments with a mix of competitive and cooperative elements? Can the methodology be adapted and extended to cover broader types of social interactions with different rules and structures?"}}
{"paper_id": "gwbQ2YwLhD", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper effectively addresses the seldom-explored influence of data scaling on structure learning algorithms in higher dimensions and non-linear settings. It provides theoretical insights and practical evaluations with both synthetic and real-world datasets, advancing the understanding of bias introduced by least square and log-likelihood losses. The clear demonstration of scale effects under these scenarios fills a gap in existing literature.", "Weaknesses": "While the paper presents valuable theoretical proofs, there's a lack of novel methodology or substantial theoretical innovation beyond scaling insights. The primary contribution revolves around the exploration of existing loss functions in new contexts rather than proposing or developing new structure learning approaches. Additionally, applying the findings operationally might require deeper exploration, particularly in achieving scale-invariant results.", "Questions": "What specific strategies can be employed to mitigate scale effects in real-world applications beyond simple normalization, and how might the insights of this study integrate with existing robustness approaches in structure learning? Are there computational cost implications associated with applying the suggested normalization techniques to various data types and dimensions?"}}
{"paper_id": "eIYDKNqXuV", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. Village-Net Clustering efficiently identifies and clusters complex datasets while being scalable due to its low time complexity.\n2. The method autonomously determines the number of clusters, which is a significant and practical advantage over many traditional clustering techniques.\n3. Demonstrates competitive performance on real-world datasets and proposes a novel way of combining K-Means with community detection algorithms.", "Weaknesses": "1. The accuracy of the method might be limited by the initial K-Means step, which relies on predefined parameters. \n2. There might be challenges related to the initial hyperparameter selection, and the advantages might be limited when working with highly diverse datasets.\n3. Current implementation seems competitive on speed and efficiency, but might require further adjustments to match accuracy benchmarks of state-of-the-art methods. ", "Questions": "1. How does Village-Net Clustering perform in terms of accuracy compared to algorithms designed specifically for non-convex data structures?\n2. Is there a way to reduce the initial dependency on K-Means for constructing 'villages,' or improve it for better initial clusters?\n3. Can the community detection phase be modified or optimized further to improve the accuracy of the final clustering outcome?"}}
{"paper_id": "bAMPOUF227", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The integration of task-specific supervised knowledge from SLMs into LLM in-context learning presents a novel method to enhance performance on out-of-distribution tasks while mitigating issues like hallucinations. The use of a broad range of datasets to test the method adds credibility to the findings.", "Weaknesses": "The paper relies primarily on existing models and frameworks, limiting the originality of the contribution. The practical implementation of the SuperContext framework might also pose challenges due to resource demands. Additionally, the necessity of hand-curated datasets could limit scalability.", "Questions": "Is there a quantifiable measure of the computational overhead introduced by the SuperContext integration compared to baseline methods? How does the method perform when SLM predictions are incorrect or highly uncertain?"}}
{"paper_id": "eNoiRal5xi", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper provides a novel approach by combining parameter and data space perturbations to improve domain generalization, addressing a gap left by existing methods. The proposed UDIM framework shows statistically significant improvements over existing SAM variants, showcasing its potential for robust model generalization.", "Weaknesses": "The proposed method's reliance on simulated perturbations from the source domain may not fully capture the complexities of truly unknown domains. Additionally, while the theory is well-founded, practical implementation details and the selection of perturbations in data space could be further clarified for broader application.", "Questions": "How does UDIM decide the extent of perturbations in the data space, and is there a risk of overfitting to perturbed simulations rather than generalizing to genuinely unseen domains? Can the approach be extended to scenarios with extremely diverse unknown target domains?"}}
{"paper_id": "uU0Adp7Sfo", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. Introduces a novel collaborative-competitive framework for GAN training, merging competition with cooperation for enhanced performance.\n2. Provides both theoretical analysis and comprehensive empirical evaluation, demonstrating improvements over traditional GANs.\n3. The proposed method is robust to training collapse, ensuring stability in data generation.", "Weaknesses": "1. The presentation of results, particularly the visual examples, is lacking in detail and clarity, making it difficult to fully appreciate the improvements claimed.\n2. There is a lack of direct comparison with state-of-the-art GAN methods in terms of standard metrics such as FID or IS, which is a common practice in GAN evaluation.\n3. The method's compatibility with existing advanced GAN architectures (like StyleGAN) is not discussed or evaluated.", "Questions": "1. How does CCGAN perform in terms of standard evaluation metrics (e.g., FID, IS) compared to state-of-the-art GAN models?\n2. Can CCGAN be integrated with or improved by more complex GAN architectures such as StyleGAN?\n3. What are the computational costs associated with the proposed collaborative-competitive framework compared to traditional GANs?"}}
{"paper_id": "dKju7tbe6D", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper introduces a novel integration of iterative and parallel computation, which potentially enhances the efficiency and generalization of visual reasoning models.\n2. The proposed IPRM model demonstrates superior performance on several benchmarks, showcasing its practical impact in visual reasoning tasks.\n3. The combination of iterative and parallel processing strategies is well-motivated to address the limitations of existing purely iterative or parallel models.", "Weaknesses": "1. The paper could benefit from a clearer explanation of how parallel reasoning is distinctly implemented within the model architecture. The interpretation of 'parallel' operations, in this case, seems somewhat implicit from matrix operations, and more explicit illustrations or explanations are needed.\n2. The design choices, especially for Operation Composition, seem complex and are not entirely intuitive from the description provided. Better elucidation in this area would enhance understanding.\n3. Some visualizations in the supplement, while potentially indicating interesting result aspects, lack clarity in demonstrating the model's parallel and iterative reasoning processes.", "Questions": "1. How is the 'identity attention' mechanism enabling higher degrees of operation composition, and how does this relate to traditional attention mechanisms?\n2. Could additional visualizations or examples showing the step-by-step operations of IPRM be included to illustrate the iterative and parallel processing more effectively?\n3. Can you provide further detail on how the model's parallel processing component explicitly contributes to the performance gains observed in different reasoning benchmark tasks?"}}
{"paper_id": "DL7JWbdGr3", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper effectively applies pre-training paradigms from other domains to epidemic forecasting, a novel application area, demonstrating significant performance improvements.\n2. The combination of multiple self-supervised learning tasks (RANDMASK, LASTMASK, etc.) presents a robust methodology for extracting useful data representations from heterogeneous datasets.\n3. The evaluation shows a comprehensive improvement over state-of-the-art models in forecasting accuracy and adaptability to new epidemics.", "Weaknesses": "1. The paper may lack detailed explanations on how specific methodological choices like parameter settings for learning tasks (e.g., gamma for LASTMASK) were determined.\n2. The experimental setup may not clearly establish how the baselines were trained and if resource discrepancies (like data and computational power) were normalized across comparisons.\n3. There might be a potential issue with data bleeding between temporally aligned datasets, such as influenza and cryptosporidiosis, which could affect the reported improvements in data efficiency.", "Questions": "1. How do you choose the value of T (length of the input time series) in your experiments, and how sensitive is the model performance to this parameter?\n2. Could you clarify how the training process is normalized when comparing PEM with baseline models? Specifically, how do you ensure that additional data or compute does not skew the comparisons?\n3. Can PEM be potentially applied to more non-traditional epidemic data types, or is it specifically designed for datasets similar to those used in the evaluation?"}}
{"paper_id": "1PaDPHDhwe", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper introduces a novel post-processing technique for managing the trade-off between robust and average accuracies, which does not require additional training.\n2. The proposed class-specific scaling strategy is simple yet effective, demonstrating improvements across various datasets.\n3. A new evaluation metric, robust coverage, is presented to capture the trade-off and provides a comprehensive evaluation of debiasing algorithms.", "Weaknesses": "1. The method relies on pre-trained models and thus may have limitations if those models have inherent biases or incorrect calibrations.\n2. The paper does not deeply explore the theoretical underpinnings of why class-specific scaling should work well in all cases.\n3. The simplistic nature of the post-processing method might limit its scalability or applicability to more complex, non-linear trade-offs.", "Questions": "1. How does the proposed method perform compared to existing state-of-the-art techniques in terms of computational efficiency?\n2. Can the class-specific scaling technique be adapted to handle other types of biases or is it specifically tailored for robust vs. average accuracy trade-offs? \n3. Has the robustness of the proposed method been tested across a range of different model architectures?"}}
{"paper_id": "iI7hZSczxE", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses an important challenge in disentangled representation learning for time series data by introducing a novel approach that relaxes the assumption of attribute independence. The proposed DIOSC method, which integrates contrastive learning with attentive l-variational inference, appears to enhance disentanglement and improve robustness in scenarios involving correlated attributes. The introduction of the Time Disentangling Score (TDS) as a metric also contributes to a more precise evaluation of disentanglement quality and performance.", "Weaknesses": "The method's general applicability to domains beyond energy consumption datasets like NILM is not extensively demonstrated, which might limit the perceived versatility of DIOSC. Furthermore, while the paper claims significant improvements over existing methods, more explicit examples or case studies detailing performance advantages and scenario applicability would strengthen the argument. The necessity of intricate setup for l-variational inference with self-attention might pose a practical hurdle.", "Questions": "1. How does the DIOSC method's performance vary across different types of time series datasets beyond energy consumption?\n2. Can the Time Disentangling Score (TDS) be applied effectively for evaluating other disentanglement approaches that do not employ independence-of-support?"}}
{"paper_id": "qrGjFJVl3m", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The Qwen-VL series offers significant upgrades to LVLMs by achieving remarkable improvements in fine-grained visual understanding and multilingual support. The authors provide extensive evaluations across various real-world scenarios, which enhances the credibility of the results and establishes new benchmarks. Additionally, the comprehensive training on diverse datasets presents a robust framework highly applicable for vision-language tasks.", "Weaknesses": "While the Qwen-VL series shows impressive performance gains, the novelty in terms of the architectural innovation may be somewhat limited, as it builds upon and slightly refines existing methods (e.g., Vision Transformers and adapters). The effectiveness spurts could also be heavily attributed to large-scale training rather than fundamental methodological innovations. Further, it is not entirely clear how scalable the approach is with regards to incorporating additional modalities beyond text and visual data.", "Questions": "How does the Qwen-VL architecture quantitatively compare to state-of-the-art proprietary models across fine-grained tasks? Are there any quantitative benchmarks showing the performance variation specifically introduced by each stage of the training pipeline? Additionally, how does the model's size and computational requirements compare to other models with similar capabilities?"}}
{"paper_id": "qup9xD8mW4", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper presents an innovative approach to adapting dataset distillation to reinforcement learning, addressing the lack of fixed datasets in RL by introducing a novel method, HaDES, which enables behavior distillation without prior expert data.\n2. The use of a meta-evolutionary approach combined with bi-level optimization for distilling RL information is sophisticated and effective, as demonstrated across a wide range of tasks and architectures.\n3. The methodology demonstrates strong generalization capabilities, showing that the distilled datasets can be effectively used across different player architectures and in multi-task learning scenarios.", "Weaknesses": "1. The paper could further elaborate on the potential limitations of the proposed method, particularly regarding the scalability of the approach to more complex RL environments or tasks beyond those demonstrated in the experiments.\n2. While the study is extensive, it might benefit from a more detailed comparison with existing RL methods beyond traditional dataset distillation techniques to highlight where HaDES stands in relation to current state-of-the-art.\n3. The study addresses the adaptation of dataset distillation in RL, but it might not thoroughly discuss the broader implications and potential real-world applications where this adaptation could prove especially beneficial.", "Questions": "1. How does the performance of HaDES compare with traditional RL methods across more complex environments, and are there any specific challenges noted when scaling the approach?\n2. Can the synthetic datasets generated by HaDES be interpreted or visualized in a way that provides additional insights into the learned RL policies, potentially enhancing explainability or trust in the distilled policies?\n3. How does HaDES perform in scenarios where continuous updates to the environment or task objectives occur—can the distilled datasets rapidly adapt in such dynamic settings?"}}
{"paper_id": "Zw8YxUWL4R", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces an innovative extended textual conditioning space, P+, which provides greater control and expressiveness in text-to-image synthesis. This method significantly enhances the capabilities of existing models by using layer-specific textual tokens, improving image generation customization. Furthermore, the introduction of Extended Textual Inversion (XTI) provides notable improvements in reconstruction quality and editability compared to existing methods like Textual Inversion and DreamBooth.", "Weaknesses": "The methodology primarily focuses on empirical results without providing detailed theoretical insights into the underlying mechanisms. The extended conditioning approach assumes access to fine-grained textual tokens and may require more in-depth investigation on the scalability and applicability to other models. Additionally, while the results are promising, the effectiveness of this approach in varied and broader contexts remains to be extensively validated.", "Questions": "How does the proposed P+ conditioning space handle scenarios with ambiguous or conflicting textual prompts across different layers? Is there a mechanism in place to ensure coherence in the final image output? Additionally, can the model adapt to dynamic prompts that change over time or are generated interactively during image synthesis?"}}
{"paper_id": "3NXhwkZGjz", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach to Source-Free Unsupervised Domain Adaptation by integrating hypothesis consolidation with semi-supervised learning. The method transforms domain adaptation challenges into semi-supervised learning tasks effectively. State-of-the-art performance achieved on SFUDA tasks demonstrates the method's practical applicability. The three-step method effectively consolidates hypotheses for reliable pseudo-label generation, enhancing training outcomes.", "Weaknesses": "The approach relies heavily on the accuracy of initial prediction hypotheses, which might be sensitive to initial conditions. The method requires the construction of class-wise rationale centroids, which may introduce complexity in implementation and computational overhead. The dependence on existing semi-supervised learning frameworks might limit the versatility of the approach in different contexts.", "Questions": "How do different sizes or diversities of the initial hypothesis set affect the method's performance? Are there any limitations or challenges in constructing rationale representations using GradCAM in different domain settings?"}}
{"paper_id": "Fn655mJ4bv", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a novel approach to interpreting structured output models by taking into account correlations among output variables, which is an important advancement in the field. The SOInter method demonstrated competitive performance compared to existing interpretation techniques, and its scalability makes it applicable for large-scale problems. The integration of structural information during training results in improved explanation quality, particularly when output variable correlations are significant.", "Weaknesses": "The method may require careful tuning of the energy-based model and the Gumbel-Softmax trick, which could complicate its applicability in some cases. The exposition of the methodology could be clearer, particularly regarding the training phases and the specifics of the loss function used. Additionally, the paper could further detail the evaluation metrics and their significance in the context of interpretability.", "Questions": "How robust is the method to variations in the choice of target output variables during training? Can the approach be generalized to other model architectures beyond those explicitly examined in the paper? How do changes in hyperparameters, such as the number of important features selected, impact the quality and robustness of the interpretations?"}}
{"paper_id": "VyMW4YZfw7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper challenges the prevailing trend of increasingly complex GNN architectures, highlighting that simpler, traditional methods can achieve competitive performance on SSNC tasks.\n2. By utilizing classical nonparametric techniques in the spectral domain, the study opens avenues for more efficient and interpretable models, promoting cleaner theoretical analysis.\n3. The narrative regarding the impact of changing evaluation standards provides valuable insights into model benchmarking and evaluation practices in graph-based learning.", "Weaknesses": "1. The approach may lack novelty as it leverages traditional methods within a new context, but without significantly advancing theoretical or methodological understanding.\n2. While claiming competitive performance, the paper relies predominantly on benchmark datasets that may not fully capture the potential nuances or challenges posed to GNNs in real-world scenarios.\n3. The work may require extended empirical validation across diverse datasets and more discussion on the trade-offs between model simplicity and expressive power.", "Questions": "1. How do the simple spectral methods perform when the graph structure presents significant noise or irregularities, and would the method require adaptation for such scenarios?\n2. Considering the cleaner theoretical analysis enabled by your method, what specific insights can be drawn about the typical pitfalls or inefficiencies in larger, more complex GNNs?\n3. Are there any specific limitations identified when applying these nonparametric approaches in practice, particularly concerning scalability or adapting to various types of graph data?"}}
{"paper_id": "09xFexjhqE", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses the significant issue of gradient divergence in Robust Fine-Tuning and proposes a novel method, AutoLoRa, which effectively separates natural and adversarial optimization objectives. The method is validated through extensive experiments across various datasets, achieving state-of-the-art adversarial robustness. Additionally, it alleviates the sensitivity to hyperparameters, making it a practical solution.", "Weaknesses": "While the paper presents a promising approach, the explanation of the automated scheduling for hyperparameters could be more detailed. Further, the introduction of the low-rank branch is intriguing but not entirely novel. The clarity of certain experimental results, such as those in Table 4, could be improved to avoid confusion. The paper also lacks diversity in tested network architectures, using primarily ResNet models.", "Questions": "How does AutoLoRa perform on architectures other than ResNet? Can the heuristic scheduling strategies for learning rates be applied to other domains or models effectively? What would be the implications of varying the constant factor in Formula 7?"}}
{"paper_id": "nmBjBZoySX", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses key limitations of existing Graph Lottery Ticket methods by proposing a novel framework that integrates adaptive, dynamic, and automated features, effectively demonstrating enhancements in both performance and applicability in complex GNN scenarios.\n2. Theoretical proofs provided ensure that AdaGLT can mitigate over-smoothing and improve sparse structure handling in deeper GNNs, adding a strong theoretical underpinning to the proposed method.\n3. Empirical results across multiple datasets showcase AdaGLT's superiority in scalability, automation, and efficiency in uncovering sparse subnetworks within GNNs, highlighting its practical significance.", "Weaknesses": "1. While the paper proposes an innovative approach, it might appear incremental given the existing research on Graph Lottery Tickets, especially with works focusing on sparsity and pruning techniques in GNNs.\n2. The experiments, though extensive, are primarily focused on existing datasets, potentially limiting a comprehensive evaluation in significantly larger scale or real-world dynamic graph settings.\n3. Details on the computational overhead or resource utilization in dynamic pruning and restoration during training are not explicitly discussed, which might be crucial for practitioners considering scalable implementations.", "Questions": "1. How does the AdaGLT framework perform in real-world dynamic or evolving graph scenarios outside of the conventional benchmarks?\n2. Can the AdaGLT method be extended to incorporate other types of neural networks beyond GNNs, or is the methodology particularly tailored for graph-based architectures?"}}
{"paper_id": "di52zR8xgf", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a significantly improved version of an existing open-source model, making it a competitive alternative to state-of-the-art black-box models. \n2. The model enhancements maintain transparency and reproducibility, which are valuable for the research community.\n3. The proposed model demonstrates notable improvements in image quality and adherence to text prompts.", "Weaknesses": "1. The paper does not provide extensive details on the specific limitations or failure cases of the new conditioning schemes.\n2. There is limited discussion on potential challenges or trade-offs involved in training with the larger architecture.", "Questions": "1. How does the training time of SDXL compare to previous versions, and what resources are required for effective training?\n2. What specific areas in the model architecture contribute most to the improvements in image quality and adherence to text prompts?"}}
{"paper_id": "0b328CMwn1", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a novel and efficient technique, Activation Prompts (AP), which improves upon Visual Prompts by utilizing intermediate activation layers.\n2. The approach is theoretically connected to normalization tuning, providing deeper insights into the operational mechanics of pre-trained models.\n3. Extensive empirical evaluation across 29 datasets and various architectures convincingly demonstrates the advantage of AP over existing PEFT techniques in terms of accuracy and efficiency.", "Weaknesses": "1. While the paper introduces a new method, it largely builds upon existing concepts such as Visual Prompts and PEFT, and the novelty may be seen as incremental.\n2. The performance of AP is highly dependent on the choice of layer depth for application, which may require significant fine-tuning and domain expertise to optimize.\n3. The paper could provide more in-depth analysis on the potential limitations or failure cases of AP in certain scenarios or datasets.", "Questions": "1. How sensitive is the performance of AP to the specific choice of layer depth for application? Are there practical heuristics or guidelines for selecting them?\n2. Can the proposed AP method be generalized to modalities beyond vision, or is it inherently tied to visual data?\n3. What are the potential challenges in deploying AP in real-world applications where computational resources might be limited?"}}
{"paper_id": "AMDKqZcZbi", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents a novel approach to overcoming catastrophic forgetting in machine learning by drawing parallels with biological neural architectures, specifically the entorhinal-hippocampal circuit. The proposed model, MESH, effectively combines biologically inspired memory systems with modern neural network architectures to achieve both rapid learning and memory retention, which is a significant contribution. The paper's presentation is clear, with a logical structure and detailed descriptions of the methods and experiments. The proposed sequential Morris Water Maze (sWM) task provides a useful benchmark for evaluating continual learning models.", "Weaknesses": "While the approach is inspired by biological systems, the practical implementation may rely on assumptions that deviate from actual biological processes. The evaluation primarily focuses on a task that the model is explicitly designed to excel at, which may limit the generalizability of the results to other domains or tasks. Additionally, further comparisons with state-of-the-art methods in continual learning are needed to validate the model's effectiveness more comprehensively.", "Questions": "How does the proposed model generalize to tasks beyond the sequential Morris Water Maze, particularly those that may not have a direct biological analog?\nWhat are the specific limitations of the MESH model in terms of scalability and computational resources?\nCan the content-addressable memory system be adapted for other types of inputs, such as non-image data, while retaining its effectiveness?"}}
{"paper_id": "am7BPV3Cwo", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses a significant gap in the literature by focusing on the problem of OOD detection in imbalanced datasets, which is an important real-world issue.\n2. The proposed method, ImOOD, demonstrates a significant improvement in OOD detection on imbalanced datasets, showcasing robustness and effectiveness across multiple benchmarks.\n3. The combination of post-hoc normalization and training-time regularization is innovative and contributes to reducing the errors associated with class-aware biases.", "Weaknesses": "1. The paper may not fully address all possible scenarios of imbalanced data since it primarily focuses on imbalanced ID data, and it would be beneficial to study its efficacy in more diverse settings, including imbalanced OOD scenarios.\n2. There is a potential lack of clarity on how well post-hoc normalization alone contributes to the improvements without the training-time regularization, especially on larger datasets where improvement might be marginal.\n3. The method's applicability beyond the tested benchmarks could be further explored to verify its generalizability.", "Questions": "1. How does ImOOD handle situations where both ID and OOD datasets are imbalanced? Is the method's performance robust in such scenarios?\n2. Can the method be extended or adapted to deal with other types of imbalanced settings, such as imbalanced OOD data during training or evaluation?\n3. How sensitive is the proposed framework to the choice of thresholds and hyperparameters during the post-hoc normalization and training-time regularization processes?"}}
{"paper_id": "R1crLHQ4kf", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper addresses a critical security threat in ASR systems by introducing a novel method to detect adversarial attacks, thereby providing significant practical utility.\n2. The approach leverages statistical characteristics of output probability distributions, exploiting properties of ASR system outputs that are often overlooked in other methods.\n3. Comprehensive empirical validation across diverse datasets and ASR systems demonstrates the effectiveness of the method, achieving high accuracy and robustness to adaptive attacks.", "Weaknesses": "1. The approach may require more detailed investigation into its limitations, especially regarding computational efficiency and potential weaknesses against more advanced adaptive attacks.\n2. The reliance on statistical characteristics might limit the method's applicability to certain types of adversarial examples, potentially missing those crafted in ways that do not alter distributions in a detectable manner.", "Questions": "1. How does the proposed method handle adversarial examples crafted to manipulate the statistical characteristics used for detection, such as entropy or divergence measures?\n2. Could this method be adapted or extended to other modalities beyond audio, or is it closely tied to the properties of ASR outputs?"}}
{"paper_id": "i7P2mK3x3o", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper proposes a novel flow-based neural ODE model, Q-flow, for computing optimal transport maps directly between two general distributions P and Q.\n2. By bypassing the need for an intermediary normal distribution, the method improves efficiency and offers new possibilities for generative models and distribution interpolation.\n3. The empirical evaluation demonstrates strong performance in various high-dimensional data applications, highlighting the model's practical utility.", "Weaknesses": "1. The paper primarily focuses on the application of Q-flow to specific tasks like density ratio estimation and image-to-image translation but lacks a deep theoretical understanding or justification of why the method should outperform existing models.\n2. While the method appears promising, the paper may have limitations regarding the scalability of the proposed model to very large datasets or distributions with complex structures.\n3. There is a need for more comparative analysis with other state-of-the-art methods to strengthen the claims of superiority in specific applications.", "Questions": "1. How does the proposed Q-flow method compare with other existing flow-based models or frameworks for tasks like image-to-image translation in terms of computational efficiency and quality of results?\n2. Are there any specific limitations or conditions under which the Q-flow model may not perform optimally?\n3. How sensitive is the model to the choice of hyperparameters, and are there any guidelines or recommendations provided by the authors based on their experiments?"}}
{"paper_id": "YIls9HEa52", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The proposed irSLDS model makes a significant contribution towards addressing the limitations of current rSLDS models. It allows for flexible state cardinality and integrates a latent geometric structure over states, which improves interpretability and applicability for neural data analysis. The model is effectively demonstrated on both synthetic and real-world datasets, showcasing its ability to capture non-stationary processes.", "Weaknesses": "The paper could benefit from more comprehensive comparisons with other state-of-the-art models beyond traditional rSLDS, such as those incorporating alternative state space representations or priors. Additionally, while the use of a PDE framework is mentioned, further elaboration on its specific advantages and limitations compared to other methods would strengthen the argument for its choice.", "Questions": "How does the performance of irSLDS compare with alternative models that utilize more recent machine learning techniques for neural data analysis? Are there potential challenges in scaling irSLDS to larger datasets or more complex neural recordings?"}}
{"paper_id": "koYsgfEwCQ", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to 3D dynamic scene decomposition using object-centric voxelization, which is an innovative step beyond existing 2D methods. The use of differentiable volume rendering, along with a comprehensive three-stage training process, allows for improved performance in scene decomposition, especially in handling occlusions. The method's ability to enable scene editing and dynamic view synthesis is a significant advancement.", "Weaknesses": "While the method is promising, there are areas that could be more clearly explained. The description of the training stages is somewhat fragmented, making it difficult to piece together how exactly the model progresses through each stage. Additionally, the reliance on defining a number of objects (N) could limit the adaptability of the method in more complex scenes unless this is dynamically determined. Some technical details about the implementation are lacking, such as the integration of the dynamics module with other components. Furthermore, simplifications or assumptions made in the method, such as object occlusion handling, might limit its applicability to more diverse datasets.", "Questions": "How does the assumed number of objects (N) affect performance in scenes with varying complexity? Is there a mechanism in place for dynamically adjusting this parameter? Is there potential to extend this method to handle more complex scenes with a higher number of interacting objects? Could the usability of this method be compromised by object occlusion or complex motions that exceed its current design considerations?"}}
{"paper_id": "o6AN2ZoNw2", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper presents a novel methodology for open-vocabulary semantic segmentation that does not rely on annotated masks, simplifying the training process.\n2. P-Seg demonstrates competitive performance on several benchmarks and showcases scalability with enlarged datasets, achieving state-of-the-art results.\n3. The method leverages a simple framework utilizing pseudo-mask generation and language supervision, reducing reliance on complex pre-trained models.", "Weaknesses": "1. The innovation of the proposed method might be limited, as it resembles existing frameworks with minor modifications, and these similarities are not thoroughly discussed in the paper.\n2. The experiments could benefit from comparing results against more recent methods in the domain to better substantiate the state-of-the-art claim.\n3. There could be more detailed ablations to justify design choices, as the current analysis primarily centers around increasing data size.\n4. Presentation-wise, some crucial procedural details are missing, such as the formation of textual prompts for evaluation and specifics of self-training.", "Questions": "1. How does the method compare directly against more recent baselines, such as OVSegmentor or SegCLIP, in terms of performance?\n2. Can the paper clarify the exact nature of its zero-shot claims? Specifically, how is zero-shot defined in this context, given the training datasets likely contain target instances?\n3. Would the inclusion of pre-trained backbones impact the method's efficacy, and what prompted the decision to train models from scratch?"}}
{"paper_id": "HXZK1Z8tHa", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper effectively addresses computational challenges in Transformer-based image restoration methods by proposing a novel Shared Portion Stripe Attention mechanism which reduces redundancy and computational overhead.\n2. ShareFormer is shown to achieve state-of-the-art performance across multiple benchmarks with improved latency and trainability, indicating the method's potential applicability in a wide range of image restoration tasks.\n3. Comprehensive evaluation and comparison with existing methods highlight the effectiveness of ShareFormer in achieving an optimal balance between speed and accuracy.", "Weaknesses": "1. The paper lacks detailed ablation studies to demonstrate the importance of proposed components like the combined shared attention unit (CSAU). This could help in clarifying individual contributions to the overall performance.\n2. Despite the improved inference speed, the performance gains in some tasks like grayscale denoising and JPEG compression artifact reduction are not significant, suggesting limited improvements in certain scenarios.\n3. The novelty of sharing attention maps might not be significant given previous methods like ELAN have proposed similar mechanisms, questioning the distinctiveness of the ShareFormer approach.", "Questions": "1. Can the proposed Shared Portion Stripe Attention mechanism be generalized to other high-dimensional vision tasks beyond image restoration, and if so, what challenges might arise?\n2. How does the Shared Portion Stripe Attention specifically impact the model's ability to handle high-resolution images compared to conventional Transformer-based methods?\n3. Are there specific cases where the proposed method underperforms compared to convolution-based approaches, and what might be the cause?"}}
{"paper_id": "QO3yH7X8JJ", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "sNtDKdcI1f", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides a thorough analysis of the output length biases in RLHF and highlights a novel concern that had not been well-addressed in previous research. The experiments conducted on multiple datasets demonstrate rigor and provide compelling evidence for the claims made regarding length biases. The study offers valuable insights into the development of more effective reward models for RLHF systems.", "Weaknesses": "The presentation of the results, particularly in figures and tables, is somewhat unclear and could be better structured to aid comprehension. There seems to be a lack of clear, actionable guidance for practitioners based on the findings, which might limit the practical impact of the research. Additionally, there could be more exploration of other qualitative factors that contribute to reward improvements beyond output length.", "Questions": "1. Have the authors considered evaluating the impact of output length biases on other RLHF objectives such as harmfulness or honesty, and how might these factors play a role differently from helpfulness?\n2. Can the findings regarding length biases be generalized to other domains or tasks beyond language models and RLHF settings?\n3. Are there more concrete suggestions or methodologies proposed for practitioners to mitigate length biases in reward modeling beyond those tested in the study?\n4. What are the next steps anticipated in evolving reward models that better align with human preferences without being skewed by factors like output length?"}}
{"paper_id": "HFtrXBfNru", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. SMART introduces an innovative approach to address the problem of evolving graphs in GNNs through self-supervised learning and adaptive feature extraction, which is a novel contribution to the field.\n2. The methodology is well-structured and leverages graph reconstruction techniques effectively to improve temporal generalization estimation.\n3. The paper demonstrates a thorough evaluation on both synthetic and real-world data, showing the effectiveness of the proposed method.", "Weaknesses": "1. The paper could benefit from a more detailed discussion on the limitations and potential pitfalls of the proposed approach, such as assumptions made during theoretical analysis and bound derivation.\n2. There is a lack of comparison with existing state-of-the-art methods in the experiments, which may undermine the claimed effectiveness of the proposed method.\n3. The paper could explore additional real-world datasets to further validate the proposed methodology.", "Questions": "1. How does SMART perform in scenarios where the graph's temporality is less predictable or has abrupt changes?\n2. Can the approach be extended to accommodate disappearing nodes, not just evolving graphs with added nodes and edges?"}}
{"paper_id": "4u0ruVk749", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The proposed technique offers a novel approach to modeling unobserved confounders using diffusion models, which could enhance the estimation of individual treatment effects.\n2. The paper demonstrates improved performance over several state-of-the-art methods in causal inference tasks, suggesting the practical utility of diffusion models in this area.\n3. The methodology is well-founded on a clear theoretical basis, combining diffusion processes with deep learning techniques.\n4. Comprehensive experiments and tests on benchmark datasets help validate the framework's effectiveness vis-à-vis existing models.", "Weaknesses": "1. The paper could benefit from clearer presentation in terms of algorithmic steps and intuition behind the diffusion processes.\n2. The approach, while innovative, may require complex configurations that could limit its accessibility to practitioners who are less familiar with diffusion models.\n3. There is a lack of detailed discussion regarding computational costs and potential limitations in highly dynamic, less understood environments.", "Questions": "1. How do the computational requirements of the proposed diffusion model-based method compare to those of simpler generative models like VAEs or GANs?\n2. The notion of 'capturing unobserved latent spaces' through diffusion models might have computational trade-offs in scale. Can you discuss potential pathways to optimize efficiency or handle larger datasets?\n3. Can the diffusion-based framework be adapted or scaled to different contexts beyond healthcare or recommendation systems?"}}
{"paper_id": "Pa6SiS66p0", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper addresses an important gap in the field of continual learning by exploring the integration of multi-modal learning, which has been overlooked in previous studies.\n2. The introduction of a benchmark for multi-modal continual learning using a well-known dataset like VGGSound is a significant contribution that sets a foundation for further research.\n3. The proposed SAMM method shows potential in improving the stability-plasticity trade-off in dynamic environments, indicating robustness and versatility in handling multi-modal data.", "Weaknesses": "1. The evaluation is somewhat limited, as it focuses on a single dataset (VGGSound) for the experiments. Broader validation across different datasets and settings could strengthen the conclusions.\n2. The paper's novelty mainly lies in the integration aspect of the approach, which might not be groundbreaking considering existing work in i.i.d. settings and domain-specific applications.\n3. It would have been beneficial to include a more comprehensive comparison against existing state-of-the-art methods in both unimodal and multimodal continual learning.", "Questions": "1. Can the proposed SAMM method be effectively applied to other multimodal contexts beyond audio-visual, such as textual data?\n2. How does the proposed method handle scenarios where there is significant noise or missing data in one of the modalities?\n3. Are there any limitations or specific challenges expected when extending this benchmark or method to real-world applications beyond controlled experimental settings?"}}
{"paper_id": "rkplYfqUr0", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The proposed GEN-Z method addresses a relevant problem in NLP by providing a robust alternative to discriminative prompting for zero-shot text classification.\n2. The method demonstrates impressive performance across a wide range of tasks and models, showcasing its generalizability and robustness.\n3. The approach of using generative prompting with label descriptions and context is innovative and novel, potentially contributing significantly to the field of language model prompting.", "Weaknesses": "1. Although the approach improves robustness to prompt variations, it still relies on manually crafted label descriptions and paraphrases generated by ChatGPT, which may limit scalability and practicality.\n2. The method's effectiveness is somewhat contingent on the quality of the label descriptions, which could vary widely depending on the task and domain.\n3. The approach may face challenges in standardization and consistency across different NLP tasks without significant manual intervention.", "Questions": "1. Can the approach be fully automated, such as through advanced algorithms or tools, to eliminate the need for manually crafted label descriptions and still maintain performance?\n2. How does the performance of GEN-Z compare to state-of-the-art methodologies for zero-shot text classification in terms of computational efficiency and resource usage?\n3. What are the potential limitations of using generative prompting in highly specialized or less-studied domains?"}}
{"paper_id": "pTU2X9mUBe", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 5, "Strengths": "1. LaDe is a comprehensive and large-scale dataset that fills a critical gap in the logistics research domain, by providing researchers with real-world, diverse data that includes pick-up and delivery scenarios, as well as detailed courier information.\n2. The dataset covers a wide range of geographical locations and operational conditions, making it versatile for benchmarking various logistics algorithms and tasks. \n3. The work not only contributes a valuable resource but also benchmarks its utility across multiple relevant tasks, demonstrating the dataset's practical applicability.", "Weaknesses": "1. While the dataset is introduced as a significant contribution, the paper does not deeply explore how it specifically enhances or challenges existing logistic models beyond initial benchmarking. This limits insights into its transformative potential.\n2. The potential privacy issues related to the released data, especially concerning details of couriers and operation specifics, need more discussion on how these are addressed to ensure ethical data use.", "Questions": "1. Beyond the current benchmark tasks (route prediction, ETA prediction, and spatio-temporal forecasting), what are some other potential research areas that could benefit from the LaDe dataset?\n2. Are there any plans to update or expand the dataset in the future to include more recent data or additional features, such as more detailed traffic conditions or customer feedback? \n3. How does the LaDe dataset handle data imbalances or bias inherent in operational data across different cities or courier profiles?"}}
{"paper_id": "uhtQyRrTzY", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The method MIMIC addresses an important gap by generating large-scale multi-view datasets from real-world unannotated videos.\n2. The dataset provides impressive scalability, aligning with the current need for real-world large-scale datasets for dense vision tasks.\n3. The approach demonstrates superior performance in dense prediction tasks compared to models trained on annotated datasets.", "Weaknesses": "1. The method's reliance on classical computer vision techniques might not adequately handle complex real-world scenes.\n2. There could be limitations in terms of the diversity and variability of scenes in the curated datasets.", "Questions": "1. How does MIMIC handle scenarios with significant dynamic changes in the scene?\n2. Are there any limitations in terms of the type or scope of videos that can be used to generate datasets with MIMIC?"}}
{"paper_id": "WZfatbNdLV", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The TrASPr model introduces an innovative use of transformers for the task of predicting tissue-specific RNA splicing, which is a crucial step forward given the existing challenges in the field. The integration with a Bayesian Optimization framework showcases the potential for practical applications in RNA splicing outcome design.", "Weaknesses": "The paper may have some gaps in comparing its results with existing models in depth, and there might be issues with scaling the approach to different datasets or generalizing across various cellular conditions. The reliance on specific datasets also raises questions about its broader applicability.", "Questions": "How well does the TrASPr model generalize across different tissue types not seen in training? Are there any limitations anticipated in adapting the Bayesian Optimization framework for other splicing-related tasks?"}}
{"paper_id": "YkRwadXWHd", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper proposes a novel multi-modal framework combining video, keypoints, and optical flow with a hierarchical knowledge distillation framework, which shows significant improvements over existing methods for continuous sign language recognition.\n2. State-of-the-art performance is achieved on multiple benchmarks such as Phoenix-2014, Phoenix-2014T, and CSL-Daily, demonstrating the effectiveness of the approach.\n3. The method reduces computational costs by using a knowledge distillation technique, which is essential for deploying models in real-world scenarios.\n4. Comprehensive evaluation across different datasets enhances the reliability of the results presented.", "Weaknesses": "1. While the integration of multiple modalities is beneficial, the novelty might be limited as multi-modal learning and knowledge distillation are established techniques, suggesting that the key contribution lies more in the application to CSLR rather than advancing these techniques.\n2. The paper does not discuss the computational requirements in detail, such as how training times compare to other methods or the specific requirements needed for practical deployment.\n3. There is a dependency on choosing the right modalities and fusion techniques, which may limit general applicability across different CSLR tasks or benchmarks.", "Questions": "1. How does the model performance vary with different fusion methods, and what criteria should be used to choose between MLP, attention, and convolution-based methods?\n2. Are there any specific challenges or limitations encountered when integrating the three modalities, particularly with synchronization or alignment issues?\n3. How resilient is the proposed model to variations in input quality, such as noise in keypoints or low-quality video data?\n4. What are the training times and hardware requirements needed to train the teacher model compared to the student model?"}}
{"paper_id": "q4Bim1dDzb", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The proposed UniVoxel framework effectively addresses the inefficiencies in traditional inverse rendering methods by utilizing a unified voxelization approach. \n2. The use of Spherical Gaussians for modeling local incident light is a novel and efficient way to incorporate illumination without complex calculations, improving performance across varying lighting conditions.\n3. UniVoxel significantly reduces per-scene training time while achieving high-quality renderings, demonstrating robustness across diverse datasets.", "Weaknesses": "1. The paper may lack substantial novelty as some aspects of the framework resemble existing methods, and it may not fully address how global illumination and self-occlusion are managed during relighting.\n2. Although promising, comparisons might not fully account for parameter equivalency when assessing representations like Spherical Gaussians versus Spherical Harmonics, which could challenge claimed efficiency gains.\n3. There might be limitations in benchmarking only a limited range of scene complexities, potentially not testing edge cases where more complex lighting scenarios are present.", "Questions": "1. How does UniVoxel handle global illumination and self-occlusion effects during the relighting process to ensure realistic outcomes?\n2. Are there any scalability constraints when incorporating complex environments or larger scene datasets with the current framework design?\n3. Have the authors considered extending the evaluation to include more diverse lighting conditions to robustly test the versatility of the proposed method?"}}
{"paper_id": "39cPKijBed", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper addresses a critical issue of dataset bias in diffusion models, providing a novel solution with time-dependent importance reweighting that enhances fairness and quality of generative models. \n2. Comprehensive experiments across multiple standard datasets demonstrate the effectiveness of the proposed method in bias reduction compared to existing baselines.\n3. The approach is theoretically grounded, with a solid framework that supports the practical applicability of the method in various settings.", "Weaknesses": "1. The method's reliance on accurate density ratio estimation could pose challenges in scenarios where this is difficult, potentially affecting the robustness of the results.\n2. The computational complexity and scalability of the proposed method in large-scale settings or with extremely large datasets are not thoroughly examined.", "Questions": "1. How does the proposed time-dependent importance reweighting method scale with very large datasets or in real-world applications requiring high computational efficiency?\n2. Are there any specific limitations or failures that were encountered during experimentation that could guide future improvements?"}}
{"paper_id": "aG3EARrrd1", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces the Online Sparse Residual Tree (OSRT) model, which efficaciously integrates tree decomposition with adaptive radial basis function (RBF) exploration. This framework supports dynamic and accurate handling of streaming multivariate scattered data. OSRT's innovative approach to growing and refining nodes dynamically based on streaming data points ensures model sparsity, thereby enhancing efficiency and adaptability. The model's superior prediction accuracy and efficiency are substantiated through benchmarking against time series datasets such as Mackey-Glass and Lorenz series.", "Weaknesses": "Despite its notable strengths, the paper could further detail the specific implementation steps and potential limitations encountered. Existing methodologies, such as RBF-based models, already address the problem of online learning. The degree to which the proposed OSRT model outperforms these existing solutions requires more substantial analysis and comparative metrics across a broader array of datasets. Additionally, a more comprehensive exploration into the computational complexity and resource-intensiveness when applying OSRT on larger datasets would enhance the practicality and applicability of the model.", "Questions": "What are the computational costs associated with dynamically adjusting the tree and RBF networks when operating on significantly larger datasets or more complex streams? Does the efficiency of OSRT remain consistent across varying problem domains, and how well does it generalize beyond the time series datasets explored?"}}
{"paper_id": "Ts95eXsPBc", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper effectively addresses an overlooked aspect in AI episodic memory modeling by incorporating spatial information, which aligns with cognitive science principles. 2. The introduction of Spatially-Aware Transformers (SAT) and Adaptive Memory Allocator (AMA) showcases innovative thinking, potentially leading to improved memory efficiency and accuracy in task performance. 3. The experiments across various environments and tasks provide strong evidence for the proposed models' effectiveness.", "Weaknesses": "1. While the idea of integrating spatial information in episodic memory models is valuable, the novelty of the approach may be questioned, as the adaptation of transformers to new domains is a common research trajectory. 2. The paper may lack clarity regarding the implementation details of the Adaptive Memory Allocator and the specific impacts it has on different learning tasks. 3. The scalability and generalization of the proposed approach to more complex or larger-scale environments remain uncertain.", "Questions": "1. How does the Adaptive Memory Allocator specifically operate across the different tasks presented in the experiments? Further clarification could support understanding of its functionality. 2. Can the Spatially-Aware Transformers be easily scaled or adapted for use in larger, more complex environments than those tested? 3. Are there any limitations or potential issues in using spatial information that might affect episodic memory modeling or lead to unintended consequences in task accuracy?"}}
{"paper_id": "LfhG5znxzR", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The introduction of sparse and discrete bottlenecks enhances interpretability and control of neural networks without significant performance degradation. The method utilizes vector quantization effectively and demonstrates its application on multiple datasets.", "Weaknesses": "The approach may be limited by its reliance on a large codebook, which could introduce complexity. The practical implementation across different domains may vary, and there might be challenges in selecting appropriate code vectors.", "Questions": "How does the method scale with very large models and datasets? Are there any performance trade-offs observed when applying this approach to high-dimensional input data?"}}
{"paper_id": "bUGzjiUsIq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper addresses a significant problem of learning from partially annotated datasets in multi-label classification, which is challenging and practical in real-world scenarios.\n2. The combination of reinforcement learning and supervised learning in the proposed PAPG framework is innovative and shows potential to improve performance on incomplete datasets.\n3. Comprehensive experiments with various datasets demonstrate the robustness and effectiveness of the approach.", "Weaknesses": "1. The reinforcement learning component, while novel, could add additional complexity to the training process, which might be a hurdle for practitioners to adopt it quickly.\n2. The paper lacks sufficient detail on how the local and global rewards are precisely calculated, which may affect reproducibility and understanding.\n3. The integration and benefits of the data enhancement and adaptive threshold techniques in the framework are not thoroughly analyzed in terms of their impact individually.", "Questions": "1. How does the policy gradient approach handle situations where the unannotated labels have strong interdependencies with the annotated ones?\n2. What is the sensitivity of the proposed framework to the choice of adaptive thresholds, and how are these thresholds initialized and tuned?\n3. Can PAPG be extended or adapted to handle fully annotated datasets efficiently, or is it specifically tailored for partially annotated conditions?"}}
{"paper_id": "uMAujpVi9m", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. ProFSA introduces a creative approach to handle protein-ligand complex data scarcity by generating a large set of pseudo-complexes for pretraining, showing excellent results. \n2. The method demonstrates substantial improvements over existing techniques in key tasks such as druggability prediction and ligand binding affinity prediction. \n3. The use of high-resolution protein structures for segmentation is well thought out and leverages available data effectively.", "Weaknesses": "1. The method's reliance on pseudo-ligand representations introduces a potential gap between synthetic and real ligands, which might limit the applicability to real-world scenarios.\n2. The complexity of the method, involving pseudo-ligand and pocket alignments, may require additional effort to replicate or extend. \n3. Discussion on potential limitations of the pseudo-complexes approach, including any biases introduced during pretraining, is limited.", "Questions": "1. How does the performance of ProFSA compare when pretraining with actual protein-ligand complexes versus the pseudo-complexes, if such data is available?\n2. What are the implications of using pseudo-ligands on the interpretability and explainability of ProFSA's predictions?\n3. Can this approach be generalized to model other types of biomolecular interactions beyond protein-ligand interactions?"}}
{"paper_id": "uqxBTcWRnj", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach for integrating neural networks with symbolic reasoning. The Transitional Dictionary Learning framework is innovative and leverages unsupervised learning to bridge the gap between neural and symbolic representations. The introduction of new evaluation metrics that align with human interpretation is a significant contribution, enhancing the interpretability of neural network models.", "Weaknesses": "While the framework shows promise, it primarily focuses on specific datasets and may not generalize well across different domains or more complex real-world scenarios. The method's reliance on unsupervised learning could introduce variability in results depending on the data's nature and complexity.", "Questions": "How does the proposed method perform when applied to datasets with higher complexity or more real-world applications? Can the approach be integrated into existing neural network architectures for broader practical applications?"}}
{"paper_id": "o4CLLlIaaH", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents an innovative approach to address limitations in existing Neural Radiance Fields by shifting to a point-based rendering method, demonstrating improvements in rendering quality, geometry correctness, and view consistency. The method introduces novel components like visibility-oriented feature fetching and a feature-augmented learnable kernel, which contribute to the effectiveness of GPF. The experiments conducted on multiple datasets underscore its potential for generalization and finetuning.", "Weaknesses": "The paper, while presenting a novel approach, may face challenges in terms of scalability and efficiency due to the complexity of the proposed method. Additionally, the reliance on external processes like PatchmatchMVS for the initial point scaffold introduces a dependency that might affect standalone deployment or application in varied scenarios.", "Questions": "How does the reliance on PatchmatchMVS for initial point scaffolding affect the method’s scalability and applicability in real-world scenarios? Can future work aiming at a NeRF-based initialization resolve potential limitations? Furthermore, how does GPF compare in terms of computational efficiency with existing methods such as E-NeRF?"}}
{"paper_id": "KNzL1nglNB", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "pvhyBB86Bt", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses an important issue related to the training of deep neural networks, specifically the stability of the Jacobian matrix throughout the training process. By exploring the relationship between the initial stability of the Jacobian and its behavior during training, the paper contributes valuable insights to the theoretical understanding of neural network stability.\n\nThe work leverages advanced concepts from random matrix theory and offers a general stability theorem, which enriches the discussion and analysis. This solid theoretical foundation is a notable strength of the paper.", "Weaknesses": "While the theoretical contributions are significant, the paper could benefit from more empirical validation to complement the theoretical analysis. Real-world experiments, especially those demonstrating the practical implications of Jacobian stability throughout training, would strengthen the findings.\n\nThe assumption of Jacobian stability based on initialization might not fully capture the nuances of network training dynamics, especially in complex architectures or diverse training scenarios. More exploration of these scenarios would provide a more comprehensive understanding.", "Questions": "How generalizable are the findings to architectures beyond MLPs or to setups involving non-standard configurations (e.g., different pruning strategies, diverse datasets)? \n\nWhat are the specific implications for network design or training protocols based on the stability insight achieved in the study?"}}
{"paper_id": "Mylk5iamJC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces the Latent Gaussian Mixture Model (L-GMM), which offers a unified approach for tackling both closed-set and open-set recognition challenges. By using generative modeling, it provides a coherent solution that doesn't rely on training modifications or prior knowledge about unknown classes.", "Weaknesses": "While the approach is innovative, it might be challenging to adopt in practical settings where interpretability and computational resources are key concerns. Additionally, there might be limited novelty as similar generative approaches have been explored in some contexts; the paper doesn't clearly distinguish itself from such existing work.", "Questions": "How does the performance of L-GMM compare to other state-of-the-art methods specifically designed for CSR or OSR, in terms of computational efficiency and resource demands? Can the model's approach be extended or adapted to different modalities beyond image recognition and segmentation?"}}
{"paper_id": "MsOcVFzv8D", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a notable gap in multi-domain text classification by providing a theoretical basis for the task. The use of margin discrepancy as a measurement tool for domain divergence in adversarial training offers both innovation and a solid ground for better model performance. Additionally, the empirical results demonstrate significant advancements over previous approaches across multiple datasets, validating the concept and claims effectively.", "Weaknesses": "The originality of the theoretical contribution might be questioned, as it largely extends existing work rather than developing entirely new principles. The implementation details and theoretical proofs could benefit from more clarity for practitioners less familiar with the background literature. Furthermore, the dependence on effectively computing and utilizing margin discrepancies in high-dimensional feature spaces could challenge broader applicability in different settings.", "Questions": "How does the complexity of computing margin discrepancies scale with the size of the datasets and feature spaces? Is the method tested or applicable in real-world large-scale classification tasks where computational efficiency is critical?"}}
{"paper_id": "fBlHaSGKNg", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper proposes an innovative sample selection method that integrates well with existing SSL frameworks, offering improved performance, especially under budget constraints.\n2. The use of the Generalized Kernel Herding without Replacement (GKHR) algorithm to minimize α-MMD is a novel contribution that demonstrates good theoretical grounding while addressing the problem of optimal sample selection.\n3. Extensive experimentation on multiple datasets highlights the effectiveness of the UPA approach.", "Weaknesses": "1. The paper could benefit from more clarity in its explanation of the α-Maximum Mean Discrepancy (α-MMD) and how it directly affects the generalization ability of SSL frameworks.\n2. The method's scalability and computational overhead are not thoroughly discussed, especially concerning the proposed use of the modified Frank-Wolfe algorithm.\n3. While performance improvements are demonstrated, there is a lack of qualitative analysis or case studies showing the real-world applicability of the method.", "Questions": "1. Can the proposed UPA method be generalized to other domains beyond those tested in the paper, such as more complex real-world data where labeled samples might be even scarcer?\n2. How does the computational efficiency of UPA compare when integrated with different SSL frameworks or when applied to larger datasets?\n3. Is there a theoretical guarantee on the improvement of sample diversity and representativeness afforded by the GKHR algorithm in practical scenarios?"}}
{"paper_id": "HwQ8NVvdmm", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a novel integration of Hadamard transforms with quantization for continual learning, successfully demonstrating minimal accuracy loss combined with significant computational efficiency gains. It offers a valuable contribution to the field of deploying machine learning on edge devices, specifically under resource constraints. The proposed method, HDQT, shows promising results under stringent conditions akin to real-world applications.", "Weaknesses": "The scalability of the proposed method to more complex datasets or tasks with larger models remains largely unexplored. Additionally, the reliance on specific quantization techniques and stochastic rounding poses potential implementation challenges in different hardware environments. There is also limited discussion on broader applicability beyond the presented datasets.", "Questions": "How does the method handle more complex models or larger datasets beyond CIFAR100 and the mentioned HAR datasets? Are there specific types of models or tasks where HDQT would not be applicable? Also, what are the potential implications of the specific hardware requirements for deploying HDQT in edge computing scenarios?"}}
{"paper_id": "cZo6pDtDZr", "review": {"Soundness": 3, "Presentation": 2, "Contribution": 3, "Rating": 5, "Confidence": 4, "Strengths": "The paper introduces two novel algorithms that address significant gaps in the existing literature. The private estimation algorithm has a promising approach to reducing sample complexity while maintaining privacy, a critical aspect for real-world applications. Additionally, the development of a sequential testing algorithm that adapts to unknown difficulty parameters is innovative and practically useful.", "Weaknesses": "The presentation of the paper could be improved, particularly in terms of contextualizing the results with respect to prior work. The novelty of the algorithms, while present, is limited and may not represent a substantial leap forward in the field. Additionally, the paper might benefit from a more detailed comparison with other related works.", "Questions": "How do the algorithms perform in practical settings where epsilon is not only unknown but potentially variable over time? Are there any assumptions in your algorithms that may limit their applicability in certain domains?"}}
{"paper_id": "F7QnIKlC1N", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel approach to predicting 3D ground-state molecular conformations from 2D topological data using an innovative self-attention mechanism, which is a significant step forward in molecular modeling.\n2. The proposed model, GTMGC, demonstrates impressive improvements over current state-of-the-art models, as evidenced by the benchmark results on the Molecule3D and QM9 datasets.\n3. The research has broad implications for molecular property predictions, highlighting the robustness and general applicability of the MSRSA module.", "Weaknesses": "1. The paper does not thoroughly compare the proposed method with other recent Transformer-based architectures in molecular modeling, which could further substantiate the claims of superiority.\n2. The reliance on specific datasets like Molecule3D and QM9 might limit the generalizability of the results across other types of molecules or different datasets not evaluated.\n3. While the MSRSA mechanism is innovative, the implementation details for replicability are not fully fleshed out, which could hinder reproducibility by other researchers.", "Questions": "1. How does the GTMGC model perform with molecules that have more complex conformational spaces or higher degrees of flexibility beyond the datasets tested?\n2. Can the proposed MSRSA mechanism be adapted or applied to other domains outside molecular modeling, and if so, what adjustments might be necessary?\n3. Are there any plans to open-source the GTMGC model or provide additional implementation details to ensure the community can replicate and build upon this work?"}}
{"paper_id": "8JCn0kmS8W", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. WavJourney introduces a novel approach to audio generation by combining large language models with structured semantic representations, which is innovative and addresses a significant gap in the domain of audio creation.\n2. The method achieves state-of-the-art results on established benchmarks, demonstrating its effectiveness in synthesizing complex audio compositions.\n3. The framework is compositional and interpretable, allowing the use of different expert audio models without requiring additional training.", "Weaknesses": "1. While the approach is innovative, the reliance on existing audio models and large language models may limit the novelty and scope of technical contributions.\n2. The efficiency and real-world applicability of the system might be constrained by its dependence on computationally expensive models.\n3. The paper discusses potential limitations in artificial composition and efficiency, but does not provide concrete solutions or performance data in these areas.", "Questions": "1. How does the system handle complex dialogues and transitions in storytelling audio, especially in scenarios requiring intricate timing and layering of audio elements?\n2. Can the proposed framework be adapted to other domains or modalities, such as video storytelling, using a similar approach?\n3. What are the specific limitations related to the artificial composition of audio, and how do these limitations impact the realism and quality of the generated audio?"}}
{"paper_id": "XbLffB0T2z", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses an important aspect of data poisoning attacks — their transferability across different learning paradigms — which is crucial given the diversity of training algorithms used in practice.\n2. The proposed method demonstrates significant improvement over existing techniques in terms of reducing test accuracy across varied datasets and learning paradigms.\n3. The integration of both supervised and unsupervised contrastive learning to enhance attack transferability is a novel approach.", "Weaknesses": "1. The reliance on high-frequency perturbations might not be sufficient to ensure transferability across all possible scenarios, and the paper may not fully address how to systematically select or design these perturbations.\n2. While the experiments are promising, additional analysis or theoretical grounding on why these perturbations are efficient across learning paradigms would strengthen the results.\n3. The dependency on pretrained models and specific datasets could limit the generalizability of the approach.", "Questions": "1. How does the method perform on larger or more varied datasets beyond CIFAR-10, CIFAR-100, and TinyImageNet? \n2. Is there any theoretical justification or insight into why high-frequency perturbations are particularly transferable with contrastive learning?"}}
{"paper_id": "4y3GDTFv70", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper provides a novel theoretical framework for understanding the emergent abilities of large language models, focusing on Bayesian inference and joint distributions.\n2. The theoretical approach offers a new perspective on how LLMs leverage data distribution properties without explicit semantic training.", "Weaknesses": "1. The theoretical framework may lack empirical support from real-world datasets, as the validation relies on synthetic data.\n2. The concept of ε-ambiguous languages and latent spaces needs further clarification to enhance comprehensibility for a broader audience.", "Questions": "1. How does this theoretical model extend to real-world applications and datasets beyond synthetic ones?\n2. Are there specific guidelines for designing experiments that can empirically test the proposed latent space theory in practical scenarios?"}}
{"paper_id": "ODSgo2m8aE", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper presents a novel approach to enhancing fairness in GNNs by applying Lipschitz bounds, which is a well-established stabilization method in other neural network domains.\n2. The method is practical and can be integrated into existing GNN training workflows with minimal overhead, leveraging automatic differentiation.\n3. Provides both theoretical validation and empirical results that demonstrate the effectiveness of the method on standard graph-based tasks.", "Weaknesses": "1. While the concept of applying Lipschitz bounds to control GNN output is novel, the paper could have explored more diverse datasets beyond standard node classification and link prediction tasks to thoroughly test the robustness of the method.\n2. The presentation could be improved with clearer explanations on how Lipschitz bounds specifically enhance fairness and the choice of metrics used to evaluate this.\n3. The theoretical aspects might be challenging to grasp for readers not deeply familiar with differential matrix calculus.", "Questions": "1. How does the selection of datasets affect the observed efficacy of applying Lipschitz bounds in GNN training?\n2. Could the method be extended or adapted to incorporate additional fairness metrics, and if so, how?\n3. Are there any known limitations or scenarios where applying such Lipschitz constraints might inadvertently reduce performance on other GNN attributes like interpretability or complexity?"}}
{"paper_id": "RlfD5cE1ep", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper extends existing dynamic analyses of non-contrastive learning by incorporating feature normalization effects, providing a novel perspective on how cosine loss impacts learning dynamics.\n2. It offers a theoretical understanding that bridges a gap in the literature regarding the stability of non-contrastive methods in practical applications where normalization is used.\n3. The methodology includes both theoretical analysis and empirical validation using synthetic data and experiments with CIFAR-10, strengthening the findings.", "Weaknesses": "1. The paper could improve in its discussion of prior work, particularly regarding recent contributions that have also explored dynamics of non-contrastive methods with normalization.\n2. The experimental validation, while helpful, is limited to relatively simple settings and does not extensively explore more complex or varied data scenarios or architectures beyond ResNet-18.\n3. There's a lack of exploration of any potential limitations or failure cases of the proposed theoretical framework in practical settings.", "Questions": "1. How does the introduction of feature normalization and the associated higher-order dynamics specifically influence real-world applications? Are there scenarios where this effect is negligible or counterproductive?\n2. Can the theoretical framework proposed be generalized to other forms of loss or learning setups beyond the cosine loss in non-contrastive representations?\n3. What are the computational implications of the sixth-order dynamics introduced by cosine loss relative to the third-order dynamics of L2 loss?"}}
{"paper_id": "18TfucMNTr", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper effectively introduces and applies a continuation method to address non-convex optimization challenges in training deep networks. It provides empirical results that demonstrate improved training outcomes with reduced variability and enhanced convergence speed.", "Weaknesses": "The empirical evaluation may be limited to relatively simple datasets like MNIST, which might not fully demonstrate the method's effectiveness on more complex tasks. Additionally, the choice of specific methodologies and parameters requires further justification and exploration.", "Questions": "To better understand the proposed method's applicability, can it be extended to more complex neural network architectures and larger datasets beyond MNIST? What are the trade-offs or potential limitations when scaling this method to more challenging scenarios?"}}
{"paper_id": "JGTC6WgO4T", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper addresses a relevant problem in domain adaptation by proposing a novel framework that leverages multiple source domains for pseudo-label refinement.\n2. The method is both theoretically motivated and empirically validated across multiple benchmark datasets.\n3. The framework enables more effective target domain adaptation without direct access to source data or models, addressing privacy and security concerns.", "Weaknesses": "1. The approach, while innovative, could face challenges in practical scenarios where the statistical relationships between the sources and the target may not be straightforward or well-defined.\n2. The reliance on pseudo labels means the framework's performance might degrade if the pseudo labels are not accurate, potentially affecting its robustness.\n3. Limited information is provided on the computational complexity and scalability of the Pseudo-label Refinery Network (PRN) when applied to larger datasets or domains.", "Questions": "1. How does the PRN handle variations in the number and nature of source domains, especially with highly diverse or poorly correlated domains?\n2. Can the proposed method be adapted to scenarios where new sources are introduced incrementally during training?\n3. Is there any specific mechanism to evaluate the quality of the pseudo labels before using them in the adaptation framework?"}}
{"paper_id": "fQHb1uZzl7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper effectively integrates feature and cost aggregation for dense matching tasks, presenting a novel Transformer-based architecture that significantly improves performance. The hierarchical approach and multi-scale predictions enhance robustness and accuracy in challenging conditions.", "Weaknesses": "The approach may require further validation in different practical scenarios to assess its generalization ability. The reliance on combined aggregation may not be easily extensible to tasks with smaller overlapping regions.", "Questions": "How does the proposed method perform on datasets with limited or minimal overlap between images, particularly in terms of maintaining robust correspondence?"}}
{"paper_id": "YjG29CIOP7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The introduction of TEAPOT and ROSY demonstrates a novel approach to address key vulnerabilities in data-free meta-learning. The combination of memory-based strategy and reinforcement learning for model selection provides robustness against task-distribution shifts and corruptions. Extensive experiments validate the effectiveness of the approach.", "Weaknesses": "The practical applicability of ROSY may be constrained by computational complexity associated with reinforcement learning in real-world scenarios. It remains unclear if simpler, less resource-intensive methods could provide similar robustness enhancements.", "Questions": "How does the computational overhead of the ROSY model selection policy compare to simpler baseline methods? Are there specific scenarios where the method's effectiveness might be limited?"}}
{"paper_id": "DmDpu3r8iU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 5, "Confidence": 3, "Strengths": "1. The paper addresses a critical and timely issue concerning the alignment of LLMs with human values, which is pivotal for their safe deployment.\n2. It proposes a novel framework, VUM, to measure value understanding in LLMs, which advances beyond existing methods that mainly focus on ethical perspectives without deeper understanding of values.\n3. The study methodically uses the Schwartz Value Survey along with a discriminator-critique gap approach, providing a comprehensive evaluation mechanism.", "Weaknesses": "1. The claim that scaling laws significantly impact 'know what' but not 'know why' requires more robust evidence and analysis, given that there is limited detail on model specifics like training data, sizes, and architecture.\n2. There is some ambiguity in the implementation details, such as how various prompts are integrated or evaluated within the framework, which affects replicability and clarity.\n3. The assessment of LLMs' 'know why' capabilities relying significantly on GPT-4 annotations may lead to over-reliance on automated evaluations without sufficient human benchmarking.", "Questions": "1. Can the authors provide more details on the human study mentioned in Appendix B.2, such as the methodology and results, to bolster the findings on LLMs' 'know why' capabilities?\n2. How well does the VUM framework generalize across different LLM architectures and training regimes? Are there limitations observed when applying this framework to non-GPT models?\n3. Could the results for models' 'know what' and 'know why' performance be influenced by the specific selection of values from the Schwartz Value Survey? How do these choices impact the generalizability of the findings?"}}
{"paper_id": "kXHEBK9uAY", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The introduction of hierarchical planning into diffusion models is an innovative approach that addresses the inefficiencies seen in traditional diffusion-based generative methods.\n2. The method demonstrates empirical success, outperforming non-hierarchical and other hierarchical planning methods by improving training and planning speeds and generalizing better to compositional out-of-distribution tasks.\n3. The division of high-level and low-level diffusers, with the strategic use of subgoals, creates a scalable framework capable of handling long-horizon tasks.", "Weaknesses": "1. While the hierarchical approach is promising, the paper lacks a detailed ablation study assessing the contribution of each component of the Hierarchical Diffuser.\n2. The approach might face challenges in cases with undefined or vague subgoals, potentially affecting efficacy and generalizability.\n3. The implementation details and computational requirements of the method are not extensively discussed, leaving questions about its feasibility for diverse applications.", "Questions": "1. How does the Hierarchical Diffuser specifically manage subgoal creation in tasks with inherent uncertainty or ambiguity in goal definition?\n2. What are the computational trade-offs in employing two separate diffusers compared to existing methods, and how scalable is this approach in terms of complexity and resource requirements?\n3. Can the methodology be effectively applied or extended to real-world scenarios, particularly those with dynamic environments or adaptable objectives?"}}
{"paper_id": "i7LCsDMcZ4", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces novel methodologies (SLTRP and SLRP) adapted specifically for Spiking Neural Networks, which address a critical gap in saliency map generation. The combination of these methods with data augmentation techniques, RPGDrop and RPGMix, enhances the generalization capability of SNNs and sets a new state-of-the-art performance in various tasks. The integration of traditional augmentation techniques is also a well-rounded approach to achieve robustness.\nThe use of biologically inspired components such as event cameras and SNNs, together with advanced computational techniques, presents a meaningful contribution to both neuroscience-inspired computing and machine learning.", "Weaknesses": "The contribution, while innovative, is currently limited to classification tasks. The scope of EventRPG could be expanded to be applicable beyond classification tasks to increase its impact. Additionally, the evaluation is limited to a number of datasets; expanding the evaluation to more and varied datasets could provide further evidence of the method's generalization capabilities. The computational demands and efficiency across different hardware platforms could have been discussed more comprehensively to provide insights into real-world applicability.", "Questions": "Could the methods presented (SLTRP, SLRP, RPGDrop, RPGMix) be adapted for use in neural network types other than SNNs or tasks beyond classification? Are there specific limitations posed by the methods that restrict their application to SNNs or classification tasks? How do these methods perform in real-time scenarios or under dynamic conditions that are typical for event-based sensing?"}}
{"paper_id": "jHdz0CIS2y", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents an innovative approach to voice conversion using entangled speech representations, improving zero-shot voice conversion capabilities. The self-synthesized examples as a part of the iterative training strategy contribute to the model's robustness, allowing it to achieve significant improvements over existing baselines. The model's applicability across different languages without reliance on text makes it versatile for various tasks.", "Weaknesses": "The reliance on existing methodologies like self-supervised learning and speaker verification might limit the novelty of the approach. Although the method shows improved results, it remains unclear how critical the self-synthesized examples are or how they specifically enhance the training process. There is also limited discussion on possible limitations when scaling to more diverse datasets or real-world scenarios.", "Questions": "How does the system perform in more complex voice conversion scenarios involving significant background noise or more diverse accents? Are there any insights or benchmarks against entirely different frameworks that do not rely on self-supervised learning components?"}}
{"paper_id": "NkYCuGM7E2", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. Innovative integration of Large Language Models (LLMs) in autonomous driving, which enhances decision-making capabilities and interpretability. \n2. The proposed system shows improvement in handling complex driving tasks, illustrating the potential of LLMs in improving safety and adaptability in realistic scenarios. \n3. The cognitive pathway framework and chain-of-thought processes provide a systematic approach that mimics human-like reasoning in AD systems.", "Weaknesses": "1. The paper might not fully address the potential limitations and challenges of implementing LLMs in real-time environments, such as computational overhead and response times. \n2. Further clarity is needed on how the system handles edge cases or fails gracefully, especially under real-world conditions. \n3. The dependency on language-based reasoning could be limiting in scenarios that require real-time processing speed to ensure safety.", "Questions": "1. How does the proposed method address the potential computational delays associated with running LLMs in real-time autonomous driving scenarios?\n2. What are the mechanisms in place to ensure consistent and fail-safe decision-making, especially in dynamic and rapidly changing environments?\n3. Is there any discussion on the ethical implications and trustworthiness of decisions made by AI in safety-critical applications like autonomous driving?"}}
{"paper_id": "RtDok9eS3s", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "- The paper addresses an important aspect of deep learning architectures by simplifying the Transformer blocks, which are widely used in various applications.\n- The study shows that it is possible to maintain performance while achieving significant improvements in training throughput and parameter reduction.\n- The study is backed by empirical results on both decoder-only and encoder-only models, demonstrating the applicability of the proposed simplifications across different model architectures.", "Weaknesses": "- The simplifications and results have been demonstrated primarily on smaller-scale models and may not directly transfer to larger state-of-the-art models in practical use.\n- The specific design choices and the interplay between them could be further explained, particularly how certain components interact to ensure performance is maintained.\n- The experimental evaluation could be more comprehensive, covering a wider range of tasks beyond the datasets considered to validate the generality of the findings.", "Questions": "- How well do the simplified Transformer blocks perform on larger, more complex datasets and more substantial model architectures?\n- Can the proposed simplifications be integrated with other Transformer improvements, such as those targeting attention mechanisms or alternative architectures?\n- What are the implications of these simplifications on tasks beyond language modeling, such as those in vision or multimodal domains?\n- Are there potential drawbacks of the simplification concerning the model's capacity to capture complex patterns in data?"}}
{"paper_id": "YCPDFfmkFr", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The approach addresses the problem of infeasibility in QP layers, which can be a significant limitation in neural network design.\n2. The paper proposes a novel method using augmented Lagrangian techniques to differentiate through infeasible QPs, expanding the capabilities of QP layers.\n3. A practical implementation with the QPLayer package that interfaces with common frameworks, showing robust and efficient results in numerical experiments.", "Weaknesses": "1. The presentation could benefit from more clarity and detail on the mathematical underpinnings of the proposed method.\n2. While the proposed method is innovative, the paper could include more extensive comparisons with existing methods, including potential drawbacks or limitations.\n3. The reliance on augmented Lagrangian techniques may introduce complexity in certain scenarios which the paper does not fully address.", "Questions": "1. How does the proposed ECJ framework compare in computational complexity to traditional methods when dealing with large-scale QP layers?\n2. Are there specific domains or types of neural network architectures where the proposed method might face challenges or limitations?\n3. Can the QPLayer package be easily integrated into existing neural network training pipelines, and what support is provided for users implementing it?"}}
{"paper_id": "ueTdErd5Ib", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The method proposes an integrated approach to contextual stochastic optimization, enhancing robustness against uncertainty, which is a critical aspect in real-world applications.\n2. Theoretical guarantees are provided, bounding the regret of decisions, which adds soundness to the approach.\n3. Experimental validation, including a real-world electricity generation problem, demonstrates the effectiveness of the method in reducing worst-case costs.", "Weaknesses": "1. The presentation might lack clarity in explaining the complex methodology and the theoretical aspects, which could limit accessibility for readers not deeply familiar with the topic.\n2. The dependence on discretizing the feasible region might limit the method's scalability or applicability to problems with large or continuous feasible spaces.", "Questions": "1. How does the method scale with larger datasets or different types of uncertainties? \n2. Are there any limitations in the types of contextual information or distributions that can be effectively handled with this approach?"}}
{"paper_id": "sDmjlpphdB", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The Mixture-of-Prompts framework significantly improves performance on benchmark tasks by splitting tasks into specialized experts, showcasing potential in dynamic prompt generation.\n2. The approach introduces a novel way of combining instruction and demonstration prompts, leveraging their respective strengths for enhancing LLM capabilities.", "Weaknesses": "1. The methodology depends heavily on effective clustering of demonstrations into homogeneous regions, which may not always accurately reflect real-world data characteristics.\n2. The assumption that clustering can effectively divide problem spaces into distinct regions could be problematic, especially if task characteristics are not easily separable or the chosen method influences cluster quality.", "Questions": "1. How robust is the MoP method to changes in the initial parameters or clustering methods? Are there specific scenarios where its performance is significantly affected?\n2. Can the approach be generalized beyond the tested NLP benchmark tasks, or does it require adjustments to remain effective in different application domains or modalities?"}}
{"paper_id": "Mdk7YP52V3", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper develops a theoretical framework to understand the failure modes of overparameterized heteroskedastic regression models, which is a significant contribution to the field. The use of a field-theoretical approach from statistical physics to study these models is innovative and provides new insights into their behaviors. The authors successfully validate their framework experimentally, demonstrating its practical relevance. The findings related to phase transitions and regularization strategies are potentially very impactful.", "Weaknesses": "While the theoretical insights are strong, the paper may be quite complex and challenging to follow for readers not familiar with field theory and statistical physics concepts. The empirical validation, although present, might not cover all potential applications of the theory, and the proposed regularization strategies could require further exploration to assess their efficacy across diverse datasets and neural network architectures.", "Questions": "1. Can the proposed NFE framework and insights about regularization be extended to other types of probabilistic models beyond heteroskedastic regression?\n2. How sensitive are the phase transition observations and regularization strategies to variations in the model's architecture and the nature of the data?\n3. What specific challenges might arise when applying the proposed regularization strategies in large-scale real-world datasets?"}}
{"paper_id": "YGTSLDAPqb", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "This paper addresses a critical issue in machine learning domain adaptation, focusing on OOD scenarios where traditional fine-tuning methods fall short. The introduction of the 'Connect Later' framework offers a novel approach by using targeted augmentations to fine-tune models after self-supervised pretraining, yielding significant improvements in benchmarks across various datasets. The study's methodology is well-validated, showcasing impressive performance boosts in benchmarks such as AstroClassification and Redshift regression tasks, indicating the applicability and potential of their approach across different real-world applications.", "Weaknesses": "Despite the promising results, there is a lack of clarity on how well the findings can be generalized beyond the specific tasks and datasets tested. Additionally, while the framework improves OOD metrics, the paper does not extensively explore the underlying reasons behind these improvements, particularly in relation to the choice and design of targeted augmentations. Furthermore, comparisons between different pretraining strategies are not thoroughly addressed, which limits understanding of how various self-supervised techniques might interact with the proposed fine-tuning method.", "Questions": "How were the targeted augmentations crafted for each dataset, and is there a systematic way to design these for new datasets? Additionally, can this method be applied to domains where the distribution shifts are more complex or not well understood? How does the performance of the Connect Later framework compare if generic data augmentations are used during the fine-tuning phase instead of targeted ones?"}}
{"paper_id": "JTcaziw7G1", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The proposed PRAG system effectively addresses the gap in maintaining the privacy of queries and data during retrieval, which is crucial for privacy preservation in LLMs. The method is theoretically sound, leveraging multi-party computation techniques to ensure secure interactions across distributed servers without revealing sensitive information. The use of synthetic and real datasets for evaluation demonstrates the practical applicability of the approach.", "Weaknesses": "The computational complexity of the proposed method is still a concern, suggesting a trade-off between privacy and computational cost that may limit practicality in some settings. Further optimization is required to make the solution more feasible for large-scale applications. The presentation could benefit from clearer explanations of the novel protocol for IVF used, and more concrete comparisons with existing methods in terms of execution time and resource requirements.", "Questions": "How does the computational overhead of the proposed PRAG system compare to existing privacy-preserving retrieval methods on average-sized and large databases? What specific optimizations could be explored to reduce the computational cost while maintaining the same level of privacy? Are there scenarios or data distributions where the PRAG system might not perform optimally, and if so, how can those be addressed?"}}
{"paper_id": "lEkFq4RUCX", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The proposed DDF metric introduces a novel approach to measure differences between 3D point clouds by focusing on underlying surface differences rather than point-wise correspondences. \n2. The DDF metric significantly improves accuracy and computational efficiency in several 3D tasks such as shape reconstruction, rigid registration, and feature representation.\n3. The approach has shown to be memory-efficient and provides a more robust alternative to traditional methods like EMD and CD.", "Weaknesses": "1. The paper lacks detailed explanations on how the reference points are generated and may not be clear to all readers.\n2. While promising, the DDF metric's implications on practical applications outside the tested scenarios need further exploration and validation.\n3. The method's effectiveness relies heavily on the selection and distribution of reference points, which might limit its applicability in highly irregular or sparse point clouds.", "Questions": "1. How does the choice and placement of reference points affect the performance of the DDF metric in various scenarios?\n2. Can the DDF method be extended or adapted for use in highly irregular or non-uniformly sampled 3D point clouds?\n3. Are there specific types of 3D point cloud structures or scenarios where DDF does not perform as well compared to traditional metrics?"}}
{"paper_id": "Fq8tKtjACC", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The approach significantly reduces computational resources while achieving state-of-the-art performance, showcasing the importance of data quality over quantity. This could influence future research directions in training language models. The method is well-documented, not only showing substantial quantitative results but also presenting a novel aspect of leveraging 'textbook quality' data.", "Weaknesses": "The model shows specialization in Python and sensitivity to prompt variations, which limits its versatility across different programming tasks and might affect performance consistency.", "Questions": "Could the approach be generalized to other programming languages, or is it inherently tailored to Python? How does the model handle polyglot programming code or code that mixes different languages?"}}
{"paper_id": "8fQlGQkj0S", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a novel theoretical framework that distinguishes between task learning and task retrieval in in-context learning, which is a valuable contribution to understanding large language models' behavior. The use of generative models, specifically the Gaussian mixture model, provides a solid basis for analyzing task diversity and deriving risk upper bounds.", "Weaknesses": "The reliance on the Gaussian mixture model may oversimplify the properties and complexities of actual pretraining distributions and in-context learning scenarios. The clarity of the presentation could be improved, as some of the theoretical derivations and concepts might be hard to follow for a broader audience. Additionally, the paper's novelty might be questioned since the separation of task learning and retrieval has been an area of interest in the community.", "Questions": "How does the proposed theoretical framework compare to other existing frameworks that analyze task learning and retrieval in terms of practical applicability and predictive performance? Is the Gaussian mixture model assumption limiting, and if so, how could it potentially be extended to more accurately capture the complexities of real-world data distributions?"}}
{"paper_id": "hRos9WldRK", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper provides a new approach, Learning to Bootstrap (L2B), that does not depend on explicit assumptions about noise or require a clean validation set, which is a notable advantage in handling label noise.\n2. Extensive experiments demonstrate the method's robustness and effectiveness across multiple datasets, highlighting its ability to generalize well.", "Weaknesses": "1. The reliance on a validation set to adjust weights raises questions about the method's practical applicability, especially in scenarios where such a set might not be available.\n2. The method's performance heavily depends on effective pseudo-labeling, which could be challenging in environments with extreme levels of noise or in less structured domains.", "Questions": "1. How does the L2B method perform in real-world noisy data scenarios outside of the tested datasets, particularly in non-image domains?\n2. Could further explanation be provided regarding how pseudo-labels are generated and validated during the training process to ensure quality without a clean validation set?"}}
{"paper_id": "ttRSBZiCiu", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. WaveFluid introduces a novel approach to speech synthesis by learning a velocity field, which improves efficiency and reduces computational overhead.\n2. The model achieves competitive high-fidelity audio synthesis with only one inference step, addressing a key limitation of diffusion models.\n3. The modular design and use of adversarial training enhance model adaptability and performance improvements.", "Weaknesses": "1. The paper lacks a comprehensive comparison with all state-of-the-art methods, particularly the latest GAN-based vocoders.\n2. There is limited discussion on the generalization of WaveFluid beyond the specific task of mel-spectrogram to audio synthesis.\n3. The reliance on adversarial training can introduce instability and make training sensitive to hyperparameter choices.", "Questions": "1. How does the model perform on synthesis tasks beyond mel-spectrogram to audio conversion?\n2. Have any stability issues been observed during adversarial training in WaveFluid?\n3. Could the approach of learning a velocity field be extended to other generative tasks outside of audio synthesis?"}}
{"paper_id": "WYsLU5TEEo", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper presents a novel approach that combines interpretability and robustness in neural networks, addressing two critical issues simultaneously with a unified framework. \n2. The proposed method shows improved performance in terms of interpretability through competitive IoU scores and robustness against adversarial attacks compared to traditional classifiers. \n3. The methodology has practical significance, potentially improving the reliability and trustworthiness of neural networks in sensitive applications such as medical diagnosis.", "Weaknesses": "1. The approach largely focuses on binary classification, which may limit its applicability in more complex scenarios involving multiple classes. \n2. The paper could benefit from a more extensive evaluation, including comparisons with state-of-the-art counterfactual generation and adversarial robustness techniques to better position its contributions. \n3. While the cycle-consistent loss term and specialized architectures contribute to improved performance, the specifics of these components and their exact impact on the results are not fully detailed, which may affect reproducibility.", "Questions": "1. How does the approach extend to multiclass classification problems? Are there inherent limitations in scaling the method to more complex classification tasks? \n2. Can the discriminator's output reliably measure prediction uncertainty across different datasets, or is this a dataset-specific feature? \n3. How sensitive is the proposed method to changes in the architecture of the GAN components, and are there best practices for selecting these architectures?"}}
{"paper_id": "KKZaj2QS3G", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper presents a novel approach for unsupervised time series representation learning using a noise-resilient sampling strategy and an effective encoder design.\n2. The framework outperforms state-of-the-art methods across benchmarks, showcasing its scalability and robustness.\n3. The method's architecture is designed to be parameter-efficient, facilitating scalability.\n4. The paper is well-structured and clearly articulated, with thorough experimental evaluations showing the method's effectiveness.", "Weaknesses": "1. The paper does not sufficiently address potential limitations or edge cases where the CoInception approach may not perform well.\n2. The novelty of employing a noise-resilient sampling strategy based on a low-pass filter is somewhat limited, as it is a well-established concept in signal processing.\n3. Clarity could be improved on how the hierarchical triplet loss specifically contributes to noise resilience, particularly in quantitative comparisons to simpler loss functions.", "Questions": "1. How does CoInception compare to classical signal processing methods that also employ spectral analysis with low-pass filters in terms of performance and computational efficiency?\n2. Can the authors provide more insights into the selection of hyperparameters, particularly those relevant to the noise-resilient sampling strategy?\n3. How sensitive is the method to different types of noise, and does it maintain robustness across varying noise levels?"}}
{"paper_id": "LWDRiFzbHQ", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses a significant challenge in OOD generalization assessment by proposing a novel approach (Vicinal Risk Proxy) that considers neighboring test sample responses.\n2. The introduced VRP method improves the robustness and accuracy of risk proxies for OOD scenarios, demonstrated through experiments across multiple datasets.\n3. The presentation is clear and well-structured, making the methodology comprehensible.\n4. The method has practical implications as it can be applied without the need for ground truth labels, thus reducing the cost associated with label acquisition in real-world applications.", "Weaknesses": "1. The reliance on neighboring test samples assumes the existence of sufficiently relevant neighbors in the test set, which might not always be the case.\n2. The generalization of VRP across diverse datasets or transferability to unseen types of shifts is not thoroughly explored in the paper.\n3. The paper does not fully investigate the computational overhead introduced by the VRP calculation, which may impact its applicability to large-scale scenarios.", "Questions": "1. How well does the VRP approach perform when there is a significant domain shift between training and test data, where the vicinal space may not be accurately defined?\n2. Could the VRP method be integrated with existing ensemble techniques to further enhance OOD generalization assessment?\n3. Are there specific characteristics of datasets where the VRP method performs particularly well or poorly?"}}
{"paper_id": "Yp01vcQSNl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "DiGT leverages a novel attention mechanism to incorporate edge directionality, which is crucial for directed graph tasks. The method shows significant performance improvements over state-of-the-art models on directed graph datasets, highlighting its effectiveness. The introduction of dual encodings and interpretable attention matrices adds to its innovation.", "Weaknesses": "The method may rely heavily on the assumption that edge directionality is always crucial, which might limit its generalizability to graphs where directionality is less important. Additionally, the need for k-hop neighborhood localization and masking may complicate the model's implementation and computational efficiency.", "Questions": "How does the performance of DiGT compare on undirected graphs, and is there a mechanism to adapt it to scenarios where directionality is less significant? What are the computational overheads introduced by the k-hop localization and dual encodings?"}}
{"paper_id": "LndMyiBl3n", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses an important problem in the context of adversarial attacks on Graph Neural Networks, providing a novel approach that does not rely on the common assumptions of previous models, such as homophily.\n2. SheAttack is designed to function effectively across both homophilic and heterophilic graphs and is shown to be scalable and efficient under the black-box setting.\n3. The use of Modified Silhouette Score to guide attacks is both innovative and a significant improvement over existing methods, providing a generalized approach to enhance attack strategies.", "Weaknesses": "1. The paper could further clarify the mechanisms of the proposed method. While MSS is a novel approach, the paper does not provide in-depth theoretical analyses or insights into its application beyond empirical results, which could strengthen its contribution.\n2. The scalability and efficiency claims, while demonstrated with experimental results, would benefit from clear comparative computational complexity analyses against existing methods.\n3. The presentation, while acceptable, could be improved in terms of clarity and accessibility, especially regarding the explanation of the Modified Silhouette Score and the optimization process employed by SheAttack.", "Questions": "1. How does the selection of parameters in the Modified Silhouette Score impact the performance of SheAttack, particularly in graphs with different properties?\n2. Can the proposed method be extended or adapted to work with different categories of graph embeddings or attack scenarios beyond the ones discussed?\n3. How does SheAttack compare in performance and efficiency to state-of-the-art methods in scenarios with varying degrees of partial or noisy knowledge of graph properties?"}}
