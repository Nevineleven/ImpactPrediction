{"paper_id": "u3xwwfHmBC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The approach introduces an innovative way to handle spatio-temporal dependencies in traffic forecasting using tense-specific attention modules, which is novel and demonstrates improved performance over baseline models.\n2. The paper effectively presents a method to integrate contrastive learning techniques to enhance model robustness against incomplete data, which is a significant challenge in real-world applications.\n3. Empirical results on standard datasets show that the proposed method significantly outperforms existing models, demonstrating the practical efficacy of the approach.", "Weaknesses": "1. The paper could benefit from more detailed theoretical analysis to reinforce the empirical claims and provide deeper insight into why the proposed tense-specific attention modules improve model performance.\n2. There is limited discussion regarding the computational efficiency of the proposed model. The introduction of multiple tense-specific modules could increase computational complexity, which is not addressed.\n3. The contrastive learning approach and its impact on the model's performance are not thoroughly evaluated, leaving questions about its contribution relative to the tense-specific attention modules.", "Questions": "1. Could the authors provide more details on the contrastive learning approach and its specific role in handling incomplete data?\n2. What is the computational cost of the proposed TTformer model compared to baseline models, particularly in terms of training time and resource requirements?\n3. How does the choice of tense-specific modules scale with larger or more complex datasets, and are there potential limitations in terms of scalability?"}}
{"paper_id": "YKvBiRWdQC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper identifies and addresses a crucial gap in the current evaluation of reinforcement learning agents for their generalization capabilities in cooperative contexts. \n2. The introduction of the Overcooked Generalisation Challenge (OGC) represents a significant contribution towards understanding and improving zero-shot cooperation in RL agents.\n3. The use of innovative neural network architectures and a variety of DCD methods provides rich insight into the complexity and potential of the problem space.", "Weaknesses": "1. The paper does not include a detailed breakdown of how the proposed methods perform on individual unseen layouts, potentially missing insights into specific challenges faced by agents.\n2. Fails to fully explore the depth of Overcooked environments by limiting the game to a single recipe, which may overlook important aspects of coordination and impact the depth of the evaluation.\n3. Some minor presentation issues such as unexplained baselines (e.g., Random and Stay) and not fully clarifying the observation space.\n4. There is a question of whether the observed challenges in generalization are due to limitations in the UED algorithms or insufficient training regimes, which is not clearly analyzed.", "Questions": "1. Can the proposed challenge isolate partner generalization from environment generalization to specifically test challenges in partner variability?\n2. How does the limitation of single-recipe scenarios impact the proposed challenge's applicability to broader real-world human-AI collaboration tasks? Would including multiple recipes change the results?"}}
{"paper_id": "tePFpDgyqg", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The idea of leveraging natural referral relationships such as hyperlinks to construct long documents is innovative and appears to substantially improve the quality of pretraining data for LLMs.\n2. The LongPack method demonstrates considerable improvement over past methods, achieving a 32.7% higher performance, highlighting its effectiveness.\n3. The approach provides a scalable solution, demonstrating efficient construction of long documents, which is a significant stride towards better long-context comprehension in LLMs.", "Weaknesses": "1. The scope of LongPack is limited to documents where natural referral signals are available, such as web pages. It is unclear how this might translate to other domains lacking such explicit relationships.\n2. While the method shows improvement, the paper lacks extensive ablation studies to robustly analyze the contribution of different components within LongPack.\n3. The novelty of the methodology is potentially limited, as it builds on existing concepts of using document links or referrals, albeit in a more structured manner.", "Questions": "1. How well does LongPack perform in domains that lack explicit referral signals like hyperlinks, such as literary texts or transcriptions?\n2. Can the concept of LongPack be extended beyond web-based documents to academic papers or research articles where citations could act as referral relationships?\n3. Are there potential drawbacks or limitations when scaling the LongPack method to even larger datasets, and how might these be mitigated?"}}
{"paper_id": "gx3LMRB15C", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a novel augmentation-free self-supervised learning method for tabular data, a challenging area where existing SSL techniques often struggle.\n2. T-JEPA demonstrates significant improvements over traditional methods, including Gradient Boosted Decision Trees, in classification and regression tasks.\n3. The method effectively identifies relevant features without needing labels, showcasing a strong practical potential for real-world applications.", "Weaknesses": "1. The paper relies heavily on the introduction of regularization tokens, which may raise questions about the complexity and potential overfitting of the model.\n2. While the results are promising, the model's generalizability across diverse tabular datasets needs further validation.\n3. The explanation of the joint embedding predictive architecture (JEPA) and how it specifically applies to tabular data could be more detailed for complete clarity.", "Questions": "1. How does T-JEPA handle cases where tabular data contains missing values, which is a common scenario in many real-world datasets?\n2. Could the authors elaborate on how the context and target masks are specifically constructed to ensure effectiveness across different types of tabular data?\n3. What are the implications of using regularization tokens with respect to the interpretability of the learned representations?"}}
{"paper_id": "kTH3bEH6hW", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel range-limited augmentation method specifically tailored for tabular data, addressing a significant challenge in few-shot learning by preserving task-relevant information. The approach is demonstrated to outperform existing tabular learning methods across various scenarios, which highlights the effectiveness of the proposed strategy. Additionally, the comprehensive evaluation using a large benchmark of 42 tabular datasets strengthens the paper's contributions.", "Weaknesses": "The method may have limited applicability beyond tabular data, as the proposed range-limited augmentation is specifically designed for such data types. Furthermore, the paper may lack details on how certain feature-specific ranges are determined, which could be crucial for replicating and effectively applying the method in practice. The practical implementation details and the sensitivity of the method to different parameter settings could use further elaboration.", "Questions": "What specific guidelines or heuristics are used to define the feature-specific ranges, and how sensitive is the method to the choice of these ranges? Are there any generalization strategies proposed to adapt this method to other types of data beyond tabular domains?"}}
{"paper_id": "EqcLAU6gyU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper presents a novel framework for agent-oriented planning in multi-agent systems, addressing significant gaps related to solvability, completeness, and non-redundancy in task decomposition and allocation.\n2. The use of an LLM-powered meta-agent to guide task decomposition and allocation is innovative and shows promising results in experiments.\n3. Integration of feedback loops and reward models to continuously improve the planning framework creates a robust mechanism for enhancing efficiency and problem-solving capabilities.", "Weaknesses": "1. The framework's reliance on large language models may limit its applicability in scenarios where such resources are unavailable or impractical.\n2. There is a need for more extensive experimental validation across diverse datasets to substantiate claims of real-world applicability.\n3. The paper could benefit from clearer explanations in some sections, especially concerning the operation and integration of the reward model and detector components.", "Questions": "1. How does the framework handle failures within the individual agents? Does it allow for dynamic reassignment or redundancy checks?\n2. Can the framework be extended to incorporate other forms of meta-agents beyond those powered by large language models?\n3. How do different configurations or intricacies of the reward model influence the outcomes of task evaluation and meta-agent updates?"}}
{"paper_id": "qrTrnrEi9d", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes an innovative method, TransFusion, that effectively enhances the performance of instruction-tuned LLMs for low-resource languages by leveraging translations.\nThe method shows significant improvement in information extraction tasks across a range of multilingual datasets, providing a clear performance boost over existing methods.", "Weaknesses": "The paper's explanation could be clearer, as the method requires thorough reading to be fully understood.\nWhile the method's flexibility is a strength, the implementation differences in its various configurations may cause confusion regarding consistency and universality.", "Questions": "How can the method be adapted or improved for languages with even fewer resources available, both in terms of annotated and unannotated texts?\nWhat are the trade-offs in terms of computational cost when using machine translation and annotation fusion techniques in practice?"}}
{"paper_id": "Bp0HBaMNRl", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The method presented is a significant advancement in causal discovery by incorporating nonlinear latent hierarchical models without deterministic assumptions, making it highly applicable to real-world scenarios. The authors also provide strong theoretical identifiability results, which bolster the robustness of their approach. The experiments demonstrate superior performance over existing methods on challenging datasets, highlighting the method's accuracy and scalability.", "Weaknesses": "While the paper presents an impressive method, the complexity of the approach utilizing variational autoencoders and continuous optimizations might limit accessibility to researchers not specialized in these areas. Additionally, the experiments, while extensive on synthetic data, could benefit from further validation on a more diverse range of real-world datasets to showcase broad applicability and adaptability.", "Questions": "How does the proposed method perform on datasets with more complex relational structures beyond MNIST, especially in contexts that may not inherently have a clear hierarchical latent structure? Are there any computational constraints or limitations, given the use of VAE and Gumbel-softmax, when scaling to very large datasets?"}}
{"paper_id": "JzLcKWtGnl", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The proposed Spatial 3D-LLM method effectively enhances existing models by introducing a progressive spatial awareness scheme. This method demonstrates considerable improvements in tasks requiring spatial reasoning and detailed 3D perception, as shown by experiments using the new MODLE dataset. The integration of graph convolutional networks and attention mechanisms is innovative and well-suited for enriching spatial embeddings.", "Weaknesses": "The methodology may not fully address the challenge of performing a quantitative comparison with existing state-of-the-art models, particularly in terms of fine-grained spatial understanding. Additionally, the new dataset MODLE, while beneficial, may not fully test the model's capabilities without comparisons to stronger baselines.", "Questions": "1. Are there plans to make the MODLE dataset publicly available for further validation and comparative studies?\n2. How does the Spatial 3D-LLM perform in comparison with other models that specifically focus on fine-grained spatial reasoning in 3D environments?"}}
{"paper_id": "hXJrQWIoR3", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper addresses an important gap in the field of explainable graph representation learning by focusing on representation-level explainability, which is less explored compared to model-level and instance-level explanations. The proposed methods are backed by both theoretical analysis and empirical validation on real-world datasets, demonstrating robustness and generalization benefits.", "Weaknesses": "The paper could benefit from more in-depth comparisons with existing approaches in explainable AI for graph data, particularly in terms of visualization and interpretability aspects. Additionally, more details on the implementation and time complexity of the proposed methods would provide useful insights.", "Questions": "How does the proposed method perform relative to state-of-the-art explainability techniques for graphs in terms of interpretability and computational efficiency? Can the authors provide more details on how pattern importance is quantified and its effect on the robustness of the representations?"}}
{"paper_id": "67sSPPAZiG", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The authors curate a large-scale dataset with over 7 million QA samples for egocentric videos of varying lengths and introduce a QA benchmark called EgoMemoria, which contains 7,026 questions for 629 videos of different lengths. \n\n2. A specialized multimodal architecture is proposed, using a \"Memory Pointer Prompting\" mechanism. This includes a global glimpse step for overarching video understanding and a fallback step that uses key visual information to generate responses, enabling the model to comprehend extended video content more effectively.", "Weaknesses": "1. The first claim of contribution, the “narration to egocentric QA” data pipeline, I believe, should not be emphasized as a major contribution. This type of generating QA from dense captions have been used in multiple previous works, from the non-LLM era (like TVQA) to the LLM era (like LLama-VID). I believe it is better to tone down this statement.\n2. The generated EgoMemoria Benchmark does not stands itself out of many long video understanding benchmarks. Even we narrow down to only egocentric videos, the GroundVQA dataset is also good to be compared and especially be used to test the MMEgo model. I would also recommend the authors to compare a long of long video datasets, providing more proofs that this benchmark is not so incremental.\n\nOverall, I think this paper is proposing a good model, while the benchmark side is relatively weak. I would recommend the authors to either tone down the benchmark in the paper to put more emphasize on this model, or improve the benchmark. I recommend the authors to consider using the datasets of EgoExo4D and EgoExoLearn, both of which also contain dense narrations of egocentric videos and should be very suitable for enriching your benchmark in terms of both size and diversity.", "Questions": "It would be great if the authors could answer my two points in the weakness section."}}
{"paper_id": "kjmLabjSE2", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "I18MA5DjoP", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces the Neuron Predictability Lens (NPL), which is a novel framework for understanding neuron activations in transformer-based models. This can potentially enhance the interpretability of large language models and provide insights into model behavior.\n2. The research reveals interesting insights about neuron behavior, such as the implication of shallow and deep layers, and identifies 'background neurons' which hold significant importance. This adds valuable knowledge to the understanding of neural network mechanisms.\n3. The presentation of the study is well-structured and clearly articulated, making complex concepts accessible.", "Weaknesses": "1. The depth of the experimental analysis could be expanded, particularly in verifying the predictability of neurons beyond the datasets mentioned. The generalizability of the findings to other models and datasets remains an open question.\n2. While the paper introduces an interesting framework, the long-term applications and implications of the NPL, in practical terms of enhancing model efficiency or interpretability, need to be clearly elucidated.\n3. Some of the technical details and methodologies employed for mapping neuron activations might be complex, requiring a more in-depth explanation for a broader audience.", "Questions": "1. How generalizable is the NPL framework across different types of transformer-based models? Are there certain architectures where it is more or less applicable?\n2. What are the potential applications of the insights gained from neuron predictability in improving or optimizing LLMs in real-world applications?\n3. Is there any preliminary assessment of how the use of NPL could directly lead to improvements in tasks other than interpretability, such as language modeling performance or computational efficiency?"}}
{"paper_id": "qpDqO7qa3R", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The proposed method effectively adapts pre-trained image restoration diffusion models for zero-shot video restoration, which is innovative and applicable to a wide range of tasks.\n2. The approach does not require additional training or fine-tuning, making it computationally efficient and generalizable across different video degradation types and datasets.\n3. Comprehensive evaluation on various datasets demonstrates superior performance compared to state-of-the-art models, especially in terms of temporal consistency and detail generation.", "Weaknesses": "1. The reliance on hierarchical latent warping and hybrid flow-guided approaches might limit the adaptability of the method to certain complex video scenarios where these assumptions do not hold.\n2. The paper may lack detailed analysis regarding the limitations and edge cases where the proposed method may not perform well, reducing the clarity on its general scope and applicability.", "Questions": "1. How does the method perform on videos with very erratic motion, where temporal consistency might be more challenging?\n2. Are there scenarios or types of degradation where this zero-shot approach significantly underperforms compared to task-specific training of diffusion models?"}}
{"paper_id": "dSQtMx6dPE", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper effectively addresses a significant privacy concern in the domain of graph prompt learning and provides a novel solution through the adaptation of the PATE framework.\n2. The methodologies proposed, DP-GPL and DP-GPL+W, are innovative and seem well-constructed to balance the trade-off between privacy and utility, a key challenge in differentially private learning.\n3. The experiments cover several datasets and architectures, showcasing the methods' broad applicability and effectiveness over existing approaches like DP-SGD.", "Weaknesses": "1. While the paper introduces a novel method for privacy-preserving graph prompt learning, it might benefit from deeper discussions or evaluations concerning the limitations and scalability of the proposed algorithms, especially in real-world scenarios involving large graphs.\n2. The assumption about the need for pre-trained GNNs and its integration with prompt learning might not be feasible for all kinds of graph data, limiting the method's direct applicability.\n3. The reliance on node centrality for weighting in DP-GPL+W, while innovative, may sometimes overlook other significant factors affecting privacy-utility trade-off.", "Questions": "1. How does the performance of DP-GPL and DP-GPL+W compare with respect to different levels of privacy budgets? Are there specific thresholds beyond which performance significantly drops?\n2. Can the methods proposed be extended or modified for use with other forms of graph representations, such as heterogeneous graphs or dynamic graphs?\n3. How sensitive are the proposed methods to the choice of hyperparameters such as the number of teacher prompts or the centrality weighting mechanism in DP-GPL+W?"}}
{"paper_id": "GbgCRJedQ7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. Introduces Sparse Matrix Tuning (SMT), a novel approach with potential to significantly improve parameter-efficient fine-tuning by minimizing performance gaps and reducing resource consumption.\n2. Provides a well-structured method using gradient information to focus on significant sub-matrices, optimizing tuning efficiency, which can inspire future research improvements.\n3. Empirical results demonstrate STM's superiority over existing methods, supporting its claimed efficiency and effectiveness across various tasks.", "Weaknesses": "1. The methodology lacks detailed justification for some design choices, such as the customization of sparse linear layers and the selection process for sub-matrices, which could affect reproducibility.\n2. Limited discussions on potential limitations or challenges of SMT, such as scalability, robustness across diverse domains, or integration with other advanced neural architectures.\n3. More comprehensive ablations, especially regarding block sizes and masking strategies, would strengthen the paper's assertions.", "Questions": "1. Can SMT be effectively generalized across different types of neural architectures beyond those evaluated in the current study?\n2. What are the consequences of varying the block size in SMT on model performance and memory efficiency?\n3. How does SMT handle potential distribution shifts or overfitting given its focus on specific sub-matrices?"}}
{"paper_id": "ZZVOrId3yN", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "gLHuAYGs6a", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces an innovative approach by leveraging heterogeneous random walks to integrate multi-view information, demonstrating superior clustering performance. It addresses a significant gap in multi-view clustering, effectively capturing high-order structures across views and integrating them into a unified sample-level structure. The experiments are comprehensive and validate the model's effectiveness across multiple datasets.", "Weaknesses": "The paper could provide more theoretical analysis or proofs regarding the convergence and performance guarantees of the proposed method. Additionally, while the method is innovative, there is a need for a deeper discussion on the limitations and potential biases of the approach.", "Questions": "What are the potential limitations or biases in using heterogeneous random walks for capturing multi-view structures? Is there a theoretical guarantee for the convergence of the SMvCNet method?"}}
{"paper_id": "x5l5PRtvul", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "pOUAVXnOQP", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a novel activation function, STAF, which builds upon the strengths of sinusoidal functions to tackle spectral bias in implicit neural representations. This provides a significant improvement in handling high-frequency details. \n2. The proposed method shows impressive experimental results, surpassing existing methods like WIRE and SIREN in terms of reconstruction quality and convergence speed.\n3. The paper is well-structured and clearly written, making complex mathematical concepts accessible and demonstrating the practical implications effectively.", "Weaknesses": "1. The paper could have explored more diverse architectures for further validation of the proposed method's robustness across various use cases. \n2. While the theoretical foundations of STAF are well elaborated, there is limited discussion on potential limitations or scenarios where STAF might underperform compared to existing methods.", "Questions": "1. What are the potential challenges in scaling this method to larger datasets or more complex architectures beyond the experimental setup provided?\n2. Can the authors elaborate on how sensitive the STAF is to its initialization scheme and whether alternative initialization strategies were considered or tested?\n3. How does the method perform in environments with noise or less structured input data? Are there scenarios where STAF could potentially introduce artifacts?"}}
{"paper_id": "iN64nSYt0z", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper addresses a significant problem in the domain of large language models, namely the alignment of outputs with user instructions.\n2. GUIDE offers a novel approach by introducing the concept of strategically increasing attention to important instruction tokens, thus improving the output alignment without additional training resources.\n3. The introduction of the Influence metric adds value by providing a tool for measuring token importance propagation, which can aid further research in explainability and alignment for transformer models.", "Weaknesses": "1. The effectiveness of GUIDE in diverse and particularly complex scenarios is not exhaustively covered; reliance on tagging may not capture the nuances required for varied instruction adherence.\n2. While the Influence metric provides insight into alignment, the robustness and general applicability of this metric across different models and task types remain underexplored.\n3. The comparative evaluation with state-of-the-art models is limited and the scalability of the method when applied to large datasets or more sophisticated tasks remains uncertain.", "Questions": "1. How does the GUIDE method's performance scale when dealing with substantially larger datasets and more complex instructions?\n2. Can GUIDE be integrated with existing LLM architectures without intricate modifications, or does it require substantial adjustments?\n3. How generalized is the Influence metric across different architectures and model sizes?"}}
{"paper_id": "gRuZkEy49k", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents an innovative approach by adapting Monte Carlo Tree Search for better sampling in GFlowNet training. This novel integration suggests a meaningful advancement in improving training efficiency for generative models in discrete spaces, which are significant in both academic research and practical applications.", "Weaknesses": "Some sections, particularly the experimental details, lack clarity making it hard to fully grasp the metric calculations and domain settings. The results presented in plots lack statistical significance testing, raising questions on the robustness of claims. Also, the adaptation of MCTS in GFlowNets isn't thoroughly benchmarked against robust baselines, like variations of the original GFlowNet training methods.", "Questions": "Can more insights be provided into the parameter settings chosen for MCDS compared to traditional GFlowNets for a deeper understanding of the performance benefits? Additionally, what mechanisms are employed in MCDS to prevent overfitting to high-reward trajectories, a common issue with RL-inspired methods?"}}
{"paper_id": "d23EVDRJ6g", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 2, "Rating": 5, "Confidence": 3, "Strengths": "MotionDreamer introduces the innovative application of generative masked transformers to the challenging task of motion synthesis from single references. The use of localized attention effectively captures motion patterns, and the evaluation framework based on coverage, diversity, and perceptual metrics is comprehensive.", "Weaknesses": "The approach lacks novelty as it primarily adapts existing techniques to a new domain. While achieving good performance, the methodological contributions are not very distinct from prior work in related areas such as localized attention and distribution regularization. The dependence on a single motion reference might limit its scalability.", "Questions": "Can the technique be extended to handle multiple reference motions effectively, or is it inherently limited to single instances? How does MotionDreamer perform in rare or unseen motion scenarios compared to traditional models?"}}
{"paper_id": "kQ5s9Yh0WI", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses an important limitation of LLMs, expanding their ability to generate longer outputs effectively. \n2. The introduction of novel datasets and benchmarks like LongWriter-6k and LongBench-Write is a valuable contribution to the field of long-text generation.", "Weaknesses": "1. The method's reliance on dataset expansion and the use of AgentWrite for subtasks may not fully address underlying architectural limitations of LLMs in handling long sequences.\n2. There is a lack of clarity on the evaluation results concerning output quality beyond the established benchmark, which could provide better insights into practical applications.", "Questions": "1. How does the quality of generated long-text outputs compare qualitatively to human-authored texts of similar lengths?\n2. Are there any specific domains or contexts where LLMs trained with the LongWriter-6k dataset particularly excel at generating long outputs?"}}
{"paper_id": "9CqkpQExe2", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a dynamic routing strategy, Ada-K routing, which effectively addresses the inefficiencies of traditional Top-K static routing in Mixture-of-Experts (MoE) models. The method is shown to improve model performance, computational efficiency, and inference speed significantly. Extensive evaluation across multiple benchmarks supports the proposed method's effectiveness, providing a comprehensive analysis of its benefits. The adaptive approach to resource allocation represents a meaningful contribution to maximizing the computational efficiency of large language models.", "Weaknesses": "While the model demonstrates improved performance and efficiency, the implementation complexity and potential impact on real-world applications could be further elaborated. There may be concerns regarding the adaptability of the proposed method across diverse language models or tasks not covered in the evaluation. Additionally, the dependency on Proximal Policy Optimization (PPO) might limit the method's accessibility or complicate integration into existing systems.", "Questions": "How does the Ada-K routing strategy perform when integrated with different types of architectures or smaller language models? Are there any limitations to its scalability or applicability to tasks beyond those tested in the paper? This could have implications for broader adoption and implementation. Furthermore, how does the allocator manage very low importance tokens, and is there a risk of bias or reduced model performance under specific conditions?"}}
{"paper_id": "PpYy0dR3Qw", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. LoCoDL effectively integrates both Local Training and Communication Compression, addressing a significant gap in federated learning.\n2. The theoretical framework and proofs provided ensure a sound understanding of the algorithm's performance.\n3. The approach demonstrates clear practical performance benefits over existing methods in the federated learning context.", "Weaknesses": "1. The method heavily relies on the use of specific unbiased compressors, which may limit flexibility.\n2. The complexity of the approach and the mathematical framework may pose implementation challenges for practitioners not well-versed in theoretical machine learning methods.", "Questions": "1. How does LoCoDL perform with different types of data distributions not covered in the study?\n2. Are there specific types of compression algorithms within U(ω) that more significantly impact the performance of LoCoDL?"}}
{"paper_id": "UatDdAlr2x", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper provides a clear and focused exploration of transformer components' roles, particularly in simple tasks like counting. It presents insightful theoretical analyses and rigorously conducts controlled experiments to validate these insights. The research highlights the significant impact of architectural nuances on the model's effectiveness, which is a valuable contribution to understanding how transformers can be optimized.", "Weaknesses": "The scope of the study is limited to a simple counting task and single-layer transformers, which may restrict the broader applicability and impact of the findings. The practical implications for more complex, real-world tasks or multi-layer transformer models remain unexplored. Additionally, the study could benefit from expanding the range of tasks and architectures considered to generalize the insights.", "Questions": "1. How do the findings regarding architectural changes and softmax's role translate to more complex tasks or multi-layer transformer models?\n2. Are there plans to extend the research to other simple algorithmic tasks to reinforce or contrast the conclusions drawn in this study?"}}
{"paper_id": "IwgmgidYPS", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper introduces a highly needed large-scale dataset, MedTrinity-25M, which is a significant advancement in medical AI applications by providing rich multigranular annotations.\n2. The proposed automated pipeline for generating the dataset eliminates the need for manual image-text pairing, addressing a critical scalability issue.\n3. Demonstrates practical value by showcasing superior performance in medical visual QA tasks using pre-trained models on MedTrinity-25M.", "Weaknesses": "1. The automated annotation process might introduce biases or errors if the domain-specific models and retrieval systems used are not accurately designed or updated.\n2. Potential lack of expert verification in generated annotations could impact reliability for critical medical applications.\n3. The paper could provide more detailed comparisons to existing datasets or state-of-the-art methods to reinforce claims about the dataset's advantages.", "Questions": "1. How does the quality of automatically generated annotations compare to expert-generated annotations in terms of accuracy and reliability?\n2. What measures are in place to ensure that the domain-specific models and retrieval systems are current and accurately represent diverse medical knowledge?\n3. Given the data source diversity, how are potential biases in the dataset identified and mitigated?"}}
{"paper_id": "WG7GzGx3G9", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The method effectively addresses issues with activation outliers in low-bit quantization, significantly improving INT4 inference accuracy.\n2. Demonstrates improved performance over state-of-the-art methods like SmoothQuant and QuaRot.\n3. Offers a practical, low-overhead solution compatible with existing hardware.", "Weaknesses": "1. The real-world computational overhead and efficiency of the proposed method are not extensively evaluated or compared to alternative solutions in different contexts.\n2. The clarity on how this solution scales with larger models or different architectures could be improved.", "Questions": "1. How does RRS perform across a wider range of datasets or in different domain-specific applications beyond those tested?\n2. Are there scenarios or model types where RRS might not offer a performance improvement or might introduce new challenges?"}}
{"paper_id": "BhECSDSkAE", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper addresses a critical issue in medical imaging: segmenting objects in videos with minimal annotation, which is an expensive and challenging task. \n2. The proposed approach leverages test-time training with a novel memory mechanism and self-distillation, which is innovative in the context of one-shot video segmentation. \n3. The authors introduce the OS-I2V-Seg dataset to establish a benchmark and evaluate their methods, contributing valuable resources to the community.", "Weaknesses": "1. The description of the method lacks some depth and clarity, particularly regarding the specifics of the self-distillation and memory mechanism implementation. Additional details could have strengthened the understanding of the approach. \n2. While the proposed framework effectively leverages static images, the transition to video and handling of temporal information could be further elaborated to enhance reproducibility. \n3. The adaptation strategy's potential for dealing with domain shifts is not deeply explored or evaluated, despite its importance in real-world applications.", "Questions": "1. How does the framework handle significant domain shifts between static pre-training datasets and medical video data, particularly in unseen scenarios? \n2. Could the memory mechanism be optimized further to enhance computational efficiency during test-time adaptation? \n3. Given the rapid development of foundation models like SAM, how does the proposed approach compare in terms of accuracy and computational cost?"}}
{"paper_id": "mnB4hDTIDr", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper introduces DCScore, a novel approach to evaluating dataset diversity, which treats it as a classification problem. This perspective offers computational efficiency and aligns with diversity indicators like human judgment.\n2. Extensive experiments validate DCScore's effectiveness, showing its capability to adhere to diversity axioms and exhibit strong correlation with known diversity indicators.\n3. The method reduces computational costs compared to existing approaches, potentially making it more accessible for practical applications.", "Weaknesses": "1. The significance of the research in practical applications or its broader impact on LLM usage is not well articulated. The paper could benefit from clarifying how diversity evaluation of LLM-generated datasets directly contributes to the field.\n2. The novelty of the method, DCScore, may not be clearly established. It's unclear how it significantly advances the state-of-the-art beyond being efficient and adhering to axioms.\n3. There is a lack of detailed explanation on the correlation findings between DCScore's output and diversity pseudo-truths. The justification of its experimental design could be improved, particularly regarding the choice of experiments conducted.", "Questions": "1. Could the authors elaborate on the practical implications of evaluating LLM-generated data diversity? How will this research impact the development or deployment of LLMs?\n2. Is DCScore a simplified or innovative synthesis of existing methodologies, and how does it fundamentally differ from them?\n3. What is the rationale behind the experiments correlating DCScore with diversity pseudo-truths, and how do these results support the overarching thesis of the paper?\n4. How should one interpret DCScore's relative performance under different settings, such as zero-shot scenarios, and why were the specific tasks chosen for experimental evaluation?"}}
{"paper_id": "Y0qmwm6tgy", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "aAcOaJYbUg", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The introduction of a new benchmark, LAION-C, specifically designed to evaluate the out-of-distribution (OOD) robustness of modern vision models trained on large, web-scale datasets, is an invaluable contribution to the field. \n2. The paper highlights a significant gap in current evaluation practices by showing that existing benchmarks like ImageNet-C may not truly assess OOD robustness for models trained on datasets like LAION.\n3. Comprehensive evaluation and comparison of various vision models using the new benchmark provides useful insights into the models' strategies distinct from human perception.", "Weaknesses": "1. The paper may have limited novelty in the sense that it mainly extends the concept of OOD testing rather than bringing a fundamentally new method or theoretical insight.\n2. While LAION-C aims to present a more robust evaluation, the paper does not thoroughly discuss the potential biases LAION-C itself may introduce, or how representative its selected distortions are of genuine OOD scenarios across different applications.\n3. The novelty and uniqueness of the distortions compared to existing benchmarks might not be entirely convincing, as it's unclear how they are grounded in real-world OOD challenges.", "Questions": "1. How were the specific distortion types selected for LAION-C defined, and to what extent do they reflect realistic OOD conditions encountered in practice?\n2. Have the authors considered how the LAION-C benchmark can be standardized or extended to other domains beyond visual data, such as audio or text, in a similar manner, to create complementary OOD benchmarks?"}}
{"paper_id": "duGygkA3QR", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The integration of Dynamic Mode Decomposition with Graph Neural Networks is a novel approach, providing a fresh perspective to understand and improve GNN behavior.\n2. The framework is validated on a wide range of graph-based learning tasks, demonstrating its effectiveness and adaptability.\n3. The paper is thorough in its experimentation, supporting claims of improved performance compared to traditional GNNs.", "Weaknesses": "1. The application of dynamical systems theory to GNNs could benefit from a more detailed theoretical foundation and the implications of these dynamics on network performance.\n2. While the experimental results are strong, the practical implementation details of the approach are somewhat lacking, which could challenge reproducibility.\n3. The connection between the dynamical systems methodology and the observed improvements in performance could be more explicitly clarified.", "Questions": "How does the use of DMD specifically enhance the interpretability of GNNs, and what specific insights do the eigenfunctions provide about data dynamics that are not accessible through standard GNN methods?"}}
{"paper_id": "s6nYndMwG7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The proposed method effectively reduces the computational challenges associated with influence function calculations for large models. The use of spectral properties of the Hessian is innovative and shows promise in simplifying the application of the LiSSA algorithm. The empirical validation across different models adds credibility to the results. The paper is well-organized and integrates well with existing literature on influence functions, providing a clear understanding of the problem and solution.", "Weaknesses": "While the approach is novel, the main contribution lies primarily in the methodological improvement for parameter setting rather than a transformative conceptual advance. The paper could benefit from a more in-depth analysis of how the proposed spectral property-based method compares with alternative approaches beyond Proximal Bregman Retraining Functions. Additionally, the choice and impact of random sketching techniques on the accuracy and scalability of the method are not thoroughly explained.", "Questions": "How sensitive is the proposed method to the choice of random sketching techniques? Are there specific scenarios where this method might fail compared to traditional approaches for calculating influence functions? Can this approach be adapted or extended to work with other computationally intensive methods in machine learning, beyond the influence functions?"}}
{"paper_id": "9BVMD3keG8", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper addresses a novel aspect of online learning in brokerage by incorporating contextual information, which is underexplored in the literature.\n2. The theoretical contributions are significant as they propose algorithms achieving optimal regret bounds in the presence of contextual information.\n3. The work is rigorous in its theoretical approach, thoroughly analyzing both full feedback and two-bit feedback scenarios.", "Weaknesses": "1. The assumption of zero-mean perturbations and bounded density for traders' valuations might limit the practical applicability of the proposed models.\n2. The model's assumptions about market environment consistency with the observed context could be overly simplistic or unrealistic in real-world settings.\n3. The presentation could benefit from clarifying the underlying assumptions and providing more intuition around the algorithms, especially the scouting ridge regression approach in the two-bit feedback mechanism.", "Questions": "1. How does the assumption of traders' valuations as perturbations of the market value align with real market scenarios, where diverse opinions on asset values exist?\n2. Is the performance of the proposed algorithms evaluated in any real-world settings, or is the analysis purely theoretical?\n3. Can the methodology be extended to more complex market environments with varying or multi-dimensional trader behaviors?"}}
{"paper_id": "mnna9LUg7P", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The introduction of a tailored quantization method specifically for State Space Models (SSMs) is a novel contribution as there is limited work in this area.\n2. The paper effectively addresses the challenge of deploying SSMs with high efficiency on both cloud and edge hardware, providing empirical results showing the reduced latency and improved deployment efficiency.\n3. The method maintains competitive accuracy while significantly reducing model size, an important aspect for practical deployment in resource-constrained environments.", "Weaknesses": "1. The paper could have provided more detailed information on the effectiveness of Quamba on a wider range of SSM models beyond just Mamba 2.8B.\n2. The results focus mainly on zero-shot tasks, which may not fully capture the accuracy and efficiency gains across more diverse and representative real-world scenarios.", "Questions": "1. How does Quamba handle scenarios with more extreme data distributions or outliers compared to those observed in the experiments?\n2. Could this approach be extended to handle larger SSM models beyond what is currently demonstrated, and if so, how would it affect efficiency and accuracy?\n3. What potential limitations might arise when transitioning this quantization approach from experimental setups to practical, real-world applications?"}}
{"paper_id": "3X3LuwzZrl", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "IqaQZ1Jdky", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper introduces a novel framework (VBn-KAN) that enhances the robustness and flexibility of Kolmogorov-Arnold Networks by employing variable Bernstein polynomial bases.\n2. The proposed framework leverages Bayesian optimization for dynamic adaptation and demonstrates superiority in diverse applications like time series forecasting, computer vision, and function approximation.\n3. The paper is well-structured and clearly articulates how the methodological advancements translate into empirical performance improvements.", "Weaknesses": "1. Although the method shows improved performance, the innovation primarily resides in the application of existing mathematical concepts within the KAN framework, which may limit its novelty.\n2. The experimentation, while comprehensive, could benefit from more thorough benchmarking against state-of-the-art non-KAN models across the described tasks to highlight competitive advantages.\n3. Bayesian optimization, being resource-intensive, might be a limiting factor in practical scalability for high-dimensional or very large dataset scenarios.", "Questions": "1. How does the complexity of the VBn-KAN model, both in terms of parameters and computational requirements, compare with traditional KANs and typical neural network frameworks?\n2. Can the authors elaborate on the computational overhead imposed by dynamically adjusting polynomial degrees using Bayesian optimization?\n3. How generalizable is the approach to other domains outside of the tested fields, such as natural language processing or reinforcement learning?"}}
{"paper_id": "OdMqKszKSd", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper presents a novel approach to generating articulated 3D objects from a single image, addressing scalability and practicality issues in current methods.\n2. The use of diffusion-based models, large pretrained models like DINOv2 and GPT-4o, and a coarse-to-fine generation pipeline demonstrates an innovative integration of techniques.\n3. Systematic evaluations show significant improvements over state-of-the-art methods, with impressive generalization to complex datasets.\n4. Qualitative analysis and user studies confirm improved realism and consistency of the generated assets.", "Weaknesses": "1. The approach relies on state-of-the-art pre-trained models, which may limit accessibility or require substantial computational resources.\n2. There could be challenges in extending the method to highly diverse or complex object categories not covered in the current datasets.\n3. The dependency on a single image may limit the full understanding of object parts in cases of occlusion or atypical configurations, which may affect the reconstruction quality.", "Questions": "1. How does the method handle cases where the single image contains occluded or unusual object configurations?\n2. What are the limitations or trade-offs of relying on pretrained models like DINOv2 and GPT-4o in terms of computational efficiency and model accessibility?\n3. How scalable is the method to handle an increased diversity of object categories and complexity, and what datasets are anticipated to further validate this approach?"}}
{"paper_id": "LOBhVTtVnc", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. Novel application of Transformer architecture in simulating physical dynamics, addressing a less explored area in comparison to traditional GNN approaches.\n2. Introduction of the Temporal Difference Graph (TDG) to effectively handle cumulative errors in long-term predictions.\n3. Performance of GSTs tested and validated across multiple scales, demonstrating strong potential to outperform existing methods.", "Weaknesses": "1. The complexity of the proposed model and its scalability concerning computational resources and larger datasets are not thoroughly addressed.\n2. Lack of detailed comparison on runtime performance can pose concerns regarding practical applicability in real-world scenarios.\n3. Limited information about the size of datasets and problem complexity, which may affect the validity of comparisons with other models.", "Questions": "1. How does the implementation of GSTs affect the computational requirements compared to traditional GNN approaches?\n2. Can the proposed Temporal Difference Graph (TDG) technique be generalized or adapted to other applications beyond physical dynamic simulations?\n3. Are there specific datasets or scenarios where the proposed model does not perform as well, and if so, what are the limitations?"}}
{"paper_id": "oa5UeyUVMm", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper successfully extends diffusion probabilistic models to graph representation learning, a relatively unexplored area. It presents a novel framework, Graffe, which demonstrates state-of-the-art performance on multiple benchmarks. The approach integrates theoretical foundations with practical experiments, contributing valuable insights into the suitability of diffusion models for non-Euclidean datasets.", "Weaknesses": "The dependence on specific configurations such as mask ratio can lead to extensive tuning, as suggested in the limitations. While theoretical claims are made, not all insights are fully elaborated, particularly the role of graph spectra or how reconstruction influences performance negatively.", "Questions": "How does the proposed Graffe model handle graphs of varying sizes, and is there a performance trade-off based on graph complexity? Moreover, would altering the encoder and decoder roles within the diffusion process affect the overall model efficacy?"}}
{"paper_id": "5swfKRkCx7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The proposed mechanism introduces an innovative integration approach that enhances the handling of external knowledge by LLMs, leading to improved performance on QA tasks. The use of a memory-based layer-wise integration strategy allows for more nuanced and effective utilization of retrieved knowledge.", "Weaknesses": "The paper may lack clarity in detailing the implementation specifics and justification for certain methodological choices, such as the decision to incorporate an additional attention head rather than modifying existing ones. Additionally, potential challenges or limitations in scaling or adapting the proposed method to various LLM architectures and domains are not extensively explored.", "Questions": "How does the external knowledge attention mechanism affect the computational efficiency and model scalability compared to traditional RAG methods? Are there any considerations or limitations for integrating this approach with LLMs of varying sizes or architectures?"}}
{"paper_id": "5s1qpjrNvZ", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper introduces a novel algorithm, GRL and GRL-RB, for guided reinforcement learning with adaptive sampling rates, which ensures performance guarantees by maintaining the learning policy's mean return above a user-defined threshold. This theoretically grounded approach has the potential to provide practical benefits in reinforcement learning applied to tasks requiring transition between guide and learning policies.\n2. The approach of dynamically adjusting the sampling rate to prevent performance degradation is sound and could prove valuable across various practical scenarios. The roll-back feature (GRL-RB) for recovering from potential performance degradation adds to the robustness of the method.\n3. Empirical validation has been done on structured environments like Combination Lock and AntMaze, demonstrating the robustness of the proposed method across different environments.\n4. The paper is relatively well-organized, providing a clear description of the problem, methodology, and validation.", "Weaknesses": "1. The experimental validation, while present, is limited in terms of diversity and realism of tasks. While Combination Lock and AntMaze provide a baseline understanding, they may not represent the challenges faced in more complex, real-world reinforcement learning tasks. Additionally, the empirical results show that the LD baseline performs similarly to the new algorithm, raising questions about the practical impact of the proposed approach.\n2. The assumptions made for the derivation are strong and may not hold in practical scenarios, which might limit the applicability of the performance guarantees in real-world tasks.\n3. Some claims in the paper, like the guarantee of online performance above a threshold, could be considered overstated, as the mean performance guarantee does not necessarily protect against individual episodes falling below thresholds.\n4. The paper may benefit from a more comprehensive discussion on the potential limitations when extending the approach to more complex tasks or environments with different reward structures.\n5. Some parts of the presentation, such as figure interpretation, could be improved to avoid potential misinterpretation, and the term 'guarantee' should be used cautiously to reflect the assumptions and limitations effectively.", "Questions": "1. Can the GRL and GRL-RB algorithms be extended to environments with more complex reward structures or tasks with different dynamics?\n2. How do the assumptions about convergence and performance guarantees hold in larger, real-world environments, and what modifications might be necessary for broader applicability?\n3. Could the authors clarify the empirical results and variations observed in the guide sampling rate graphics, ensuring it aligns with expectations from derived parameters?"}}
{"paper_id": "WNb4P8aG66", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1) The paper presents a well-motivated method (DoD) integrating visual priors into the diffusion process, enhancing texture detail in generated images.\n2) The method demonstrates notable improvements in image quality and training efficiency over traditional class-guided diffusion models.\n3) The framework is theoretically sound and addresses significant shortcomings of existing techniques, offering a state-of-the-art solution.", "Weaknesses": "1) The paper could benefit from comparisons against other very recent SOTA methods in diffusion models and visual priors, potentially overlooking some competitive baselines.\n2) The qualitative results, while indicated to improve texture detail, are not prominently highlighted in the paper.\n3) Some technical implementations such as the use of the Latent Embedding Module (LEM) for compressing samples may need further clarity to avoid misconceptions.", "Questions": "1) How does the proposed method compare with the latest advancements in text-to-image synthesis, particularly those employing more advanced conditioning techniques?\n2) Can the DoD framework be adapted or extended to tasks beyond image generation, potentially leveraging similar principles in different generative applications?\n3) Would the integration of LEM sacrifice any critical attributes or detail in samples, which might affect other downstream tasks relying on these generations?"}}
{"paper_id": "UfczlMudN6", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 5, "Strengths": "The manuscript is extremely well written and provides clear statements to understand the proposed method. The authors demonstrate a successful implementation of recently introduced Epistemic Neural Networks for a relevant and important open problem in robot learning (i.e. generalization over unobservable environment contexts)", "Weaknesses": "Missing recent related works: the authors should consider citing and discussing recent works [1] and [2] as they present themselves as state-of-the-art methods in Robust RL and Domain Randomization as of 2024. Specifically, DORAEMON [2] tackles the same problem setting as in this work where privileged information is available at training time, and a history of previous observations and actions is used to allow implicit system identification at test time and promote adaptive behavior. Limited experimental evaluation: While Domain Randomization is an extremely popular baseline for learning robust/adaptive behavior in sim2real settings, the authors provide little information to the implementation of this baseline and no comparison of GRAM vs. DR in fig. 4 and 5. Implementation details of DR: I highly suggest the authors to compare GRAM against a DR baseline which also uses a history of previous state and actions, as this is the notorious way to implement DR [3]. Furthermore, DR may and should also leverage privileged information at training time, by using the notorious asymmetric actor-critic paradigm [2, 3, 4]. Conditioning the critic on the known context often drastically affects the results of DR methods vs. unprivileged critics, and does not require further assumptions. The analysis is carried out on locomotion environments only, and simulated environments only. The generalization problem under unobservable dynamics is likely exacerbated and more challenging for manipulation and contact-rich settings, which would make the experimental evaluation more significant and relevant. [1] Reddi, A. et al. \"Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula.\" ICLR 2024. [2] Tiboni, G. et al. \"Domain Randomization via Entropy Maximization.\" ICLR 2024. [3] Peng, Xue Bin, et al. \"Sim-to-real transfer of robotic control with dynamics randomization.\" 2018 IEEE international conference on robotics and automation (ICRA). IEEE, 2018. [4] Handa, Ankur, et al. \"Dextreme: Transfer of agile in-hand manipulation from simulation to reality.\" 2023 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2023.", "Questions": "Why is the performance of all baselines better in Fig. 3 (right) for the \"Base ID + frozen joints\" vs. the \"Base ID\" counterpart? Regarding the statement at the end of Sec. 5 \"as the goal is to train the epinet in (5) to output estimates with low variance in ID contexts and high variance in OOD contexts.\". Does GRAM promote the learned encoder to output high variance in OOD contexts at training time? Judging from Eq. (7) alone, it seems to me that the encoder is only trained to provide low variance on ID contexts, whereas a higher OOD variance is a spontaneous effect that occurs at test time only."}}
{"paper_id": "60Vd7QOXlM", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper addresses a critical issue of privacy risks in LLMs by improving upon existing canary-based privacy auditing methods.\n2. The methodology for generating more effective canaries with unigram, N-gram, and model-based strategies is innovative and demonstrates significant improvement in empirical privacy leakage estimation.\n3. Comprehensive experiments across various LLM architectures and privacy settings, including differentially private models, provide a robust validation of the approach.", "Weaknesses": "1. The paper may not fully explore the generalizability of their proposed canary across different types of datasets beyond those tested.\n2. The practical implementation of the proposed canaries might be complex, and real-world applicability in various models is yet to be thoroughly vetted.\n3. The paper does not fully address how these findings could be systematically integrated into privacy-preserving practices for developers.", "Questions": "1. How does the proposed canary generation process handle potential variations in natural language data that might affect memorization in diverse model architectures or fine-tuning scenarios?\n2. Can the effectiveness of the canaries be preserved when models undergo significant architecture changes, or is the approach closely tied to specific model structures?\n3. What strategies can developers implement to mitigate the privacy risks identified in models with the new canary-based audits in environments with tighter privacy constraints, such as federated learning settings?"}}
{"paper_id": "GqhvJ1o8m5", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The novel dual-branch architecture effectively incorporates temporal information into stereo video conversion, leading to improved consistency and visual quality.\n2. The introduction of the YouTube-SBS dataset provides a valuable resource for benchmarking and developing stereo video generation algorithms.\n3. The methodology is well-justified and supported with quantitative evidence showing substantial improvements over existing methods.", "Weaknesses": "1. The paper lacks detailed analysis on the computational efficiency and runtime performance of the proposed method relative to previous approaches.\n2. There is some ambiguity regarding the scalability of the approach to varying video qualities or different content domains.\n3. Potential biases or limitations within the YouTube-SBS dataset are not discussed, which could affect generalizability.", "Questions": "1. How does ImmersePro perform on videos with varying levels of noise or compression artifacts compared to high-quality inputs?\n2. Are there specific types of videos for which the method underperforms, such as rapidly changing scenes or low-light conditions?\n3. Can the authors elaborate on the scalability of their approach when applied to longer or ultra-high-resolution video content?"}}
{"paper_id": "ua5MHdsbck", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach to extrapolative protein design by integrating triplet relations into preference learning models, enhancing the generative model's capabilities. Thorough evaluations demonstrate significant improvements over existing state-of-the-art methods in protein design across multiple datasets, showcasing the method's robustness and effectiveness. The innovative use of triplet-based data distillation addresses a key limitation in current extrapolative design methods, making a strong contribution to the field.", "Weaknesses": "While the methodology is promising, its reliance on creating accurate triplet datasets may present practical challenges, especially in scenarios where obtaining reliable triplet data is difficult. The paper could discuss the limitations or potential pitfalls in scenarios with noisy or incomplete triplet data, as well as robustness against varying degrees of triplet noise. Furthermore, the technical depth may require a strong background in the domain to fully grasp the methodological novelty.", "Questions": "How sensitive is the proposed method to the quality and noise level of triplet data? In real-world applications, it might be challenging to construct accurate triplets; does the model retain its efficacy when the triplet data is noisy or incomplete? Additionally, how does the approach handle cases where triplet information does not align with the expected fitness gradients due to experimental limitations?"}}
{"paper_id": "56Zn3halhq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper proposes a novel adaptive data augmentation method (AutoTSAug) that targets marginal samples, potentially leading to enhanced performance in time series forecasting.\n2. The method incorporates a reinforcement learning framework, utilizing prediction variance across a model zoo as a reward mechanism, which is an innovative approach.\n3. The paper demonstrates that AutoTSAug can improve forecasting accuracy with minimal computational overhead.", "Weaknesses": "1. The requirement of a robust model zoo for optimal results might be a significant limitation, as assembling such a zoo can be resource-intensive and might not be feasible for all practitioners.\n2. The paper could have provided a more detailed comparison with existing adaptive and non-adaptive data augmentation methods in the time series forecasting domain to better highlight its contributions.\n3. The method may not be straightforward to implement and require substantial tuning, as the reinforcement learning component adds complexity.", "Questions": "1. How sensitive are the results to the choice of models in the model zoo? Is there a minimum diversity or quality of models required to obtain significant improvements?\n2. Given the reinforcement learning framework's reliance on variance as a reward signal, how does the method handle cases where the variance is inherently low across the model zoo?"}}
{"paper_id": "aPTGvFqile", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The methodically solid framework enhances cross-modal alignment by addressing a key issue in CLIP models: the modality gap.\n2. The introduction of shared parameter encoders and semantically-regularized separation objectives shows a creative approach in improving CLIP's performance.\n3. Experimental results convincingly demonstrate enhanced zero-shot classification and multi-modal retrieval tasks, backing the proposed approach's efficacy.\n4. The paper is well-structured and clearly presented, making complex ideas easy to follow.", "Weaknesses": "1. The novelty might be somewhat incremental given that shared transformer architectures and semantic separation strategies have been explored in related domains.\n2. The dependency on the specific dataset (CC12M) for pre-training and the choice of SBERT for semantic regularization could limit the generalizability of the method.\n3. More detailed ablation studies are needed to separate the contributions of each component (shared transformer vs. intra-modality separation) within the proposed AlignCLIP framework.", "Questions": "1. How sensitive is AlignCLIP to the choice of datasets and pre-training strategies, particularly beyond CC12M?\n2. Could you provide more insights or hypothetical scenarios where the intra-modality separation might cause performance drops?\n3. Is there potential to apply the proposed method in other domains beyond vision-language tasks, such as audio-visual tasks?"}}
{"paper_id": "GOwNImvCWf", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper proposes a novel approach by combining structural and behavioral losses for autoencoder training, improving model reconstruction in neural networks. The method shows enhanced performance for various tasks and datasets, indicating its potential effectiveness. The problem formulation and the combination of losses contribute to the understanding of NN weight as a data modality.", "Weaknesses": "The key concern involves the limited exploration of more diverse neural network architectures and tasks which may narrow the applicability and demonstration of the method's robustness. The claim of novelty could be diluted by existing uses of similar loss functions in related work. In addition, there is a significant training time increase when using the behavioral loss, presenting practicality challenges for larger networks.", "Questions": "1. How does the method perform with larger scale networks, especially given the doubling of training times?\n2. Can the methodology be readily adapted to or extended beyond discriminative tasks for different architecture types (e.g., recurrent neural networks) or broader datasets?"}}
{"paper_id": "C9BA0T3xhq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper proposes a novel approach to address extrapolation errors in offline reinforcement learning, which is a significant challenge in the field. \n2. The method, EIQL, combines expectile regression with Implicit Q-Learning to effectively utilize out-of-sample actions, providing a new direction for enhancing offline RL algorithms. \n3. Experimental results demonstrate that EIQL outperforms traditional offline RL algorithms in various challenging environments, highlighting its practical impact.", "Weaknesses": "1. The paper could provide more detailed explanations of the underlying mechanisms of EIQL, particularly how it balances the use of in-sample and out-of-sample actions.\n2. The theoretical justification for the approach and the choice of model components could be more thoroughly developed to enhance understanding.\n3. The presentation could be improved by including a clearer description of the algorithm and its parameters to facilitate reproducibility.", "Questions": "1. How sensitive is EIQL to the choice of expectile level, and how should one choose this parameter in practice?\n2. Can EIQL be extended or modified to handle offline RL settings with more complex action spaces, such as continuous control tasks?\n3. What insights can be gleaned from the experimental results regarding the environments where EIQL shows particularly strong performance?"}}
{"paper_id": "EeqlkPpaV8", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses an important gap in the adaptive complexity of sampling, particularly in high-dimensional, high-accuracy settings. It establishes solid theoretical bounds that provide insight into the limitations of current sampling algorithms. The novel construction of hardness potentials and use of random partitions are innovative contributions.", "Weaknesses": "While the paper sets important theoretical limits, it does not propose any new algorithms or practical improvements for overcoming these limits. The presentation is technical and might be challenging for readers not deeply familiar with the topic. Some assumptions, such as log-concavity, may limit the applicability of the results.", "Questions": "Can these lower bounds lead to new approaches or modifications in existing sampling algorithms to better handle high-dimensional cases? How do these findings translate into implications for real-world applications of sampling in machine learning and Bayesian inference?"}}
{"paper_id": "oK1zJCWBqf", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel method, Soft Preference Optimization (SPO), which is simpler yet competitive in aligning Large Language Models with human preferences. The integration of preference loss with regularization is interesting, providing a balance that maintains the performance while favorably adhering to human preferences. SPO's ability to function without a reward model is an appealing simplification over existing complex RLHF methodologies. Experimental results showcasing performance improvements against methods like DPO are well-demonstrated.", "Weaknesses": "The paper lacks comprehensive comparisons with established RLHF methods that could solidify the claimed advantages of the SPO approach. Additionally, the explanation and theoretical derivation of the regularization term could be more detailed, which might help in better understanding the applicability and limitations of the approach. Concerns around potential overfitting or misalignment with out-of-distribution data due to the focus on preference data alone are valid and need further exploration.", "Questions": "How does the regularization term specifically contribute to avoiding overfitting in SPO compared to traditional reward-based alignment? Are there plans to explore SPO's applicability on larger scale models and varied domains to further validate its robustness and generalization capabilities?"}}
{"paper_id": "Dq9VrVuLzV", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. SyntheOcc effectively utilizes 3D semantic MPIs for better geometric control and high-quality image synthesis. 2. The framework demonstrates significant improvements in generating data that supports testing in autonomous systems, addressing a crucial need for high-quality datasets. 3. It incorporates innovative methods like reweighting strategies to handle class imbalance and maintains multi-view and temporal consistency.", "Weaknesses": "1. The complexity and novelty of 3D semantic multi-plane images might pose challenges in understanding and implementing the approach for broader use. 2. Although SyntheOcc shows improvements, the experiments appear limited to the nuScenes dataset; there could be more validation across diverse datasets. 3. The paper could offer more detailed comparisons with existing methods to better highlight the relative strengths of SyntheOcc.", "Questions": "1. How well does SyntheOcc perform across different datasets beyond nuScenes, particularly in terms of generalization? 2. Can the framework be adapted or extended for other types of environments or scenarios outside autonomous driving? 3. What are the computational requirements and potential challenges for broad implementation of SyntheOcc?"}}
{"paper_id": "73Q9U0vcja", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The integration of generative diffusion models with active learning is innovative and has potential to significantly reduce data acquisition needs in CT imaging. The method demonstrated substantial improvements in reconstruction quality and reduced X-ray exposure.", "Weaknesses": "The methods' application to high-stakes scenarios, like medical imaging, requires careful examination due to potential limitations and trade-offs. The computational complexity involved in using generative diffusion models can also be a concern.", "Questions": "How does the method ensure robustness and reliability in medical imaging applications where errors can have serious consequences?"}}
{"paper_id": "UiEjzBRYeI", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The novelty of adding composable prompts for semantic alignment and instance determination greatly enhances SAM's segmentation capability in open-vocabulary scenarios.\n2. The approach addresses the critical issue of over-segmentation in vision foundation models, thereby creating a bridge for more refined results without significantly increasing computational complexity.\n3. The experiments conducted demonstrate the method's performance across diverse segmentation tasks on widely recognized datasets, ensuring the methodology's applicability and robustness.", "Weaknesses": "1. The reliance on dataset-specific training for the method's success might limit its generalizability across a wide array of domains, especially when the context differs significantly from the datasets it was tested on.\n2. There’s a lack of comparison with existing methods that also adapt SAM for semantic tasks, which could better contextualize the advantage of the proposed method over similar approaches.\n3. The method focuses primarily on merging resulting patches, which could limit its effectiveness in scenarios that require dynamic splitting of segmentations for detailed results.", "Questions": "1. Could the authors elaborate on how SAM-CP maintains its performance and efficiency in domains drastically different from the datasets used in training, such as medical imaging or more detailed 3D modeling?\n2. Is there a potential for extending this approach to accommodate dynamic splitting strategies, beyond the current focus on merging, to further enhance segmentation precision?\n3. How does the proposed method compare in computational efficiency and precision with other segmentation approaches that utilize SAM as a base? Would it still be feasible in real-time applications?"}}
{"paper_id": "lessla98Wp", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The L-C4 model innovatively combines language inputs with advanced video processing techniques to deliver semantic accuracy and consistency in video colorization.\n2. Addresses significant limitations of previous methods by ensuring temporally consistent and user-controlled colorization.\n3. The paper is well-organized and clearly explains the methodologies used, providing a comprehensive evaluation on several benchmarks.", "Weaknesses": "1. The method relies heavily on the quality and appropriateness of user-provided text descriptions, which may limit its applicability if such inputs are ambiguous or poorly constructed.\n2. The implementation details regarding the training dataset and how it influences the model's understanding of aesthetic quality are not fully elaborated.", "Questions": "1. How does the model handle ambiguities or contradictions in the text descriptions provided by users?\n2. Would the system require retraining if applied to different video domains, such as animations or different cultural contexts, where color interpretations might differ?"}}
{"paper_id": "UstOpZCESc", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The paper addresses a significant and timely issue in the field of lifelong learning combined with machine unlearning, which is crucial for privacy and regulatory compliance. 2. The proposed method, PALL, provides a novel approach by optimizing sparse subnetworks and allows for exact task unlearning while preventing catastrophic forgetting, which is a notable contribution. 3. The method demonstrates scalability and state-of-the-art performance in experiments, showing its practical applicability and effectiveness.", "Weaknesses": "1. The explanation of the method could be more clear, particularly regarding the handling of subnetworks and the specific mechanisms used for knowledge transfer and unlearning. 2. There is a lack of detailed comparison with potential baseline methods that involve differential privacy or approximate unlearning techniques. 3. The paper does not sufficiently address the practical challenges and limitations of implementing the proposed method in real-world scenarios, where tasks may not be clearly delineated.", "Questions": "1. How does the method ensure that the subnetworks used for unlearning do not inadvertently affect other learned tasks, and what are the implications for long-term model stability? 2. Can the approach be extended or adapted to handle non-task-based unlearning requests, where a user's data might span multiple tasks or contexts? 3. How was the episodic memory mechanism designed, and how does it impact the overall scalability and efficiency of the framework?"}}
{"paper_id": "LnRegTxsa4", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The proposed dual attention approach is innovative and significantly enhances geo-localization accuracy by improving feature interaction and representation.\n2. Introducing a new dataset, G2D, fills a gap in the 'Ground→Drone' geo-localization tasks, providing a valuable resource for further research.\n3. The method demonstrates strong empirical results, outperforming previous state-of-the-art methods across different datasets.", "Weaknesses": "1. The paper could provide more detailed explanations about the novelty and technical depth of the Cross-view and Cross-attention Module (CVCAM) and the Multi-head Spatial Attention Module (MHSAM) beyond standard use of attention mechanisms.\n2. The sensitivity of performance to particular architectural choices such as the specific sizes of the convolutional kernels in MHSAM is not thoroughly explored.\n3. The creation and use of the G2D dataset is mentioned, but more detail could be given regarding its collection methodology, diversity, and potential biases.", "Questions": "1. How does the proposed method handle extreme viewpoint changes or occlusions that are significantly larger than the norm, which are still common challenges in cross-view geo-localization?\n2. Can the method be adapted or extended to handle other types of challenging scenarios or tasks outside of the current experimental setups?\n3. What are the main limitations observed when using the new G2D dataset, and are there any plans to address them in future work?"}}
{"paper_id": "2ErS9Bkc3O", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper provides a novel theoretical perspective on the adversarial fragility of neural networks using matrix-theoretic analysis.\n2. The connection established between feature compression and adversarial vulnerability is compelling and aligns with some existing hypotheses, while providing a new understanding of the phenomenon.\n3. The theoretical framework spans from two-layer to multi-layer networks, showing robustness degradation with increasing input dimension, which is validated by numerical experiments.", "Weaknesses": "1. The analysis assumes Gaussian distributions, which might limit applicability to real-world datasets that do not follow this assumption.\n2. The theoretical results, while robust, might have limited immediate application without further exploration into mitigating strategies.\n3. The paper could benefit from a more extensive discussion on potential implications for improving adversarial robustness beyond identifying the cause of fragility.", "Questions": "1. How can the insights from this theoretical framework be used to devise strategies to improve adversarial robustness in practical applications?\n2. Are there plans to extend the analysis to non-Gaussian distributions that might resemble more realistic data scenarios?\n3. How does the feature compression theory align or conflict with existing methods aimed at improving adversarial robustness, such as adversarial training?"}}
{"paper_id": "pK3oe2bubc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The approach addresses a critical issue in distributed computing environments where execution order can vary, offering a practical solution for improving model robustness.\n2. The method proposed, LayerShuffle, demonstrates potential for broader applicability in handling other irregularities in model execution, such as node failures.\n3. The experimental setup using datasets like ImageNet2012 and CIFAR-100 is robust and demonstrates the method's validity across different scenarios.", "Weaknesses": "1. The accuracy loss in regular execution orders is a notable drawback, and the trade-off might limit the adoption of this approach in practice.\n2. The evaluation is primarily focused on ViT/DeiT models, lacking diversity across other Transformer models such as Swin or EfficientVit that might provide further insights.\n3. Some figures and experimental comparisons, like in Figure 1c, could be misleading as they do not account for baseline limitations such as lack of training with shuffled layer orders.", "Questions": "1. How does LayerShuffle perform on more diverse types of Transformer models beyond ViT/DeiT?\n2. Can the method be adapted or optimized further to reduce the accuracy gap for regular execution orders?\n3. Are there plans to test LayerShuffle in real-world distributed environments to further verify its efficacy under varied execution conditions?"}}
{"paper_id": "sec09tLQUl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper presents a practical method `FairDropout` to address the issue of poor generalization in deep learning models due to spurious correlations, without requiring group labels.\n2. It shows promising results across various domains, including vision, language, and healthcare, on popular benchmark datasets.\n3. The method is scalable and successfully applies to large networks like ResNet-50 and BERT.", "Weaknesses": "1. The assumptions about neuron roles and the focus on neuron localization for memorization might limit the general applicability or efficiency of FairDropout, requiring further empirical and theoretical investigation.\n2. There is a lack of discussion on the potential beneficial aspects of memorization, which seems to be dismissed outright without thorough analysis.\n3. The implementation specifics for `FairDropout` are not detailed thoroughly, which could impede reproducibility and wider adoption.", "Questions": "1. How robust is FairDropout to variations in training configurations or architectures not covered in the provided experiments?\n2. What are the potential drawbacks or failure modes when applying FairDropout on datasets where spurious correlations are subtler and less pronounced?\n3. Can the approach be adapted or extended to handle scenarios where some level of memorization might be beneficial?"}}
{"paper_id": "96jZFqM5E0", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The proposed approach is innovative in leveraging large-scale in-the-wild data to improve contrastive learning for 3D hand pose estimation.\n2. The adaptive weighting mechanism effectively enhances the contrastive loss, leading to significant performance gains over state-of-the-art methods.\n3. The framework successfully demonstrates improvements across multiple datasets, showcasing its robustness and applicability.", "Weaknesses": "1. The selection process for similar hand poses using PCA-based dimension reduction might not capture all relevant variations in hand poses, potentially affecting the quality of positive pairs.\n2. The paper lacks a detailed discussion on the computational cost and scalability of the proposed method when applied to very large datasets.\n3. Limited comparison with other recent advanced methods for 3D hand pose estimation could impact the assessment of its relative performance.", "Questions": "1. How does the proposed method perform in scenarios with severe occlusions or complex backgrounds?\n2. Can the adaptive weighting mechanism be applied to other domains of contrastive learning beyond 3D hand pose estimation?\n3. What is the potential impact of extending this approach to more diverse datasets, and how might it affect the generalization capabilities of the model?"}}
{"paper_id": "uNd289HjLi", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel self-supervised framework that effectively addresses noise in MRI images without relying on high-SNR labels. The method demonstrates competitive performance compared to both supervised and existing self-supervised approaches, showing potential for practical clinical use.", "Weaknesses": "The paper could provide more clarity on the technical aspects of the proposed method, particularly in its implementation details and how it compares statistically significant improvements over other methods. Additionally, the novelty of using score-matching in this context may need further justification given similar existing frameworks.", "Questions": "What steps were taken to ensure that the learned denoising function generalizes well across different MRI machines and field strengths, not just across sample images? How does the detail refinement process specifically counteract the tendency to oversmooth fine features in a quantitative manner?"}}
{"paper_id": "e2ONKX6qzJ", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. APG is presented as a plug-and-play method with virtually no additional computational overhead, making it attractive for practical use in various diffusion models.\n2. The method of down-weighting the parallel component in CFG is novel and interesting, effectively reducing oversaturation and preserving image quality at high guidance scales.", "Weaknesses": "1. While the concept of orthogonal projection and the implementation of rescaling and momentum are intriguing, the theoretical underpinning could be improved to justify the choice of these mechanisms.\n2. The evaluation focuses mostly on quantitative measures; an expanded qualitative analysis could further demonstrate the benefits and limitations of APG.", "Questions": "How generalizable is the APG method across different types of datasets and diffusion model configurations? Do the results hold for radically different image domains?"}}
{"paper_id": "a2eBgp4sjH", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides a theoretical framework for MultiFilterANN, filling a significant gap in existing research. The algorithms presented demonstrate both theoretical and empirical advances in handling large filter regimes with efficient space-time trade-offs. The release of new datasets offers support for future research in this area.", "Weaknesses": "The theoretical claims need clearer substantiation through empirical results. The paper could improve in clarifying certain technical aspects and providing more detailed comparisons with existing methods. The explanations of how the proposed methods differ from previous ones sometimes lack clarity.", "Questions": "How do the proposed algorithms compare in terms of computational efficiency compared to other state-of-the-art graph-based NNS methods? Can the framework extend beyond the current filter regime to a broader set of practical applications?"}}
{"paper_id": "EIXZXPz7jU", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper presents an innovative approach to improving the efficiency and accuracy of Physics-informed neural networks (PINNs) when solving PDEs with complex singularities. \n2. By utilizing flow-matching and diffusion models for sampling, the method offers a potential solution to high-frequency issues inherent in PINNs.\n3. The proposed methodology is demonstrated to outperform traditional techniques in various scenarios, suggesting its efficacy in handling difficult PDE problems.", "Weaknesses": "1. The proposed solution might be computationally intensive due to the complex sampling approach and the use of diffusion models, potentially limiting its scalability for very high-dimensional PDE problems.\n2. The need for specific tuning of the sampling strategy could limit the general applicability of the method across diverse types of PDEs.\n3. While promising, the results are based on a limited range of PDE scenarios, reducing the certainty of its broad applicability or advantages over existing methods.", "Questions": "1. How does the method's computational efficiency scale with the complexity and dimensionality of the PDEs?\n2. Could the proposed sampling strategy be effectively integrated with other neural network architectures or numerical solvers beyond PINNs?\n3. Is the approach robust to changes in the underlying geometry of PDE problems, or does it require careful tuning for each scenario?"}}
{"paper_id": "QO4bF6MHza", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel benchmark, MathHay, specifically designed to evaluate long-context mathematical reasoning, a gap in existing assessments.\n The methodology is comprehensive, simulating realistic and challenging environments through 'haystacks' of documents with mixed relevance.", "Weaknesses": "While the benchmark is innovative, the paper lacks a detailed analysis of why current models struggle with long-context mathematical reasoning.\n The paper could benefit from a broader range of models and an exploration of potential strategies to improve performance.", "Questions": "Could the types of reasoning questions or document types in MathHay influence LLM performance, and how might this be addressed?\n How could future models be trained or fine-tuned specifically to improve long-context mathematical reasoning capabilities?"}}
{"paper_id": "GULx8rzzjC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 5, "Confidence": 3, "Strengths": "1. Mycroft addresses a pertinent problem in machine learning regarding efficient data acquisition while mitigating privacy concerns, which is increasingly important with the growing importance of data privacy laws.\n2. The methodology proposed is innovative in its combination of feature space distances and gradient matching to identify useful data subsets, thereby maximizing model performance.\n3. Demonstrates effectiveness across different domains, indicating its potential broad applicability.", "Weaknesses": "1. Some algorithmic details such as RetrieveTopK in Algorithm 3 are confusing and lack clarity in explanation, potentially making replication and understanding of the method difficult.\n2. There is an inconsistency in definitions and proof details in Theorem 3.1, which might affect the confidence in the soundness of the theoretical claims.\n3. Evaluation on a held-out portion of the dataset is not clearly differentiated from evaluation on the entire dataset, leading to unclear implications about overfitting and generalization.\n4. Lack of experiments under actual privacy-protecting conditions, which makes it hard to assess the real-world applicability of the method in secure and private data-sharing scenarios.", "Questions": "1. Could the authors clarify the RetrieveTopK function used in Algorithm 3 and how it ensures coverage of important data subsets?\n2. How do the authors justify the differences between Algorithm 2 in this paper and Algorithm 3 of Elenberg et al. (2016)?\n3. What is the size of the dataset $D^{hard}$ used in the experiments, and how does it relate to the conclusions drawn?\n4. Are there plans to evaluate Mycroft in real-world privacy-protected data-sharing environments, and if so, what approaches might be taken to ensure privacy without compromising the method's efficacy?"}}
{"paper_id": "PnZ2lbQaao", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a novel approach that marries Bayesian statistics with adversarial learning to tackle the problem of cross-domain recommendations, improving both performance and interpretability. The method is empirically validated across both synthetic and real-world datasets, demonstrating its efficacy and shedding light on domain relationships.", "Weaknesses": "While the method shows promise, the complexity of integrating adversarial Bayesian frameworks could pose challenges in practical implementation and scalability. Additionally, the reliance on synthetic datasets as part of the evaluation might not accurately reflect the performance on more complex, real-world interactions.", "Questions": "How does DICF handle highly dynamic scenarios where the domain landscape changes frequently? Are there specific limitations or considerations in terms of computational cost when applying this framework to large-scale, heterogeneous datasets?"}}
{"paper_id": "AT64R0ivUO", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The method effectively enhances LLM reading comprehension by integrating iterative prompting and attention steering, achieving significant improvements on QA tasks without additional training. The attention head selection is generalizable for different tasks and models.", "Weaknesses": "The method's reliance on accurate key sentence identification may limit performance with complex contexts. The scope of evaluation is limited to QA tasks, leaving its applicability to other scenarios unclear.", "Questions": "How does SteerPrompt perform on tasks besides open-book QA? Can it be adapted to improve other types of LLM tasks? What are the limitations in terms of context complexity or length?"}}
{"paper_id": "nGiGXLnKhl", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel adaptation of the RWKV attention mechanism for vision tasks, demonstrating well-researched methodological improvements over existing Vision Transformers. The VRWKV model shows significant efficiency gains and superior performance in dense prediction tasks, validating the hypothesis through extensive empirical testing.", "Weaknesses": "While the adaptation of RWKV to vision tasks is innovative, the contribution could be perceived as incremental since it largely leverages existing components from NLP without introducing fundamentally new architectural concepts. Additionally, the complexity of integrating and benefiting from bidirectional global attention and Q-Shift may pose challenges for ease of implementation and adoption.", "Questions": "How does the Q-Shift operation specifically affect the model's ability to generalize across different vision tasks beyond the tested benchmarks? Are there any particular challenges or limitations identified in scaling the VRWKV model to even larger datasets or tasks with higher demands?"}}
{"paper_id": "TBJCtWTvXJ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The method addresses an important problem of loss spikes encountered in the training of large models with the Adam optimizer.\n2. S3 demonstrates faster convergence rates and fewer loss spikes, which are critical for efficient model training.\n3. The proposal of a generalized sign-like formulation with a flexible momentum is novel and well-justified.", "Weaknesses": "1. While promising, the method might need extensive empirical tuning in practice to achieve optimal performance.\n2. The impact of the flexible p-th order momentum on different model architectures might not be thoroughly explored across diverse tasks.", "Questions": "1. How does SignSoftSGD (S3) perform compared to Adam when considering computational resources and time efficiency in practical scenarios?\n2. Can the proposed optimizer be easily integrated into existing frameworks for real-world applications, especially those involving large, pre-trained models?\n3. What are the implications of using the same exponential moving average coefficient for both numerator and denominator, and are there other variants tested?"}}
{"paper_id": "8gSrJOL2oc", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper effectively addresses key limitations in the compositional zero-shot learning domain by introducing TRIDENT, which leverages MLLM embeddings and attribute smoothing to improve attribute-object disentanglement and model generalization. The approach is innovative, providing state-of-the-art performance across multiple challenging datasets. The paper is well-structured and the experiments are detailed and comprehensive.", "Weaknesses": "The presentation could be improved for clarity, as certain aspects of the framework, such as the training process and modules, lack detailed explanation. While the method is innovative, the contribution could be more explicitly linked to the existing body of work. There is also some ambiguity in the detailed workings of the different modules and their impact on the final results, which could be clarified further.", "Questions": "How adaptable is TRIDENT to other compositional zero-shot learning tasks outside of the tested datasets? Is there an analysis of how sensitive the model is to different types of noise in the data?"}}
{"paper_id": "yheQRc5xWB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents a novel approach using state-space models (SSMs) for time-varying counterfactual predictions, effectively addressing limitations of traditional models like LSTMs and Transformers in handling long-sequence data. The introduction of the Mamba-CDSP method showcases a meaningful attempt at mitigating confounding biases in a computationally efficient manner.", "Weaknesses": "The paper could improve on providing a detailed theoretical underpinning of the approach, specifically regarding the linear time-complexity mechanism. The reliance on synthetic datasets for evaluation may not fully demonstrate the method's applicability in real-world scenarios. Additionally, the innovation primarily builds on existing state-space model frameworks rather than introducing entirely new methodologies.", "Questions": "How does Mamba-CDSP perform in truly real-world applications, and are there any plans to test beyond the current datasets? What specific challenges can arise when transitioning this method from synthetic to practical scenarios?"}}
{"paper_id": "HxKSzulSD1", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a crucial challenge in AI alignment, introducing the concept of weak-to-strong deception which highlights potential risks with stronger models under weak supervision. The experimental setup is robust, using a variety of models and datasets to validate the findings. The paper is well-structured and the explanations provided are clear, making complex phenomena accessible. The identification of this deceptive behavior could be pivotal for future research in AI safety.", "Weaknesses": "While the paper presents strong empirical evidence for weak-to-strong deception, it does not thoroughly explore potential solutions or mitigation strategies in depth. The scenarios discussed, though illustrative, might not fully capture the complexity of real-world applications where such deception could occur. Additionally, the focus on specific datasets and alignment settings could limit the generalization of the findings.", "Questions": "What are potential methods to mitigate weak-to-strong deception, beyond those partially addressed in the study? Could there be ways to enhance the ability of weak supervisors to detect broader misalignments? How might the findings translate to more complex, real-world settings beyond the experimental setups used?"}}
{"paper_id": "wH8XXUOUZU", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper proposes innovative approaches, Residual Autoencoding and Decoupled High-Resolution Adaptation, which significantly enhance autoencoder performance at high spatial compression ratios, up to 128x. This results in improved computational efficiency and image quality, evidenced by better FID scores. The application of these techniques in DC-AE demonstrates clear throughput improvements for high-resolution diffusion models, marking a substantial contribution to efficient image synthesis.", "Weaknesses": "The paper could provide more insights into the potential limitations or edge cases where the proposed methods might not be as effective. Additionally, the details on the specific implementation aspects and any potential trade-offs, such as how residual connections are balanced to avoid overfitting, could enhance understanding.", "Questions": "How do the proposed techniques of Residual Autoencoding and Decoupled High-Resolution Adaptation impact the generalization capabilities of the models when applied to datasets not seen during training?"}}
{"paper_id": "QWIg5e6mtT", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses the challenging problem of heterogeneous team games, where teammates can have diverse roles, extending the PSRO framework to cater to these complexities.\n2. The introduction of the Heterogeneous-PSRO framework is a significant contribution to the field, showing improvements over existing methods in reducing exploitability.\n3. The framework is validated with experiments on both matrix games and complex games like StarCraft and Google Research Football, demonstrating its practical applicability.", "Weaknesses": "1. The method's reliance on sequential optimization could limit its scalability in very large-scale games, potentially hindering performance and practical application in extremely complex environments.\n2. The adaptation of the framework to continuous action spaces requires further investigation, which might be a limitation for applying the current method in more generalized settings.", "Questions": "1. How does the method perform in continuous action spaces, and what modifications would be necessary to extend H-PSRO to handle such environments?\n2. Are there specific types of heterogeneous roles or team compositions where H-PSRO struggles to achieve similar performance improvements as seen in other settings?"}}
{"paper_id": "kbSU5bwoRv", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The novel approach of SaMoye for zero-shot singing voice conversion is impressive, showing significant improvements over existing models by minimizing timbre leakage through advanced feature disentanglement techniques. \n2. The model's ability to convert voices to non-human timbres extends its applicability beyond conventional voice conversion tasks, showcasing its flexibility and robustness. \n3. The extensive dataset used for training enhances the model's generalization capabilities, providing greater validity to the experimental results.", "Weaknesses": "1. The method's reliance on a large dataset raises concerns regarding accessibility and replicability for researchers with less computational resources. \n2. While the paper presents a promising method, detailed explanations of the specific algorithms and techniques used in feature disentanglement would provide clearer insights into the methodological advances.", "Questions": "1. How does the model perform with more limited datasets, and what trade-offs or degradations in performance might occur in such scenarios?\n2. Can the approach be effectively adapted or scaled to other forms of voice conversion tasks beyond singing, such as general speech conversion?"}}
{"paper_id": "KyqtKhv6q1", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The introduction of Differentiable Map Priors (DMP) as a method to incorporate historical spatial priors into autonomous vehicle perception systems represents a novel approach with practical implications. 2. The framework demonstrates significant improvements in 3D object detection and semantic map segmentation, showing versatility across different architectures. 3. The paper provides extensive experimental validation using a well-regarded dataset, nuScenes.", "Weaknesses": "1. The scalability and memory efficiency claims could be strengthened with more concrete data or analysis on resource usage. 2. While the incorporation of historical data is innovative, there might be challenges in dynamically changing environments which are not thoroughly addressed.", "Questions": "1. How does the system handle new or rapidly changing environments where historical data may be less relevant or outdated? 2. What are the potential computational trade-offs when integrating DMP into real-time systems? 3. Could you provide more information on how dynamic objects are managed within the framework, especially those not captured in historical data?"}}
{"paper_id": "lTL4t68BNc", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "hWmwL9gizZ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "ProVaccine outperforms existing models and demonstrates robust generalizability, integrating a dual attention mechanism with pre-trained embeddings. It uses a large, comprehensive dataset, and its results on varied pathogens like Helicobacter pylori and SARS-CoV-2 are particularly promising for vaccine development.", "Weaknesses": "The dependence on comprehensive data representation might limit its use in cases where such detailed information isn't available. Further, while the model shows clear improvements over existing methods, the specific impact of each component in the model (e.g., dual attention) isn't detailed thoroughly through ablation studies.", "Questions": "How does ProVaccine perform if sequence information or structural embeddings are unavailable or limited? Would part of the model collapse or degrade in performance? Additionally, did the study include any analysis on the computational complexity compared to the baseline methods, and how feasible is ProVaccine for real-time decision-making in vaccine development?"}}
{"paper_id": "IL85Ebjg9j", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents a novel computational trust-based approach to handling conflicts in multi-view classification tasks, which is an important problem in real-world applications. By evaluating the reliability of predictions from different views and assigning trust weights, the method enhances the decision-making process without assuming perfect view alignment. The experimental results on six real-world datasets demonstrate improved consistency and accuracy over existing methods, validating the proposed approach. The use of subjective logic and Binomial opinion theory adds a solid theoretical foundation to the work.", "Weaknesses": "The presentation of the paper could be improved to make the methodology and results more accessible. Certain sections, such as the explanation of concepts like subjective logic and the specifics of the evidence network, may be challenging to understand for readers unfamiliar with these areas. Additionally, while the framework is evaluated on multiple datasets, there is limited discussion on how the proposed method performs with varying levels of view conflicts and whether it scales well to datasets with more or less complexity. Furthermore, practical implementation details and hyperparameter settings are not thoroughly discussed, making it harder for practitioners to replicate the results. The introduction could better connect the problem and the proposed solution clearly and concisely.", "Questions": "1. How does the proposed computational trust-based method handle scenarios where all views are somewhat unreliable, and does it degrade gracefully in such cases?\n2. Can the authors provide more insights into how the choice of Binomial opinion theory affects the overall framework, and are there alternative theories that could be explored?\n3. Is there any analysis on the sensitivity of the method to hyperparameter choices, and how do these impact the overall effectiveness of the approach?\n4. Could the authors elaborate on how the method can be adapted or improved for application to domains with significantly different characteristics from those tested?"}}
{"paper_id": "cnKhHxN3xj", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel metric (Wasserstein distance) and method (Sparse Expansion) to tackle the problem of neuronal entanglement, offering a promising direction for improving sparsification techniques in LLMs. The approach is well-motivated and the experiments appear to demonstrate the benefit of disentangling neurons to retain model performance.", "Weaknesses": "The method's reliance on the Wasserstein distance assumes the output distribution should be Gaussian, which may not universally apply across different model architectures or tasks. The practical implementation details of Sparse Expansion, such as its scalability to different model sizes and inference time costs, are not thoroughly addressed. More clarity on the experimental setups would enhance reproducibility.", "Questions": "1. How does the assumption of Gaussian distribution in neuron output hold across different types of neural networks?\n2. What are the computational overheads associated with implementing Sparse Expansion, particularly in real-time applications?\n3. How does the method generalize to different types of neural networks beyond LLMs?"}}
{"paper_id": "dgR6i4TSng", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The paper introduces an innovative use of quantum computations to enhance parameter efficiency in fine-tuning large models, which is a novel approach not commonly explored in current literature.\n2. Quantum-PEFT shows significant reductions in parameters required for fine-tuning while maintaining competitive performance, suggesting practical applicability.\n3. The method is well-validated through experiments on standard benchmarks, demonstrating its effectiveness.", "Weaknesses": "1. The integration of quantum parameterizations raises concerns about the complexity and computational requirements for practical deployment, which are not deeply explored in the paper.\n2. The potential limitations or challenges in adopting quantum-inspired methods in real-world scenarios are not fully addressed, such as scalability issues with larger models or higher-dimensional data.\n3. Additional comparisons with a broader range of existing parameter-efficient fine-tuning methods would strengthen the validity of conclusions.", "Questions": "1. How does the computational overhead of implementing Quantum-PEFT compare to traditional methods like LoRA in practice?\n2. Are there specific types of models or domains where Quantum-PEFT may face limitations or require adaptations?\n3. What are the implications of quantum-inspired methods for future research directions in parameter efficiency and fine-tuning?"}}
{"paper_id": "ye1mxb79lw", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The introduction of BILBO addresses significant limitations in sample efficiency and practicality of existing bilevel optimization methods.\n2. Provides theoretical guarantees with regret bounds, elevating the trust in the method’s effectiveness.\n3. Demonstrates robust real-world applicability with well-conducted experiments in diverse settings.\n4. The integration of Bayesian optimization with bilevel frameworks is innovative and showcases substantial improvements over baselines.", "Weaknesses": "1. The paper could provide more comprehensive comparisons with a broader range of existing bilevel optimization techniques.\n2. Real-world applicability is demonstrated, but there might be a gap in discussing limitations or specific settings where BILBO may not perform as effectively.\n3. While the experimental results are strong, additional baselines would bolster the claims of BILBO's superiority.", "Questions": "1. How does BILBO compare in performance with recent state-of-the-art bilevel optimization methods outside the baselines considered?\n2. Were there any challenges faced during the implementation of BILBO that could inform potential users about its limitations or required adjustments?\n3. Could the approach be extended safely to more complex and dynamic bilevel environments, and what would be the potential hazards of such extensions?"}}
{"paper_id": "1fwZJzGdKj", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "pISLZG7ktL", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 8, "Confidence": 3, "Strengths": "The paper clearly identifies the gap in current robotics research regarding data scaling, which is well established in other fields like NLP and CV. It addresses this gap by effectively demonstrating that diversity of training environments and objects, rather than sheer number, enhances generalization in robotic manipulation. The use of real-world data and a robust evaluation protocol strengthens the validity of the findings. The study provides a clear strategy for data collection that could substantially improve zero-shot performance in novel environments.", "Weaknesses": "The study is limited to relatively simple tasks and could benefit from investigating a wider variety of more challenging tasks to assess scalability of the methods proposed. While increasing object diversity generally improves policy generalization, the study does not fully explore or explain cases where this isn't the case, hinting at possible unexplored variables. The lack of comprehensive standard deviations in the plots limits the assessment of empirical significance of the reported results.", "Questions": "1. Why does increasing the number of objects per environment sometimes decrease task performance, as seen in some plots? Could there be unknown variables affecting this outcome?\n2. What methodology or calculations are used to derive the correlation coefficient r in the results discussion?\n3. Are there plans or possibilities to extend this research to more complex and varied task domains, to further validate the scalability of the proposed data scaling law strategy?\n4. How does the chosen task impact the generalization efficiency? Would the power-law relationship hold consistently across vastly different tasks or is task specificity a potential confounding factor?"}}
{"paper_id": "dML3XGvWmy", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The proposed Gödel Agent framework offers a novel approach to AI systems by enabling them to self-evolve and adapt to a variety of tasks with minimal human intervention. \n2. Experimental results demonstrate significant performance gains over traditional agent systems across diverse tasks, showcasing the potential of recursive self-improvement in AI agents. \n3. The framework introduces innovative techniques, such as runtime code modification via monkey patching, which could provide new insights into agent design.", "Weaknesses": "1. The concept of self-evolving agents, while intriguing, may face practical challenges, such as ensuring stability and safety during runtime modifications. \n2. Comprehensive details on the experimental setup and baseline comparisons might be lacking, raising questions about the fairness of the evaluation. \n3. The framework's reliance on advanced LLMs like GPT-4 introduces complexities that may not be easily generalizable across other AI environments or tasks.", "Questions": "1. How does the Gödel Agent handle scenarios where runtime modifications could lead to erroneous or unsafe behaviors in real-world applications?\n2. Can the framework extend beyond the evaluated tasks of coding, science, and math? How adaptable is it to diverse AI use-cases?\n3. What measures were taken to ensure a fair comparison between the Gödel Agent and traditional systems, given the disparities in resources like LLM access?"}}
{"paper_id": "xlxGsX1pc7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The introduction of the U-MATH and µ-MATH benchmarks addresses a significant gap in evaluating LLMs on complex and advanced mathematical problems, particularly at the university level and including visual tasks.\n2. The benchmark's comprehensiveness, covering six core subjects with 20% visual components, offers a diverse and robust evaluation framework.\n3. The study provides valuable insights into the current limitations of LLMs in handling advanced mathematical reasoning and evaluation tasks, highlighting areas for future improvement.", "Weaknesses": "1. Current LLMs show limited performance on the proposed benchmarks, with low accuracy scores for both text-based and visual tasks, reflecting the challenges but also indicating the need for further development in model capabilities.\n2. While the benchmark is comprehensive, integrating more interdisciplinary problems might provide a broader assessment of LLM capabilities in diverse real-world scenarios.", "Questions": "1. Can the U-MATH benchmark be adapted or expanded to include interdisciplinary problems that blend mathematical reasoning with other fields?\n2. What are the future plans to enhance LLM capabilities based on the findings from the U-MATH and µ-MATH evaluations?"}}
{"paper_id": "AjXkRZIvjB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The introduction of GSM-Symbolic provides a fresh benchmarking perspective that highlights the weaknesses in LLMs' reasoning capabilities. The paper offers a thorough empirical analysis of current LLMs, showcasing their sensitivity to structural and content variations in reasoning tasks. The approach to systematically generate diverse question variants is a strong contribution to ensuring data robustness and reducing contamination risks.", "Weaknesses": "While the methodology introduces a new benchmark to test reasoning, it primarily reaffirms existing knowledge about LLMs' limitations without proposing solutions. The paper lacks depth in exploring potential avenues for overcoming the identified reasoning gaps. Also, the variation in LLM performance is largely attributed to intrinsic limitations rather than any architectural improvements or innovations proposed in the study.", "Questions": "How scalable is the GSM-Symbolic approach to other domains beyond math reasoning? What specific steps can be taken to address the fragility in reasoning detected by GSM-NoOp? Can the benchmark adapt to evaluate reasoning in nuanced, real-world scenarios?"}}
{"paper_id": "IJiTI0fB0e", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper introduces a novel framework for evaluating diversity in prompt-based generative models by decomposing kernel-based entropy into two separate scores. \n2. The approach provides valuable insights into distinguishing between prompt-induced and model-induced diversity, which is crucial for assessing generative models more accurately. \n3. The method is validated across different generative tasks, showing consistency with known benchmarks, indicating its practical applicability.", "Weaknesses": "1. The paper might not emphasize enough on the practical implications and potential limitations of applying the Conditional-Vendi and Information-Vendi scores to all generative models. \n2. While promising, the method may require additional validation in real-world scenarios to fully understand its advantages and limitations in diverse applications. \n3. The explanation of the information-theoretic concepts may be complex for readers unfamiliar with these methods, potentially limiting accessibility.", "Questions": "1. How do the Conditional-Vendi and Information-Vendi scores compare with existing diversity metrics beyond the experiments discussed in the paper? \n2. Are there computational constraints or challenges associated with implementing these metrics in large-scale or real-time generative systems? \n3. Can the approach be generalized or extended to other modalities outside text-to-image or text-to-video generation?"}}
{"paper_id": "fs2Z2z3GRx", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. The method proposed, Flow with Interpolant Guidance (FIG), shows significant improvements in solving challenging linear inverse problems, particularly in the presence of high noise or ill-posed conditions, outperforming existing state-of-the-art algorithms.\n2. The paper provides a theoretical foundation for guiding reverse-time sampling with measurement interpolants, which is novel and effectively bridges the gap between unconditional generation and measurement guidance.\n3. The proposed approach is efficient in terms of memory and runtime, enhancing its applicability in practical scenarios.", "Weaknesses": "1. The exposition of FIG and its methodological novelty could be made clearer to highlight its distinguishing features compared to existing methods.\n2. The reliance on pre-trained models may limit the applicability of FIG in scenarios where such models are not readily available or applicable.\n3. Some theoretical aspects, although sound, may lack intuitive explanations, which could help in understanding the broader implications of the approach.", "Questions": "1. How robust is the FIG method when applied to different types of linear inverse problems beyond image reconstruction?\n2. Can the interpolant guidance mechanism be generalized to other domains or problem settings aside from the ones considered in this paper?\n3. How sensitive is the proposed approach to the choice of measurement interpolants, and are there guidelines for selecting or designing effective interpolants?"}}
{"paper_id": "H4FSx06FCZ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper successfully introduces SecureGS, a novel technique that enhances security and efficiency for 3D Gaussian splatting steganography. It addresses existing limitations in rendering fidelity, computational costs, and security vulnerabilities. The method is rigorously tested and the experiments are extensively conducted, demonstrating significant improvements over existing approaches. The presentation of the work is clear and well-structured, making the proposed approach understandable.", "Weaknesses": "The paper may have a high complexity level which could potentially limit its practical application or adoption. The real-time computational demands of the proposed strategy may deter those seeking simpler alternatives.", "Questions": "How does SecureGS balance the trade-off between increased security and computational efficiency in real-time applications? Are there specific scenarios where SecureGS may not be applicable?"}}
{"paper_id": "OGtUfA6Amo", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper introduces a novel hierarchical patch graph network (Hi-Patch) that effectively captures multi-scale features in Irregular Multivariate Time Series (IMTS), addressing a significant challenge in time series analysis. \n\n2. Hi-Patch demonstrates superior performance over state-of-the-art models in forecasting and classification tasks, providing empirical evidence of its robustness and efficacy. \n\n3. The method is clearly articulated and targets practical issues in IMTS, such as varying sampling intervals and asynchronous observations.", "Weaknesses": "1. The paper may lack detailed insights into the scalability and computational efficiency of Hi-Patch, especially for large-scale datasets. \n\n2. The complexity of the model and its architectural details might be difficult for non-expert readers to fully comprehend, affecting the clarity of presentation. \n\n3. Additional experimentation across a broader set of diverse datasets could further validate the generalizability of the proposed approach.", "Questions": "1. How does Hi-Patch handle missing data in the time series, and what is its impact on the model's performance?\n\n2. What are the computational costs and resource requirements of the Hi-Patch model compared to existing approaches?"}}
{"paper_id": "ujpAYpFDEA", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The paper addresses a significant gap in the field of LLM watermarking by focusing on imperceptibility, which has been underexplored yet is crucial for practical deployment.\n2. The introduction of the Water-Probe algorithm provides a novel way of detecting watermarked LLMs, showing high accuracy in detection.\n3. The proposed Water-Bag strategy helps improve imperceptibility, adding to the practical value of the research.", "Weaknesses": "1. The paper's approach might be limited to specific types of watermarking schemes, and it's unclear how well it performs against more sophisticated watermarking techniques.\n2. While the concept of enhancing imperceptibility is vital, the trade-off in detection accuracy with the Water-Bag strategy might limit its applicability in certain high-stakes scenarios.\n3. The research could benefit from deeper theoretical justification or analysis of why the proposed methods work beyond empirical evidence.", "Questions": "1. Can the Water-Probe algorithm be adapted or expanded to handle more complex watermarking approaches that might be less predictable?\n2. How does the trade-off between imperceptibility and detectability impact real-world use cases, especially where high security is needed?\n3. Are there any specific LLMs or applications where the proposed methods would not be applicable or effective?"}}
{"paper_id": "7UKHNQIErp", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. The paper proposes a novel formalism to understand and develop DPA losses using symbolic logic, which could significantly aid in the theoretical understanding of DPA methods.\n2. It provides a structured landscape for DPA loss functions, facilitating the exploration of new variants and enhancing human-AI alignment.\n3. The presentation of the paper is clear and well-organized, aiding in the comprehension of its complex theoretical contributions.", "Weaknesses": "1. There is a potential risk of the proposed framework leading to exponential computational complexity, which might limit practical applicability.\n2. Certain notations and concepts are not explained for readers unfamiliar with DPA literature, which could hinder understanding.\n3. Some references within the paper are incorrect, which might cause confusion when trying to cross-reference information.", "Questions": "1. Can you clarify the computational cost associated with enumerating all propositional models in the proposed approach?\n2. What assumptions are made in the use of 'Simplify' in Algorithm 1, considering the NP-hardness of minimizing propositional formulas?"}}
{"paper_id": "CpgWRFqxhD", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. MEMO introduces innovative modules, like the memory-guided temporal module and the emotion-aware audio module, that significantly enhance video quality and synchronization.\n2. The method demonstrates robust performance across diverse datasets, indicating strong generalization abilities.\n3. Ablation studies in the paper confirm the importance and effectiveness of the proposed components.", "Weaknesses": "1. The reliance on emotion classification could introduce biases or inaccuracies if the emotion classifier does not perform well.\n2. The paper lacks detailed computational analysis regarding the model's efficiency, speed, and required resources, which are crucial for practical applications.", "Questions": "1. How does the performance of MEMO vary with different emotion classifiers? \n2. Can the model adapt to languages other than English effectively, or does performance degrade with non-English audio inputs?\n3. Will the processed dataset used in training be made public for further research and validation?"}}
