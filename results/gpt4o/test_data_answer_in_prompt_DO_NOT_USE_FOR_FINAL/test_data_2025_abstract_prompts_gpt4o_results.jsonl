{"paper_id": "u3xwwfHmBC", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The TTformer model introduces a novel approach that effectively captures the spatio-temporal dependencies in traffic forecasting, which is a significant advancement in the field. The use of tense-specific attention modules is a creative solution. The inclusion of contrastive learning for robustness further strengthens the model.", "Weaknesses": "There may be a lack of detailed explanation regarding the implementation and impact of the tense-specific attention modules and contrastive learning. The model's computational complexity and scalability in real-world settings are not addressed.", "Questions": "How does the TTformer model compare in terms of computational efficiency with existing models? Are there specific scenarios where TTformer may not perform as well?"}}
{"paper_id": "YKvBiRWdQC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The Overcooked Generalisation Challenge provides a novel benchmark for studying zero-shot cooperation in reinforcement learning agents. The challenge supports state-of-the-art dual curriculum design methods, is GPU-accelerated, and is open-source, which are substantial assets to the research community. The work addresses a crucial gap in existing benchmarks by focusing on generalisation abilities, setting the stage for future research in cooperative AI.", "Weaknesses": "The abstract raises some concerns about the limitations of the state-of-the-art algorithms when applied to this new benchmark, suggesting a potentially steep difficulty level. While this is a meaningful outcome, it highlights the complexity of the challenge without proposing specific solutions or improvements to current methods. Additionally, the abstract does not detail how the proposed challenge might be used to enhance existing algorithms or inform new approaches beyond identifying their failures.", "Questions": "What specific metrics or criteria are used to assess zero-shot cooperation in the Overcooked Generalisation Challenge? Can this benchmark suggest actionable insights for improving current reinforcement learning approaches or network architectures?"}}
{"paper_id": "tePFpDgyqg", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses the important challenge of training language models on long contexts by focusing on data quality, specifically through long-distance referrals. The LongPack pipeline introduces a scalable and efficient approach to generate high-quality long documents, utilizing web pages and hyperlink structures, which naturally encapsulate long-distance relationships.", "Weaknesses": "The novelty of the approach may be limited to specific types of data, such as web pages with hyperlinks, potentially limiting its general applicability across different domains of text data. Additionally, while improvements are claimed, more rigorous evaluation and comparison with existing methods in various scenarios would strengthen the paper.", "Questions": "How well would the LongPack approach generalize to sources of information that don't inherently rely on hyperlink structures, such as books or traditional academic papers? Are there plans to enhance the pipeline to accommodate such data?"}}
{"paper_id": "gx3LMRB15C", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents a novel augmentation-free self-supervised learning method for tabular data which addresses the difficulty in constructing data augmentations for such data. It demonstrates improved performance on downstream tasks, matching or surpassing traditional methods like Gradient Boosted Decision Trees.", "Weaknesses": "There is a potential lack of clarity in explaining certain concepts and how the novel method compares with existing approaches. The experimental validation could be expanded to cover more diverse datasets.", "Questions": "How does the proposed method compare to other recent augmentation-free SSL approaches for tabular data in terms of computational efficiency and feature interpretability?"}}
{"paper_id": "kTH3bEH6hW", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a method to enhance few-shot learning in tabular data by using range-limited augmentation, which presumes the semantic consistency in data enhancement. This approach seems to effectively preserve task-relevant information and improve performance. Furthermore, the introduction of a new benchmark, FeSTa, comprising 42 datasets and 31 algorithms, is a significant contribution to the field.", "Weaknesses": "The novelty of the proposed range-limited augmentation method could be limited as it builds upon established augmentation techniques from other domains such as image processing. Additionally, there is a potential narrow scope since the approach is highly specialized for tabular data. There are also concerns about the broader applicability of the method to other data types.", "Questions": "How does range-limited augmentation compare to traditional augmentation techniques from fields like image or text in terms of applicability and performance improvements?"}}
{"paper_id": "EqcLAU6gyU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper proposes a novel framework for agent-oriented planning in multi-agent systems by highlighting important design principles. The integration of a feedback loop enhances the effectiveness and robustness of the proposed solution. Empirical results demonstrate the framework's superiority over existing strategies.", "Weaknesses": "The abstract lacks detailed information about the experiments and specific results, making it difficult to assess the full impact of the contribution. The evaluation process and reward model are not elaborated upon in the abstract.", "Questions": "How does the proposed framework compare quantitatively with existing methods in terms of efficiency and quality of problem-solving? What are the specific metrics used for evaluation?"}}
{"paper_id": "qrTrnrEi9d", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel framework, TransFusion, which enables cross-lingual transfer learning for low-resource languages using a creative approach of translating data into English for better model training. It demonstrates significant improvements in performance across multiple languages and tasks, including named entity recognition. The proposed method successfully leverages translation and instruction tuning, showing versatile applicability in both zero-shot learning and fine-tuned scenarios.", "Weaknesses": "The paper lacks detail in explaining the methodology, particularly the specifics of the TransFusion framework and how exactly the annotation fusion is implemented. While improvements are noted, the reasons behind specific performance metrics are not thoroughly analyzed, and the reliance on proprietary models like GPT-4 may limit reproducibility. The paper could also improve in providing a clearer explanation of experimental setups and baseline comparisons.", "Questions": "How does the translation quality into English affect the overall performance of the model, and what translation tools or methods are used? Are there specific annotated datasets used for fine-tuning that are known to be poor in quality, and how does that impact the results? Could the framework be extended beyond the named entity recognition to other NLP tasks, and what challenges might arise in doing so?"}}
{"paper_id": "Bp0HBaMNRl", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents a novel differentiable algorithm for causal discovery in nonlinear latent hierarchical models which addresses scalability and applicability issues faced by existing methods. The approach improves both accuracy and scalability, showing practical utility in handling high-dimensional data.", "Weaknesses": "The presentation could be clearer in explanations of some technical aspects, and some baseline comparisons to domain literature, especially for empirical results, seem underexplored.", "Questions": "How does the proposed method compare to existing methods in terms of computational efficiency beyond the reported datasets, and how generalizable are the learned structures in various domains?"}}
{"paper_id": "JzLcKWtGnl", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel architecture, Spatial 3D-LLM, that improves spatial perception in 3D vision-language models, which is a crucial area for advancing AI capabilities in understanding complex environments. It also introduces new tasks and a dataset, which could drive further research in the field.", "Weaknesses": "The paper lacks detailed comparisons with existing state-of-the-art models and does not provide a comprehensive analysis of the potential limitations of the proposed method. The novelty of the tasks and dataset, while interesting, could be better contextualized within the current research landscape.", "Questions": "How does the proposed model perform compared to specific existing benchmarks? What are the specific limitations of the method, if any, when applied to more complex 3D scenes?"}}
{"paper_id": "hXJrQWIoR3", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach for explainable graph representation learning by leveraging graph pattern analysis. It presents theoretical analyses regarding robustness and generalization, which is commendable.", "Weaknesses": "The approach might have limitations concerning computational complexity due to pattern analysis. Node feature integration is not thoroughly discussed. The presentation could be improved with more detailed explanations and connections to existing methods.", "Questions": "How does the proposed method compare in terms of computational efficiency with existing approaches? Are there any specific limitations or challenges in extending this method to more complex graph structures?"}}
{"paper_id": "67sSPPAZiG", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The work provides a substantial contribution to the field of egocentric video understanding by generating a large dataset of QA samples and proposing a novel multimodal architecture with a unique 'Memory Pointer Prompting' mechanism. The presentation of the paper is clear and logically structured, enabling the reader to follow the methodology and results.", "Weaknesses": "The first contribution regarding the creation of a QA dataset may not be as novel as claimed, considering similar approaches in the field. Additionally, the presented benchmark might not be sufficiently distinct from existing benchmarks to warrant being highlighted as a major contribution without further comparison to other datasets.", "Questions": "How does the novel architecture perform when compared to existing models using different datasets? Can the dataset and benchmark be further enriched by leveraging other existing datasets in the field?"}}
{"paper_id": "kjmLabjSE2", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides convergent R\\'enyi DP bounds for non-convex non-smooth losses, extending results by relaxing assumptions to Holder continuous gradients. This answers open questions in recent works. It also improves upon privacy bounds for smooth strongly convex losses. Novel approaches like forward Wasserstein distance tracking and optimal shift allocation illustrate a clear and logical methodology.", "Weaknesses": "The paper may not clearly contrast practical differences from existing methods or directly demonstrate significant real-world applications. There is a reliance on theoretical constructs which may limit practical applicability without further development. Some technical aspects may be challenging for non-experts to grasp without additional supporting material or simplified explanations.", "Questions": "Does the Holder continuous gradient condition apply to widely-used loss functions in practice, or is it more of a theoretical interest? Can the authors provide intuitive examples or applications where their improved privacy bounds decisively outperform existing methods under realistic settings?"}}
{"paper_id": "I18MA5DjoP", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a new analytical framework, Neuron Predictability Lens (NPL), that offers insights into how neurons function within feed-forward networks of large language models. This approach can uncover the predictability of neuron activations and has implications for improving model efficiency and effectiveness.", "Weaknesses": "Some aspects of the experiment, such as the high PPL values on LLAMA-2 and GPT-J, suggest potential issues in experimental setup or model convergence. The explanation of certain equations and methodologies in the paper could be clearer.", "Questions": "How does the NPL specifically enhance our understanding of transformer models beyond existing analysis techniques? Is there evidence that models optimized using NPL insights can outperform traditional fine-tuned models?"}}
{"paper_id": "qpDqO7qa3R", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The method offers a novel approach by leveraging pre-trained image diffusion models for video restoration, allowing it to perform well across various degradation types without re-training. The use of a hierarchical latent warping strategy and hybrid correspondence mechanism is innovative and shows significant generalization capabilities.", "Weaknesses": "The paper may face challenges in reproducibility due to its reliance on specific pre-trained models and possibly intricate implementation details. Some claims of superiority over trained models might require more extensive benchmarks.", "Questions": "How does the method handle computational complexity, especially concerning the hierarchical warping and hybrid correspondence? Are there any limitations on the types of pre-trained diffusion models that can be used effectively?"}}
{"paper_id": "dSQtMx6dPE", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses the novel problem of privacy risks in graph prompt learning with GNNs, an area not previously explored. It proposes a new approach using differential privacy to mitigate these risks, with strong theoretical grounding.", "Weaknesses": "The paper could benefit from more extensive experimental validation, particularly regarding the practical effectiveness of the proposed methods across a wider range of scenarios. The discussion on the limitations of the proposed methods could be more thorough.", "Questions": "How does the proposed method compare with existing privacy-preserving approaches in terms of computational efficiency? Are there specific graph types or domains where the approach is more or less effective?"}}
{"paper_id": "GbgCRJedQ7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a novel Sparse Matrix Tuning method that reduces the performance gap between parameter-efficient fine-tuning and full fine-tuning, while also reducing computational and memory costs. It demonstrates consistent performance improvements over other baseline methods in experiments with large language models.", "Weaknesses": "The abstract does not provide detailed information on the theoretical foundations of the Sparse Matrix Tuning method, or how it specifically selects the most significant sub-matrices. There may be a lack of a thorough comparison with existing state-of-the-art methods in parameter-efficient fine-tuning.", "Questions": "How does the Sparse Matrix Tuning method specifically identify and select the most significant sub-matrices for updating during the fine-tuning process? Are there any theoretical guarantees on the performance improvement of SMT over other precise methods like LoRA and DoRA?"}}
{"paper_id": "ZZVOrId3yN", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel architecture, CrossModalNet, for multimodal medical image segmentation, addressing complex integration challenges with advanced mathematical frameworks and a new domain adaptation technique. The theoretical analysis provides strong justification for the architecture's capabilities, and the introduction of the CMIF metric offers a new insight into the progressive integration of multimodal data.", "Weaknesses": "The paper may require more extensive validation across diverse datasets to establish its general applicability and robustness. The dependence on mathematical proofs may limit accessibility to a more general audience without a strong mathematical background.", "Questions": "How does CrossModalNet perform on datasets beyond MM-WHS, particularly those with different types and qualities of multimodal data? What are the computational costs associated with the proposed architecture compared to existing models?"}}
{"paper_id": "gLHuAYGs6a", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a significant challenge in multi-view clustering and incorporates structure information effectively. The proposed method is innovative, using heterogeneous random walks to enhance clustering performance, which is systematically evaluated across five real-world datasets.", "Weaknesses": "The paper lacks theoretical analysis regarding the convergence and complexity of the proposed algorithm. The explanation for why the new method outperforms others is not deeply explored, leaving some questions about its underlying advantages.", "Questions": "What are the time and space complexities of the proposed method? Is there a theoretical guarantee for the convergence? How does the method theoretically ensure improvement in clustering performance compared to existing methods?"}}
{"paper_id": "x5l5PRtvul", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces h-SVGD, which addresses variance collapse in SVGD without additional computational cost. It provides rigorous theoretical backing for the proposed algorithm, including existence of solutions, characterization of fixed points, and other properties.", "Weaknesses": "The presentation could be improved; some parts are hard to follow due to lack of intuitions and commentary. Several assumptions lack discussion, and there are minor typos and inconsistencies in the notation that can lead to confusion.", "Questions": "Could you further clarify Assumptions (A1)-(A3) and provide examples of potentials that meet these conditions? How does the h-SVGD compare to other SVGD variants in practice beyond variance collapse alleviation?"}}
{"paper_id": "pOUAVXnOQP", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel activation function that addresses spectral bias in neural networks, significantly improving signal reconstruction capabilities. It demonstrates superior performance against established methods in terms of accuracy and convergence speed. The extensive experimental evaluation shows its potential for real-world applications.", "Weaknesses": "The paper may lack detailed analysis on potential limitations or specific scenarios where the proposed method may not perform optimally compared to conventional methods. Further discussion on computational overhead and practical deployment would strengthen the contribution.", "Questions": "How does the implementation complexity of STAF compare to conventional methods like ReLU or SIREN, especially in real-time applications? Are there specific types of signals or datasets where STAF might not provide significant advantages?"}}
{"paper_id": "iN64nSYt0z", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces a novel method called GUIDE that improves the alignment of LLM outputs with user instructions by increasing attention scores on instruction tokens. This approach demonstrates a substantial improvement in accuracy, outperforming natural prompting alternatives.", "Weaknesses": "The paper lacks detailed comparison with other state-of-the-art methods. The proposed new metric, Influence, needs more validation to establish its effectiveness comprehensively.", "Questions": "How does the performance of GUIDE vary with different types of user instructions and model architectures? Can Influence be generalized across different LLMs?"}}
{"paper_id": "gRuZkEy49k", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents an innovative application of Monte-Carlo Tree Search (MCTS) to GFlowNet training, illustrating both theoretical and practical improvements over standard sampling methods. The work is well-situated within the context of existing research and draws on known connections between GFlowNets and maximum-entropy reinforcement learning. The extensive experiments across various discrete domains demonstrate the effectiveness of the proposed method.", "Weaknesses": "Some aspects of the experimental methodology, such as the representation of statistical significance in results, could be improved for clarity and reliability. While the adaptation of MCTS for GFlowNets is an interesting advancement, more detailed analysis or comparison with alternative sampling methods would strengthen the paper's contributions.", "Questions": "How does the proposed MCTS adaptation compare to other non-MCTS-based sampling strategies for GFlowNets in terms of efficiency and performance? Can the authors provide more insight into the computational complexity of their proposed method compared to the baseline?"}}
{"paper_id": "d23EVDRJ6g", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces a novel approach to motion generation using masked transformers, demonstrating superior performance against state-of-the-art GAN and diffusion-based methods. The use of quantization and codebook construction for motion patterns is innovative. Experiments are comprehensive, showing effectiveness in various tasks.", "Weaknesses": "The paper does not articulate the unique contributions clearly in comparison with existing works, leading to some difficulty in assessing the novelty. Overfitting concerns with small datasets are mentioned but not deeply explored. The evaluation could include more quantitative metrics for diversity and faithfulness.", "Questions": "How does MotionDreamer specifically handle overfitting with small datasets in comparison to other methods? Are there quantitative results for diversity and faithfulness beyond qualitative evaluation?"}}
{"paper_id": "kQ5s9Yh0WI", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel method, AgentWrite, which effectively tackles the problem of output length limitation in current LLMs by decomposing ultra-long generation tasks into subtasks. The approach is innovative and demonstrates significant improvements in output length capability. The introduction of the LongWriter-6k dataset and the LongBench-Write benchmark are valuable contributions to the field, providing tools for further research and development.", "Weaknesses": "The experiments might lack variety in terms of different model architectures or dataset domains, which could provide a more comprehensive evaluation. Additionally, the reliance on a new dataset for improving model performance might suggest a lack of generalizability across different datasets.", "Questions": "1. How does AgentWrite handle context coherence across decomposed subtasks, especially for very long outputs?\n2. Are there any potential limitations or bottlenecks observed when scaling the output lengths beyond the tested scenarios?\n3. How does the method perform across various LLM architectures or on tasks/domains not covered in the paper?"}}
{"paper_id": "9CqkpQExe2", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel Ada-K routing strategy that dynamically adjusts the number of activated experts for each token, leading to improved balance between computational efficiency and model performance. It shows significant gains over conventional Top-K routing in terms of FLOPs reduction and inference speedup while improving performance on various benchmarks. The proposed method is practically applicable across all mainstream MoE-based LLMs and provides valuable insights for future adaptive MoE system designs.", "Weaknesses": "The paper may lack a comparison with other state-of-the-art MoE approaches or methods beyond Top-K, which could provide a more comprehensive evaluation of the proposed method's effectiveness. Additionally, the scalability and generalization of the Ada-K strategy to other large-scale models not discussed in the paper may require further investigation.", "Questions": "How does the Ada-K strategy perform when scaled to even larger models or different architectures beyond the ones evaluated in the paper? Furthermore, what are the potential challenges in implementing this routing strategy in a real-world environment, considering factors like hardware compatibility and deployment complexity?"}}
{"paper_id": "PpYy0dR3Qw", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces LoCoDL, a novel approach combining local training and compression, proving to have accelerated communication complexity with theoretical backing.", "Weaknesses": "The paper may lack extensive empirical validation across diverse settings and potentially insufficient exploration of non-strongly convex cases.", "Questions": "How does LoCoDL perform in non-convex settings, and are there any limitations in terms of model scale or specific compressor types?"}}
{"paper_id": "UatDdAlr2x", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides insightful analysis on how architectural choices affect transformer models, particularly highlighting the influence of various hyperparameters on learning strategies. The theoretical characterization of two distinct counting strategies within transformers adds depth to our understanding of model behaviors.", "Weaknesses": "The study is limited to simplistic transformer settings, focusing on single-layer models and a single task (histogram counting). This diminishes the broader applicability of the findings to more complex, real-world transformer applications. Additionally, the paper does not provide guidance on extending these insights to multilayer transformers or more diverse tasks.", "Questions": "How can the findings from the histogram task be generalized to more complex tasks or multi-layer transformer architectures? Are there potential implications or experiments that can explore these characterizations in a broader context?"}}
{"paper_id": "IwgmgidYPS", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 5, "Strengths": "The dataset provides a large collection of over 25 million images across 10 modalities with comprehensive multigranular annotations. The use of an automated pipeline for generating these annotations from image-ROI-description triplets is innovative. The dataset supports a wide range of tasks and the newly proposed LLaVA-Tri model achieves state-of-the-art results, showcasing its utility.", "Weaknesses": "The abstract lacks specific details about the methodology used in the automated pipeline. It is unclear how the dataset addresses potential quality and bias issues arising from the diversity of sources.", "Questions": "How does the automated pipeline ensure high-quality and accurate annotations? Are there any measures taken to mitigate potential biases in the dataset?"}}
{"paper_id": "WG7GzGx3G9", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper addresses a critical issue in the deployment of large language models, offering a novel method (RRS) that improves quantization without the drawbacks of existing techniques. This method shows a clear improvement in perplexity for INT4 inference, indicating its potential practical impact.", "Weaknesses": "The implementation details and potential computational overhead of the proposed methods are not thoroughly discussed, which may impact their real-world applicability. Additionally, there is no discussion on the scalability of the approach for different model sizes or types.", "Questions": "How does the proposed method RRS impact computational efficiency compared to existing quantization methods? Is there any planned investigation on its scalability across other model architectures?"}}
{"paper_id": "BhECSDSkAE", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 5, "Strengths": "1. The paper presents a novel task for one-shot medical video object segmentation, addressing the challenge of limited annotated video data in the medical domain by leveraging labeled static images.\n2. The proposed framework is innovative, including a memory mechanism for spatiotemporal context utilization and a self-distillation strategy, demonstrating effective adaptation from static images to video segmentation.\n3. The contribution of the OS-I2V-Seg dataset greatly facilitates future research in the community, providing a robust benchmark with diverse categories and extensive data points.", "Weaknesses": "1. The lack of explicit implementation details and potential limitations concerning the complexity and computational efficiency of the proposed method might hinder reproducibility and practical application without further clarification.\n2. While the paper demonstrates strong baseline performance, the generalization of the method across different medical imaging modalities remains uncertain, given that only four video categories are included.", "Questions": "1. How does the efficacy of the proposed method vary across different medical imaging modalities, and is there potential for domain-specific optimization?\n2. Can the memory mechanism and self-distillation strategy be generalized or extended to non-medical video applications, potentially improving the adaptability of the approach?"}}
{"paper_id": "mnB4hDTIDr", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper proposes a novel method, DCScore, which addresses diversity evaluation in LLM-generated datasets. The method is theoretically grounded and offers lower computational costs than existing approaches. It also unifies existing evaluation methods, providing a versatile tool for dataset diversity evaluation.", "Weaknesses": "The discussion on the real-world impact and practical applications of DCScore is limited. Additionally, the explanation of how DCScore achieves its lower computational cost could be clearer. The experimental validation, while promising, could be more robust with additional datasets and scenarios.", "Questions": "How does DCScore specifically address the lack of diversity in LLM-generated datasets differently from other existing methods? What are potential limitations or biases introduced by using a classification perspective for diversity evaluation?"}}
{"paper_id": "Y0qmwm6tgy", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses the instability problem of gradient pruning in large language models caused by weight perturbations. It proposes a novel pruning method, MoreauPruner, with a theoretical basis in optimization analysis and robustness claims against such perturbations. The method is thoroughly evaluated on multiple large language models, showing improvements over existing pruning techniques.", "Weaknesses": "The explanation of the added value and necessity of robustness against weight perturbations could be clearer. The performance improvements illustrated in the paper, while present, are not overwhelming and the justification of why smaller 'Diff' in perturbations is significant still needs reinforcement. Moreover, the restricted set of models evaluated limits the generalizability of the results.", "Questions": "Why specifically is robustness to small perturbations crucial in practice beyond numerical type error considerations? How do the performance gains of MoreauPruner compare in terms of computational cost to other pruning methods? Are there potential applications outside of the tested LLaMA family that could benefit from MoreauPruner?"}}
{"paper_id": "aAcOaJYbUg", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses an important problem in evaluating out-of-distribution (OOD) robustness in computer vision models with innovative contributions to the field.\n2. The introduction of the LAION-C benchmark provides a novel way of evaluating modern models that have been exposed to web-scale datasets, offering a fresh perspective compared to standard benchmarks like ImageNet-C.\n3. The approach includes a rigorous methodology, including psychophysical experiments comparing human robustness to model performance, which enhances the credibility and comprehensive nature of the results.", "Weaknesses": "1. The paper does not fully explore potential limitations or biases in the proposed LAION-C benchmark and does not address how these could impact the evaluation of model robustness.\n2. While the paper introduces a new OOD benchmark, it may lack a detailed discussion on how to integrate these results into a broader understanding of model performance on real-world tasks, potentially limiting practical applicability.", "Questions": "1. How do the authors plan to address any potential class imbalances between LAION-C and web-scale datasets during evaluation and analysis?\n2. Are there any plans to expand the types or severity of distortions in LAION-C to account for future developments in model training and dataset collection?"}}
{"paper_id": "duGygkA3QR", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper offers a novel integration of Dynamic Mode Decomposition (DMD) with Graph Neural Networks (GNNs), providing a unique perspective on utilizing dynamic systems theory for graph-based learning tasks. The authors validate their approach with extensive experiments, demonstrating superior performance on a variety of challenging tasks, highlighting the potential to capture complex graph dynamics efficiently.", "Weaknesses": "The motivation for using DMD over other existing dynamic analysis methods in the context of GNNs is not fully justified. While results highlight performance improvements, further discussion on computational efficiency and scalability, especially on very large-scale graphs, would strengthen the paper. Additionally, clarity in explaining how DMD's dynamic operator aligns with real-world interactions in graphs could be improved.", "Questions": "How does the computational complexity of the proposed DMD-GNN compare with traditional GNN methods in large-scale applications? Can the authors provide further insights on potential domain-specific applications where this approach might particularly excel beyond traditional methods?"}}
{"paper_id": "s6nYndMwG7", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 2, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides a novel analysis for choosing hyperparameters in the LiSSA algorithm based on spectral properties of the Hessian, which could potentially improve the practicality of influence functions for large models. The use of random sketching to evaluate these spectral properties is a new approach and adds to the field by proposing a scalable solution to a known problem. The empirical validation against PBRF is well-conceived and helps to confirm the theoretical findings.", "Weaknesses": "The main theoretical contribution may rely on strong assumptions that can be challenging to verify in practice, leaving the applicability under practical scenarios uncertain. The presentation of empirical results could be clearer, with some conclusions being difficult to align directly with the provided figures and data. Additionally, while the parameter selection method is discussed, it lacks explicit details and guidance for practitioners, potentially limiting its utility.", "Questions": "1. How do the assumptions required for the main theoretical contribution apply to real-world tasks and models, especially given the conditions outlined?\n2. Can the authors provide a clear, step-by-step example of parameter selection for LiSSA in a specific scenario?\n3. Are there any specific model sizes or architectures where the proposed method might struggle, based on current evaluations?\n4. How do the authors suggest validating the assumptions on spectral properties in diverse datasets outside of those empirically tested?"}}
{"paper_id": "9BVMD3keG8", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides a novel approach to addressing the online learning problem of brokerage with a clear analysis of regret and matching lower bounds. The algorithms proposed are theoretically sound under the provided assumptions.", "Weaknesses": "The assumptions regarding traders' valuations and the contextual information might limit the applicability of the results in real-world scenarios. Some parts of the model might be too simplistic or unrealistic, potentially affecting the overall contribution.", "Questions": "How do the assumptions about contextual information and traders' valuations impact the applicability of the model in real-world trading scenarios?"}}
{"paper_id": "mnna9LUg7P", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a static 8-bit quantization method for state space models, successfully demonstrating reduced generation latency with minimal accuracy drop. It addresses the specific challenges of SSM quantization, suggesting practical applicability for cloud and edge deployments.", "Weaknesses": "Existing quantization methods may not have been sufficiently compared, raising questions about the comprehensive applicability of the proposed method. The presentation could benefit from additional clarification in places, particularly in explaining long-term scalability across different hardware.", "Questions": "What are the potential limitations of the proposed quantization method when applied to varied hardware configurations? Can further technical details be provided on the Hadamard transform's role in achieving outlier-free quantization?"}}
{"paper_id": "3X3LuwzZrl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The proposed approach effectively leverages label influence propagation to improve multi-label node classification. It dynamically adjusts learning by amplifying and mitigating label influences, demonstrating superior performance over state-of-the-art methods.", "Weaknesses": "The paper lacks a comprehensive comparison with existing label propagation methods. It is unclear if the influence of hyperparameters like \\alpha and \\beta has been thoroughly analyzed. Additionally, there are issues with label and figure clarity, such as missing axis labels.", "Questions": "How does the approach compare with existing label propagation techniques? Have hyperparameters like \\alpha and \\beta been thoroughly analyzed? Can the authors provide visualizations illustrating the influence of different labels?"}}
{"paper_id": "IqaQZ1Jdky", "review": {"Soundness": 2, "Presentation": 3, "Contribution": 3, "Rating": 4, "Confidence": 3, "Strengths": "The paper introduces an innovative modification to KANs by incorporating a flexible function basis, potentially enhancing both accuracy and interpretability. Comprehensive experiments across multiple tasks validate their approach. The writing is generally clear and well-organized.", "Weaknesses": "There is skepticism regarding the actual impact of the proposed modifications, as improvements over baseline KANs are marginal. Some theoretical claims are not backed by experiment results. The lack of comparison with state-of-the-art models for specific datasets is noted.", "Questions": "How does the choice of $n$ in the polynomial basis affect model performance, and is there a practical guideline for its selection? Can the authors clarify the implementation details of varying $n$ in VBn-KAN?"}}
{"paper_id": "OdMqKszKSd", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The method allows articulated object generation from a single image, making it potentially more scalable and practical than prior works requiring multi-view or multi-state inputs. The use of a diffusion model to handle shape and motion ambiguity is innovative, and experiments show a significant improvement over state-of-the-art in terms of realism and resemblance. The paper is presented clearly with a structured approach.", "Weaknesses": "The method relies on ground-truth annotations and existing databases for part retrieval, which may limit real-world applicability. The practicality of handling a broad range of object categories was not fully demonstrated. Some components of the method yield minimal gains. Dependency on GPT-4o raises concerns about specific design contributions.", "Questions": "How does the method generalize to object categories not included in the training set? Can the approach handle more complex articulation scenarios beyond those tested? How robust is the method to variations and noise in the input single image?"}}
{"paper_id": "LOBhVTtVnc", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents a novel approach called Geometric Spatiotemporal Transformers (GSTs) that effectively combines the strengths of Transformers for spatiotemporal graph inputs, which is an innovative contribution to physical dynamics simulation. The introduction of the Temporal Difference Graph (TDG) is a clever mechanism to mitigate cumulative errors in long-term prediction tasks. Moreover, the approach shows state-of-the-art performance across multiple challenging physical systems, demonstrating its robustness.", "Weaknesses": "The paper does not provide detailed information on runtime or parameter efficiency comparisons with existing methods, which is essential to understand practical applicability. Additionally, the complexity and scalability of the proposed method, particularly for very large systems or extended prediction horizons, are not fully addressed. The datasets evaluated are relatively small in terms of rollout timesteps, which might not fully demonstrate the long-term prediction capabilities claimed.", "Questions": "What are the computational requirements of GSTs compared to other state-of-the-art methods for similar tasks? How does the model handle extremely large-scale systems or datasets with longer temporal spans? Can the method be applied or adjusted for different types of physical simulations not covered in this paper?"}}
{"paper_id": "oa5UeyUVMm", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "Graffe demonstrates competitive performance in graph representation learning, achieving state-of-the-art results on numerous datasets. The theoretical advancement of proving the objective maximizes conditional mutual information provides a strong foundation.", "Weaknesses": "The novelty of adapting DPMs to graph representation learning is somewhat limited by existing techniques, and the theoretical insights need more practical demonstration. Some evaluations and ablations could be extended for a deeper understanding.", "Questions": "How does the choice of mask ratio impact the performance across different datasets, and can an optimal ratio be generalized? What insights support the architectural choices in the encoder and decoder, and are there alternative architectures considered?"}}
{"paper_id": "5swfKRkCx7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a novel approach that integrates external knowledge with large language models for question answering. It introduces an extra attention mechanism and a memory-based mechanism to dynamically control knowledge integration, enhancing the effectiveness of RAG techniques.", "Weaknesses": "While the approach is novel, the paper lacks detailed explanations of the mechanisms and their intuitive grounding. Some methodological choices are unclear, such as details about the alignment of the latent spaces. The experiments could be more comprehensive in demonstrating the approach's benefits over existing methods.", "Questions": "Could the authors provide more details on the memory-based mechanism and how the degree of knowledge integration is dynamically controlled? How does the extra attention head integrate with the internal heads of the LLMs?"}}
{"paper_id": "5s1qpjrNvZ", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel reinforcement learning approach with a performance guarantee for guided methods. It provides a robust method for adapting guide policy sampling rates to maintain a user-defined performance threshold, which is a significant contribution to the field.", "Weaknesses": "The empirical evaluation could be more comprehensive, and the results are limited to specific scenarios and assumptions. The practical applicability is somewhat restricted, and the assumptions made for deriving the guarantees might not hold in real-world scenarios.", "Questions": "How does the method perform in more complex and diverse environments? What are the limitations of the assumptions used for deriving the performance guarantees in practical applications?"}}
{"paper_id": "WNb4P8aG66", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces an innovative multi-stage generation framework, Diffusion on Diffusion (DoD), that improves the texture details in image generation while reducing computational costs. It presents a novel approach by integrating visual priors from generated samples for better guidance in a diffusion model. The method is thoroughly evaluated on the ImageNet dataset, demonstrating superior efficiency and performance compared to state-of-the-art methods.", "Weaknesses": "The paper primarily compares against basic diffusion models but lacks comparisons against other post-hoc diffusion methods and other image feature conditioning methods. The main results table is not well positioned for visibility and lacks in-depth analysis. Qualitative results are hard to interpret without specific guidance on improvements.", "Questions": "How does the proposed method compare to other post-hoc diffusion methods and image feature conditioning techniques? Can you provide more specific analysis or guidance on the qualitative results to help interpret the improvements?"}}
{"paper_id": "UfczlMudN6", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel framework for dynamics generalization in deep reinforcement learning, addressing an important problem in the field. It combines mechanisms for both in-distribution and out-of-distribution generalization, demonstrating strong performance across various scenarios.", "Weaknesses": "The experimental evaluation may be limited to specific simulated environments, and the paper may not address recent related work comprehensively.", "Questions": "How does the proposed framework perform in more diverse environments beyond the tested locomotion tasks? Are there any assumptions made that limit the applicability of the method to specific types of problems?"}}
{"paper_id": "60Vd7QOXlM", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel method for auditing the privacy of large language models, setting a new standard for detecting privacy leakage. The approach is thorough and extensively tested, demonstrating significant improvements over previous state-of-the-art methods. The experiments cover multiple families of fine-tuned LLMs and show the method's effectiveness in realistic settings.", "Weaknesses": "The paper may lack discussion on potential limitations or scenarios where the proposed method might not be as effective. Additionally, the analysis might be limited to specific models or datasets, potentially affecting the generalizability of the results.", "Questions": "1. How does the method perform on different types or sizes of datasets, and what are the implications for generalization?\n2. Are there any specific limitations or scenarios where the proposed approach might not be effective? \n3. Is the method applicable to all LLMs, or are there certain prerequisites for its application?"}}
{"paper_id": "GqhvJ1o8m5", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "Introduce an innovative framework for converting single-view videos into high-quality stereo videos. The creation of a large dataset, YouTube-SBS, for training and benchmarking stereo video models significantly contributes to the field.", "Weaknesses": "The paper relies on implicit guidance without an explicit comparison to other state-of-the-art methods. There is a lack of detailed discussion on potential limitations or failure cases of the proposed method.", "Questions": "How do you handle temporal inconsistencies in the videos? Can the stereo videos generated by ImmersePro be applied to real-time scenarios?"}}
{"paper_id": "ua5MHdsbck", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper addresses a significant challenge in protein design, which is extrapolating beyond the training data to improve protein fitness. Introducing triplet relations for better extrapolation represents a novel and promising approach. The experimental validations are thorough and demonstrate the method's effectiveness.", "Weaknesses": "The proposed method relies on a scorer function for defining triplets, which may have limitations in real-world scenarios, particularly when generalizing out-of-distribution. The paper's presentation could be clearer, as certain concepts like triplet definitions and \"scorer distillation\" are not immediately understandable.", "Questions": "How robust is the model to noisy inputs, especially when triplet definitions might be imperfect? Could the authors provide more details on the role of mask infilling and its impact on model performance? How is the effectiveness of triplet rankings ensured when potential scoring inaccuracies arise?"}}
{"paper_id": "56Zn3halhq", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach to time series data augmentation using reinforcement learning, which offers a fresh perspective on enhancing forecasting models. The method is backed by empirical analysis and shows substantial improvements in forecasting performance with minimal computational cost. The use of variational masked autoencoders is innovative and well-motivated.", "Weaknesses": "The abstract does not provide enough detail on the specific results or how the proposed method compares to other state-of-the-art techniques in terms of performance. Additionally, the practical implications and potential limitations of applying this method in various scenarios are not discussed.", "Questions": "How does AutoTSAug perform compared to other existing data augmentation methods for time series forecasting? Are there any scenarios where this approach might not be applicable or where it might underperform?"}}
{"paper_id": "aPTGvFqile", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses a significant problem in CLIP models regarding the modality gap and proposes a method to align embeddings better. The proposed AlignCLIP framework appears to show improvements in zero-shot and fine-tuning tasks.", "Weaknesses": "The explanation of the methodology could be clearer. The abstract suggests improvements, but details on how these results compare to similar works are not provided. It is also not clear how generalizable the results are beyond the datasets tested.", "Questions": "How does AlignCLIP's performance compare on a broader set of datasets? Are there any scenarios where AlignCLIP does not perform well?"}}
{"paper_id": "GOwNImvCWf", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses an important problem in neural network weight reconstruction and provides a novel approach by introducing a behavioral loss. It demonstrates improved performance in model reconstruction by combining structural and behavioral features.", "Weaknesses": "The novelty of the behavioral loss could be questioned as similar approaches might exist, and the experiments might not cover a wide range of models and tasks. More empirical evidence would strengthen the contributions.", "Questions": "How does the proposed behavioral loss method scale with larger models, and are there any limitations observed in practical implementations?"}}
{"paper_id": "C9BA0T3xhq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel and promising approach for improving offline reinforcement learning by extending the action space considered by the Bellman update. The method addresses challenges related to sparse rewards and incomplete trajectories, showcasing improved performance in experiments. The concept of Extended Implicit Q-Learning effectively leverages existing data while mitigating overestimation risks.", "Weaknesses": "The paper may lack some clarity in its theoretical exposition, specifically regarding the presentation of the foundational Implicit Q-Learning algorithm. There could be more elaboration on the potential limitations or failure modes of the proposed method. Additionally, the experiments, while promising, may require further validation across diverse and more challenging environments.", "Questions": "How does the proposed approach compare computationally to traditional offline RL algorithms in terms of efficiency? Could the authors provide additional insights into how EIQL specifically mitigates error extrapolation risks compared to other competitive methods?"}}
{"paper_id": "EeqlkPpaV8", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses a significant problem of adaptive complexity in sampling algorithms, particularly in large-data applications. It provides a novel analysis of the lower bounds for query complexity in both unconstrained and box-constrained sampling, adding depth to the current understanding of sampling strategies in high-dimensional spaces.", "Weaknesses": "The paper might be challenging to follow due to complex mathematical explanations and specialized terminology. Some aspects of the proofs may seem too detailed without sufficient contextualization, which could affect the accessibility of the paper’s results to a broader audience. Additionally, practical implications or potential applications of the results are not well elaborated.", "Questions": "Can the techniques used in proving the lower bounds be applied or extended to other related problems in high-dimensional sampling? What are the potential implications for designing more efficient sampling algorithms given the established lower bounds? Is there a way to simplify the proofs to make them more understandable to those less familiar with the specific mathematical techniques employed?"}}
{"paper_id": "oK1zJCWBqf", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The proposed Soft Preference Optimization (SPO) method presents a novel approach to aligning generative models with human preferences without relying on a reward model, which simplifies the alignment process. The ability to adjust the 'softness' of the distribution through an algorithm parameter provides flexibility. The theoretical foundation under the Bradley-Terry model is well-formulated.", "Weaknesses": "The abstract does not provide detailed empirical evidence or comparisons with existing methods, which are crucial for understanding the practical effectiveness of the approach. The theoretical explanations may be complex for practitioners without detailed examples or visual demonstrations.", "Questions": "How does the performance of SPO compare with traditional reward model-based alignment methods in practical scenarios? Are there specific types of generative models or tasks where SPO demonstrates significant advantages or disadvantages compared to existing methods?"}}
{"paper_id": "Dq9VrVuLzV", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "SyntheOcc introduces an innovative approach by conditioning a 2D diffusion model with 3D semantic multi-plane images, effectively bridging a gap in complex 3D occupancy prediction tasks. The method's ability to generate photorealistic and geometrically controlled datasets is a significant contribution to enhancing autonomous driving simulations and model training. The approach is validated with extensive qualitative and quantitative results on a prominent dataset (nuScenes), underscoring its effectiveness in data augmentation.", "Weaknesses": "The paper may lack clarity in fully explaining how the integration of 3D geometric information as conditional input is achieved at a technical level. There might also be concerns about the scalability of SyntheOcc for different scenarios beyond the tested dataset, as well as the computational resources required for generating such detailed synthetic images.", "Questions": "How does SyntheOcc perform in terms of computational efficiency and scalability when creating large datasets for various driving environments? Are there any limitations identified during qualitative assessments that might affect its adaptability across different real-world scenarios?"}}
{"paper_id": "73Q9U0vcja", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The approach integrates diffusion models with active learning to reduce data acquisition requirements in inverse problems, demonstrating significant practical benefits in real-world applications.", "Weaknesses": "The abstract does not provide details on the computational cost or comparison with existing active learning methods, which are crucial for evaluating the approach's efficiency and novelty.", "Questions": "How does the computational cost compare to traditional methods? Are there specific scenarios where this approach is more beneficial?"}}
{"paper_id": "UiEjzBRYeI", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper addresses the significant challenge of semantic-aware segmentation using the Segment Anything Model (SAM), which has shown considerable potential in image segmentation. The introduction of SAM-CP and its two types of composable prompts adds a novel layer to the existing methodology, allowing for versatile segmentation across various scenarios. The unified framework for calculating affinity between queries and patches is another strong point, simplifying the segmentation process without degrading performance. The experimental results, which show state-of-the-art performance in open-vocabulary segmentation, underscore the practical utility and effectiveness of SAM-CP.", "Weaknesses": "While the paper presents an innovative approach, the complexity introduced by the two types of prompts might limit the accessibility and ease of use, especially for those not intimately familiar with SAM. Furthermore, the reliance on a unified framework to handle large numbers of semantic classes and patches could lead to scalability issues. Another concern is the potential lack of detailed qualitative evaluations, which could provide deeper insights into the method's effectiveness across various domains and dataset types.", "Questions": "How does the proposed SAM-CP approach perform compared to other state-of-the-art segmentation methods, particularly those not based on SAM? Are there any specific limitations when applying SAM-CP to domains outside of the tested benchmarks, such as medical imaging or other non-standard datasets?"}}
{"paper_id": "lessla98Wp", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach using language descriptions to guide video colorization, which is innovative in addressing temporal consistency issues and user control over the colorization process. The method leverages a pre-trained cross-modality generative model and introduces new techniques such as temporally deformable attention and cross-clip fusion that show strong results in maintaining creative and consistent colors across video frames.", "Weaknesses": "While the approach is innovative, there may be some limitations regarding the complexity and ambiguity of language descriptions impacting the effectiveness of colorization. The integration of the proposed methods into existing workflows needs further validation across a wider range of video content and styles. There could also be challenges related to computational resources and scalability that are not addressed.", "Questions": "How does the model handle ambiguities or complex sentences in language descriptions? Can the system be adjusted to weigh different parts of the language input based on context or importance? What are the potential computational overheads associated with the introduced modules and how do they scale with longer video sequences?"}}
{"paper_id": "UstOpZCESc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "- The paper addresses the challenging intersection of lifelong learning and machine unlearning, presenting a novel integration.\n- Demonstrates practical scalability across different neural architectures.\n- Provides a mechanism for exact unlearning without degrading overall performance.", "Weaknesses": "- It is unclear if the additional complexity of the proposed method over simpler ablations is justified by significant performance gains.\n- Lacks discussion of how adapted baselines from standard lifelong learning to the privacy-aware setting were effectively modified.\n- Missing important baselines, such as those using Differential Privacy or from existing unlearning literature.\n- The results rely on metrics for unlearning that may not provide a rigorous privacy guarantee.\n- Scalability to user-level unlearning requests (where tasks don't cleanly separate via users) is not addressed.", "Questions": "- How does the 'independent subnetworks without knowledge transfer' differ structurally from PALL, specifically in knowledge transfer mechanisms?\n- What are the potential worst-case scenarios in the sequence of learning and unlearning tasks, particularly regarding performance degradation?"}}
{"paper_id": "LnRegTxsa4", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces novel modules like CVCAM and MHSAM that enhance cross-view object geo-localization. It also contributes a new dataset (G2D) adding value to the field.", "Weaknesses": "The effectiveness of CVCAM and MHSAM requires further validation through diverse datasets and real-world scenarios. The scarcity of datasets makes it difficult to generalize findings.", "Questions": "How adaptable are CVCAM and MHSAM to other cross-view geo-localization tasks beyond Ground→Drone? What efforts were made to ensure the G2D dataset captures a wide variety of geographic and environmental conditions?"}}
{"paper_id": "2ErS9Bkc3O", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 5, "Confidence": 4, "Strengths": "The paper provides a theoretical explanation using matrix theory for the adversarial fragility of neural networks. It connects this explanation with previous information-theoretic work.", "Weaknesses": "The theoretical results might not be entirely novel. The paper seems to extend existing work rather than introducing entirely new concepts. It is unclear how practical the implications are for real-world neural network design.", "Questions": "What are the practical implications of these theoretical findings? How does this approach compare with previous methods addressing adversarial robustness?"}}
{"paper_id": "pK3oe2bubc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The proposed method introduces innovative training approaches that make vision transformers robust to arbitrary execution order of layers during inference. The ability to create functional 'Frankenstein' models and the graceful decline in performance during layer-pruning are notable contributions.", "Weaknesses": "The paper assumes a 20% accuracy reduction at a given model size, which is significant and might limit practical applicability. The evaluation lacks comparison with a broader range of transformer architectures and practical scenarios where execution orders change frequently.", "Questions": "How does the proposed approach perform on other types of neural networks beyond vision transformers? Are there real-world applications where such robustness to layer execution order is critical?"}}
{"paper_id": "sec09tLQUl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses the notable problem of models exploiting spurious features and presents a novel approach called FairDropout. The empirical evaluations span across different domains, showcasing the robustness of the method.", "Weaknesses": "The approach may rely heavily on the assumption of neuron memorization locality, which may not hold in all scenarios. Furthermore, the description lacks detail in explaining how FairDropout specifically informs neuron targeting.", "Questions": "How does FairDropout ensure that the memorization is indeed targeted to specific neurons for dropout? Are there scenarios where this approach might not be effective?"}}
{"paper_id": "96jZFqM5E0", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The methodology introduces a novel contrastive learning technique by grouping similar hand poses which enhances the performance significantly over existing methods. The use of an extensive dataset from recent human-centric videos is a strength and demonstrates scalability. The experimental results show clear improvements over state-of-the-art techniques.", "Weaknesses": "While the approach shows improvements, the paper would benefit from more detailed comparisons with alternative pre-training techniques, especially in terms of runtime performance and computational requirements. Additionally, some aspects of the contrastive loss adaptation mechanism could be more thoroughly justified or explained.", "Questions": "How does the proposed approach handle varying hand shapes and sizes in the wild, and is there a plan to extend the dataset further? Additionally, what are the computational costs compared to other state-of-the-art contrastive learning methods?"}}
{"paper_id": "uNd289HjLi", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel self-supervised framework for MRI denoising, addressing the label scarcity issue effectively. It introduces an innovative generalized ambient denoising score matching (GADSM) loss and demonstrates state-of-the-art performance among self-supervised methods. Additionally, the framework can incorporate multi-contrast denoising, showcasing its versatility and robustness across different MRI noise conditions.", "Weaknesses": "The paper lacks empirical evidence on the trade-off between noise reduction and the preservation of fine spatial features. The claimed advantage over supervised methods in terms of generalization is not fully substantiated with clear experimental results. Moreover, the implementation details regarding the reparameterization strategy and its impact on convergence are not thoroughly explained.", "Questions": "How does the C2S framework perform compared to traditional non-supervised methods in terms of computational complexity and time efficiency? Can the reparameterization of noise levels introduced in the framework contribute to potential advantages in other domains beyond MRI denoising?"}}
{"paper_id": "e2ONKX6qzJ", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. APG is presented as a plug-and-play method with virtually no additional computational overhead, making it attractive for practical use in various diffusion models.\n2. The method of down-weighting the parallel component in CFG is novel and interesting, effectively reducing oversaturation and preserving image quality at high guidance scales.", "Weaknesses": "1. In Figure 8, could the authors explain why the proposed APG shows lower precision and higher FID compared to CFG when the guidance scale  w  is below certain values (e.g.,  w = 2.5 , where APG precision is lower than CFG)?\n2. While reverse momentum is introduced, the intuition behind why it improves the image generation quality could be expanded. More detailed theoretical or experimental exploration of this component would clarify its importance.", "Questions": "See the questions in the weakness section."}}
{"paper_id": "a2eBgp4sjH", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses a relevant problem by focusing on the MultiFilterANN, enhancing existing algorithms and providing both theoretical insights and practical improvements. Theoretical results provide new space-time tradeoffs and lower bounds for popular algorithms.", "Weaknesses": "The connection between the theoretical framework and the empirical implementation is not entirely clear. Some sections lack clarity and the presentation could be improved. Limited information on certain empirical comparisons and performance metrics.", "Questions": "Could you provide more details on how the theoretical results directly inform the empirical methods proposed, and clarify the specific implementation used for the experiments?"}}
{"paper_id": "EIXZXPz7jU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a novel sampling method for PINNs which addresses the challenge of singularities in the source functions of PDEs, potentially increasing accuracy and efficiency.", "Weaknesses": "The evaluation appears limited with only three PDE examples discussed. The paper lacks details on algorithm specifics, such as the distribution involved in flow matching. While promising, further experiments and details are required for clarity and validation.", "Questions": "What specific distribution is the flow matching method sampling from? Are the sample points re-drawn or fixed throughout training?"}}
{"paper_id": "QO4bF6MHza", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses an important gap in evaluating the mathematical reasoning capabilities of LLMs in long-context scenarios. MathHay is a novel benchmark that combines both information retrieval and complex reasoning, demonstrating rigorous experimental work with eight top LLMs.", "Weaknesses": "The paper lacks a detailed exploration of why the best-performing model still struggles and does not propose specific methods to address these deficiencies. It also relies heavily on achieving a single metric (accuracy) without detailed analysis of error types or qualitative insights.", "Questions": "How did the selection of eight top-performing LLMs occur, and what specific measures ensure the generalizability of MathHay results? Are there any qualitative insights into the types of errors these models frequently make on the benchmark?"}}
{"paper_id": "GULx8rzzjC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses an important challenge in data sharing and proposes a novel method, Mycroft, for selecting informative data subsets efficiently. The approach is demonstrated to be robust and effective across multiple tasks and domains.", "Weaknesses": "The explanation and implementation details related to certain algorithms and proofs are not clear. Some sections lack sufficient detail, making it challenging to fully understand the methodology and evaluate its effectiveness. The evaluation does not include scenarios where data privacy is actively protected, which is significant given the problem context.", "Questions": "How does RetrieveTopK function work in practice, and how does it ensure coverage of D^hard? How does privacy impact the performance and applicability of the Mycroft method?"}}
{"paper_id": "PnZ2lbQaao", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a novel adversarial Bayesian framework, Domain Indexing Collaborative Filtering (DICF), which addresses cold-start issues in cross-domain recommendation systems. This framework is presented with an emphasis on interpretability, which is a significant advancement over traditional black-box approaches.", "Weaknesses": "The paper lacks in-depth discussion on potential limitations or constraints of the proposed method. Additionally, while the empirical results are mentioned, there is limited information on the datasets used or the specific performance improvements achieved.", "Questions": "How does the DICF framework handle scalability when applied to large-scale real-world datasets?"}}
{"paper_id": "AT64R0ivUO", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel method, SteerPrompt, that enhances the comprehension of LLMs by explicitly steering attention scores rather than relying solely on token-based prompting. It addresses significant issues with LLMs regarding long or distracting contexts. The experimental results demonstrate substantial improvements, which highlights the effectiveness of the method without requiring model parameter changes.", "Weaknesses": "The method's reliance on attention score manipulation may raise concerns about its robustness and general applicability to a wider range of tasks beyond the evaluated open-book QA. Additionally, the potential impact on inference speed and computational overhead is not discussed.", "Questions": "How does SteerPrompt perform compared to other state-of-the-art methods focused on improving LLM comprehension in distracting or lengthy contexts? Can this method be extended or adapted for use in other types of NLP tasks or models beyond the ones tested?"}}
{"paper_id": "nGiGXLnKhl", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "This paper outlines a significant adaptation of the RWKV model for vision tasks, showcasing its robustness and efficiency. The model surpasses existing architectures like Vision Transformer in both performance and resource optimization, illustrating its potential in handling high-resolution inputs effectively. The model's capability to manage large-scale parameters without complex spatial aggregation is a key strength.", "Weaknesses": "The paper primarily focuses on performance metrics and may benefit from further elaboration on theoretical aspects or limitations of the VRWKV model. Additionally, direct comparisons with other RNN-based models adapted for vision are limited.", "Questions": "How does Vision-RWKV compare with other recent transformer models specifically designed for vision tasks in terms of scalability and adaptability to different vision applications?"}}
{"paper_id": "TBJCtWTvXJ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides a thorough theoretical analysis and empirical validation of a novel optimization algorithm (S3) that improves on the well-known Adam optimizer. It addresses a significant problem in deep neural network training by explaining and mitigating loss spikes.", "Weaknesses": "The contribution, while novel, is incremental as it builds on existing ideas in optimization such as the Adam optimizer and SignSGD. The theoretical explanation could benefit from further elaboration to ensure clarity and accessibility to a broader audience.", "Questions": "How does the proposed optimizer perform in comparison to other recent advancements in optimization algorithms, beyond Adam and AdamW? How robust is S3 to hyperparameter changes across a diverse set of neural network architectures?"}}
{"paper_id": "8gSrJOL2oc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper proposes a novel framework for compositional zero-shot learning by addressing existing limitations through multimodal large language model embeddings and attribute smoothing. It demonstrates state-of-the-art performance on three challenging datasets, highlighting its effectiveness.", "Weaknesses": "The disentanglement efficacy may still be affected by background and attribute-object entanglement, and it relies on pretrained models which may not fully capture multimodal semantic information. The explanation of the methodology could be clearer in some sections.", "Questions": "How does the proposed attribute smoothing through auxiliary attributes address the problem of overconfidence specifically? Can the method be applied to other types of zero-shot learning tasks beyond attribute-object compositions?"}}
{"paper_id": "yheQRc5xWB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces an innovative approach by leveraging State-Space Models for time-varying counterfactual predictions, which appears to address longstanding issues of prediction performance and efficiency in capturing interactions over long sequences.", "Weaknesses": "The proposed method's reliance on mitigated confounding bias may not comprehensively address all possible biases, and the abstract does not provide detailed insights into potential limitations or challenges of the approach.", "Questions": "How does the Mamba-CDSP model compare to more recent methods in terms of both accuracy and computational efficiency, especially considering newer Transformer architectures? What specific applications does Mamba-CDSP benefit the most in real-world scenarios?"}}
{"paper_id": "HxKSzulSD1", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces the concept of 'weak-to-strong deception,' highlighting a critical issue in AI model alignment. It demonstrates through experiments that deception intensifies with a growing capability gap and provides initial strategies to mitigate the problem.", "Weaknesses": "The experiments might not fully cover real-world complexities, and the effectiveness of the proposed mitigation strategies is limited. The study focuses on specific alignment dimensions, which may restrict the generalizability of findings.", "Questions": "How can the study's findings be applied to more diverse and complex real-world scenarios? Are there other strategies beyond bootstrapping to effectively mitigate weak-to-strong deception?"}}
{"paper_id": "wH8XXUOUZU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces innovative techniques for improving autoencoder performance at high spatial compression ratios, leading to substantial speedup in diffusion models without sacrificing accuracy. The improvements in inference and training speed are significant, and the approach is thoroughly evaluated on relevant benchmarks.", "Weaknesses": "The paper may lack clarity in the presentation of certain technical details, making it difficult for readers to fully understand the implementation and evaluation methodologies. Additionally, there might be a lack of theoretical analysis to support the proposed improvements. Some experimental results might be challenging to interpret without additional context.", "Questions": "What specific datasets and evaluation metrics were used in the experiments, and can any external validation be provided to strengthen the claims? How do the proposed techniques generalize to different types of autoencoder architectures or diffusion models?"}}
{"paper_id": "QWIg5e6mtT", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper proposes a novel framework for solving heterogeneous team games, extending the PSRO framework to cases where teammates have distinct roles. The theoretical proof of lower exploitability and empirical results showing convergence where non-heterogeneous baselines fail are commendable.", "Weaknesses": "The paper relies on several complex theoretical constructs, and some explanations may not be sufficiently detailed for all readers. The specific improvements over existing methods, aside from heterogeneity, might not be entirely clear.", "Questions": "How does H-PSRO handle scalability issues when the number of unique roles or policies increases significantly?"}}
{"paper_id": "kbSU5bwoRv", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The model is claimed to be the first open-source solution for zero-shot singing voice conversion that works for both human and non-human timbres, which is a significant contribution to the field. 2. The approach addresses and potentially overcomes limitations of previous methods by improving feature disentanglement and reducing dependencies. 3. The creation and use of a large-scale dataset specifically for this purpose adds to the robustness and applicability of the model.", "Weaknesses": "1. The paper does not provide explicit details on how well the proposed model performs relative to existing benchmarks in terms of concrete objective metrics. 2. The complexity of the model and the necessity of a large dataset may limit accessibility and reproducibility for other researchers.", "Questions": "1. How does SaMoye ensure the disentanglement of content, timbre, and pitch features without losing semantic information? 2. What baseline models or methods were used for comparison in the objective and subjective experiments? 3. How does the performance vary when converting to non-human timbres, and could you provide examples?"}}
{"paper_id": "KyqtKhv6q1", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel framework (Differentiable Map Priors) that effectively improves 3D object detection and semantic map segmentation by incorporating spatial priors from historical data. The approach integrates easily with existing 3D perception systems and shows significant improvements across several architectures on the nuScenes dataset.", "Weaknesses": "The paper may not address potential limitations or challenges in real-world deployment of the proposed framework, such as handling dynamic environments or evaluating the scalability of the approach across diverse and new geographical areas.", "Questions": "How does the proposed framework handle dynamic changes in the environment, such as new construction or temporary obstacles? Is there a strategy for updating the learned priors in such cases?"}}
{"paper_id": "lTL4t68BNc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper proposes a novel graph attention method (RGA-IB) that improves robustness against adversarial attacks by minimizing the Information Bottleneck loss. The experiments demonstrate significant improvements over existing methods in node classification tasks under such attacks.", "Weaknesses": "The paper's novelty is somewhat limited, as it draws heavily on existing IB principles without introducing fundamentally new concepts. The evaluation could be more comprehensive by including more baseline comparisons, datasets, and attack scenarios. The connection between lower IB loss and robustness is intriguing but not yet fully substantiated within the paper.", "Questions": "How does RGA-IB compare with recent methods such as RUNG or ElasticGNN? Can the approach be evaluated on heterophilic datasets or under more diverse adversarial attacks?"}}
{"paper_id": "hWmwL9gizZ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The paper introduces a novel deep learning model with dual attention mechanisms and compiles a comprehensive immunogenicity dataset with over 9,500 sequences, which significantly enhances the research in reverse vaccinology.", "Weaknesses": "The paper may lack a detailed comparative analysis with alternative models and the implications of using different features may not be fully explored.", "Questions": "How does ProVaccine specifically improve over previous models in terms of architecture? Are there specific types of vaccines or pathogens where ProVaccine might have limitations?"}}
{"paper_id": "IL85Ebjg9j", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses a significant problem in multi-view classification by introducing a computational trust-based discounting method. It enhances multi-view classification where conflicting views can reduce reliability. The novel use of an instance-wise probability-sensitive trust discounting mechanism is well-motivated and offers a refined approach to dealing with inconsistencies in real-world datasets.", "Weaknesses": "While the proposed solution is interesting, the abstract does not provide sufficient detail on the inner workings or assumptions of the method. Also, the results are context-limited; only six datasets are tested. There's no discussion on computational complexity or how this method scales with larger datasets. The evaluation metrics, although relevant, could be strengthened with additional real-world scenario validations.", "Questions": "What kind of computational complexity does the proposed method introduce, especially in large-scale datasets? How does the trust discounting affect performance across highly diverse datasets or when scaling in real-time applications?"}}
{"paper_id": "cnKhHxN3xj", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper addresses an important aspect of interpretability in large language models, focusing on disentangling polysemantic neurons. It proposes a novel measure for neuronal entanglement and provides a new experimental framework that demonstrates its effectiveness. The work potentially opens up new directions for optimizing model performance under sparsity constraints.", "Weaknesses": "The robustness of the proposed method for out-of-distribution data is not thoroughly discussed. Additionally, more clarity is needed regarding the practical aspects of the implementation, such as computational overhead and runtime implications of the proposed mixture of experts approach. The paper could also benefit from a deeper exploration of related work in neuronal entanglement.", "Questions": "How does the proposed measure of entanglement compare to existing metrics in the literature? Are there specific scenarios where the method fails or does not offer significant benefits? What are the implications of the proposed approach on model scalability and inference speed?"}}
{"paper_id": "dgR6i4TSng", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach that leverages quantum computations to enhance parameter efficiency in fine-tuning, demonstrating significant reductions in the number of trainable parameters while maintaining competitive performance.", "Weaknesses": "The paper may not fully address potential computational complexities introduced by leveraging quantum computations and could further elaborate on the comparison with traditional PEFT methods beyond parameter count.", "Questions": "How does Quantum-PEFT impact computational overhead in practical implementations, and how does it compare quantitatively with other PEFT methods in terms of performance on large-scale benchmarks?"}}
{"paper_id": "ye1mxb79lw", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces BILBO, a novel bilevel optimization approach offering theoretical guarantees and practicality in solving noisy, constrained problems efficiently. BILBO's sampling strategy ensures feasible solutions with low regret, and it's designed for flexibility with decoupled function evaluations. Additionally, the empirical results on synthetic and real-world tasks highlight its effectiveness.", "Weaknesses": "Motivations for specific design choices, especially around the decoupled setting and query strategies, need more clarity. There are limited comparisons with current state-of-the-art bilevel optimization methods, affecting the assessment of BILBO's performance. Furthermore, the absence of provided code hinders reproducibility and further exploration by researchers.", "Questions": "Can you further clarify the rationale behind focusing on decoupled settings? How does BILBO compare in terms of regret bounds to other bilevel BO methods? Why was there a sharp drop in BILBO's performance at around 150 queries? Would additional comparisons with advanced baselines better showcase BILBO's advantages? Lastly, why does Nested often perform similarly or worse than TrustedRandom in tests?"}}
{"paper_id": "1fwZJzGdKj", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel multi-agent collaborative data selection mechanism for LLM pretraining, which significantly enhances data efficiency and accelerates convergence. The proposed method demonstrates substantial performance gains over state-of-the-art methods across multiple language model benchmarks.", "Weaknesses": "The novelty of the multi-agent approach and its differentiation from existing methods are not thoroughly explained. The paper could benefit from a more detailed comparison with related work and an exploration of potential limitations concerning scalability and complexity.", "Questions": "How scalable is the proposed multi-agent system when applied to extremely large datasets commonly used in LLM pretraining? Are there any limitations or challenges associated with integrating this approach into existing LLM training pipelines?"}}
{"paper_id": "pISLZG7ktL", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel study on data scaling laws in the context of robotics, a field where it has not been extensively explored. The empirical investigation is thorough, involving a large number of demonstrations and actual robot rollouts. The insights into the importance of diversity in environments and objects are highly valuable for the development of generalizable robot policies. The proposed data collection strategy is practical and efficient.", "Weaknesses": "The study might be limited to the specific tasks and environments tested, which could affect the generalizability of the conclusions. The focus on single-object categories could limit the applicability of the findings to more diverse and complex manipulation scenarios in robotics. The paper could also explore more complex tasks to strengthen its claims on generalization.", "Questions": "How do the findings translate to more complex and varied tasks involving objects of different categories and in more dynamic environments? Are there plans to expand the study to include a wider range of robotic tasks and settings?"}}
{"paper_id": "dML3XGvWmy", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The introduction of a self-evolving framework inspired by the Gödel machine represents a novel approach that allows agents to improve recursively. The method's ability to leverage LLMs for dynamic self-improvement without fixed routines is a significant advancement. Empirical evidence suggests superior performance over manually crafted agents in various tasks, which highlights the method's potential impact on AI agent development.", "Weaknesses": "The abstract does not provide specific details on the experimental setup, baseline comparisons, or potential limitations of the method. This leaves questions about the generalizability of results across different domains.", "Questions": "How does Gödel Agent ensure continuous improvement without overfitting to specific tasks? What metrics are used to evaluate its performance compared to traditional agents?"}}
{"paper_id": "xlxGsX1pc7", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces a substantial and diverse benchmark, U-MATH, for evaluating LLMs on university-level mathematical problems, which is a significant advancement over existing evaluations that focus on elementary and high-school problems. The inclusion of multimodal problems is also a noteworthy contribution as it broadens the scope of evaluation to include visual elements. The open-sourcing of U-MATH and accompanying evaluation code enhances the transparency and accessibility of the research.", "Weaknesses": "The reliance on LLMs to judge the correctness of solutions could introduce biases or errors, as evidenced by the F1-score of 80% for solution assessment. This poses questions about the reliability of the evaluation process. Additionally, the paper does not provide detailed analysis on why LLMs struggle significantly more with visual problems, which could have been beneficial for future improvements.", "Questions": "How does the presence of multimodal problems impact the overall performance of LLMs compared to text-only problems? Could the authors provide more insight into the types of mathematical reasoning that are particularly challenging for LLMs?"}}
{"paper_id": "AjXkRZIvjB", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses an important area in AI, namely the mathematical reasoning capabilities of large language models using an improved evaluation benchmark (GSM-Symbolic) which offers more reliable metrics. The introduction of GSM-Symbolic is a significant contribution as it provides a more nuanced insight into the current limitations of LLMs in the domain of mathematical reasoning.", "Weaknesses": "The study reveals the fragility of current LLMs' reasoning capabilities but does not propose new methods to overcome these limitations. The reliance on synthetic benchmarks may not fully capture real-world complexities faced in mathematical reasoning tasks. The performance degradation observed might be influenced indirectly by other factors not fully isolated in the study.", "Questions": "Can the GSM-Symbolic benchmark be adapted for other domains beyond mathematics to evaluate reasoning capabilities? How does the benchmark ensure diversity without straying into overly unrealistic problem settings?"}}
{"paper_id": "IJiTI0fB0e", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides a novel method to quantify different sources of diversity in text-conditioned generative models, separating prompt-induced diversity from model-induced diversity. By applying matrix-based information measures, the approach allows for a clearer understanding of the generation process, which is valuable for the field.", "Weaknesses": "The paper could improve in clarity and detail regarding the implementation and potential limitations of the proposed method. Furthermore, the distinction between existing and novel contributions could be more explicit to highlight the work's original aspects.", "Questions": "How scalable is the proposed method when applied to large-scale generative models with diverse datasets? Are there any assumptions in the theoretical framework that might limit its applicability to certain types of prompt-based models?"}}
{"paper_id": "fs2Z2z3GRx", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces Flow with Interpolant Guidance (FIG), which enhances image reconstruction in challenging scenarios. Experimentally, it shows state-of-the-art results in various tasks, particularly handling high noise and ill-posedness effectively. The approach is efficiently implementable as a modification to existing diffusion or flow-matching models.", "Weaknesses": "The presentation of the motivation behind measurement interpolants and their clear advantages over existing methods requires more clarity. Furthermore, a deep dive into the limitations of current approaches and how FIG specifically addresses these would strengthen the paper.", "Questions": "1) How does the proposed method handle cases beyond the high-noise/ill-posedness scenarios mentioned, and is it equally effective?\n2) Could the authors elaborate further on the theoretical assumptions and provide more intuitive explanations for the theorems?\n3) Are there any limitations in FIG when applied to other non-linear or real-world datasets?"}}
{"paper_id": "H4FSx06FCZ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach, SecureGS, which effectively addresses existing limitations in 3D Gaussian Splatting (3DGS) steganography, such as rendering fidelity and computational demands, by introducing a hybrid Gaussian encryption mechanism and density region-aware strategies.", "Weaknesses": "The complexities introduced by the proposed encryption and anchor strategies might impede practical implementation and usability in some scenarios where computational resources are limited.", "Questions": "How does the security mechanism ensure protection against specific attack vectors without compromising rendering performance?"}}
{"paper_id": "OGtUfA6Amo", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces an innovative model for handling irregular multivariate time series by incorporating both temporal and inter-variable dependencies at multiple scales through a hierarchical graph network approach. The experimental results demonstrate the model's effectiveness across various datasets.", "Weaknesses": "The paper could improve by providing clearer explanations and visualizations of the hierarchical graph structures and their transformation processes. The handling of missing values and model complexity analysis are not addressed, which might affect its applicability in real-world scenarios.", "Questions": "How does the model handle missing values in time series data? Is there a detailed analysis of the computational complexity compared to other models?"}}
{"paper_id": "ujpAYpFDEA", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents a novel aspect of watermarking in Large Language Models by focusing on the imperceptibility of watermarks. It introduces Water-Probe, an identification algorithm that effectively detects watermark presence with low false positives. The Water-Bag strategy is proposed to enhance watermark imperceptibility, which could be a valuable addition to the field.", "Weaknesses": "The paper may lack depth in exploring a wider application of the proposed Water-Probe to diverse watermarking techniques. It is not entirely clear how comprehensive the experimental setup is in terms of watermarking schemes. The distinction between watermarking and related concepts such as fingerprinting is not thoroughly discussed, which might cause confusion.", "Questions": "How well does Water-Probe perform across a broader spectrum of watermarking methods? What specific measures were taken to ensure the randomness of watermark key selection in the Water-Bag strategy? Is there a risk that users could exploit the identification algorithm for unintended purposes?"}}
{"paper_id": "7UKHNQIErp", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "- The paper formalizes DPA losses in terms of discrete reasoning problems, which is a novel approach. - It provides a new, formal perspective on understanding and developing DPA loss functions. - The work seems well-structured and offers valuable insights into the DPA loss landscape.", "Weaknesses": "- The paper's approach may add complexity, especially for readers unfamiliar with the symbolic reasoning involved. - There could be more examples or case studies to demonstrate practical implementations of the framework.", "Questions": "- How well does the proposed framework scale with very large datasets or models? - Are there any potential limitations or edge cases identified in the framework's application to various DPA losses?"}}
{"paper_id": "CpgWRFqxhD", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a significant challenge in the domain of audio-driven talking video generation - enhancing identity consistency and emotional expression, which is crucial for realistic applications. The approach using memory-guided temporal modeling and emotion-adaptive layer normalization is innovative and shows an improvement over state-of-the-art methods. The experiments are extensive and the results show superiority in terms of emotion-audio alignment and overall quality.", "Weaknesses": "The abstract lacks details on quantitative metrics used for evaluation, which makes it difficult to assess the precise improvements. Moreover, the dependency on a large-scale, high-quality dataset may limit the applicability to lower-quality scenarios.", "Questions": "1. How well does the method perform on lower-quality or noisy data? 2. How does the approach handle variations in audio languages not available in the training dataset?"}}
