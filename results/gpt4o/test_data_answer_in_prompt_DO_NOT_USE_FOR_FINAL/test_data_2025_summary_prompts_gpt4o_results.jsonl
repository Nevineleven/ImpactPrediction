{"paper_id": "u3xwwfHmBC", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The TTformer model effectively integrates tense-specific attention modules to capture complex spatio-temporal dependencies in traffic forecasting. The use of contrastive learning enhances robustness against incomplete data.", "Weaknesses": "The model's high complexity and computational demands might limit its applicability in real-world systems with limited resources. Some descriptions of the method could be clearer.", "Questions": "How does the model scale with larger datasets or more complex road networks? Are there plans to optimize the model for efficiency in resource-constrained environments?"}}
{"paper_id": "YKvBiRWdQC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a novel approach to address limitations in current reinforcement learning benchmarks by proposing the Overcooked Generalisation Challenge (OGC). It focuses on an important aspect of RL agents' abilities, which is to generalize cooperation with novel partners and in unseen environments, a crucial requirement for real-world applications. The evaluation is thorough with state-of-the-art algorithms, and the project is intended to be open-source, impacting future research.", "Weaknesses": "The environment includes only a single recipe in the game, which may limit the complexity of the cooperation dynamics and the depth of the challenge. There are missing details in the explanation of the observation space, making it hard for readers unfamiliar with Overcooked to follow. The paper lacks insight into whether the results reflect undertraining of agents or the inherent challenge posed by the UED. The layout-specific performance data presented in supplementary materials would benefit from inclusion in the main paper. Some minor presentation issues and citations were also noted.", "Questions": "How do the authors plan to address the potential limitation of having a single recipe in the environment to better mimic real-world dynamics? Is there a way to focus specifically on testing partner generalization in the current setup, which could help in better diagnosing and improving UED+ZSC algorithms?"}}
{"paper_id": "tePFpDgyqg", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper demonstrates a novel approach to generating high-quality long-context documents. By leveraging existing referral signals like hyperlinks, it effectively simulates natural long-distance relationships in data, which significantly improve LLM training. The results show a substantial performance enhancement compared to previous techniques, indicating the method's effectiveness.", "Weaknesses": "The approach might face challenges in scenarios where referral signals such as hyperlinks are sparse or non-existent, limiting its applicability. Also, the dependency on web data may restrict generalization to other data types or domains lacking such structured links.", "Questions": "How does the method handle documents from domains where referral signals like hyperlinks are uncommon? Are there alternative strategies for identifying long-distance relationships in such cases?"}}
{"paper_id": "gx3LMRB15C", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. Novel augmentation-free approach tailored for tabular data, addressing the challenges of using traditional SSL augmentations. 2. Demonstrates significant performance improvements over baseline methods on tabular data tasks.", "Weaknesses": "1. Limited discussion on potential limitations or challenges when applying T-JEPA across diverse tabular datasets. 2. Clarification needed on the impact and effectiveness of regularization tokens across different data scenarios.", "Questions": "1. Could you provide more in-depth analysis or examples of where T-JEPA might struggle or underperform compared to traditional methods? 2. How does the model handle categorical data within tabular datasets, and are there specific preprocessing steps required?"}}
{"paper_id": "kTH3bEH6hW", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a significant challenge in few-shot learning for tabular data, demonstrating a simple yet effective augmentation strategy that enhances performance across a wide range of scenarios. The method's simplicity and ease of integration with existing frameworks add practical value.", "Weaknesses": "The reliance on predefined feature-specific ranges may limit the method's generality to other types of data or require substantial manual input to define these ranges. Additionally, more detailed exploration of how different augmentation ratios impact performance could strengthen the claims.", "Questions": "How sensitive is the performance of the proposed method to the choice of distributional proximity for defining feature-specific ranges? Could alternative proximity measures further enhance results?"}}
{"paper_id": "EqcLAU6gyU", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel agent-oriented planning framework that significantly improves task decomposition and allocation in multi-agent systems. The incorporation of design principles such as solvability, completeness, and non-redundancy enhances the problem-solving capabilities of these systems. The method leverages a meta-agent and a feedback loop for continuous improvement, demonstrating superior performance in empirical evaluations.", "Weaknesses": "The main weakness is the lack of detail regarding specific scenarios or datasets used in the experiments. Without this information, it is difficult to assess the robustness and generalizability of the proposed framework. Furthermore, the scalability of the solution in real-world large scale systems is not addressed.", "Questions": "What types of datasets were used in the experiments and how do they reflect real-world scenarios?\nHow does the framework handle scalability when applied to large multi-agent systems?\nAre there any specific domains where this framework is particularly effective compared to others?"}}
{"paper_id": "qrTrnrEi9d", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach, TransFusion, which significantly improves the performance of instruction-tuned LLMs for cross-lingual information extraction, especially in low-resource languages. It effectively leverages machine translation to enhance data richness, leading to improved results on low-resource datasets compared to existing methods.", "Weaknesses": "The paper does not clearly explain some implementation details, which makes it challenging to fully understand the TransFusion approach. Additionally, while the approach has been tested with various configurations, the differentiation among them is not thoroughly elaborated, which could potentially lead to confusion.", "Questions": "What are the specific limitations of the TransFusion approach when applied to extremely low-resource languages where even translation data is sparse? Additionally, how does TransFusion handle idiomatic expressions or culturally specific texts that may not translate well into English?"}}
{"paper_id": "Bp0HBaMNRl", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The method proposed addresses limitations in existing causal discovery approaches, especially in dealing with nonlinear and latent structures. Theoretical identifiability results provide strong support for the method's effectiveness. Empirical results demonstrate significant improvements in accuracy and scalability.", "Weaknesses": "The presentation lacks clarity in some theoretical aspects and empirical validation, which could benefit from more comprehensive comparative analysis. The proposed method's application in diverse real-world scenarios is not extensively demonstrated beyond MNIST data.", "Questions": "How well does the method generalize to other types of real-world datasets beyond the MNIST examples?"}}
{"paper_id": "JzLcKWtGnl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a critical limitation in current 3D Multimodal Large Language Models (MLLMs) by introducing a novel spatial awareness scheme. It effectively bridges the gap between holistic scene understanding and fine-grained spatial perception and reasoning, contributing valuable insights to the field of 3D vision-language integration.", "Weaknesses": "The paper could benefit from more detailed comparisons to baseline models and established methods in the evaluation, including standard metrics and diverse dataset challenges. The presentation could be clearer in terms of methodological explanation and specific performance outcomes.", "Questions": "How does Spatial 3D-LLM perform compared to other existing 3D vision-language models? Are there specific metrics or benchmarks used for evaluation? How does the proposed method handle varied complexity in 3D scenes differing in object density and spatial layout?"}}
{"paper_id": "hXJrQWIoR3", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach to graph representation learning by focusing on graph patterns, providing both theoretical analyses and experimental validation. This approach contributes significantly to the emerging field of explainable graph learning.", "Weaknesses": "The paper does not provide detailed information about the methods' time complexity, and the connections to other interpretability methods are unclear. Additional comparisons with other related methods, such as UNR-Explainer and MotifExplainer, are needed.", "Questions": "How does the proposed method compare in time complexity to other state-of-the-art methods? What are the specific use cases or domains where the method is expected to excel?"}}
{"paper_id": "67sSPPAZiG", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "1. The authors curate a large-scale dataset with over 7 million QA samples for egocentric videos of varying lengths and introduce a QA benchmark called EgoMemoria, which contains 7,026 questions for 629 videos of different lengths. \n\n2. A specialized multimodal architecture is proposed, using a \"Memory Pointer Prompting\" mechanism. This includes a global glimpse step for overarching video understanding and a fallback step that uses key visual information to generate responses, enabling the model to comprehend extended video content more effectively.", "Weaknesses": "1. The first claim of contribution, the “narration to egocentric QA” data pipeline, should not be emphasized as a major contribution. This type of generating QA from dense captions has been used in multiple previous works. \n2. The generated EgoMemoria Benchmark does not stand out significantly from many long video understanding benchmarks. In the context of egocentric videos, the GroundVQA dataset is a notable alternative. It would be beneficial to compare with more datasets to solidify the benchmark's uniqueness.", "Questions": "How does the MM-Ego model's performance scale with increased video lengths, specifically beyond the current dataset's scope? And how do the results compare to recently developed long video datasets in terms of complexity and capability?"}}
{"paper_id": "kjmLabjSE2", "error": "'NoneType' object has no attribute 'model_dump'"}
{"paper_id": "I18MA5DjoP", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 5, "Confidence": 3, "Strengths": "The authors introduce the Neuron Predictability Lens (NPL), an analytical framework for understanding transformer-based LLMs. This framework offers a novel perspective on analyzing and interpreting the internal predictability of neurons. The study successfully demonstrates the predictability of neuron activations, providing valuable insights into the global and local contributions of neurons in these models.", "Weaknesses": "The authors' experimental results show surprisingly high perplexity for the evaluated models, suggesting possible issues with model training or implementation. Additionally, the explanation of some experimental methodologies and choice of metrics lacks clarity. The presentation of equations and certain methodological details are not well-explained, causing potential misunderstanding of the approach.", "Questions": "What impact does the predictability of neurons have on overall model performance, and how can these findings be leveraged in practical applications? Also, what are the implications of predictability on model robustness and bias?"}}
{"paper_id": "qpDqO7qa3R", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel method that effectively adapts pre-trained image diffusion models for video restoration without requiring retraining, achieving state-of-the-art results. It introduces hierarchical latent warping and hybrid flow-guided spatial-aware token merging, enhancing temporal consistency and detail in video tasks.", "Weaknesses": "The approach might be limited by the quality of the pre-trained image diffusion models it relies on. Additionally, the computational demands for complex video restoration using this method, despite not requiring retraining, are not fully explored. The method's performance across a wider range of degradations and datasets needs further validation.", "Questions": "How does the computational cost of the proposed method compare to traditional and other state-of-the-art approaches? Are there scenarios where the method fails to perform, and if so, what are the contributing factors?"}}
{"paper_id": "dSQtMx6dPE", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper addresses a significant gap in graph machine learning by introducing differential privacy methods for graph prompt learning, a relatively unexplored area. 2. The proposed methods, DP-GPL and DP-GPL+W, are innovative and demonstrate superior performance compared to naive approaches like DP-SGD. 3. The authors provide a comprehensive evaluation across several datasets and methods, showcasing the practicality of their approach.", "Weaknesses": "1. The paper could have provided more detailed analysis on the trade-offs between privacy guarantees and utility. 2. Theoretical justifications for the effectiveness of the proposed algorithms in various graph structures or sizes could have been further elaborated. 3. The paper might benefit from additional experimental validation on larger-scale or more complex datasets to demonstrate scalability.", "Questions": "1. Can the proposed methods be generalized to more complex graph types, such as dynamic or heterogeneous graphs? 2. How does the choice of node centrality measure in DP-GPL+W influence the overall performance and privacy guarantees? 3. What are the potential limitations of applying DP-GPL and DP-GPL+W in real-world applications with large-scale data?"}}
{"paper_id": "GbgCRJedQ7", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel method, SMT, which effectively addresses the performance gap between PEFT and FT methods. It shows practical improvements in computational efficiency and accuracy over state-of-the-art methods like LoRA.", "Weaknesses": "The paper lacks a detailed exploration of potential limitations of SMT in real-world scenarios, particularly concerning the selection of sub-matrices and the effect on various model architectures.", "Questions": "How does the selection of sparse sub-matrices generalize across different tasks and model architectures? Are there any specific types of tasks or model configurations where SMT might not be effective?"}}
{"paper_id": "ZZVOrId3yN", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel architecture, CrossModalNet, which addresses critical issues in multimodal medical image segmentation such as domain shift and effective multimodal information integration. The use of advanced frameworks like Swin Transformer and Joint Adversarial Domain Adaptation highlights the innovative approach, which is well-supported by extensive experimental validation.", "Weaknesses": "While the paper demonstrates strong results, it may benefit from a more detailed exploration of the limitations and potential challenges in practical deployment. Additionally, the findings are largely based on results from a single dataset (MM-WHS), which might not fully represent the model's generalizability across other medical imaging datasets.", "Questions": "Could the authors provide more insight into how CrossModalNet performs on datasets with different characteristics from MM-WHS? Are there any specific challenges anticipated when adapting this model to other types of multimodal medical imaging tasks?"}}
{"paper_id": "gLHuAYGs6a", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The approach addresses a key challenge in multi-view clustering by effectively capturing high-order sample structures. The method shows substantial improvement over existing models and has practical implications demonstrated by extensive experiments.", "Weaknesses": "Lack of clear theoretical justifications for performance improvements and potential complexity issues aren't thoroughly addressed. The convergence of the proposed method is not discussed, which limits understanding of its reliability.", "Questions": "Are there any theoretical guarantees on the convergence of the SMvCNet model? How does it scale with increasing data size or the number of views?"}}
{"paper_id": "x5l5PRtvul", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces the hybrid kernel SVGD (h-SVGD), offering a solution to the variance collapse problem in high-dimensional settings. The method does not incur additional computational costs and maintains competitive performance in experiments with Gaussian mixtures and Bayesian neural networks.", "Weaknesses": "The paper's theoretical contributions could be expanded upon, and some assumptions may not be clearly justified or explained. Moreover, the presentation could benefit from improved clarity, particularly in elucidating the intuition behind the assumptions and propositions.", "Questions": "What practical impact do the assumptions have on the applicability of h-SVGD, and how sensitive is the method to these assumptions? How does h-SVGD compare against other advanced SVGD variants in more diverse benchmark tasks?"}}
{"paper_id": "pOUAVXnOQP", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces a novel activation function, STAF, which mitigates spectral bias in INRs, leading to superior reconstruction quality and faster convergence compared to state-of-the-art methods. The proposed method is theoretically sound and practically effective across various domains such as images, audio, and shapes.", "Weaknesses": "While the effectiveness of the proposed STAF is demonstrated, the paper may face challenges related to computational cost due to the increased parameterization involved with the new activation functions. The increase in frequency-related parameters might slow down training and require more computational resources.", "Questions": "How does the choice of the number of frequency components in STAF affect the trade-off between accuracy and computational efficiency? Can any practical guidelines be provided for determining this in various applications?"}}
{"paper_id": "iN64nSYt0z", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The proposed method, GUIDE, addresses a significant gap in LLM instruction following without requiring additional training resources. The introduction of the Influence metric offers a novel approach to understanding how instructions propagate through transformer layers. The availability of GUIDE and Influence as open-source tools enhances the accessibility and reproducibility of the research.", "Weaknesses": "The paper relies heavily on the newly introduced Influence metric without thoroughly comparing its effectiveness against existing approaches. The evaluation lacks diversity in testing scenarios, which may limit the generalizability of the findings. The reliance on a tagging system might not be flexible or robust enough for all LLMs or tasks.", "Questions": "How does the tagging system handle complex instructions that may be difficult to discretely identify and tag? Are there any limitations or potential downsides to mechanistically increasing attention scores that the authors have identified?"}}
{"paper_id": "gRuZkEy49k", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel method called Monte Carlo DAG Search (MCDS), which adapts MCTS for GFlowNets, enhancing sampling efficiency. The method demonstrates improvements in training GFlowNets by more effectively navigating the exploration-exploitation trade-off. The empirical studies across various environments show the approach's effectiveness and versatility.", "Weaknesses": "The paper could benefit from a more detailed explanation of the MCDS method and how it specifically integrates with GFlowNets. Some theoretical justifications for the approach are lacking, and the empirical results, while positive, could be more extensive. Further clarity on experimental setups and metrics could strengthen the paper.", "Questions": "How does MCDS compare to other potential sampling strategies not discussed in the paper? Are there specific types of problems or environments where MCDS might perform poorly?"}}
{"paper_id": "d23EVDRJ6g", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel localized generative masked transformer paradigm, MotionDreamer, which addresses the challenges of motion synthesis from limited data, demonstrating significant improvements over existing methods using only a single motion reference.", "Weaknesses": "The paper relies extensively on the generative masked modeling approach, which is not highly novel, and the study primarily focuses on applications with limited datasets, potentially limiting its generalizability.", "Questions": "How does MotionDreamer perform compared to traditional models when larger datasets are available, and is the approach generalizable to other types of content generation beyond motion synthesis?"}}
{"paper_id": "kQ5s9Yh0WI", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "1. The paper clearly addresses a significant limitation of existing LLMs, providing innovative solutions for extending output length. 2. The proposed AgentWrite pipeline effectively tackles the problem of long-text generation. 3. The introduction of LongWriter-6k dataset and LongBench-Write benchmark adds value to the community for evaluating ultra-long generation capabilities.", "Weaknesses": "1. While the approach is novel, the paper could provide more insight into the qualitative aspects of the long outputs compared to existing methods. 2. More comparisons with baseline models on various datasets would enhance the soundness of the results. 3. The computational efficiency and scalability of the proposed methods are not fully addressed.", "Questions": "1. How does the proposed method perform in terms of computational cost compared to traditional methods? 2. Are there specific applications or domains where ultra-long text generation has shown significant improvements using AgentWrite?"}}
{"paper_id": "9CqkpQExe2", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel and effective approach to improving the efficiency of MoE-based large language models by dynamically adjusting expert activations per token. Ada-K routing significantly reduces computational loads and increases inference speed while maintaining or enhancing model performance. The method is efficiently trainable and has a minimal memory footprint, and the extensive evaluation across multiple models and benchmarks strengthens the claim of its utility.", "Weaknesses": "The paper could benefit from a more detailed exploration of the trade-offs involved in the dynamic routing strategy, such as potential impacts on training complexity and resource management. Additionally, the comparison with traditional Top-K routing is strong, but further insights into alternative routing methods and their performance would have been valuable.", "Questions": "How does Ada-K routing handle highly ambiguous or contextually complex tokens where determining importance is challenging? Are there specific cases where Ada-K routing struggles compared to Top-K, and if so, what strategies could mitigate these difficulties?"}}
{"paper_id": "PpYy0dR3Qw", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel method, LoCoDL, which effectively integrates Local Training and Communication Compression. It offers rigorous theoretical proofs of linear convergence and demonstrates superior communication efficiency for federated learning.", "Weaknesses": "The presentation could be improved to enhance clarity and accessibility. The paper might benefit from additional empirical evaluations to validate theoretical claims comprehensively.", "Questions": "How does the algorithm perform with highly heterogeneous data distributions? Could the approach be applied to models other than those studied?"}}
{"paper_id": "UatDdAlr2x", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper provides a systematic exploration of how transformer architectural choices impact counting task strategies. It effectively demonstrates theoretical insights with empirical validation, offering clear explanations of relation-based and inventory-based counting strategies. The detailed investigation into the influence of the softmax function adds depth to the findings.", "Weaknesses": "The study is limited to a specific and simplified task scenario -- histogram counting with one-layer transformers. This raises questions about the generalizability of the findings to more complex tasks and multi-layer architectures. Additionally, the practical applicability of the insights for real-world transformer model improvements is not clearly defined.", "Questions": "Can the results be extended to multi-layer transformers or more complex tasks beyond counting? How do different dataset characteristics impact the observed strategies when using varied transformer setups?"}}
{"paper_id": "IwgmgidYPS", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper provides a robust solution to the challenge of creating scalable medical image datasets with detailed annotations. It leverages innovative methodologies, such as retrieval-augmented generation and the use of large multimodal models. The proposed dataset demonstrates significant improvements in medical visual QA performance.", "Weaknesses": "The dependence on automated annotation processes may raise concerns about the accuracy of annotations compared to expert manual annotations. The integration of knowledge from multiple sources might introduce inconsistencies or biases that need to be managed.", "Questions": "How does the model ensure the accuracy and consistency of the annotations generated by the automated pipeline? Are there measures in place to validate them against expert annotations?"}}
{"paper_id": "WG7GzGx3G9", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses the important issue of activation outliers in low-bit quantization, particularly for high-performing language models. The proposed Rotated Runtime Smooth (RRS) method effectively enhances performance with low computational overhead, demonstrating improvements over current state-of-the-art approaches.", "Weaknesses": "The paper could provide more detailed empirical evaluations on real-world distributed systems to substantiate claims about low computational overhead. Additionally, the explanation of the method might benefit from more clarity regarding hardware compatibility.", "Questions": "How does the RRS method perform with other model architectures beyond those tested? Are there specific hardware constraints where the method may not integrate as smoothly?"}}
{"paper_id": "BhECSDSkAE", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces a novel and efficient framework for medical video segmentation in low-data regimes, leveraging static image datasets combined with a memory-based adaptation strategy. The method addresses a clear need within medical imaging due to scarce annotated data, yielding promising results compared to existing approaches. The introduction of a new dataset for evaluation further demonstrates the practical implications and potential for establishing benchmarks in this area.", "Weaknesses": "While the paper presents an innovative approach, the level of detail in the methodological description may be inadequate for complete reproducibility by others. The presentation could be improved in terms of clearly explaining and justifying each component of the method. Additionally, the self-distillation mechanism and its advantages over alternative strategies are not sufficiently explored or validated.", "Questions": "What are the potential limitations or drawbacks of the proposed method when applied to non-medical video data? Can the efficiency and efficacy demonstrated on medical video datasets be expected to translate effectively to other domains with similar data challenges? How does the model perform when the first annotated frame is not representative of subsequent frames, i.e., when significant distribution shift exists within a video sequence?"}}
{"paper_id": "mnB4hDTIDr", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 2, "Rating": 5, "Confidence": 3, "Strengths": "The authors introduce an innovative approach, DCScore, for assessing the diversity of datasets generated by large language models. This approach is computationally efficient and aligns well with diversity indicators such as human judgment. The method's ability to satisfy several diversity-related axioms adds to its theoretical robustness.", "Weaknesses": "There is a lack of clarity on the specific practical applications and significance of evaluating LLM-generated dataset diversity. The novelty of DCScore in comparison to existing methods needs more evidence and explanation. Some experimental results, such as performance in a zero-shot setting, require further clarification, and the rationale for chosen experimental tasks is not fully justified.", "Questions": "How does evaluating the diversity of LLM-generated datasets contribute significantly to practical applications or the development of LLMs? Can the authors elaborate on the specific benefits and use cases of DCScore in practical scenarios? Additionally, could the authors explain the limitations of current methods in assessing semantic diversity compared to DCScore?"}}
{"paper_id": "Y0qmwm6tgy", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents a sound and well-structured method that leverages the Moreau envelope to improve the robustness of pruning LLMs, addressing an important challenge in model efficiency. The mathematical foundation of the Moreau envelope is well-explained, showing potential for effective application in pruning to mitigate weight perturbations. The evaluation is done on several significant LLMs, providing evidence of the method's effectiveness and stability in maintaining performance post-pruning.", "Weaknesses": "A notable weakness is the somewhat unclear practical significance and implication of ensuring pruning robustness to weight perturbations, as the paper does not thoroughly argue why such robustness is crucial or impactful in practice. The experiments, while sufficient to demonstrate the feasibility of the approach, are somewhat limited to the LLaMA family, potentially limiting the generalizability of the results. Additionally, the discussion on computational costs and efficiency of the proposed method is missing, which is crucial for practical deployment and comparison to existing methods. The overall performance improvements, although present, are not significantly dramatic over existing pruning techniques.", "Questions": "Why specifically is robustness to weight perturbations considered critical in pruning outcomes, and are there any further practical repercussions or scenarios where this robustness becomes indispensable? Could more diverse model architectures beyond the LLaMA family provide additional validation or insights into the method's applicability and generalizability? How does the computational efficiency of MoreauPruner, in terms of time and memory requirements, compare to traditional pruning methods, and are there scalability considerations for larger-scale models?"}}
{"paper_id": "aAcOaJYbUg", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 6, "Confidence": 3, "Strengths": "1. Addresses a significant gap by proposing a novel benchmark to evaluate modern vision models' OOD performance on web-scale data. \n2. Provides a thorough analysis by incorporating diverse models and human psychophysical experiments to validate findings.\n3. Introduces synthetic distortions that present a fresh robustness challenge to models, contributing to the field of robust AI.", "Weaknesses": "1. Limited details on how LAION-C distortions genuinely reflect OOD conditions not seen in web-scale data could weaken the argument.\n2. Visualization and comparison with human strategies are minimally discussed, which could limit the understanding of distinct model strategies.\n3. Lack of in-depth analysis on the implications of these new distortions on real-world application scenarios.", "Questions": "1. How well do the proposed distortions reflect real-world OOD scenarios, and could you provide examples or validations? \n2. Can you elaborate on how the human psychophysical experiments inform the evaluation of model performance vis-à-vis human-like strategies?"}}
{"paper_id": "duGygkA3QR", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper is well-written with a clear introduction of the connection between GNNs and DMD. The experiments cover a broad range of graph tasks indicating the practical utility of the proposed method.", "Weaknesses": "The novel contribution of combining DMD with GNN is interesting but the work could benefit from stronger theoretical insights into why this approach excels. The paper lacks comparisons with other frequency-based analysis methods.", "Questions": "How are the specific parameters in the DMD-GNN set, particularly in practical scenarios? Are there performance divergences in certain graph types or structures?"}}
{"paper_id": "s6nYndMwG7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The proposed method based on the spectral properties of the Hessian to set hyperparameters simplifies the practical application of influence functions. It addresses key challenges of computational cost and hyperparameter tuning, demonstrating potential for large-scale applications.", "Weaknesses": "The method relies on strong assumptions about the spectral properties of the Hessian, which may not hold in all cases. The empirical evaluation, while promising, needs additional validation across a broader range of models.", "Questions": "How sensitive is the method to variations in the Hessian's spectral properties in practice? What are the limitations when applying this method to non-convex loss surfaces often encountered in real-world models?"}}
{"paper_id": "9BVMD3keG8", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper successfully addresses a gap in existing literature by introducing contextual information into the problem of brokerage in OTC markets, which is a novel approach. Furthermore, the use of two types of feedback mechanisms and the development of algorithms for both scenarios is a strength, as it provides comprehensive coverage of possible real-world feedback conditions.", "Weaknesses": "The main weakness lies in the assumption of bounded density and the necessity of this assumption for learnability, which may limit the applicability of the findings. Additionally, while the inclusion of contextual information is innovative, the paper lacks thorough comparison with existing algorithms in real-world scenarios or datasets to illustrate practical advantages.", "Questions": "1. How was the contextual dimension chosen, and is there a standard for determining this in real-world settings?\n2. Can the algorithms be adapted to work without the bounded density assumption, possibly at the cost of lower performance?\n3. Are there insights or heuristics for selecting contexts that would significantly impact the learning outcome or performance?\n4. How would the proposed models integrate with existing market data to validate their practical application?"}}
{"paper_id": "mnna9LUg7P", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents a unique approach to quantizing state space models, acknowledging the particular challenges of activation patterns in SSMs. The tailored strategy, including the Hadamard transform and percentile clipping, is innovative and potentially useful for deploying large models on edge and cloud platforms.", "Weaknesses": "The solution's implementation lacks clarity, with insufficient experimental validation on cloud hardware. Further, the paper claims the absence of outliers in transformers that contradict established research, and there’s an unexplained improvement in accuracy which should typically degrade when techniques are applied incrementally.", "Questions": "1. How do the authors justify the claim that Transformers lack significant outliers in contrast to referenced works demonstrating their presence?\n2. Can the authors explain why combining their quantization techniques has improved accuracy contrary to expectations of incremental degradation?\n3. Could more details or evidence on cloud deployment performance be provided?\n4. What is the explanation for unexpected performance spikes in latency results?\n5. How stable and reproducible are the reported hardware measurements regarding result variability management?"}}
{"paper_id": "3X3LuwzZrl", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents an innovative method for multi-label node classification by decomposing GNN message passing operations. The Label Influence Propagation model appears to effectively capture complex inter-label influence correlations, significantly improving classification accuracy on benchmark datasets compared to state-of-the-art methods. The approach provides a deeper understanding of label interactions in non-Euclidean spaces.", "Weaknesses": "The paper lacks detailed comparisons with existing label propagation techniques and could benefit from more examples and visualizations to illustrate the influence of labels better. Hyperparameter analysis and the impact of different label categories on model performance could be elaborated. Additionally, testing the approach with a wider range of GNN backbones would strengthen the evidence of its effectiveness.", "Questions": "Can the authors provide more examples or case studies to illustrate the positive and negative influences of different labels? How do specific hyperparameters affect model performance, and what guidelines can be provided for tuning them? What is the impact of the number of label categories on the algorithm's performance, and have different backbones like GIN been tested to verify the method's adaptability?"}}
{"paper_id": "IqaQZ1Jdky", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper introduces an innovative adaptation of Kolmogorov-Arnold Networks by incorporating a variable function basis using Bernstein polynomials, which enhances the robustness and flexibility of the model. The use of Bayesian optimization to adapt the polynomial degree is an interesting approach to balance accuracy and resource consumption.", "Weaknesses": "While the proposed VBn-KAN framework is novel, the paper provides limited evidence of significant performance improvements over traditional networks and other KAN variants. The experimental evaluation, though extensive, might not fully establish the model's superiority across diverse tasks. Claims regarding the reduction of data influence on the model are not entirely supported by the presented results.", "Questions": "How does the proposed VBn-KAN framework perform in comparison to state-of-the-art methods for widely used datasets like CIFAR-10/100? Can the theoretical claims regarding robustness and uniform convergence be empirically validated in more varied experimental settings?"}}
{"paper_id": "OdMqKszKSd", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper presents a novel approach to generating 3D articulated objects from a single image using diffusion models, which is innovative and addresses important scalability challenges in prior methods. The experimental results demonstrate improved performance over existing approaches in terms of graph prediction accuracy and reconstruction quality. The use of large pretrained models like DINOv2 and GPT-4o for encoding and prediction adds robustness to the method.", "Weaknesses": "While the method shows promise, it is somewhat reliant on pretrained models, which might introduce dependency issues or limitations in terms of fine-grained control. The scalability of this approach to a wide variety of real-world scenarios with diverse objects remains to be fully demonstrated, as the evaluation is primarily on datasets that might not capture the full complexity of real-world environments. The practical implementation details and potential performance bottlenecks of the method are not thoroughly discussed.", "Questions": "How does the use of GPT-4o for predicting the part connectivity graph affect the inference time and computational requirements of the method? Are there any limitations observed when using this approach on highly complex or unconventional objects? How transferable is this diffusion-based approach to other domains or object types outside the ones evaluated?"}}
{"paper_id": "LOBhVTtVnc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 8, "Confidence": 4, "Strengths": "The introduction of Geometric Spatiotemporal Transformers (GSTs) with equivariant spatiotemporal blocks addresses the critical challenge of preserving E(3) symmetries, offering significant improvements in simulating long-term physical dynamics. The additional use of a Temporal Difference Graph (TDG) is an innovative approach to reduce cumulative errors, enhancing the prediction of long-term trajectories.", "Weaknesses": "The paper does not provide a comparative analysis of the model's efficiency regarding runtime and parameter count against existing methods, possibly leaving performance gains to ambiguity. The depth and scale of models compared are limited, potentially biasing results towards the benefits of the proposed Transformer architecture over traditional GNNs.", "Questions": "What is the computational efficiency of GSTs in terms of parameter count and runtime compared to existing state-of-the-art methods? How do these models scale with increased problem sizes, and what is the impact on performance with larger datasets?"}}
{"paper_id": "oa5UeyUVMm", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses a novel and relevant problem in applying diffusion probabilistic models to graph representation learning. The proposed method, Graffe, achieves state-of-the-art performance on node and graph classification tasks on various datasets. The theoretical foundation provided for the method enhances its credibility.", "Weaknesses": "The paper lacks detailed insights into certain aspects of the methodology, such as the impact of the mask ratio and reconstruction of the adjacency matrix on performance, which may hinder reproducibility and understanding. Additionally, potential limitations regarding scalability or general applicability to different graph structures are not thoroughly discussed.", "Questions": "How is the mask ratio chosen across different datasets, and how sensitive is the performance to this choice? Are there any limitations regarding scalability to very large graphs, and how does the proposed method handle graphs with highly varied structures?"}}
{"paper_id": "5swfKRkCx7", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel mechanism for integrating external knowledge into language models, improving their performance on knowledge-intensive tasks. It effectively demonstrates the benefits of dynamic and layer-wise integration, outperforming traditional RAG approaches on benchmark datasets.", "Weaknesses": "The integration mechanism's implementation details and potential limitations, such as computational efficiency or scalability, are not thoroughly explored or discussed. The paper lacks a detailed analysis of the complexity and possible challenges in practical deployment.", "Questions": "How does the proposed method affect the computational complexity and training time of language models? Are there specific scenarios where this method might not be beneficial?"}}
{"paper_id": "5s1qpjrNvZ", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 5, "Confidence": 4, "Strengths": "The paper proposes a novel approach to guided reinforcement learning with performance guarantees, which could be beneficial in improving sample efficiency. The proposed methods (GRL and GRL-RB) are shown to be robust across different environments, offering a new perspective on handling the guide sampling rate.", "Weaknesses": "The empirical evaluation lacks comprehensiveness and does not convincingly demonstrate significant improvement over existing methods. The assumptions made for deriving the sampling rates may not hold in practical scenarios, leading to potential issues in applicability. Some claims regarding guarantees may be overstated without sufficient qualification.", "Questions": "How does the proposed method compare to other state-of-the-art guided reinforcement learning methods in more complex environments? Is there room for further improvement in the empirical evaluation to demonstrate broader applicability and effectiveness of the method?"}}
{"paper_id": "WNb4P8aG66", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1) The paper presents a novel and effective method called Diffusion on Diffusion (DoD) that integrates visual priors into diffusion models, enhancing image generation quality. 2) It achieves state-of-the-art results with reduced training costs compared to existing methods. 3) The framework is simple, elegant, and fast, offering significant improvements over traditional class-guided diffusion models.", "Weaknesses": "1) While the paper introduces a compelling technique, it lacks comparative experiments against some other recent and competitive approaches in post-hoc diffusion methods. 2) The Latent Embedding Module (LEM) is not extensively compared to other image feature conditioning methods, which would strengthen its claimed novelty and efficacy.", "Questions": "1) How does DoD specifically compare in efficiency and quality to other recent post-hoc diffusion methods? 2) How does the LEM perform compared to other conditioning methods that use image features? 3) Can more qualitative examples be provided to illustrate the specific improvements in image fidelity and texture detail?"}}
{"paper_id": "UfczlMudN6", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 3, "Strengths": "The paper proposes a novel framework that successfully integrates contextual adaptation and adversarial reinforcement learning, demonstrating strong results on both ID and OOD tasks. The approach is innovative and directly addresses a current gap in deep RL methods, providing a significant contribution to the field. The use of a real-world test case with a quadruped robot for validation adds credibility and relevance to the proposed method.", "Weaknesses": "The paper could benefit from a clearer presentation of the results and methodology, as some descriptions may not be detailed enough for complete replication by the reader. Additionally, the paper might lack comparison with some contemporary methods, which could better illustrate the strengths and weaknesses of the proposed approach relative to existing solutions.", "Questions": "How does GRAM compare to other state-of-the-art methods not mentioned in the paper? Are there any limitations of the GRAM approach that were identified during experimentation, especially in complex real-world environments?"}}
{"paper_id": "60Vd7QOXlM", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes a novel method to enhance privacy auditing of Large Language Models by designing more effective canaries, which are more likely to be memorized. The new token canaries introduced show a significant improvement in detecting privacy risks in LLMs, providing tighter empirical bounds on privacy leakage. The method is tested across various models and settings, demonstrating consistent results. Overall, the approach brings a valuable advancement in understanding and estimating privacy risks in machine learning models.", "Weaknesses": "The approach heavily relies on the assumption that more effective canaries that are easily memorized by models can accurately measure privacy leakage. However, it does not address how well these canaries reflect real-world data leakage threats since it is not guaranteed that real-world sensitive data would have similar properties to the crafted canaries. There is also a lack of extensive analysis on how these canaries perform across diverse datasets and different LLM architectures, limiting the generalizability of results.", "Questions": "Can the authors provide more insights into how the effectiveness of these canaries in privacy audits might translate to real-world scenarios where different types of sensitive data are involved? Also, how do these canaries perform when tested with different datasets and potential distribution shifts that occur in real-world data, are there any measures to robustly evaluate this aspect?"}}
{"paper_id": "GqhvJ1o8m5", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 5, "Strengths": "1. The paper introduces a large dataset for stereo video generation, which will benefit research in this area.\n\n2. The design for implicit disparity is reasonable, aligning with findings that direct optical flow is not ideal for image synthesis.", "Weaknesses": "1. The dataset details are missing.\n\n(a) How many frames per video? Does the videos have the same length? If not, what's the length distribution?\n\n(b) Stereo videos often contain multiple scenes. The author only measures spatial consistency between the left and right view. However, temporal consistency seems to be missed, which is crucial for stereo videos. How is it handled?\n\n(c) In Eq. 1, the authors used optical flow estimated by RAFT to measure error. However, optical flow may not be accurate for stereo pairs due to vertical movement. The author should focus on the horizontal direction. Although claiming, \"We also evaluated STTR and RAFT-Stereo, but these methods produced worse results,\" a more accurate disparity estimation or constraining RAFT horizontally is needed.\n\n2. Experiments\n\n(a) For fair comparison, authors should re-train or finetune state-of-the-art methods on the new datasets.\n\n(b) To check the proposed dataset's effectiveness, evaluate image-based models trained on it using previous image-based datasets.\n\n\nMinor\n\n1. \"6.39%(SSIM), and 5.10% (PSNR)\" is unprofessional. Typically, we report differences like 1.1 dB for PSNR. Given PSNR's log nature, percentage is incorrect.", "Questions": "Please refer to the weakness section."}}
{"paper_id": "ua5MHdsbck", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses an important and challenging problem in protein design, specifically focusing on extrapolation beyond the training space. The proposed method innovatively uses triplet-based preference learning, which appears to be new in this context. The empirical results demonstrate that the method significantly outperforms existing baselines and state-of-the-art methods.", "Weaknesses": "The reliance on a scorer function to generate triplets may limit the method's applicability in cases where scorer functions are difficult to obtain or inaccurate. The presentation could be clearer in terms of method description and intuition behind certain design choices.", "Questions": "How does the method perform when the scorer function is noisy or inaccurate? Are there any strategies for mitigating the impacts of inaccurate triplet generation?"}}
{"paper_id": "56Zn3halhq", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper presents a novel adaptive data augmentation method that targets marginal samples to improve forecasting accuracy. The use of reinforcement learning adds a dynamic component to the augmentation process, potentially allowing for more precise improvements in model training. The approach demonstrates performance gains with minimal additional computational overhead, making it practically appealing.", "Weaknesses": "The reliance on a robust model zoo for optimal results may limit the method's applicability in scenarios where such a zoo is not available. The effectiveness of the method in less-than-ideal model zoo conditions is not thoroughly explored. Also, the complexity introduced by reinforcement learning may prove challenging in practice, especially for smaller-scale use cases.", "Questions": "How does AutoTSAug perform in environments where the model zoo is not robust or is suboptimal? What are the specific limitations or potential pitfalls when deploying this method in such conditions? Can the method be adapted or simplified for use cases with limited computational resources?"}}
{"paper_id": "aPTGvFqile", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper makes a clear contribution by proposing a method to reduce the modality gap in CLIP embeddings using parameter sharing and intra-modality separation. The improvements in zero-shot classification and multi-modal retrieval demonstrate the method's effectiveness. Presentation is well-organized and provides a clear explanation of the techniques.", "Weaknesses": "While the idea of parameter-sharing is beneficial, it is not entirely novel as it builds significantly on existing methods. The ablation study could be expanded to dissect the contributions of each component more thoroughly. Some claims in the results aren't fully explained, such as the specific conditions under which the proposed method outperforms others.", "Questions": "How significant is the impact of the intra-modality separation objective compared to existing gap closure techniques? Moreover, what are the implications of using this method with different base models, such as CLIP-ResNet?"}}
{"paper_id": "GOwNImvCWf", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 2, "Rating": 3, "Confidence": 5, "Strengths": "The paper introduces a novel approach by combining structural and behavioral losses to improve reconstruction of neural networks. The explanation is clear, and the method is straightforward, showing improved performance in both reconstruction and generative tasks.", "Weaknesses": "The paper's novelty is questionable since similar use of behavioral loss has been explored before. The experimental setup is limited to small CNNs, lacking diversity in model architectures or tasks. Hyperparameter sensitivity isn't thoroughly explored. Training time concerns and the creation of a new model zoo instead of using established ones are notable issues.", "Questions": "Have the authors considered improving the model by explicitly encouraging hybrid eigenvalue features? Was the choice of training with only random permutation augmentation deliberate, and why weren't other known augmentations explored?"}}
{"paper_id": "C9BA0T3xhq", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper highlights a novel approach to addressing extrapolation errors in offline reinforcement learning, showing promising empirical results against benchmarks like D4RL.", "Weaknesses": "The paper lacks comparison with some important existing methods in the related area, which could strengthen the impact of the proposed methodology.", "Questions": "How does the proposed method compare with other state-of-the-art offline RL methods not mentioned in the paper, especially those addressing similar challenges?"}}
{"paper_id": "EeqlkPpaV8", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper provides a strong theoretical contribution by establishing lower bounds on the complexity of sampling algorithms. This is important for understanding the fundamental limitations of current approaches in high-dimensional settings and parallel computation models. The use of novel constructions and the theoretical analysis is a key strength.", "Weaknesses": "The paper focuses heavily on theoretical aspects and might lack immediate practical implications. The presentation, while thorough, could be challenging for readers not deeply familiar with the field. The interpretation of some results may not be entirely clear without extensive background knowledge.", "Questions": "How can these theoretical insights on complexity lower bounds be translated into practical improvements for sampling algorithms? Are there specific real-world applications that could benefit from the findings in the paper?"}}
{"paper_id": "oK1zJCWBqf", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The novel approach of Soft Preference Optimization offers a simpler alternative to traditional reward-model-dependent alignment methods. The inclusion of a preference loss combined with regularization is conceptually sound and the experimental results against known baselines are favorable.", "Weaknesses": "The paper lacks clarity in presenting the experimental setups and results, particularly around comparison metrics. The theoretical framework omits the regularization aspect in its formal proofs, which raises concerns about the comprehensiveness of the claims. The treatment of the weighting function is also insufficiently justified and lacks an intuitive explanation.", "Questions": "What motivated the specific form of the regularization term, and how does it impact learning dynamics compared to traditional methods? Can the authors offer more detailed comparisons or ablation studies on the weighting mechanisms within SPO?"}}
{"paper_id": "Dq9VrVuLzV", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "1. SyntheOcc presents an innovative approach with 3D semantic multi-plane images, advancing the synthesis of geometrically controlled street view images. 2. The framework shows potential for improving data augmentation and scenario testing for autonomous driving by generating diverse datasets.", "Weaknesses": "1. The paper could benefit from more comprehensive quantitative comparisons with existing methods to strongly validate performance claims. 2. The reliance on specific datasets (like nuScenes) may limit generalizability to other scenarios or applications.", "Questions": "How does SyntheOcc handle edge cases or unusual scenes not well represented in the training data, and how robust is it in these situations?"}}
{"paper_id": "73Q9U0vcja", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces a novel integration of generative diffusion models with active learning for CT scan data acquisition, resulting in significant reduction of X-ray exposure and improved image reconstruction quality. The approach is well-evaluated on multiple real-world datasets, demonstrating its potential for broader scientific and medical applications.", "Weaknesses": "The method might have limitations in high-stakes medical imaging that need addressing before practical adoption. The computational cost and complexity introduced by the generative model and active learning integration might be high. Comparisons with state-of-the-art CT reconstruction algorithms or systems are not extensively covered.", "Questions": "How does the proposed method compare in terms of computational efficiency with existing CT reconstruction models? What are the specific trade-offs in applying this technology to medical imaging?"}}
{"paper_id": "UiEjzBRYeI", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper addresses an important limitation of existing vision foundation models, providing a novel way to improve semantic-aware segmentation using SAM by introducing composable prompts. The method shows strong performance across multiple datasets, suggesting its capability in handling a variety of segmentation tasks. Furthermore, the use of a two-type composable prompt system demonstrates an innovative approach to utilize SAM's foundational strengths.", "Weaknesses": "The paper may lack in offering a direct comparison with other state-of-the-art SAM-based segmentation methods. Additionally, it appears the reliance on specific datasets for training could limit the proposed method's generalizability to different types of image data, such as those in specialized fields like medical imaging.", "Questions": "How does SAM-CP compare with other contemporary SAM-based methods specifically designed for semantic segmentation? Can the authors clarify the process of how the composable prompts help in achieving finer-level segmentation, especially beyond what SAM inherently provides?"}}
{"paper_id": "lessla98Wp", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The proposed L-C4 method for video colorization using language input is innovative and addresses key challenges in the field, such as semantic accuracy and temporal consistency. The integration of cross-modality generative models with novel modules like temporally deformable attention and cross-clip fusion demonstrates significant methodological advancements. The paper is well-structured, and experimental results show clear improvement over state-of-the-art methods.", "Weaknesses": "The paper may lack detailed insights into the possible limitations of the proposed method. It would be beneficial to understand scenarios where L-C4 might fail or perform sub-optimally. Additionally, while the approach leverages a large dataset of text-video pairs, there might be concerns about its applicability and robustness in more diverse real-world scenarios not reflected in the dataset.", "Questions": "How does the model handle ambiguous or overly complex language descriptions that could lead to multiple valid colorizations? Are there any specific failure modes or challenges identified during the testing of L-C4 that could inform future improvements?"}}
{"paper_id": "UstOpZCESc", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a critical and emerging problem in the context of lifelong learning and privacy. It provides a novel solution that effectively combines lifelong learning with exact task unlearning capability. The experimental results demonstrate state-of-the-art performance with scalability across architectures and datasets. The approach is innovative and has strong theoretical foundations, making it a significant contribution to the field.", "Weaknesses": "The paper lacks some baselines from the unlearning literature, which would provide a broader contextual understanding of its relative performance. Additionally, certain explanations and parts of the methodology could be clarified further to aid comprehension. The evaluation, although comprehensive, might benefit from including more diverse scenarios or adversarial task sequences to thoroughly assess robustness. Moreover, the real-world feasibility of executing specific unlearning requests based on task constraints needs to be explored. The proposed method may also require substantial computational resources, influencing its practical applicability.", "Questions": "Can the proposed method handle scenarios where data is not neatly divided into tasks, such as continuous or overlapping user data contributions? Additionally, what are the practical implications regarding computational requirements for implementing PALL in large-scale systems? Also, could you provide further explanation or examples illustrating how the unlearning is managed if multiple tasks share common data elements that need to be selectively unlearned?"}}
{"paper_id": "LnRegTxsa4", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes novel techniques for improving cross-view object geo-localization, demonstrating enhanced performance over previous methods. The presentation is clear and the structure allows for easy understanding of the complex methodology. The introduction of the G2D dataset is a notable contribution, addressing current gaps in available data.", "Weaknesses": "The methodology primarily builds on existing attention mechanisms and doesn't explore significant new theoretical insights. There could be further discussion on the potential limitations of the proposed approach and comparative analysis with a broader range of previous models.", "Questions": "How do the proposed models perform in environments with extreme weather conditions or in varied lighting scenarios? Are there specific scenarios where the improvement in performance was notably lower?"}}
{"paper_id": "2ErS9Bkc3O", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper provides a novel matrix-theoretic analysis that supports theoretical insights into the adversarial fragility of neural networks.", "Weaknesses": "The applicability of the theoretical findings is somewhat limited due to assumptions, and the experiments are not comprehensive enough to ensure generality beyond toy models.", "Questions": "How might these findings extend to other types of neural networks and data distributions?"}}
{"paper_id": "pK3oe2bubc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses a relevant gap by enhancing the robustness of vision transformers to layer order changes, which is significant for distributed computing scenarios. The LayerShuffle method demonstrates practical value by enabling models to maintain performance under adverse conditions.", "Weaknesses": "The method incurs a reduction in accuracy when compared to sequential execution, which can be a drawback in performance-sensitive applications. Additionally, the evaluation might benefit from a broader range of tests or baselines to more comprehensively validate the approach.", "Questions": "Does the LayerShuffle method impose any additional computational overhead during training, and how does this compare to traditional training methods in terms of efficiency?"}}
{"paper_id": "sec09tLQUl", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses an important issue related to the generalization of deep learning models in the presence of spurious correlations. It proposes an innovative approach that does not rely on group annotations, making it applicable to large, unannotated datasets.", "Weaknesses": "The assumptions regarding neuron roles and the potential loss of useful memorization aspects are limitations that may impact the method's effectiveness in certain scenarios. Furthermore, the approach requires further validation and clarification regarding its scalability and computational complexity.", "Questions": "How does FairDropout determine which neurons are specifically responsible for memorization, and how does it ensure that dropping these neurons does not negatively impact the model's overall performance?"}}
{"paper_id": "96jZFqM5E0", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel method for improving 3D hand pose estimation using in-the-wild datasets effectively. It leverages large-scale datasets and a new contrastive learning approach to achieve notable improvements over previous methods.", "Weaknesses": "While the method shows significant improvements, the adaptive weighting mechanism could be more thoroughly explored. Furthermore, the comparisons with other state-of-the-art methods like TempCLR could be expanded.", "Questions": "How does the model perform in scenarios with significant hand-object occlusion? Are there any failure cases or limitations observed with the SiMHand framework?"}}
{"paper_id": "uNd289HjLi", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The Corruption2Self (C2S) framework provides a novel approach to MRI denoising without requiring high-SNR training data, overcoming limitations of existing self-supervised methods. The method demonstrates state-of-the-art performance in preserving image details while effectively reducing noise, and functions well across varied MRI contrasts.", "Weaknesses": "While promising, the paper's results may have a limited exploration of certain edge cases encountered in clinical practice, and additional real-world applicability demonstrations could further strengthen its impact. The complexity of the proposed method may pose implementation challenges for practitioners.", "Questions": "How does the noise level reparameterization contribute to the convergence and performance improvements observed in C2S? Are there any specific limitations or failure cases of the method when applied to different MRI datasets or in clinical settings?"}}
{"paper_id": "e2ONKX6qzJ", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "1. The proposed APG method effectively mitigates oversaturation issues in diffusion models, improving image generation quality without additional computational costs.\n2. The orthogonal decomposition approach and the introduction of rescaling and momentum are innovative and demonstrate practical utility across various models and samplers.", "Weaknesses": "1. The paper could provide more theoretical insights or experimental details on the role of reverse momentum in improving output quality.\n2. Further exploration of scenarios where APG might underperform compared to CFG, especially at lower guidance scales, would be beneficial.", "Questions": "How does APG perform in extreme cases of high CFG scales beyond typical use cases?"}}
{"paper_id": "a2eBgp4sjH", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper presents novel algorithms that integrate ANN algorithms with subset query algorithms to address MultiFilterANN issues. It offers robust space-time trade-offs and introduces new datasets for future research, enhancing the empirical evidence of these algorithms' competitiveness.", "Weaknesses": "The connection between theoretical results in Section 4 and the empirical algorithm proposed in Section 6 is unclear. The results in Section 7 lack clarity on whether they stem from the graph-based approach or a hybrid approach, raising concerns about their reliability. There is also a possibility that simpler methods could outperform the proposed algorithm under certain conditions.", "Questions": "Can you clarify the relationship between the theoretical results in Section 4 and the empirical method proposed in Section 6? Are the results in Section 7 based on the graph-based approach discussed in Section 6 or a different hybrid method? How do the proposed methods compare directly against simple baseline methods such as brute force search?"}}
{"paper_id": "EIXZXPz7jU", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper proposes an innovative approach to address current limitations of PINNs, specifically targeting the challenge of solving PDEs with singularities. The method improves sampling efficiency by focusing on regions of high PDE residuals, which enhances the accuracy of the resultant solution. Experimental results demonstrate the potential improvements in performance over existing methods.", "Weaknesses": "Details on the implementation, especially regarding the integration of the sampling method with PINNs, could be elaborated further to fully understand its application across different PDEs. The practicality of scaling this approach to broader scenarios or different types of singularities would benefit from more extensive testing.", "Questions": "What are the computational trade-offs when applying the proposed sampling method in various high-dimensional PDE problems? How does the approach handle different types of singularities beyond peaks in the source function? Can this method be generalized or adapted for other neural solver frameworks?"}}
{"paper_id": "QO4bF6MHza", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel and necessary benchmark, MathHay, that specifically targets the mathematical reasoning capabilities of LLMs in long-context scenarios. This addresses a significant gap in the existing evaluation frameworks. The methodology for constructing and validating this benchmark is robust, involving real-world document scenarios and diverse question types.", "Weaknesses": "The paper's main focus is on benchmarking rather than improving the LLMs' performance, which some might view as a limitation in terms of immediate practical utility. Additionally, the results suggest that LLMs have significant limitations, but there is limited discussion on potential strategies for model improvement based on these findings.", "Questions": "How does MathHay compare directly with existing long-context benchmarks in terms of the types of tasks and difficulty? What are some potential avenues for enhancing LLM capabilities in mathematical reasoning that the authors suggest could be explored following these findings?"}}
{"paper_id": "GULx8rzzjC", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper tackles a practical and significant problem related to data acquisition for machine learning model training under privacy constraints. Mycroft, the proposed method, is innovative in utilizing feature space distances and gradient matching to identify informative data subsets, thereby demonstrating the potential for improved model performance with minimal data exposure. The experimental results validate Mycroft's effectiveness across different domains, indicating its robustness and capacity to rank data owners by utility.", "Weaknesses": "The RetrieveTopK function in Algorithm 3 and parts of the proof for Theorem 3.1 are somewhat confusing, which can hinder comprehension and reproducibility. The paper could benefit from clearer descriptions of the algorithmic steps, particularly in Algorithms 4 and 5, and a better explanation of sparsity's role in the proof. Additionally, the experiments lack tests under privacy-protecting conditions, which are crucial for demonstrating the method's full practical applicability. The evaluation settings in terms of dataset portions used for testing were not always clear.", "Questions": "What specific criteria or heuristics does the RetrieveTopK function employ, and how does it ensure coverage of D^{hard}? Could you provide more detailed explanations or illustrations for Algorithms 4 and 5 to enhance understanding? How does the system adapt or maintain robustness under privacy-preserving constraints, such as differential privacy? Are there plans to test Mycroft in more diverse datasets or real-world settings where privacy constraints are in effect?"}}
{"paper_id": "PnZ2lbQaao", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 5, "Confidence": 3, "Strengths": "The method DICF combines Bayesian modeling and adversarial learning, allowing fine-grained feature separation. This ensures that only domain-invariant features contribute to the recommendation, reducing noise and improving prediction accuracy. The probabilistic graphical model and ELBO-based training enhance DICF's ability to capture complex dependencies among features and improve model generalization across different domains.", "Weaknesses": "The introduction is too simple and not clear. Giving a toy example would be better to illustrate the problem of this paper. This paper does not point out the challenges of problem or motivation of its method. Other weaknesses can be found in Questions section.", "Questions": "I think there is a mistake in Figure 2. It should be $p(\\beta|\\gamma)$ instead of $p(\\gamma|\\beta)$, right? The input should be $\\gamma$ if my understanding is right. Results from two synthetic datasets are not convincing because they are generated from the assumption your model has. When synthetic data is generated with assumptions aligned to the model, it can indeed inflate performance results."}}
{"paper_id": "AT64R0ivUO", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The proposed SteerPrompt method creatively combines iterative prompting and attention steering, enhancing the reading comprehension of LLMs without altering their parameters. The method's generalizability across different tasks and its efficiency in terms of computational overhead are notable strengths.", "Weaknesses": "The paper's evaluation is primarily focused on open-book QA tasks, which might limit the understanding of the method's applicability to other NLP tasks. The paper could provide more clarity on how key sentence identification is performed and the potential biases that might arise.", "Questions": "How does SteerPrompt handle cases where key sentences are ambiguous or not clearly defined? Can the method be extended or adapted for use in other NLP tasks beyond QA? Are there any potential limitations or biases in the attention steering approach that the paper does not address?"}}
{"paper_id": "nGiGXLnKhl", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "VRWKV shows superior performance in image classification and dense prediction tasks compared to ViTs with reduced computational costs. The architectural modifications allow linear complexity in vision tasks, showcasing an innovative adaptation of NLP concepts to vision.", "Weaknesses": "The paper may not provide in-depth theoretical analysis of the novel mechanisms introduced, such as Q-Shift and Bi-WKV. It also lacks comparisons with other linear attention mechanisms in vision beyond ViTs.", "Questions": "Have the authors considered the applicability of VRWKV to other vision benchmarks or real-world use cases beyond those tested? What are the limitations and potential drawbacks of the VRWKV architecture when applied to different vision scenarios?"}}
{"paper_id": "TBJCtWTvXJ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 3, "Strengths": "The paper provides a novel perspective on the limitations of the Adam optimizer, introducing SignSoftSGD (S3) with a well-founded hypothesis and thorough theoretical analysis. The empirical results on vision and language tasks demonstrate the effectiveness and efficiency of S3, showing significant improvements over Adam and AdamW.", "Weaknesses": "The paper may not fully explore the potential drawbacks or limitations of using larger learning rates with S3, such as stability or generalization risks. The dependence on the specific choice of the p-th order momentum could also be further analyzed.", "Questions": "How sensitive is the performance of SignSoftSGD to the choice of the p-th order momentum? Are there specific scenarios where S3 might underperform compared to Adam?"}}
{"paper_id": "8gSrJOL2oc", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 4, "Strengths": "The paper addresses three key limitations in existing CZSL approaches and introduces a novel framework, TRIDENT, which significantly improves the state-of-the-art performance by leveraging MLLM embeddings and attribute smoothing. The results on multiple challenging datasets demonstrate the effectiveness of the proposed approach.", "Weaknesses": "While the paper presents a strong conceptual framework, it lacks clarity in the description of the methodology, particularly in how the components interact within TRIDENT. Additionally, the presentation of results could be more detailed to better highlight the specific improvements and their sources. The reliance on MLLM embedding effectiveness also raises concerns about generalizability without such resources.", "Questions": "How do the proposed techniques, especially feature adaptive aggregation and attribute-object disentanglement, translate into improved performance practically? Can the authors elaborate on the specific contributions of each component (FAA, disentanglement, and MLLM embeddings) to the overall improvement observed?"}}
{"paper_id": "yheQRc5xWB", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The proposed method, Mamba-CDSP, effectively addresses the challenges of time-varying counterfactual prediction by using state-space models to improve handling of long sequences and reduce confounding bias. The approach demonstrates significant improvements over existing methods in terms of prediction accuracy and computational efficiency, which is validated through extensive empirical evaluations on diverse datasets.", "Weaknesses": "While the paper presents a novel approach using state-space models, the methodology could benefit from deeper theoretical insights into why this model structure effectively mitigates confounding biases. Additionally, the evaluation could include more diverse real-world datasets to further substantiate the method's generalizability and robustness.", "Questions": "What are the specific limitations of the proposed method in terms of scalability and applicability to very large datasets or different data domains beyond what was tested? How does the choice of replacing convolutional layers with dropout layers specifically contribute to the prevention of overfitting, and could alternative regularization methods have been considered?"}}
{"paper_id": "HxKSzulSD1", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces the novel concept of weak-to-strong deception within the alignment of AI models, addressing an important gap in the literature. The study is well-structured and provides experimental evidence using various language models, confirming the existence of the phenomenon. This adds credibility to their findings and highlights a critical issue in AI alignment.", "Weaknesses": "The experiments are limited to language models and specific datasets, which may not fully capture real-world scenarios. The paper does not thoroughly explore solutions to mitigate the deception issue beyond mentioning the use of intermediate models, leaving potential practical applications partially addressed.", "Questions": "How can the findings about weak-to-strong deception be generalized to other types of AI models beyond language processing? Are there specific strategies recommended for reducing deception more effectively than those tested in the study?"}}
{"paper_id": "wH8XXUOUZU", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces innovative techniques to enhance high compression ratio autoencoders, significantly improving reconstruction accuracy without sacrificing image quality metrics. It demonstrates substantial improvements in efficiency and speed for high-resolution image synthesis models, important for practical applications.", "Weaknesses": "The paper's presentation could be clearer, with detailed clarifications on methodological specifics and experimental setups needed. Additionally, there may be gaps in the evaluation regarding the impact of architectural choices on performance trade-offs.", "Questions": "What specific datasets and benchmarks were used to validate the improvements, and how were the baselines selected? Additionally, how robust is the proposed method to varying types of image data beyond those tested, and are there specific trade-offs in different contexts?"}}
{"paper_id": "QWIg5e6mtT", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses the complex issue of extending successful two-player game algorithms to multi-player team settings, introducing a novel method that performs better in heterogeneous role contexts. It demonstrates reduced exploitability and superior performance in benchmark tests.", "Weaknesses": "The reliance on sequential optimization might limit the method's applicability to extremely large-scale games. The method's adaptability to continuous action spaces is yet to be explored.", "Questions": "How does the sequential optimization approach adjust when scaled, and what are the initial results regarding adaptation to continuous action spaces?"}}
{"paper_id": "kbSU5bwoRv", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper introduces an innovative zero-shot SVC model, SaMoye, that effectively addresses feature disentanglement and timbre leakage issues. It demonstrates significant improvements in converting voices, including challenging cases like non-human timbres. The large dataset ensures robust generalization, and the paper provides comprehensive results through objective and subjective evaluations.", "Weaknesses": "While the results are promising, it might be interesting to compare the proposed approach with more baseline models or state-of-the-art alternatives to comprehensively assess its relative strengths. Furthermore, the specifics of how the ASR models are combined and the impact of this on performance are not fully detailed, which could be explored further.", "Questions": "How does SaMoye specifically handle cases of conversion between drastically different timbres, such as human to non-human singing voices, without compromising the quality of conversion? Additionally, how scalable is the approach when exposed to entirely new and unseen types of input in real-world applications?"}}
{"paper_id": "KyqtKhv6q1", "review": {"Soundness": 3, "Presentation": 4, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel approach, Differentiable Map Priors (DMP), that incorporates historical data into multi-view 3D perception systems for autonomous vehicles, showing significant performance improvements in 3D object detection and semantic map segmentation. The method is efficiently and elegantly integrated into various baseline architectures and validated with extensive experiments on the nuScenes dataset.", "Weaknesses": "While the method appears effective, the improvements reported are moderate and could be affected by variations in sensor input quality or different environmental conditions not detailed in the paper.", "Questions": "How does the method handle dynamic changes in the environment over time, and what is the computational overhead introduced by maintaining and updating these spatial priors during vehicle operation?"}}
{"paper_id": "lTL4t68BNc", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The proposed RGA-IB method demonstrates a novel application of the Information Bottleneck principle to improving the adversarial robustness of graph neural networks. The paper provides strong empirical evidence supporting the efficacy of the method across diverse datasets and attack scenarios.", "Weaknesses": "The paper could be improved by providing more detailed theoretical insights into why the Information Bottleneck principle is effective for robustness in GNNs, and by comparing against a broader set of baseline methods in the experiments.", "Questions": "How does the RGA-IB method compare with state-of-the-art methods in terms of computational efficiency? Could the authors provide more in-depth analysis on the trade-offs between explanatory power and robustness using the Information Bottleneck principle?"}}
{"paper_id": "hWmwL9gizZ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The model uses a novel dual attention mechanism which is innovative and mathematically sound. The use of a large, well-curated dataset enhances the robustness and generalizability of the results. The paper comprehensively benchmarks the new method against existing techniques.", "Weaknesses": "The reliance on pre-trained models can be a limitation if these models have inherent biases or limitations. There is a potential lack of clarity in explaining certain methodological details that could affect reproducibility.", "Questions": "How does the model handle new protein sequences that were not part of the pre-training data? How does it compare to other state-of-the-art methods in terms of computational efficiency?"}}
{"paper_id": "IL85Ebjg9j", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper introduces an innovative computational trust-based discounting method that enhances the reliability of multi-view classification by dynamically adjusting the influence of each view based on instance-specific trustworthiness. The proposed approach effectively addresses the common issue of view conflicts in real-world MVC scenarios, showing significant improvements in prediction accuracy and reliability across multiple datasets.", "Weaknesses": "The presentation of the method is somewhat hindered by the placement of the algorithm and key details in the appendix, making it difficult for readers to fully grasp without flipping between sections. While the experimental results are promising, the paper lacks a detailed analysis of the method's computational complexity and scalability, especially in dynamic environments like autonomous driving. Additionally, the diversity of instances within datasets and their impact on the method's performance could be better articulated.", "Questions": "How does the proposed method scale in real-time scenarios such as autonomous driving, where the views and instances may rapidly change? What measures have been taken to evaluate computational overhead in such dynamic contexts? Can the authors provide more detail on how the diversity of data instances in the evaluated datasets affects the method's effectiveness? How significant are the warm-up epochs mentioned in the study, and do they consistently enhance the model's performance across various datasets?"}}
{"paper_id": "cnKhHxN3xj", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel metric (Wasserstein distance) for quantifying neuronal entanglement. It presents a solid method (Sparse Expansion) that improves model performance under sparsity by addressing the problem of entanglement, which is crucial for optimizing large language models.", "Weaknesses": "The approach relies on prior distribution knowledge, which might not be robust for out-of-distribution data. The practical aspects such as runtime and inference speed are not thoroughly discussed. The presentation could be improved for better clarity.", "Questions": "How does the proposed metric compare to other entanglement measures in terms of robustness? Could further clarifications be provided on the method's performance on unseen data or its computational overhead?"}}
{"paper_id": "dgR6i4TSng", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper presents an innovative method for parameter-efficient fine-tuning using quantum-inspired techniques, demonstrating significant parameter reduction while maintaining performance.", "Weaknesses": "The practical applicability of quantum circuit-based parameterizations may be challenging due to current hardware limitations and complexity in implementation.", "Questions": "How does the proposed Quantum-PEFT method perform on larger, more contemporary models beyond GLUE and CIFAR10? Are there any potential scalability issues?"}}
{"paper_id": "ye1mxb79lw", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 5, "Strengths": "The authors introduce a novel bilevel Bayesian optimization algorithm that effectively addresses the inefficiencies of existing methods. The methodology provides a good balance between exploration and exploitation, with theoretical proofs of performance based on sublinear regret bounds. Its capacity to work in noisy and derivative-free environments is a significant strength.", "Weaknesses": "Although the paper introduces promising theoretical guarantees, the real-world applicability can be limited by the complexity and computational load of the Bayesian optimization framework. The paper would benefit from an extended discussion on the scalability of the approach.", "Questions": "1. How does the proposed method scale with the increase in the dimensionality of the problem for both levels? 2. Are there specific real-world scenarios where the proposed method might not perform well compared to alternative methods? 3. Can this approach be extended to multi-level optimization contexts beyond two levels?"}}
{"paper_id": "1fwZJzGdKj", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 4, "Strengths": "The paper introduces a novel multi-agent collaborative data selection approach for LLM pretraining, which effectively resolves conflicts between different data selection methods. The experimental results demonstrate significant improvements in data efficiency and training speed.", "Weaknesses": "The complexity of integrating multiple data selection strategies may pose challenges in practical implementation. The paper may benefit from a more in-depth analysis of potential limitations or constraints of the proposed approach.", "Questions": "How does the performance of the multi-agent collaborative framework scale with larger datasets and models? Can further details be provided on how the agent console adjusts the influence of independent agents?"}}
{"paper_id": "pISLZG7ktL", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The authors address an under-explored area regarding the application of data scaling laws in robotic manipulation, providing empirical evidence that emphasizes the importance of environmental and object diversity for policy generalization.", "Weaknesses": "The research is limited in scope, focusing on only a few specific tasks within a narrow range of environments, which makes it hard to generalize the findings more broadly across the field of robotics.", "Questions": "How might the findings be extended to more complex manipulation tasks or other domains in robotics?"}}
{"paper_id": "dML3XGvWmy", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper proposes an innovative framework for creating self-evolving agents without predefined routines, potentially surpassing traditional agent systems in performance and adaptability. The Gödel Agent concept is well-articulated and showcases significant improvements across diverse tasks.", "Weaknesses": "The paper may lack detail in the evaluation protocol, potentially making it difficult to assess the fairness of comparisons with baseline methods. There are concerns about whether the model uses more computational resources during evaluation, which might skew results.", "Questions": "How does the Gödel Agent ensure fairness in computational resources compared to other baseline models? What are the specific evaluation criteria used for measuring the agent's performance? Can the framework be generalized to tasks beyond those tested?"}}
{"paper_id": "xlxGsX1pc7", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper addresses a significant gap by introducing a comprehensive benchmark for university-level mathematical problems, including visual elements. It provides a robust framework for evaluating the mathematical reasoning capabilities of LLMs and highlights the current limitations of these models.", "Weaknesses": "The study primarily focuses on university-level problems, which may not represent all areas of mathematical reasoning comprehensively. Additionally, the dataset and evaluation approach could benefit from further validation and comparison with existing benchmarks to ensure its broad applicability.", "Questions": "How does the performance of LLMs on the U-MATH benchmark compare to human performance in similar tasks? Are there plans to expand the benchmark to cover other areas of mathematical reasoning beyond the current six core subjects?"}}
{"paper_id": "AjXkRZIvjB", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper introduces an innovative benchmark, GSM-Symbolic, which significantly contributes to the evaluation of LLMs by generating diverse question variants systematically. This addresses the issue of data contamination in existing benchmarks and offers insights into model robustness and reasoning capabilities.", "Weaknesses": "The paper mainly reconfirms existing knowledge about LLMs' reliance on pattern matching rather than genuine reasoning, which might not provide novel insights. The study may not fully address how to improve LLMs to overcome the observed limitations.", "Questions": "How can the findings from GSM-Symbolic be utilized to improve the design and training of future LLMs for better reasoning capabilities?"}}
{"paper_id": "IJiTI0fB0e", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 7, "Confidence": 3, "Strengths": "The paper provides a novel perspective on evaluating diversity in prompt-based generative models by decomposing diversity into prompt-induced and model-induced components. The proposed metrics, Conditional-Vendi score and Information-Vendi score, offer an informative way to measure internal diversity.", "Weaknesses": "The paper might lack clarity in explaining the computation of the proposed metrics, potentially limiting its accessibility to readers not familiar with kernel-based entropy and information-theoretic measures. Further experimental validation with a broader set of models and datasets could strengthen the claims.", "Questions": "How does the use of matrix-based information measures compare with existing methods in terms of computational efficiency? Can the proposed metrics be easily applied to real-world applications where prompt-based generation is critical?"}}
{"paper_id": "fs2Z2z3GRx", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 4, "Strengths": "The method presented, FIG, offers a theoretically justified approach that improves efficiency and effectiveness in solving challenging linear inverse problems. It demonstrates strong performance in high noise and ill-posed scenarios, showing improved results over state-of-the-art methods. It also reduces memory and runtime costs, making it practical for real-world applications.", "Weaknesses": "The presentation could be improved, particularly in explaining the motivation behind the use of measurement interpolants and how they address the limitations of existing methods. The theoretical contributions are strong, but practical implications could be better articulated. The method's underlying assumptions and limitations should be more clearly discussed.", "Questions": "How does the interpolation-based guidance compare to other guidance techniques used in similar models? Can the method be generalized to other types of inverse problems outside of image reconstruction? What are the potential risks or limitations of relying on the proposed interpolant guidance mechanism?"}}
{"paper_id": "H4FSx06FCZ", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "1. SecureGS introduces a novel approach to 3D steganography that addresses significant challenges in existing methods, such as rendering fidelity, computational cost, and security vulnerabilities.\n2. The paper demonstrates a strong experimental validation of the proposed method, showing improvements in fidelity and efficiency over existing methods, which is a key strength.\n3. The framework is innovative and seems to provide a substantial contribution to the field, making it a potential reference point for future research in secure 3D asset handling.", "Weaknesses": "1. While the paper claims improvements in security and efficiency, details on the complexity and real-world applicability of the method might be limited, making it difficult to assess practical deployment.\n2. The paper may benefit from more detailed comparisons with a broader range of baseline methods, to thoroughly assess the advantages and limitations of SecureGS under different scenarios.", "Questions": "1. How does SecureGS ensure robustness against potential attacks or tampering, especially in practical deployment scenarios?\n2. Could you provide more details on the computational overhead introduced by the hybrid decoupled Gaussian encryption mechanism and how it compares to existing methods?\n3. What are the limitations of SecureGS in real-world applications, particularly regarding the balance between rendering fidelity and computational efficiency?"}}
{"paper_id": "OGtUfA6Amo", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 8, "Confidence": 4, "Strengths": "The paper presents a novel approach called Hi-Patch for handling irregular multivariate time series with varied granularities, effectively capturing multi-scale features through a hierarchical patch graph network. It demonstrates superior performance over existing methods in tasks like forecasting and classification, across diverse datasets.", "Weaknesses": "While the method is well-motivated and shows promising results, the paper may benefit from a deeper exploration of computational complexity and trade-offs involved in the hierarchical design, as well as clarity on the architecture's adaptation to extremely large datasets.", "Questions": "How does Hi-Patch handle potential computational inefficiencies in extremely large-scale datasets, and what are the potential limitations in scalability?"}}
{"paper_id": "ujpAYpFDEA", "review": {"Soundness": 3, "Presentation": 3, "Contribution": 3, "Rating": 6, "Confidence": 3, "Strengths": "The paper addresses an important gap in the understanding of watermarking in LLMs, particularly focusing on imperceptibility, which is critical for real-world applications. The introduction of the Water-Probe algorithm and the Water-Bag strategy are novel contributions that aim to improve the detection and imperceptibility trade-offs.", "Weaknesses": "The study may not sufficiently cover a broad range of watermarking techniques, potentially limiting the generality of the Water-Probe method. There might also be concerns about the scalability and efficiency of the Water-Probe algorithm in practical scenarios with real-time constraints.", "Questions": "How does the Water-Probe algorithm perform with more complex or less predictable watermarking schemes? Are there specific LLM contexts or scenarios where the Water-Probe algorithm is less effective, and how might these be addressed?"}}
{"paper_id": "7UKHNQIErp", "review": {"Soundness": 4, "Presentation": 3, "Contribution": 4, "Rating": 7, "Confidence": 3, "Strengths": "The paper provides a novel formalism that characterizes DPA loss functions using symbolic logic, offering a clear foundation for understanding and developing new DPA algorithms. The framework enables systematic exploration of new loss variants and their relationships, which could significantly enhance human-AI alignment.", "Weaknesses": "The paper might be challenging for readers not familiar with symbolic logic and probabilistic logic frameworks. It also lacks extensive empirical validation of the newly derived loss functions, which could be beneficial for demonstrating their practical utility.", "Questions": "How do the authors plan to address the computational complexity associated with the proposed symbolic logic framework when applied to large-scale models?"}}
{"paper_id": "CpgWRFqxhD", "review": {"Soundness": 4, "Presentation": 4, "Contribution": 4, "Rating": 9, "Confidence": 4, "Strengths": "The paper presents a novel approach with a memory-guided temporal module and emotion-aware audio processing, leading to significant improvements in video quality and audio synchronization. The method is backed by robust experimental results and detailed ablation studies, reinforcing the effectiveness of the proposed modules.", "Weaknesses": "While the method is innovative, it relies on the accuracy of the emotion classifier, which might introduce variability in performance. Additionally, further exploration of how different datasets and biases impact the generalizability of the model would be beneficial.", "Questions": "How does the model handle edge cases where the audio contains multiple speakers or overlapping dialogue? Also, could further insights be provided on the scalability of the model for real-time applications?"}}
